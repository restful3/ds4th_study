{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611c60e5",
   "metadata": {},
   "source": [
    "# 개요\n",
    "\n",
    "## 학습목표\n",
    "- 학습용 데이터 없이 모델을 학습할 수 있는 방법 설명\n",
    "- CIFAR-10 을 이용, 동물 사진을 분류하는 모델\n",
    "\n",
    "## 핵심 용어\n",
    "- 모델 경량화 : 가중치 개수가 많은 교사모델의 출력과, 가중치 개수가 적은 학생 모델의 출력이 비슷해 지도록 학습 하는 것\n",
    "- 지식증류 알고리즘 : 가중치가 많은 교사 모델을 이용, 가중치가 적은 학생 모델을 학습 시키는 것\n",
    "- 모델 경량화와 GAN을 이용하면 데이터 없이 학생 모델 학습 가능\n",
    "- 데이터 없이 학습시엔, 생성자 보다 학생 모델을 더 많이 학습\n",
    "- L1 손실 : 두 값의 절대값 차이를 의미, L2 손실은 MSE 처럼 두 값의 차이를 제곱합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fbc8b2",
   "metadata": {},
   "source": [
    "# 이해하기\n",
    "\n",
    "## 모델 경량화\n",
    "\n",
    "- 고성능의 딥러닝 모델일 수록 뉴런, 층 수 등이 늘어 남\n",
    "- 모바일 환경이나 임베딩 기기 환경에서는 이런 모델들을 사용하기 어려움\n",
    "- 큰 모델을 가볍게 만드는 경량화 기업이 필요\n",
    "- 지식증류\n",
    "    - 모델 경량화 기법의 일종\n",
    "    - 더 많은 가중치의 모델(교사 모델)을 이용, 적은 가중치를 갖는 모델(학생 모델) 학습 하는 기법\n",
    "\n",
    "<img src='./figs/15_01.png' width=800>\n",
    "\n",
    "- 1. 교사 모델과 학생 모델은 같은 입력을 갖음\n",
    "- 2. 두 모델은 서로 다른 예측값을 출력\n",
    "    - 교사 모델과 학생 모델의 예측값의 차이를 '소프트 라벨' 이라고 함\n",
    "    - '소프트 라벨'로 학습을 한 학생 모델은 교사 모델의 예측값을 흉내 냄\n",
    "    - 그러나 교사 모델이 항상 맞다고는 할 수 없어, 정답으로 다시 학습을 해야 함\n",
    "- 3. 정답과 학생 모델의 예측값의 차이를 '하드 라벨'이라고 함\n",
    "    - 하드 라벨은, 학생 모델의 학습이 올바른 방향으로 가도록 함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf7c49",
   "metadata": {},
   "source": [
    "## GAN을 이용한 경량화\n",
    "\n",
    "<img src='./figs/15_02.png' width=800>\n",
    "\n",
    "- 데이터 셋을 전혀 모르는 상황에서 학습되기 때문에 하드 라벨 이용 불가\n",
    "- 학생 모델은 교사 모델의 동작을 흉내내도록 학습 (소프트 라벨만 사용)\n",
    "- 학생 모델 학습 시, 생성자의 가중치는 불변\n",
    "- 생성자는 교사 모델과 학생 모델의 차이가 벌어질 수 있도록 학습\n",
    "    - 학생 모델에게 더 어려운 학습용 데이터를 만들어 낼 수 있도록 해야 하기 때문\n",
    "    - 교사 모델과 학생 모델의 차이를 구분하는 감별자로, 생성자 학습\n",
    "\n",
    "\n",
    "<img src='./figs/15_03.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4badf605",
   "metadata": {},
   "source": [
    "# 교사 모델 학습하기\n",
    "- 교사 모델은 resnet34과 CIFAR-10 데이터셋 사용 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6c57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.models.resnet import resnet34, resnet18\n",
    "\n",
    "from torch.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c5ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할 때 이용하는 전처리 정의\n",
    "transforms = Compose([\n",
    "    RandomCrop((32, 32), padding=4), \n",
    "    RandomHorizontalFlip(p=0.5), # y축 대칭\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.4914, 0.822, 0.4465),\n",
    "             std=(0.247, 0.243, 0.261))    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071e3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root='/home/restful3/datasets/torch/',\n",
    "                       train=True, download=True, transform=transforms)\n",
    "test_data = CIFAR10(root='/home/restful3/datasets/torch/',\n",
    "                       train=False, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a77c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 검증용 데이터 준비\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51531a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39bd049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/restful3/anaconda3/envs/trading/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/restful3/anaconda3/envs/trading/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교사 모델 정의, Pretrained 를 사용하지 않는 경우\n",
    "teacher = resnet34(pretrained=False, num_classes=10)\n",
    "# # 모델을 사용할 디바이스로 이동\n",
    "teacher.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "447028b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained 를 사용하는 경우\n",
    "# teacher = resnet34(pretrained=False)\n",
    "# # 새로운 클래스 개수\n",
    "# num_classes = 10\n",
    "\n",
    "# # 모델의 fc 레이어를 새로운 클래스 개수에 맞게 변경\n",
    "# teacher.fc = nn.Linear(in_features=teacher.fc.in_features, out_features=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# # 모델의 fc 레이어 파라미터만 학습 가능하도록 설정\n",
    "# for name, param in teacher.named_parameters():\n",
    "#     if name.startswith('fc'):\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396541b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "optim = Adam(teacher.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a30c3c",
   "metadata": {},
   "source": [
    "- 교사 모델 학습 루프 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef2b6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1, loss : 0.27944424748420715 : 100%|█| 1563/1563 [00:39<00:00, 39.75it/\n",
      "epoch : 2, loss : 0.5613102912902832 : 100%|█| 1563/1563 [00:37<00:00, 41.37it/s\n",
      "epoch : 3, loss : 0.3663482964038849 : 100%|█| 1563/1563 [00:35<00:00, 43.42it/s\n",
      "epoch : 4, loss : 0.2970852255821228 : 100%|█| 1563/1563 [00:35<00:00, 43.67it/s\n",
      "epoch : 5, loss : 0.4349748194217682 : 100%|█| 1563/1563 [00:36<00:00, 42.50it/s\n",
      "epoch : 6, loss : 0.44562119245529175 : 100%|█| 1563/1563 [00:38<00:00, 41.12it/\n",
      "epoch : 7, loss : 0.30879324674606323 : 100%|█| 1563/1563 [00:39<00:00, 39.73it/\n",
      "epoch : 8, loss : 0.404263436794281 : 100%|█| 1563/1563 [00:38<00:00, 40.55it/s]\n",
      "epoch : 9, loss : 0.7797971367835999 : 100%|█| 1563/1563 [00:38<00:00, 40.29it/s\n",
      "epoch : 10, loss : 0.6153092384338379 : 100%|█| 1563/1563 [00:38<00:00, 40.45it/\n",
      "epoch : 11, loss : 0.6239849328994751 : 100%|█| 1563/1563 [00:38<00:00, 40.40it/\n",
      "epoch : 12, loss : 0.6754651069641113 : 100%|█| 1563/1563 [00:38<00:00, 40.58it/\n",
      "epoch : 13, loss : 0.48947620391845703 : 100%|█| 1563/1563 [00:38<00:00, 40.42it\n",
      "epoch : 14, loss : 0.6182830929756165 : 100%|█| 1563/1563 [00:36<00:00, 42.59it/\n",
      "epoch : 15, loss : 0.27615079283714294 : 100%|█| 1563/1563 [00:34<00:00, 44.71it\n",
      "epoch : 16, loss : 0.26638057827949524 : 100%|█| 1563/1563 [00:36<00:00, 43.38it\n",
      "epoch : 17, loss : 0.8487932682037354 : 100%|█| 1563/1563 [00:34<00:00, 45.21it/\n",
      "epoch : 18, loss : 0.13616403937339783 : 100%|█| 1563/1563 [00:35<00:00, 43.43it\n",
      "epoch : 19, loss : 0.6900112628936768 : 100%|█| 1563/1563 [00:40<00:00, 38.91it/\n",
      "epoch : 20, loss : 0.493673712015152 : 100%|█| 1563/1563 [00:36<00:00, 42.42it/s\n",
      "epoch : 21, loss : 0.12746649980545044 : 100%|█| 1563/1563 [00:36<00:00, 42.43it\n",
      "epoch : 22, loss : 0.7866880893707275 : 100%|█| 1563/1563 [00:36<00:00, 42.69it/\n",
      "epoch : 23, loss : 0.4641101658344269 : 100%|█| 1563/1563 [00:36<00:00, 42.70it/\n",
      "epoch : 24, loss : 0.46643325686454773 : 100%|█| 1563/1563 [00:36<00:00, 42.52it\n",
      "epoch : 25, loss : 0.2389969676733017 : 100%|█| 1563/1563 [00:36<00:00, 42.30it/\n",
      "epoch : 26, loss : 0.4339175820350647 : 100%|█| 1563/1563 [00:36<00:00, 42.74it/\n",
      "epoch : 27, loss : 0.28601256012916565 : 100%|█| 1563/1563 [00:36<00:00, 42.55it\n",
      "epoch : 28, loss : 0.38776859641075134 : 100%|█| 1563/1563 [00:36<00:00, 42.35it\n",
      "epoch : 29, loss : 0.6498134136199951 : 100%|█| 1563/1563 [00:36<00:00, 42.57it/\n",
      "epoch : 30, loss : 0.22930721938610077 : 100%|█| 1563/1563 [00:36<00:00, 42.54it\n",
      "epoch : 31, loss : 0.7425096035003662 : 100%|█| 1563/1563 [00:36<00:00, 42.42it/\n",
      "epoch : 32, loss : 0.2174515724182129 : 100%|█| 1563/1563 [00:36<00:00, 42.58it/\n",
      "epoch : 33, loss : 0.2050306648015976 : 100%|█| 1563/1563 [00:36<00:00, 43.02it/\n",
      "epoch : 34, loss : 0.4491247832775116 : 100%|█| 1563/1563 [00:36<00:00, 43.22it/\n",
      "epoch : 35, loss : 0.4777059853076935 : 100%|█| 1563/1563 [00:36<00:00, 43.32it/\n",
      "epoch : 36, loss : 0.7350980043411255 : 100%|█| 1563/1563 [00:36<00:00, 43.06it/\n",
      "epoch : 37, loss : 0.4625052511692047 : 100%|█| 1563/1563 [00:36<00:00, 43.06it/\n",
      "epoch : 38, loss : 0.25801411271095276 : 100%|█| 1563/1563 [00:36<00:00, 42.96it\n",
      "epoch : 39, loss : 0.6006782054901123 : 100%|█| 1563/1563 [00:36<00:00, 43.04it/\n",
      "epoch : 40, loss : 0.7531371116638184 : 100%|█| 1563/1563 [00:36<00:00, 43.12it/\n",
      "epoch : 41, loss : 0.38285309076309204 : 100%|█| 1563/1563 [00:36<00:00, 43.03it\n",
      "epoch : 42, loss : 0.21162229776382446 : 100%|█| 1563/1563 [00:36<00:00, 42.51it\n",
      "epoch : 43, loss : 0.19313816726207733 : 100%|█| 1563/1563 [00:36<00:00, 42.27it\n",
      "epoch : 44, loss : 0.48630112409591675 : 100%|█| 1563/1563 [00:39<00:00, 39.24it\n",
      "epoch : 45, loss : 0.3133706748485565 : 100%|█| 1563/1563 [00:37<00:00, 41.17it/\n",
      "epoch : 46, loss : 0.3008827567100525 : 100%|█| 1563/1563 [00:38<00:00, 41.00it/\n",
      "epoch : 47, loss : 0.28513145446777344 : 100%|█| 1563/1563 [00:37<00:00, 41.29it\n",
      "epoch : 48, loss : 0.33146369457244873 : 100%|█| 1563/1563 [00:37<00:00, 41.14it\n",
      "epoch : 49, loss : 0.6280587315559387 : 100%|█| 1563/1563 [00:37<00:00, 41.87it/\n",
      "epoch : 50, loss : 0.2322317510843277 : 100%|█| 1563/1563 [00:37<00:00, 41.79it/\n",
      "epoch : 51, loss : 0.1982455849647522 : 100%|█| 1563/1563 [00:37<00:00, 41.74it/\n",
      "epoch : 52, loss : 0.2771387994289398 : 100%|█| 1563/1563 [00:35<00:00, 44.01it/\n",
      "epoch : 53, loss : 0.5096775889396667 : 100%|█| 1563/1563 [00:36<00:00, 42.64it/\n",
      "epoch : 54, loss : 0.10436966270208359 : 100%|█| 1563/1563 [00:37<00:00, 41.59it\n",
      "epoch : 55, loss : 0.30102667212486267 : 100%|█| 1563/1563 [00:37<00:00, 41.53it\n",
      "epoch : 56, loss : 0.6739006042480469 : 100%|█| 1563/1563 [00:37<00:00, 41.58it/\n",
      "epoch : 57, loss : 0.6466876268386841 : 100%|█| 1563/1563 [00:37<00:00, 41.77it/\n",
      "epoch : 58, loss : 0.5837335586547852 : 100%|█| 1563/1563 [00:39<00:00, 40.04it/\n",
      "epoch : 59, loss : 0.4601587951183319 : 100%|█| 1563/1563 [00:37<00:00, 41.50it/\n",
      "epoch : 60, loss : 0.15696626901626587 : 100%|█| 1563/1563 [00:37<00:00, 41.45it\n",
      "epoch : 61, loss : 0.13921035826206207 : 100%|█| 1563/1563 [00:37<00:00, 41.37it\n",
      "epoch : 62, loss : 0.11029207706451416 : 100%|█| 1563/1563 [00:37<00:00, 41.55it\n",
      "epoch : 63, loss : 0.1088171973824501 : 100%|█| 1563/1563 [00:37<00:00, 41.62it/\n",
      "epoch : 64, loss : 0.6412026882171631 : 100%|█| 1563/1563 [00:37<00:00, 41.69it/\n",
      "epoch : 65, loss : 0.22308874130249023 : 100%|█| 1563/1563 [00:37<00:00, 41.54it\n",
      "epoch : 66, loss : 0.2709677219390869 : 100%|█| 1563/1563 [00:37<00:00, 41.88it/\n",
      "epoch : 67, loss : 0.2782820761203766 : 100%|█| 1563/1563 [00:36<00:00, 42.95it/\n",
      "epoch : 68, loss : 0.72017502784729 : 100%|█| 1563/1563 [00:37<00:00, 41.98it/s]\n",
      "epoch : 69, loss : 0.25167274475097656 : 100%|█| 1563/1563 [00:37<00:00, 41.50it\n",
      "epoch : 70, loss : 0.48236238956451416 : 100%|█| 1563/1563 [00:35<00:00, 43.66it\n",
      "epoch : 71, loss : 0.2048986703157425 : 100%|█| 1563/1563 [00:37<00:00, 41.63it/\n",
      "epoch : 72, loss : 0.06049284711480141 : 100%|█| 1563/1563 [00:37<00:00, 41.72it\n",
      "epoch : 73, loss : 0.9308990240097046 : 100%|█| 1563/1563 [00:36<00:00, 42.94it/\n",
      "epoch : 74, loss : 0.47541648149490356 : 100%|█| 1563/1563 [00:37<00:00, 41.88it\n",
      "epoch : 75, loss : 0.1349027007818222 : 100%|█| 1563/1563 [00:40<00:00, 39.07it/\n",
      "epoch : 76, loss : 0.6478814482688904 : 100%|█| 1563/1563 [00:37<00:00, 41.76it/\n",
      "epoch : 77, loss : 0.47988465428352356 : 100%|█| 1563/1563 [00:38<00:00, 40.58it\n",
      "epoch : 78, loss : 0.3369944989681244 : 100%|█| 1563/1563 [00:37<00:00, 41.23it/\n",
      "epoch : 79, loss : 0.43495503067970276 : 100%|█| 1563/1563 [00:37<00:00, 41.66it\n",
      "epoch : 80, loss : 0.16352616250514984 : 100%|█| 1563/1563 [00:37<00:00, 41.63it\n",
      "epoch : 81, loss : 0.5351366400718689 : 100%|█| 1563/1563 [00:38<00:00, 40.37it/\n",
      "epoch : 82, loss : 0.5211400389671326 : 100%|█| 1563/1563 [00:36<00:00, 42.29it/\n",
      "epoch : 83, loss : 0.3292841911315918 : 100%|█| 1563/1563 [00:36<00:00, 42.27it/\n",
      "epoch : 84, loss : 0.0664435550570488 : 100%|█| 1563/1563 [00:36<00:00, 42.26it/\n",
      "epoch : 85, loss : 0.1584639549255371 : 100%|█| 1563/1563 [00:36<00:00, 42.41it/\n",
      "epoch : 86, loss : 0.31248939037323 : 100%|█| 1563/1563 [00:37<00:00, 41.94it/s]\n",
      "epoch : 87, loss : 0.16418156027793884 : 100%|█| 1563/1563 [00:38<00:00, 40.87it\n",
      "epoch : 88, loss : 0.07034502923488617 : 100%|█| 1563/1563 [00:36<00:00, 42.29it\n",
      "epoch : 89, loss : 0.3621322810649872 : 100%|█| 1563/1563 [00:37<00:00, 42.19it/\n",
      "epoch : 90, loss : 0.2541795074939728 : 100%|█| 1563/1563 [00:37<00:00, 41.88it/\n",
      "epoch : 91, loss : 0.19509470462799072 : 100%|█| 1563/1563 [00:37<00:00, 41.82it\n",
      "epoch : 92, loss : 0.051744427531957626 : 100%|█| 1563/1563 [00:37<00:00, 42.01i\n",
      "epoch : 93, loss : 0.1222677156329155 : 100%|█| 1563/1563 [00:37<00:00, 41.20it/\n",
      "epoch : 94, loss : 0.24772651493549347 : 100%|█| 1563/1563 [00:37<00:00, 41.73it\n",
      "epoch : 95, loss : 0.2585417926311493 : 100%|█| 1563/1563 [00:37<00:00, 41.48it/\n",
      "epoch : 96, loss : 0.10413292795419693 : 100%|█| 1563/1563 [00:37<00:00, 41.57it\n",
      "epoch : 97, loss : 0.04194359481334686 : 100%|█| 1563/1563 [00:37<00:00, 41.57it\n",
      "epoch : 98, loss : 0.0859389677643776 : 100%|█| 1563/1563 [00:37<00:00, 41.45it/\n",
      "epoch : 99, loss : 0.3491843342781067 : 100%|█| 1563/1563 [00:38<00:00, 41.08it/\n",
      "epoch : 100, loss : 0.427603542804718 : 100%|█| 1563/1563 [00:37<00:00, 41.46it/\n",
      "epoch : 101, loss : 0.35555511713027954 : 100%|█| 1563/1563 [00:37<00:00, 41.67i\n",
      "epoch : 102, loss : 0.8415662050247192 : 100%|█| 1563/1563 [00:37<00:00, 41.57it\n",
      "epoch : 103, loss : 0.4732454717159271 : 100%|█| 1563/1563 [00:37<00:00, 41.81it\n",
      "epoch : 104, loss : 0.12012161314487457 : 100%|█| 1563/1563 [00:37<00:00, 41.83i\n",
      "epoch : 105, loss : 0.18853850662708282 : 100%|█| 1563/1563 [00:37<00:00, 41.58i\n",
      "epoch : 106, loss : 0.05979517102241516 : 100%|█| 1563/1563 [00:37<00:00, 41.66i\n",
      "epoch : 107, loss : 0.42848116159439087 : 100%|█| 1563/1563 [00:37<00:00, 41.72i\n",
      "epoch : 108, loss : 0.8774283528327942 : 100%|█| 1563/1563 [00:37<00:00, 41.50it\n",
      "epoch : 109, loss : 0.25166189670562744 : 100%|█| 1563/1563 [00:37<00:00, 41.85i\n",
      "epoch : 110, loss : 0.10768010467290878 : 100%|█| 1563/1563 [00:37<00:00, 41.91i\n",
      "epoch : 111, loss : 0.021905571222305298 : 100%|█| 1563/1563 [00:37<00:00, 41.97\n",
      "epoch : 112, loss : 0.5881716012954712 : 100%|█| 1563/1563 [00:37<00:00, 42.01it\n",
      "epoch : 113, loss : 0.07588446885347366 : 100%|█| 1563/1563 [00:37<00:00, 41.81i\n",
      "epoch : 114, loss : 0.02344360575079918 : 100%|█| 1563/1563 [00:37<00:00, 41.75i\n",
      "epoch : 115, loss : 0.30345627665519714 : 100%|█| 1563/1563 [00:37<00:00, 41.83i\n",
      "epoch : 116, loss : 0.4754294753074646 : 100%|█| 1563/1563 [00:37<00:00, 41.87it\n",
      "epoch : 117, loss : 0.12418623268604279 : 100%|█| 1563/1563 [00:37<00:00, 41.77i\n",
      "epoch : 118, loss : 0.16300110518932343 : 100%|█| 1563/1563 [00:37<00:00, 41.79i\n",
      "epoch : 119, loss : 0.6082555651664734 : 100%|█| 1563/1563 [00:37<00:00, 41.76it\n",
      "epoch : 120, loss : 0.43487951159477234 : 100%|█| 1563/1563 [00:37<00:00, 41.66i\n",
      "epoch : 121, loss : 0.053119923919439316 : 100%|█| 1563/1563 [00:37<00:00, 41.70\n",
      "epoch : 122, loss : 0.4698158800601959 : 100%|█| 1563/1563 [00:37<00:00, 41.51it\n",
      "epoch : 123, loss : 0.6133982539176941 : 100%|█| 1563/1563 [00:37<00:00, 41.45it\n",
      "epoch : 124, loss : 0.06118544191122055 : 100%|█| 1563/1563 [00:37<00:00, 41.38i\n",
      "epoch : 125, loss : 0.1571313440799713 : 100%|█| 1563/1563 [00:37<00:00, 41.47it\n",
      "epoch : 126, loss : 0.05984814092516899 : 100%|█| 1563/1563 [00:37<00:00, 41.59i\n",
      "epoch : 127, loss : 0.21645471453666687 : 100%|█| 1563/1563 [00:37<00:00, 41.72i\n",
      "epoch : 128, loss : 0.16496291756629944 : 100%|█| 1563/1563 [00:37<00:00, 41.36i\n",
      "epoch : 129, loss : 0.5444129705429077 : 100%|█| 1563/1563 [00:37<00:00, 41.39it\n",
      "epoch : 130, loss : 0.1692824810743332 : 100%|█| 1563/1563 [00:37<00:00, 41.48it\n",
      "epoch : 131, loss : 0.6021749973297119 : 100%|█| 1563/1563 [00:37<00:00, 41.44it\n",
      "epoch : 132, loss : 0.010016200132668018 : 100%|█| 1563/1563 [00:37<00:00, 41.51\n",
      "epoch : 133, loss : 0.3483699560165405 : 100%|█| 1563/1563 [00:37<00:00, 41.67it\n",
      "epoch : 134, loss : 0.06441055983304977 : 100%|█| 1563/1563 [00:37<00:00, 41.81i\n",
      "epoch : 135, loss : 0.11562515050172806 : 100%|█| 1563/1563 [00:37<00:00, 41.61i\n",
      "epoch : 136, loss : 0.07632295787334442 : 100%|█| 1563/1563 [00:37<00:00, 41.39i\n",
      "epoch : 137, loss : 0.18052858114242554 : 100%|█| 1563/1563 [00:36<00:00, 43.10i\n",
      "epoch : 138, loss : 0.527114748954773 : 100%|█| 1563/1563 [00:36<00:00, 42.42it/\n",
      "epoch : 139, loss : 0.0403301902115345 : 100%|█| 1563/1563 [00:35<00:00, 44.31it\n",
      "epoch : 140, loss : 0.09742583334445953 : 100%|█| 1563/1563 [00:36<00:00, 42.62i\n",
      "epoch : 141, loss : 0.2689593732357025 : 100%|█| 1563/1563 [00:37<00:00, 42.00it\n",
      "epoch : 142, loss : 0.3456810414791107 : 100%|█| 1563/1563 [00:36<00:00, 42.95it\n",
      "epoch : 143, loss : 0.1367081105709076 : 100%|█| 1563/1563 [00:37<00:00, 41.84it\n",
      "epoch : 144, loss : 0.2495190054178238 : 100%|█| 1563/1563 [00:37<00:00, 41.94it\n",
      "epoch : 145, loss : 0.3856944441795349 : 100%|█| 1563/1563 [00:36<00:00, 42.63it\n",
      "epoch : 146, loss : 0.19903184473514557 : 100%|█| 1563/1563 [00:36<00:00, 42.74i\n",
      "epoch : 147, loss : 0.10894103348255157 : 100%|█| 1563/1563 [00:36<00:00, 42.79i\n",
      "epoch : 148, loss : 0.23915714025497437 : 100%|█| 1563/1563 [00:37<00:00, 41.71i\n",
      "epoch : 149, loss : 0.22330929338932037 : 100%|█| 1563/1563 [00:37<00:00, 42.15i\n",
      "epoch : 150, loss : 0.11374876648187637 : 100%|█| 1563/1563 [00:37<00:00, 41.22i\n",
      "epoch : 151, loss : 0.2132297158241272 : 100%|█| 1563/1563 [00:38<00:00, 41.13it\n",
      "epoch : 152, loss : 0.018872663378715515 : 100%|█| 1563/1563 [00:37<00:00, 41.19\n",
      "epoch : 153, loss : 0.2452150583267212 : 100%|█| 1563/1563 [00:39<00:00, 39.48it\n",
      "epoch : 154, loss : 0.10283316671848297 : 100%|█| 1563/1563 [00:34<00:00, 45.07i\n",
      "epoch : 155, loss : 0.09659000486135483 : 100%|█| 1563/1563 [00:36<00:00, 42.82i\n",
      "epoch : 156, loss : 0.1580270528793335 : 100%|█| 1563/1563 [00:39<00:00, 39.45it\n",
      "epoch : 157, loss : 0.6657043695449829 : 100%|█| 1563/1563 [00:37<00:00, 41.18it\n",
      "epoch : 158, loss : 0.34960615634918213 : 100%|█| 1563/1563 [00:37<00:00, 41.62i\n",
      "epoch : 159, loss : 0.24250131845474243 : 100%|█| 1563/1563 [00:36<00:00, 42.81i\n",
      "epoch : 160, loss : 0.4291533827781677 : 100%|█| 1563/1563 [00:37<00:00, 41.60it\n",
      "epoch : 161, loss : 0.034157976508140564 : 100%|█| 1563/1563 [00:37<00:00, 41.76\n",
      "epoch : 162, loss : 0.36108705401420593 : 100%|█| 1563/1563 [00:37<00:00, 41.61i\n",
      "epoch : 163, loss : 0.1366259753704071 : 100%|█| 1563/1563 [00:37<00:00, 42.20it\n",
      "epoch : 164, loss : 0.11759345233440399 : 100%|█| 1563/1563 [00:37<00:00, 41.31i\n",
      "epoch : 165, loss : 0.013372550718486309 : 100%|█| 1563/1563 [00:37<00:00, 41.49\n",
      "epoch : 166, loss : 0.03289872407913208 : 100%|█| 1563/1563 [00:38<00:00, 40.10i\n",
      "epoch : 167, loss : 0.029510993510484695 : 100%|█| 1563/1563 [00:37<00:00, 41.66\n",
      "epoch : 168, loss : 0.39265188574790955 : 100%|█| 1563/1563 [00:35<00:00, 43.64i\n",
      "epoch : 169, loss : 0.20382952690124512 : 100%|█| 1563/1563 [00:36<00:00, 42.65i\n",
      "epoch : 170, loss : 0.19017763435840607 : 100%|█| 1563/1563 [00:35<00:00, 43.44i\n",
      "epoch : 171, loss : 0.04990239813923836 : 100%|█| 1563/1563 [00:36<00:00, 42.49i\n",
      "epoch : 172, loss : 0.1086452528834343 : 100%|█| 1563/1563 [00:37<00:00, 41.41it\n",
      "epoch : 173, loss : 0.19062866270542145 : 100%|█| 1563/1563 [00:38<00:00, 40.89i\n",
      "epoch : 174, loss : 0.1267101764678955 : 100%|█| 1563/1563 [00:38<00:00, 40.28it\n",
      "epoch : 175, loss : 0.025228900834918022 : 100%|█| 1563/1563 [00:38<00:00, 40.36\n",
      "epoch : 176, loss : 0.2098207175731659 : 100%|█| 1563/1563 [00:37<00:00, 41.67it\n",
      "epoch : 177, loss : 0.4988129734992981 : 100%|█| 1563/1563 [00:37<00:00, 41.80it\n",
      "epoch : 178, loss : 0.2804902195930481 : 100%|█| 1563/1563 [00:36<00:00, 42.67it\n",
      "epoch : 179, loss : 0.9373685121536255 : 100%|█| 1563/1563 [00:36<00:00, 42.52it\n",
      "epoch : 180, loss : 0.2320275604724884 : 100%|█| 1563/1563 [00:36<00:00, 42.41it\n",
      "epoch : 181, loss : 0.08749789744615555 : 100%|█| 1563/1563 [00:36<00:00, 42.37i\n",
      "epoch : 182, loss : 0.06365341693162918 : 100%|█| 1563/1563 [00:36<00:00, 42.33i\n",
      "epoch : 183, loss : 0.07131228595972061 : 100%|█| 1563/1563 [00:36<00:00, 42.42i\n",
      "epoch : 184, loss : 0.35757938027381897 : 100%|█| 1563/1563 [00:36<00:00, 42.29i\n",
      "epoch : 185, loss : 0.2774953246116638 : 100%|█| 1563/1563 [00:36<00:00, 42.31it\n",
      "epoch : 186, loss : 0.10397497564554214 : 100%|█| 1563/1563 [00:36<00:00, 42.29i\n",
      "epoch : 187, loss : 0.30030861496925354 : 100%|█| 1563/1563 [00:36<00:00, 42.34i\n",
      "epoch : 188, loss : 0.025463055819272995 : 100%|█| 1563/1563 [00:36<00:00, 42.25\n",
      "epoch : 189, loss : 0.18879270553588867 : 100%|█| 1563/1563 [00:37<00:00, 42.23i\n",
      "epoch : 190, loss : 0.1271999031305313 : 100%|█| 1563/1563 [00:36<00:00, 42.66it\n",
      "epoch : 191, loss : 0.32935604453086853 : 100%|█| 1563/1563 [00:36<00:00, 42.90i\n",
      "epoch : 192, loss : 0.04434593766927719 : 100%|█| 1563/1563 [00:36<00:00, 42.53i\n",
      "epoch : 193, loss : 0.26105454564094543 : 100%|█| 1563/1563 [00:38<00:00, 40.50i\n",
      "epoch : 194, loss : 0.6188746690750122 : 100%|█| 1563/1563 [00:37<00:00, 41.14it\n",
      "epoch : 195, loss : 0.051899030804634094 : 100%|█| 1563/1563 [00:37<00:00, 41.23\n",
      "epoch : 196, loss : 0.08159073442220688 : 100%|█| 1563/1563 [00:38<00:00, 40.82i\n",
      "epoch : 197, loss : 0.6490466594696045 : 100%|█| 1563/1563 [00:38<00:00, 40.42it\n",
      "epoch : 198, loss : 0.10154984146356583 : 100%|█| 1563/1563 [00:38<00:00, 40.83i\n",
      "epoch : 199, loss : 0.11246926337480545 : 100%|█| 1563/1563 [00:36<00:00, 43.00i\n",
      "epoch : 200, loss : 0.6346358060836792 : 100%|█| 1563/1563 [00:36<00:00, 42.50it\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for epoch in range(200):\n",
    "    iterator = tqdm(train_loader)\n",
    "    for data, label in iterator:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        preds = teacher(data)\n",
    "        loss = nn.CrossEntropyLoss()(preds, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        \n",
    "        iterator.set_description(f'epoch : {epoch+1}, loss : {loss.item()} ')\n",
    "\n",
    "# 교사 모델 가중치 저장        \n",
    "torch.save(teacher.state_dict(), './models/teacher.pth')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c3b18",
   "metadata": {},
   "source": [
    "- 교사 모델 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6682e2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 313/313 [00:04<00:00, 75.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 0.7371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 교사 모델의 가중치 불러오기\n",
    "teacher.load_state_dict(torch.load('./models/teacher.pth', map_location=device))\n",
    "\n",
    "num_corr = 0\n",
    "\n",
    "# 교사 모델 성능 검증\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(test_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        output = teacher(data)\n",
    "        preds = output.data.max(1)[1]\n",
    "        corr = preds.eq(label).sum().item()\n",
    "        num_corr += corr\n",
    "        \n",
    "    print(f'Acc : {num_corr/len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9563803",
   "metadata": {},
   "source": [
    "# GAN 생성자 정의하기\n",
    "- GAN 생성자\n",
    "    - 학생 모델을 학습할 때 사용할 이미지를 만듦\n",
    "    - 중요한 점 : \n",
    "        - 학생 모델과 생성자의 학습 속도에 차이가 나면 안된다.\n",
    "        - ResNet의 학습 속도가 GAN의 생성자에 비해 너무 빨라 학습이 되지 않는다.\n",
    "        - 생성자는 학생 모델 학습에 필요한 이미지를 제대로 만들어 낼 수 없다.\n",
    "        - 학생 모델의 학습 방향이 이상해 진다.\n",
    "    - 따라서 GAN이 아닌, 합성곱층을 이용한 간단한 생성자 모델을 만든다.\n",
    "\n",
    "<img src='./figs/15_04.png' width=800>\n",
    "\n",
    "- 1. MLP 층과 배치 정규화층을 거친 입력은 128 채널, 8x8 이미지가 된다.\n",
    "- 2. 합성곱과 업샘플링\n",
    "    - 업샘플링 : interpolate() 메서드 이용\n",
    "        - 가중치를 사용하지 않고 이미지의 해상도를 scale_factor 만큼 키움 \n",
    "        - 2배 만큼 키우려면 scale_factor를 2로 설정\n",
    "- 3. 합성곱층\n",
    "    - 이미지의 픽셀값을 나타내는 출력층, 활성화층이 없다.\n",
    "    - 활성함수를 통하게 되면 픽셀값의 변화가 생겨 정보 손실이 되기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80fcab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dims=256, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # 256 차원 벡터를 입력 받아 128 채널 8x8 이미지 생성\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(dims, 128*8*8)\n",
    "        )\n",
    "        \n",
    "        self.conv_blocks0 = nn.Sequential(\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        \n",
    "        self.conv_blocks1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2) # 활성화 함수\n",
    "        )\n",
    "        \n",
    "        self.conv_blocks2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.BatchNorm2d(channels, affine=False)# 배치 정규화\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        # 256 차원 벡터를 입력 받아 128 채널 8x8 이미지 생성\n",
    "        out = self.l1(z.view(z.shape[0], -1))\n",
    "        out = out.view(out.shape[0], -1, 8, 8)\n",
    "        \n",
    "        out = self.conv_blocks0(out)\n",
    "        # 이미지를 두배 늘려 줌\n",
    "        out = nn.functional.interpolate(out, scale_factor=2)\n",
    "        out = self.conv_blocks1(out)\n",
    "        out = nn.functional.interpolate(out, scale_factor=2)\n",
    "        out = self.conv_blocks2(out)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d9723d",
   "metadata": {},
   "source": [
    "# 학생 모델과 생성자 학습하기\n",
    "\n",
    "- 학습 순서\n",
    "    - 교사 모델 -> 생성자 -> 학생 모델\n",
    "\n",
    "<img src='./figs/15_05.png' width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3d3a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim.adam import Adam\n",
    "from torch.optim.sgd import SGD\n",
    "\n",
    "# 교사 모델 불러오기\n",
    "teacher = resnet34(pretrained=False, num_classes=10)\n",
    "teacher.load_state_dict(torch.load('./models/teacher.pth', map_location=device))\n",
    "teacher.to(device)\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da640e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학생 모델 정의\n",
    "student = resnet18(pretrained=False, num_classes=10)\n",
    "student.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff463994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=8192, bias=True)\n",
       "  )\n",
       "  (conv_blocks0): Sequential(\n",
       "    (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_blocks1): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (conv_blocks2): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2)\n",
       "    (3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성자 정의\n",
    "generator = Generator()\n",
    "generator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1487ae",
   "metadata": {},
   "source": [
    "- 생성자와 학생 모델의 최적화 알고리즘\n",
    "    - 생성자는 수렴 속도가 빠른 adam\n",
    "    - 학생 모델은 오버 피팅을 피하기 유리한 SGD\n",
    "        - 1. **미니 배치 학습**: SGD는 전체 데이터셋 대신 작은 미니 배치를 사용하여 모델을 업데이트합니다. 이렇게 하면 각 반복(iteration)에서 모델이 전체 데이터셋을 기억하거나 과도하게 학습하는 것을 방지할 수 있습니다. 큰 데이터셋에서는 미니 배치 학습이 일반화(generalization)에 도움을 줄 수 있습니다.\n",
    "\n",
    "        - 2. **노이즈 추가**: SGD는 확률적인 요소를 가지고 있기 때문에 학습 동안에 노이즈를 추가할 수 있습니다. 이러한 노이즈는 모델이 데이터에 과도하게 적합(fit)되는 것을 방지하고, 일반화 능력을 향상시킬 수 있습니다.\n",
    "\n",
    "        - 3. **학습률 스케줄링**: SGD에서는 학습률(learning rate)을 조절할 수 있습니다. 학습률을 조절함으로써 모델이 수렴할 때 학습률을 줄이거나 증가시켜 오버피팅을 방지할 수 있습니다.\n",
    "    - 생성자가 만들어내는 이미지는 원래의 데이터셋에 없음, 수렴이 빠른 adam으로 학생 모델을 학습하면 생성자의 이미지에 과적합 할 가능성 있음\n",
    "    - SGD는 수렴 속도가 느려, 학생 모델에게 다양한 이미지를 제공하기 어려워, 생성자에는 맞지 않음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b199e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자는 Adam으로, 학생 모델은 SGD를 이용해 학습\n",
    "G_optim = Adam(generator.parameters(), lr=1e-3)\n",
    "S_optim = SGD(student.parameters(), lr=0.1, weight_decay=5e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed11f3",
   "metadata": {},
   "source": [
    "- 학생 모델 학습\n",
    "    - 최종 목표는 학생 모델\n",
    "    - 생성자 모델은 한 번 학습 할 때 마다 분류하기 더 어려운 이미지를 만들어 냄\n",
    "    - 생성자가 너무 빨리 학습되면 학생 모델은 학습이 어려움\n",
    "    - 따라서, 학생 모델이 5번 학습 할 때, 생성자는 1번 학습\n",
    "- L1손실\n",
    "    - L2은 오차가 1보다 크면 더 크게 반영(제곱) 1보다 작으면 오차가 더 줄어들게 됨\n",
    "    - 소프트맥스를 사용하여, 0~1사이로 오차가 나오게 되어, L2보다 L1을 써야 함\n",
    "- 생성자 학습\n",
    "    - 생성자는 교사 모델과 학생 모델의 오차가 커지는 방향으로 학습을 해야 함\n",
    "    - 학생 모델이 분간하기 어려운 이미지를 만들어 내야 하기 때문\n",
    "    - 따라서 오차 계산시 마이너스 곱해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f652d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:39<00:00, 10.05it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch_list = []\n",
    "g_loss_list = []\n",
    "s_loss_list = []\n",
    "for epoch in tqdm(range(1000)):\n",
    "    # 학생 모델을 5번 학습 할 때, 생성자는 1번 가중치 학습\n",
    "    for i in range(5):\n",
    "        # 이미지 생성을 위한 노이즈 생성\n",
    "        noise = torch.randn(256, 256, 1, 1, device=device)\n",
    "        S_optim.zero_grad()\n",
    "        \n",
    "        # 이미지 생성\n",
    "        fake = generator(noise).detach()\n",
    "        # 교사의 예측\n",
    "        teacher_output = teacher(fake)\n",
    "        # 학생의 예측\n",
    "        student_output = student(fake)\n",
    "        # 학생의 오차 계산, L1손실 사용\n",
    "        S_loss = nn.L1Loss()(student_output, teacher_output.detach())\n",
    "        \n",
    "#         if (epoch%10 == 0) and (i == 4):\n",
    "#             print(f'epoch : {epoch +1}, S_loss : {S_loss.item()}')\n",
    "        \n",
    "        # 오차 역전파\n",
    "        S_loss.backward()\n",
    "        S_optim.step()\n",
    "    \n",
    "    # 이미지 생성을 위한 노이즈 정의\n",
    "    noise = torch.randn(256, 256, 1, 1, device=device)\n",
    "    G_optim.zero_grad()\n",
    "    # 이미지 생성\n",
    "    fake = generator(noise)\n",
    "    \n",
    "    # 교사와 학생의 모델 출력 계산\n",
    "    teacher_output = teacher(fake)\n",
    "    student_output = student(fake)\n",
    "\n",
    "    # 생성자 오차 계산, 마이너스 곱해 줌에 주의\n",
    "    G_loss = -1*nn.L1Loss()(student_output, teacher_output.detach())\n",
    "    \n",
    "    # 오차 역전파\n",
    "    G_loss.backward()\n",
    "    G_optim.step()    \n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "#         print(f'epoch : {epoch +1}, G_loss : {G_loss.item()}, S_loss : {S_loss.item()}')\n",
    "        epoch_list.append(epoch)\n",
    "        g_loss_list.append(G_loss.item())\n",
    "        s_loss_list.append(S_loss.item())\n",
    "    \n",
    "torch.save(student.state_dict(), './models/student.pth')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03763be5",
   "metadata": {},
   "source": [
    "- 학습 과정 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e0cb861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='epoch'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'epoch': epoch_list, 'G_loss':g_loss_list, 'S_loss':s_loss_list})\n",
    "df = df.set_index('epoch')\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc10b81",
   "metadata": {},
   "source": [
    "# 모델 성능 평가하기\n",
    "- 학생 모델은 학습 시, CIFAR-10 데이터를 사용하지 않음\n",
    "- 과연 얼마나 정확하게 분류 할 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19619c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1563/1563 [00:11<00:00, 134.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 0.5233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_corr = 0\n",
    "\n",
    "student.load_state_dict(torch.load('./models/student.pth', map_location=device))\n",
    "\n",
    "# 교사 모델이 사용한 학습용 데이터에 대한 학생 모델의 정확도\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        output = student(data)\n",
    "        preds = output.data.max(1)[1]\n",
    "        corr = preds.eq(label).sum().item()\n",
    "        num_corr += corr\n",
    "        \n",
    "    print(f'Acc : {num_corr/len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008da336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 313/313 [00:02<00:00, 134.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc : 0.6294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 검증용 데이터에 대한 학생 모델의 정확도\n",
    "with torch.no_grad():\n",
    "    for data, label in tqdm(test_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        \n",
    "        output = student(data)\n",
    "        preds = output.data.max(1)[1]\n",
    "        corr = preds.eq(label).sum().item()\n",
    "        num_corr += corr\n",
    "        \n",
    "    print(f'Acc : {num_corr/len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d709f",
   "metadata": {},
   "source": [
    "# 학습 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdfa09",
   "metadata": {},
   "source": [
    "<img src='./figs/15_07.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55264ebf",
   "metadata": {},
   "source": [
    "# 연습문제\n",
    "\n",
    "<img src='./figs/15_06.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.571px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
