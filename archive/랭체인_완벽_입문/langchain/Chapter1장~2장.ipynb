{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555679b9-3c61-4293-889e-64814590668e",
   "metadata": {},
   "source": [
    "# 1장. 챗GPT와 랭체인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd8282-01e1-4e3e-96cb-9103b0bf4bf7",
   "metadata": {},
   "source": [
    "[dotenv](https://hyunhp.tistory.com/718) 설명을 참조하여 API Password를 저장할 수 있도록 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aaee27-3528-4080-93ca-b1ae43d46d4a",
   "metadata": {},
   "source": [
    "## 모델의 바닐라코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e8bd9f2-512a-4aba-b0a9-43eb499f7a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM은 \"Last Laugh Memo\"의 약자로, 웃음을 유발하는 메모나 이야기를 뜻합니다. 이런 유머 감각이 사람들에게 긍정적인 영감을 주거나 즐거운 느낌을 전해주기 때문에 갑자기 인기를 얻을 수 있습니다. 또한, 특정한 사건이나 이슈에 관련된 재미있는 해석이나 해결책을 제시하는 등의 요소가 있을 수 있습니다.재능 있는 작가나 엔터테이너가 그것에 착안하여 창의적이고 오리지널한 콘텐츠를 제공할 경우에도 갑자기 뜰 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "기본 챗팅모델을 호출하여 답변을 불러와 봅시다.\n",
    "'''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "# from openai import OpenAI\n",
    "\n",
    "# 모델별 API pw를 저장합니다 .env 파일에 저장하고 불러옵니다.\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# \n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"LLM이 갑자기 뜬 이유를 알려주세요\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd8ce56-8938-4e75-af4a-7f55641d7e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9IyQMbHWPqGoDK3wcv6gIXrdEHjMh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='아이폰8은 2017년 9월 22일에 발매되었습니다.', role='assistant', function_call=None, tool_calls=None))], created=1714309202, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=27, prompt_tokens=23, total_tokens=50))\n"
     ]
    }
   ],
   "source": [
    "# completion의 형태를 확인해봅시다\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9322102-e52f-4c36-bb22-67f037aa594b",
   "metadata": {},
   "source": [
    "- 좋은 결과를 위해서는 더  맥락을 고려한 프롬프트 입력이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f101232-d386-408c-96d4-7393163b58d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM(Language Model)이 요즘 핫한 이유는 그 성능과 활용 가능성 때문입니다. LLM은 자연어 처리와 인공지능 분야에서 중요한 역할을 합니다. 이 모델은 대량의 텍스트 데이터를 학습하여 인간과 유사한 자연어 생성 능력을 가지게 되었습니다.\n",
      "\n",
      "LLM의 핵심 기술은 전이학습(Transfer Learning)입니다. 전이학습은 이미 학습된 모델을 새로운 작업에 적용하여 추가적인 학습 없이 성능을 빠르게 향상시킬 수 있는 기술입니다. LLM은 거대한 모델 구조와 대용량 데이터셋을 이용해 사전 학습하여 일반 언어 이해와 생성 작업에 사용될 수 있습니다.\n",
      "\n",
      "잘 알려진 LLM 중 하나는 OpenAI에서 개발한 GPT-3 모델입니다. 이 모델은 1750억 개의 파라미터로 구성되어 있으며, 탁월한 언어 생성 능력을 보여주었습니다. GPT-3는 대화 형식의 질문/응답, 자동 작문, 기계 번역 등 다양한 작업에 활용됩니다.\n",
      "\n",
      "LLM의 영향력은 매우 광범위합니다. 우선, 인간과의 상호작용 분야에서 진보가 있었습니다. LLM은 사용자의 질문에 대답을 생성하거나, 특정 도메인에서 콘텐츠를 작성하는 등 다양한 상호작용을 가능케 합니다. 이를 통해 가상의 개인 비서, 자동 응답 시스템 등이 발전될 수 있습니다.\n",
      "\n",
      "또한, LLM은 글 쓰기, 문서 요약, 번역, 내용 생성 등 컨텐츠 관련 작업에서도 많은 영향을 미칩니다. 이러한 작업들은 기존에 인간이 수행했던 작업이었으나, LLM을 통해 자동화 및 개선이 가능해졌습니다. 이는 생산성 향상과 새로운 비즈니스 모델의 도입을 가능케 합니다.\n",
      "\n",
      "앞으로 LLM은 더욱 발전할 것으로 예상됩니다. 먼저, 모델의 크기와 학습 데이터셋의 양은 더욱 증가할 것입니다. 이로 인해 LLM은 더욱 정확하고 다양한 작업을 수행할 수 있게 될 것입니다.\n",
      "\n",
      "또한, 연구와 개발을 통해 LLM의 상호작용 능력과 이해력을 향상시키는 방향으로 진행될 것입니다. 현재는 여전히 LLM이 생성한 내용에 사람이 미리 정의된 기준으로 가이드를 제공해야 하는 경우가 많습니다. 하지만 향후 개선을 통해 LLM은 더욱 독립적이고 사람처럼 상세한 지시 없이 작업을 수행할 수 있는 모델이 될 것입니다.\n",
      "\n",
      "마지막으로, LLM의 활용은 새로운 윤리적, 법적, 사회적 문제들을 도출해냅니다. LLM이 인간과 거의 구별되지 않는 언어 생성 능력을 갖추게 되면, 의도적인 오용이나 유해한 콘텐츠 생성의 가능성도 높아집니다. 이러한 문제들에 대한 대응과 규제는 앞으로 더욱 중요해질 것입니다.\n",
      "\n",
      "요약하면, LLM은 성능과 활용 가능성으로 인해 요즘 핫한 주제입니다. 상호작용, 컨텐츠 생성, 생산성 향상 등 다양한 영역에서 영향력을 미치고 있으며, 더욱 발전하여 더 큰 규모의 작업을 수행할 수 있는 모델로 발전할 것으로 예상됩니다. 단, 윤리적, 법적 문제에 대한 관심과 대응은 계속해서 강화되어야 합니다.\n"
     ]
    }
   ],
   "source": [
    "# 더 긴문장을 호출할 때 모델을 바꿈\n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ChatGPT 같은 LLM이 요즘에 핫한데, 대두가 된 배경과 어떤 영향을 미치고 있으며, 앞으로는 어떻게 바뀔지 상세히 알려줘 \",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed8724-1ad4-43f0-8400-761f04f79bd8",
   "metadata": {},
   "source": [
    "- openai에서 antroprophic으로 바꿀 경우 코드호출이 불가능\n",
    "- 그래서 language model(langchain등)을 쓰는이유임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd5954-b92a-4374-992e-900cb707f7c0",
   "metadata": {},
   "source": [
    "# 2장. Model I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756212d-2ab2-4e42-a681-2d1a68e5ee3a",
   "metadata": {},
   "source": [
    "## 랭귀지모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6fc7c25-3444-4329-9c7f-208488f7d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI  #← 모듈 가져오기\n",
    "from langchain.schema import HumanMessage  #← 사용자의 메시지인 HumanMessage 가져오기\n",
    "\n",
    "## 모델객체 만들기\n",
    "chat = ChatOpenAI(  #← 클라이언트를 만들고 chat에 저장\n",
    "    model=\"gpt-3.5-turbo\",  #← 호출할 모델 지정\n",
    ")\n",
    "\n",
    "## 위에서 만든 객체 실행하기\n",
    "result = chat( #← 실행하기\n",
    "    [\n",
    "        HumanMessage(content=\"안녕하세요!\"),\n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20061e-01c1-4f5e-a005-3bdf02629dca",
   "metadata": {},
   "source": [
    "### AIMessage를 사용하여 언어모델의 응답을 표현할 수 있음\n",
    "- 대화형식의 상로작용을 표현 위해 AI Message도 준비됨. \n",
    "    - 첫번째 HumanMessage에 레시피를 반환,\n",
    "    - 아래와 같은 대화흐름에서 어떻게 표현하는지 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40f10afc-8a01-4251-9d91-7f8aa8e5ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Berikut adalah terjemahan saya tentang budaya Kpop dalam bahasa Indonesia:\n",
      "\n",
      "Kpop atau Korean pop adalah genre musik populer Korea Selatan. Kpop dicirikan oleh grup vokal pria atau wanita yang tampil dengan tari dan koreografi yang sangat kaya. Beberapa grup Kpop terkenal adalah BTS, Blackpink, TWICE, EXO, dan banyak lagi. Kpop juga terkenal karena gaya berpakaian dan riasan yang mencolok dan modis dari para penyanyi.\n",
      "\n",
      "Budaya Kpop telah menjadi sangat populer di seluruh dunia terutama di Asia. Banyak penggemar Kpop yang disebut \"Kpopers\". Mereka sangat mendukung grup dan penyanyi favorit mereka. Budaya Kpop juga mencakup banyak acara seperti fan meeting, konser, festival musik Korea, dan banyak lagi yang mempertemukan Kpopers dari\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "result = chat( #← 실행하기\n",
    "    [\n",
    "        HumanMessage(content=\"Kpop문화에 대해 알려줘\"),\n",
    "        AIMessage(content=\"{ChatModel의 답변}\"),\n",
    "        HumanMessage(content=\"인도네시아어로 번역해줘\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c465e6-e9eb-4139-bba6-832e69c34f4c",
   "metadata": {},
   "source": [
    "> HumanMessage, AIMessage를 통해 상호작용을 표현할 수 있다.\n",
    "위의 랭귀지 모델만으로는 매번 소스코드를 다시 작성해야 하므로 번거로움\n",
    "- 상호작용을 지원하기 위해 Memory모듈이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae5981-315e-4219-8e08-1a419f5eee11",
   "metadata": {},
   "source": [
    "### SystemMessage를 통해 메타 지시 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8cc92f6-f4f7-404f-8480-4aa2941c1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! 응, 밥은 먹었어. 너는?\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "result = chat( #← 실행하기\n",
    "    [\n",
    "        SystemMessage(content=\"친한친구처럼, 존댓말 쓰지말고 솔직하게 답변\"),\n",
    "        HumanMessage(content=\"안녕? 밥은 먹었니\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03907583-0565-4a16-8063-0c7bb1392554",
   "metadata": {},
   "source": [
    "### 언어모델 바꿔보자 앤트로픽으로!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830094b3-4501-4b6c-91bf-e30644e4570c",
   "metadata": {},
   "source": [
    "[엔트로픽API](https://console.anthropic.com/settings/keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cd52c76-5cc2-4141-9480-cbfee6e6e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 네, 밥은 잘 먹었어요. 저는 인공지능 채팅봇이라 밥을 먹진 않지만 답변해드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "anthropic_api_key = os.getenv(\"Anthropic_API_KEY\")\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-2\",\n",
    "    anthropic_api_key=anthropic_api_key\n",
    ")\n",
    "\n",
    "result = chat([\n",
    "    SystemMessage(content=\"친한친구처럼, 존댓말 쓰지말고 솔직하게 답변\"),\n",
    "    HumanMessage(content=\"안녕? 밥은 먹었니\"),\n",
    "])\n",
    "\n",
    "print(result.content) # claude2는 좀 멍청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a285843d-db5c-46d1-99a5-ebc91b94be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentBlock(text='아직 밥은 안 먹었어. 배고프긴 한데 너무 귀찮아서 말이야. 너는 밥 먹었어?', type='text')]\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=anthropic_api_key\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"친한친구처럼, 존댓말 쓰지말고 솔직하게 답변\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"안녕? 밥은 먹었니\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content) # claude3-sonnet 똑똑한데 랭체인에서 아직 사용 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95ec9b-d70a-43c6-a820-23a78ec9e157",
   "metadata": {},
   "source": [
    "## PromptTemplate을 쓰면 쉽게 변수를 바꿔서 프롬프트를 만들수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0d26783-0ac4-4e1e-9851-6ea5d72ef213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈지노는 어느 학교 출신？\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate  #← PromptTemplate 가져오기\n",
    "\n",
    "prompt = PromptTemplate(  #← PromptTemplate 초기화하기\n",
    "    template=\"{influencer}는 어느 학교 출신？\", \n",
    "    input_variables=[\n",
    "        \"product\"  #← influencer 입력할 변수 지정\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt.format(influencer=\"빈지노\")) # influencer= 로 매개변수 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd224576-c31b-4289-85bd-0ac8151e0aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김구라는 어느 학교 출신？\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(influencer=\"김구라\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f150573-d0e3-4996-ab15-bcbccb1e3901",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'product'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\prompts\\prompt.py:132\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:190\u001b[0m, in \u001b[0;36mFormatter.format\u001b[1;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\utils\\formatting.py:18\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:194\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[0;32m    193\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m--> 194\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:234\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[1;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[0;32m    230\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:299\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[1;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[0;32m    297\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[1;32m--> 299\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:256\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[1;34m(self, key, args, kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'product'"
     ]
    }
   ],
   "source": [
    "print(prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa0371-1360-4c50-bdae-46c05ad95d9d",
   "metadata": {},
   "source": [
    "> 키를 넣지 않으면 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0d219ec-64c6-40a3-a3b3-486b508602e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미안해요, 확인해보니 아이유는 동대문디자인고등학교를 졸업한 것으로 알려져요.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(  #← 클라이언트 생성 및 chat에 저장\n",
    "    model=\"gpt-3.5-turbo\",  #← 호출할 모델 지정\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(  #← PromptTemplate을 작성\n",
    "    template=\"{influencer}는 어느 학교 출신이야\",  #← {product}라는 변수를 포함하는 프롬프트 작성하기\n",
    "    input_variables=[\n",
    "        \"influencer\"  #← product에 입력할 변수 지정\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = chat( #← 실행\n",
    "    [\n",
    "        SystemMessage(content=\"친한친구처럼, 존댓말 쓰지말고 솔직하게 답변\"),\n",
    "        HumanMessage(content=prompt.format(influencer=\"가수 아이유\")),\n",
    "        AIMessage(content=\"{ChatModel의 답변}\"),\n",
    "        SystemMessage(content=\"친한친구처럼, 존댓말 쓰지말고 솔직하게 답변\"),\n",
    "        HumanMessage(content=\"맞는지 다시 확인하고 답변해줘\"),\n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f7e2bc4-56fc-42cd-a360-8a7b8d8e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_json = prompt.save('prompt.json') # 프롬프트템플릿을 json으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df1d9dea-de3e-4d83-a0c2-8bcba2c109e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박명수는 어느 학교 출신이야\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "prompt = load_prompt('prompt.json')\n",
    "print(prompt.format(influencer='박명수'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f501b2-b80b-4afd-9eb8-2a7cdf3ff480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tw311",
   "language": "python",
   "name": "tw311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
