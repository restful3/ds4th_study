{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa3jiAqTVFx8"
      },
      "source": [
        "**19장 – 대규모 텐서플로 모델 훈련과 배포**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0mmskPJVFx_"
      },
      "source": [
        "_이 노트북에는 19장의 모든 샘플 코드와 연습 문제에 대한 해답이 포함되어 있습니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh9j-moeVFx_"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/rickiepark/handson-ml3/blob/main/19_training_and_deploying_at_scale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFXIv9qNpKzt",
        "tags": []
      },
      "source": [
        "# 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IPbJEmZpKzu"
      },
      "source": [
        "이 프로젝트에는 Python 3.7 이상이 필요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TFSU3FCOpKzu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtVEqxfpKzw"
      },
      "source": [
        "그리고 TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0Piq5se2pKzx"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODwjUF3aVFyC"
      },
      "source": [
        "코랩에서 실행하는 경우, 이 노트북의 뒷부분에서 사용하게 될 구글 AI 플랫폼 클라이언트 라이브러리를 설치해야 합니다. 버전 비호환성에 대한 경고는 무시해도 됩니다.\n",
        "\n",
        "* **경고**: 코랩에서는 설치 후 런타임을 다시 시작하고 다음 셀을 계속 진행해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DDl364CIVFyC",
        "outputId": "9b3786b1-c97d-4a40-8408-16dec577070a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.0/321.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules or \"kaggle_secrets\" in sys.modules:\n",
        "    %pip install -q -U google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTsawKlapKzy"
      },
      "source": [
        "이 장에서는 하나 이상의 GPU에서 모델을 실행하거나 훈련하는 방법에 대해 설명하므로 적어도 하나 이상의 GPU가 있는지 확인하거나 그렇지 않으면 경고를 발행합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ekxzo6pOpKzy"
      },
      "outputs": [],
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU가 감지되지 않았습니다. 신경망은 GPU가 없으면 매우 느릴 수 있습니다.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"런타임 > 런타임 유형 변경으로 이동하여 하드웨어 가속기로 GPU를 선택합니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L81AL0m7VFyD"
      },
      "source": [
        "# 텐서플로 모델 서빙하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeTybvxdVFyD"
      },
      "source": [
        "먼저 TF 서빙을 사용하여 모델을 배포한 다음 Google Vertex AI에 배포해 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZaFLkHCVFyD"
      },
      "source": [
        "## 텐서플로 서빙 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKEy9mBwVFyD"
      },
      "source": [
        "가장 먼저 해야 할 일은 모델을 빌드하고 학습한 다음 SavedModel 포맷으로 내보내는 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goSzUGwCVFyD"
      },
      "source": [
        "### SavedModel 내보내기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRFHavXnVFyD"
      },
      "source": [
        "MNIST 데이터 세트를 로드하고, 스케일을 조정하고, 분할해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G5Nnv92XVFyD",
        "outputId": "0997a3c3-35d7-450d-c4a2-9761f8bccece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 17s 6ms/step - loss: 0.6884 - accuracy: 0.8215 - val_loss: 0.3751 - val_accuracy: 0.8962\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3543 - accuracy: 0.9013 - val_loss: 0.3003 - val_accuracy: 0.9148\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3005 - accuracy: 0.9158 - val_loss: 0.2630 - val_accuracy: 0.9256\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2677 - accuracy: 0.9249 - val_loss: 0.2394 - val_accuracy: 0.9334\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2439 - accuracy: 0.9322 - val_loss: 0.2205 - val_accuracy: 0.9398\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2255 - accuracy: 0.9365 - val_loss: 0.2069 - val_accuracy: 0.9420\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2103 - accuracy: 0.9412 - val_loss: 0.1927 - val_accuracy: 0.9474\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1974 - accuracy: 0.9443 - val_loss: 0.1843 - val_accuracy: 0.9494\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1861 - accuracy: 0.9479 - val_loss: 0.1748 - val_accuracy: 0.9536\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1765 - accuracy: 0.9505 - val_loss: 0.1659 - val_accuracy: 0.9558\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "\n",
        "# 추가 코드 - MNIST 데이터 세트 로드 및 분할\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# 추가 코드 - MNIST 모델 구축 및 훈련(이미지 전처리도 처리)\n",
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "model_name = \"my_mnist_model\"\n",
        "model_version = \"0001\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIK2q8hoVFyE"
      },
      "source": [
        "파일 트리를 살펴보겠습니다(각 파일의 용도에 대해서는 10장에서 설명했습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FPiU7aVqVFyE",
        "outputId": "127720df-f443-40b5-b387-bf2697a6d017",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my_mnist_model/0001',\n",
              " 'my_mnist_model/0001/assets',\n",
              " 'my_mnist_model/0001/fingerprint.pb',\n",
              " 'my_mnist_model/0001/keras_metadata.pb',\n",
              " 'my_mnist_model/0001/saved_model.pb',\n",
              " 'my_mnist_model/0001/variables',\n",
              " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0001/variables/variables.index']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "sorted([str(path) for path in model_path.parent.glob(\"**/*\")])  # 추가 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cx61kc5VFyE"
      },
      "source": [
        "SavedModel을 검사해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CQfjlLGzVFyE",
        "outputId": "bbdb9a4b-4c8b-4746-f20c-af746da30dc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-16 08:44:21.480374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The given SavedModel contains the following tag-sets:\n",
            "'serve'\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir '{model_path}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RqGsNMdfVFyF",
        "outputId": "55095f17-e3b6-4590-d826-fb73abe10e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-16 08:44:26.556166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir '{model_path}' --tag_set serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ue8ArznoVFyF",
        "outputId": "7dc2a352-1a46-4c42-d3f2-ab4d9e8f6d7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-16 08:44:29.997828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['flatten_input'] tensor_info:\n",
            "      dtype: DT_UINT8\n",
            "      shape: (-1, 28, 28)\n",
            "      name: serving_default_flatten_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_1'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir '{model_path}' --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F--NjCq2VFyF"
      },
      "source": [
        "더 자세한 내용을 보려면 다음 명령을 실행하세요:\n",
        "\n",
        "```ipython\n",
        "!saved_model_cli show --dir '{model_path}' --all\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvMBNdCDVFyF"
      },
      "source": [
        "### 텐서플로 서빙 설치 및 시작하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcX97TewVFyF"
      },
      "source": [
        "이 노트북을 코랩에서 실행하는 경우, 텐서플로 서버를 설치해야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pKXcSIgjVFyF",
        "outputId": "52b3a991-e5cc-466c-aa33-a9348f3287d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "100  2943  100  2943    0     0   8603      0 --:--:-- --:--:-- --:--:--  8630\n",
            "OK\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://storage.googleapis.com/tensorflow-serving-apt stable InRelease [3,026 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 Packages [340 B]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [979 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server-universal amd64 Packages [349 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,236 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [832 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,129 kB]\n",
            "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 4,521 kB in 3s (1,471 kB/s)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mhttps://storage.googleapis.com/tensorflow-serving-apt/dists/stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 438 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.13.0 [438 MB]\n",
            "Fetched 438 MB in 27s (16.3 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 120831 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.13.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.13.0) ...\n",
            "Setting up tensorflow-model-server (2.13.0) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    url = \"https://storage.googleapis.com/tensorflow-serving-apt\"\n",
        "    src = \"stable tensorflow-model-server tensorflow-model-server-universal\"\n",
        "    !echo 'deb {url} {src}' > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl '{url}/tensorflow-serving.release.pub.gpg' | apt-key add -\n",
        "    !apt update -q && apt-get install -y tensorflow-model-server\n",
        "    %pip install -q -U tensorflow-serving-api==2.11.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9gGFmALVFyF"
      },
      "source": [
        "`tensorflow_model_server`가 설치된 경우(예: Colab에서 이 노트북을 실행하는 경우) 다음 2개의 셀을 실행하여 서버를 시작하세요. 사용 중인 OS가 Windows인 경우, 터미널에서 `tensorflow_model_server` 명령을 실행하고 `${MODEL_DIR}`을 `my_mnist_model` 디렉터리의 전체 경로로 바꿔야 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BT-t-vBeVFyG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MODEL_DIR\"] = str(model_path.parent.absolute())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jD-tXMjiVFyG"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "tensorflow_model_server \\\n",
        "    --port=8500 \\\n",
        "    --rest_api_port=8501 \\\n",
        "    --model_name=my_mnist_model \\\n",
        "    --model_base_path=\"${MODEL_DIR}\" >my_server.log 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueDMUZy7VFyG"
      },
      "source": [
        "개인 컴퓨터에서 이 노트북을 실행하는 경우, 도커를 사용해 TF 서빙을 설치하려면 먼저 [Docker](https://docs.docker.com/install/)가 설치되어 있는지 확인한 후 터미널에서 다음 명령을 실행하세요. `path/to/my_mnist_model`을 `my_mnist_model` 디렉토리의 적절한 절대 경로로 대체해야 하지만, 컨테이너 경로 `/models/my_mnist_model`은 수정하지 마세요.\n",
        "\n",
        "```bash\n",
        "docker pull tensorflow/serving  # 최신 TF 서빙 이미지 다운로드\n",
        "\n",
        "docker run -it --rm -v \"/path/to/my_mnist_model:/models/my_mnist_model\" \\\n",
        "    -p 8500:8500 -p 8501:8501 -e MODEL_NAME=my_mnist_model tensorflow/serving\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AK-0xoYVFyG"
      },
      "source": [
        "### REST API로 TF 서빙에 쿼리하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaftl-rVFyG"
      },
      "source": [
        "다음으로 TF 서빙에 REST 쿼리를 전송해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "q0NbOueUVFyG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "X_new = X_test[:3]  # 분류할 새로운 숫자 이미지가 3개 있다고 가정합니다.\n",
        "request_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l0hVGuAfVFyG",
        "outputId": "7f0f0d0f-3c9e-4d41-d403-86853dcc8e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"signature_name\": \"serving_default\", \"instances\": [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0..., 0, 0]]]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "request_json[:100] + \"...\" + request_json[-10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xdNZs2rVFyG"
      },
      "source": [
        "이제 텐서플로 서빙의 REST API를 사용하여 예측을 해보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j5yu0zFBVFyG"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()  # 오류 발생 시 예외 발생\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZlJmlvAIVFyK",
        "outputId": "dc6bf9e1-c474-43d2-bb27-7793b0bdeaa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEiYgEi_VFyK"
      },
      "source": [
        "### gRPC API로 TF 서빙에 쿼리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUToMOrzVFyL"
      },
      "outputs": [],
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0]  # == \"flatten_input\"\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHBmIeE7VFyL"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a-7lekeVFyL"
      },
      "source": [
        "응답을 텐서로 변환합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "WQHAgtqRVFyL"
      },
      "outputs": [],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LBQEosaVFyL",
        "outputId": "94dda864-4c1a-4418-ab34-399a561885db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoybdjXXVFyL"
      },
      "source": [
        "클라이언트에 텐서플로 라이브러리가 포함되어 있지 않은 경우, 다음과 같이 응답을 넘파이 배열로 변환할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ky9iJVvVFyL",
        "outputId": "36604828-56cd-48f5-851e-7c6486ba63b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 추가 코드 - tf.make_ndarray() 사용을 피하는 방법을 보여줍니다.\n",
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhgWRCnFVFyM"
      },
      "source": [
        "### 새 모델 버전 배포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GJVZGSMvVFyM",
        "outputId": "e61bcadd-a716-4750-d6df-854e758a3dcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 2s 931us/step - loss: 0.7039 - accuracy: 0.8056 - val_loss: 0.3418 - val_accuracy: 0.9042\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 1s 855us/step - loss: 0.3204 - accuracy: 0.9082 - val_loss: 0.2674 - val_accuracy: 0.9242\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 2s 883us/step - loss: 0.2650 - accuracy: 0.9235 - val_loss: 0.2227 - val_accuracy: 0.9368\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 1s 869us/step - loss: 0.2319 - accuracy: 0.9329 - val_loss: 0.2032 - val_accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 1s 870us/step - loss: 0.2089 - accuracy: 0.9399 - val_loss: 0.1833 - val_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 1s 871us/step - loss: 0.1908 - accuracy: 0.9446 - val_loss: 0.1740 - val_accuracy: 0.9498\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 2s 873us/step - loss: 0.1756 - accuracy: 0.9490 - val_loss: 0.1605 - val_accuracy: 0.9540\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 2s 877us/step - loss: 0.1631 - accuracy: 0.9524 - val_loss: 0.1543 - val_accuracy: 0.9558\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 2s 879us/step - loss: 0.1517 - accuracy: 0.9567 - val_loss: 0.1460 - val_accuracy: 0.9570\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 1s 872us/step - loss: 0.1429 - accuracy: 0.9584 - val_loss: 0.1358 - val_accuracy: 0.9618\n"
          ]
        }
      ],
      "source": [
        "# 추가 코드 - 새로운 MNIST 모델 버전 빌드 및 훈련\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
        "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHACx7frVFyM",
        "outputId": "7524fe33-7012-463b-8824-f0d2ff46774a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
          ]
        }
      ],
      "source": [
        "model_version = \"0002\"\n",
        "model_path = Path(model_name) / model_version\n",
        "model.save(model_path, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6XXX9L7VFyM"
      },
      "source": [
        "파일 트리를 다시 한 번 살펴봅시다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ltGecbxVFyM",
        "outputId": "064b7489-5de3-4e79-c303-cac0b5161e5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['my_mnist_model/0001',\n",
              " 'my_mnist_model/0001/assets',\n",
              " 'my_mnist_model/0001/keras_metadata.pb',\n",
              " 'my_mnist_model/0001/saved_model.pb',\n",
              " 'my_mnist_model/0001/variables',\n",
              " 'my_mnist_model/0001/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0001/variables/variables.index',\n",
              " 'my_mnist_model/0002',\n",
              " 'my_mnist_model/0002/assets',\n",
              " 'my_mnist_model/0002/keras_metadata.pb',\n",
              " 'my_mnist_model/0002/saved_model.pb',\n",
              " 'my_mnist_model/0002/variables',\n",
              " 'my_mnist_model/0002/variables/variables.data-00000-of-00001',\n",
              " 'my_mnist_model/0002/variables/variables.index']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted([str(path) for path in model_path.parent.glob(\"**/*\")])  # 추가 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S31FFXYGVFyM"
      },
      "source": [
        "**경고**: 텐서플로 서빙이 새 모델을 로드하기까지 잠시 기다려야 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFFZeS6RVFyM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
        "\n",
        "response = requests.post(server_url, data=request_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R52p4WotVFyN",
        "outputId": "7f34637f-0350-4147-ed5f-2c9f0845730d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOo5le0TVFyN",
        "outputId": "a9987c71-e18e-47b0-992f-98838929dd07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFmBWIlFVFyN"
      },
      "source": [
        "## 버텍스 AI에서 예측 서비스 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAWb6eAFVFyN"
      },
      "source": [
        "책의 가이드를 따라 구글 클라우드 플랫폼 계정을 생성하고 버텍스 AI 및 클라우드 스토리지 API를 활성화하세요. 그런 다음, 코랩에서 이 노트북을 실행하는 경우 다음 셀을 실행하여 구글 클라우드 플랫폼에서 사용한 것과 동일한 구글 계정으로 인증하고 코랩이 데이터에 액세스할 수 있도록 권한을 부여할 수 있습니다.\n",
        "\n",
        "**경고: 이 노트북을 신뢰하는 경우에만 이 작업을 수행하세요!**\n",
        "* https://github.com/rickiepark/handson-ml3 에 있는 공식 노트북이 아닌 경우 특히 주의하세요: 코랩 URL은 https://colab.research.google.com/github/rickiepark/handson-ml3 으로 시작합니다. 그렇지 않으면 이 코드가 여러분의 데이터로 원하는 모든 작업을 수행할 수 있습니다.\n",
        "\n",
        "코랩에서 이 노트북을 실행하지 않는 경우, 책의 가이드를 따라 서비스 계정을 만들고 해당 서비스 계정의 키를 생성한 다음, 이 노트북의 디렉터리에 다운로드하고 이름을 `my_service_account_key.json`으로 지정해야 합니다(또는 `GOOGLE_APPLICATION_CREDENTIALS` 환경 변수가 이 파일을 가리키도록 합니다)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G24_xI5VFyN"
      },
      "outputs": [],
      "source": [
        "project_id = \"my_project\"  ##### 이를 프로젝트 ID로 변경합니다. #####\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "else:\n",
        "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_key.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZFTG7xVVFyN"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "bucket_name = \"my_bucket\"  ##### 고유한 버킷 이름으로 변경합니다. #####\n",
        "location = \"us-central1\"\n",
        "\n",
        "storage_client = storage.Client(project=project_id)\n",
        "bucket = storage_client.create_bucket(bucket_name, location=location)\n",
        "#bucket = storage_client.bucket(bucket_name)  # 버킷을 재사용하는 경우"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lyxtLFvVFyN"
      },
      "outputs": [],
      "source": [
        "def upload_directory(bucket, dirpath):\n",
        "    dirpath = Path(dirpath)\n",
        "    for filepath in dirpath.glob(\"**/*\"):\n",
        "        if filepath.is_file():\n",
        "            blob = bucket.blob(filepath.relative_to(dirpath.parent).as_posix())\n",
        "            blob.upload_from_filename(filepath)\n",
        "\n",
        "upload_directory(bucket, \"my_mnist_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQWOKJZyVFyN"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 – upload_directory()의 훨씬 빠른 멀티 스레드 구현\n",
        "#           타깃 경로의 prefix를 받고 출력 기능도 있습니다.\n",
        "\n",
        "from concurrent import futures\n",
        "\n",
        "def upload_file(bucket, filepath, blob_path):\n",
        "    blob = bucket.blob(blob_path)\n",
        "    blob.upload_from_filename(filepath)\n",
        "\n",
        "def upload_directory(bucket, dirpath, prefix=None, max_workers=50):\n",
        "    dirpath = Path(dirpath)\n",
        "    prefix = prefix or dirpath.name\n",
        "    with futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_filepath = {\n",
        "            executor.submit(\n",
        "                upload_file,\n",
        "                bucket, filepath,\n",
        "                f\"{prefix}/{filepath.relative_to(dirpath).as_posix()}\"\n",
        "            ): filepath\n",
        "            for filepath in sorted(dirpath.glob(\"**/*\"))\n",
        "            if filepath.is_file()\n",
        "        }\n",
        "        for future in futures.as_completed(future_to_filepath):\n",
        "            filepath = future_to_filepath[future]\n",
        "            try:\n",
        "                result = future.result()\n",
        "            except Exception as ex:\n",
        "                print(f\"{filepath!s:60} 업로드 에러: {ex}\")  # f!s is str(f)\n",
        "            else:\n",
        "                print(f\"{filepath!s:60} 업로드 완료\", end=\"\\r\")\n",
        "\n",
        "    print(f\"{dirpath!s:60} 업로드 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHoge3Q3VFyO"
      },
      "source": [
        "또는 구글 클라우드 CLI를 설치한 경우(코랩에는 이미 설치되어 있음) 다음 `gsutil` 명령을 사용할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRuJkd_0VFyO"
      },
      "outputs": [],
      "source": [
        "#!gsutil -m cp -r my_mnist_model gs://{bucket_name}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VDUUbp5VFyO",
        "outputId": "c9db6903-1bf9-4599-87cc-3591f043965f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Model\n",
            "Create Model backing LRO: projects/522977795627/locations/us-central1/models/4798114811986575360/operations/53403898236370944\n",
            "Model created. Resource name: projects/522977795627/locations/us-central1/models/4798114811986575360\n",
            "To use this Model in another session:\n",
            "model = aiplatform.Model('projects/522977795627/locations/us-central1/models/4798114811986575360')\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "server_image = \"gcr.io/cloud-aiplatform/prediction/tf2-gpu.2-8:latest\"\n",
        "\n",
        "aiplatform.init(project=project_id, location=location)\n",
        "mnist_model = aiplatform.Model.upload(\n",
        "    display_name=\"mnist\",\n",
        "    artifact_uri=f\"gs://{bucket_name}/my_mnist_model/0001\",\n",
        "    serving_container_image_uri=server_image,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whzT_ehIVFyO"
      },
      "source": [
        "**경고**: 이 셀은 버텍스 AI가 컴퓨팅 노드를 프로비저닝할 때까지 기다리므로 실행하는 데 몇 분 정도 걸릴 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1IyPtz1VFyO",
        "outputId": "8c69a01d-c4ee-4a75-d299-26648801d68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Endpoint\n",
            "Create Endpoint backing LRO: projects/522977795627/locations/us-central1/endpoints/5133373499481522176/operations/4135354010494304256\n",
            "Endpoint created. Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "To use this Endpoint in another session:\n",
            "endpoint = aiplatform.Endpoint('projects/522977795627/locations/us-central1/endpoints/5133373499481522176')\n",
            "Deploying Model projects/522977795627/locations/us-central1/models/4798114811986575360 to Endpoint : projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Deploy Endpoint model backing LRO: projects/522977795627/locations/us-central1/endpoints/5133373499481522176/operations/388359120522051584\n",
            "Endpoint model deployed. Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n"
          ]
        }
      ],
      "source": [
        "endpoint = aiplatform.Endpoint.create(display_name=\"mnist-endpoint\")\n",
        "\n",
        "endpoint.deploy(\n",
        "    mnist_model,\n",
        "    min_replica_count=1,\n",
        "    max_replica_count=5,\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh-j5somVFyO"
      },
      "outputs": [],
      "source": [
        "response = endpoint.predict(instances=X_new.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYxcRJwDVFyO",
        "outputId": "1febf806-62ff-4c47-eadf-695f75f6cb6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.round(response.predictions, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LHeL9N3VFyP",
        "outputId": "3c24c16a-660f-4ee5-f491-b59ed228afde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Undeploying Endpoint model: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Undeploy Endpoint model backing LRO: projects/522977795627/locations/us-central1/endpoints/5133373499481522176/operations/3579722406467469312\n",
            "Endpoint model undeployed. Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Deleting Endpoint : projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n",
            "Delete Endpoint  backing LRO: projects/522977795627/locations/us-central1/operations/4738836360561950720\n",
            "Endpoint deleted. . Resource name: projects/522977795627/locations/us-central1/endpoints/5133373499481522176\n"
          ]
        }
      ],
      "source": [
        "endpoint.undeploy_all()  # 엔드포인트에서 모든 모델 배포 취소\n",
        "endpoint.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG1aRQH8VFyP"
      },
      "source": [
        "## 버텍스 AI에서 배치 예측 작업 실행하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7BYQamwVFyP",
        "outputId": "7e378644-5adf-4e1f-9efa-e69a655de3e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded my_mnist_batch                                              \n"
          ]
        }
      ],
      "source": [
        "batch_path = Path(\"my_mnist_batch\")\n",
        "batch_path.mkdir(exist_ok=True)\n",
        "with open(batch_path / \"my_mnist_batch.jsonl\", \"w\") as jsonl_file:\n",
        "    for image in X_test[:100].tolist():\n",
        "        jsonl_file.write(json.dumps(image))\n",
        "        jsonl_file.write(\"\\n\")\n",
        "\n",
        "upload_directory(bucket, batch_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1nJfIMmVFyP",
        "outputId": "5b1bbe76-0087-4a37-8d0a-ac2b231c8b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating BatchPredictionJob\n",
            "BatchPredictionJob created. Resource name: projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n",
            "To use this BatchPredictionJob in another session:\n",
            "bpj = aiplatform.BatchPredictionJob('projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544')\n",
            "View Batch Prediction Job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/4346926367237996544?project=522977795627\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_PENDING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "BatchPredictionJob projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544 current state:\n",
            "JobState.JOB_STATE_SUCCEEDED\n",
            "BatchPredictionJob run completed. Resource name: projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n"
          ]
        }
      ],
      "source": [
        "batch_prediction_job = mnist_model.batch_predict(\n",
        "    job_display_name=\"my_batch_prediction_job\",\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    starting_replica_count=1,\n",
        "    max_replica_count=5,\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=1,\n",
        "    gcs_source=[f\"gs://{bucket_name}/{batch_path.name}/my_mnist_batch.jsonl\"],\n",
        "    gcs_destination_prefix=f\"gs://{bucket_name}/my_mnist_predictions/\",\n",
        "    sync=True  # 완료될 때까지 기다리지 않으려면 False로 설정합니다.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WZQ_8pSVFyP",
        "outputId": "ec40e240-6268-4d31-f840-c806a915031d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "gcs_output_directory: \"gs://my_bucket/my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_prediction_job.output_info  # 추가 코드 - 출력 디렉토리를 표시합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR00V4WQVFyP",
        "outputId": "6ae8557f-e898-4719-c4e9-ff1c4872dba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z/prediction.errors_stats-00000-of-00001\n",
            "my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z/prediction.results-00000-of-00002\n",
            "my_mnist_predictions/prediction-mnist-2022_04_12T21_30_08_071Z/prediction.results-00001-of-00002\n"
          ]
        }
      ],
      "source": [
        "y_probas = []\n",
        "for blob in batch_prediction_job.iter_outputs():\n",
        "    print(blob.name)  # 추가 코드\n",
        "    if \"prediction.results\" in blob.name:\n",
        "        for line in blob.download_as_text().splitlines():\n",
        "            y_proba = json.loads(line)[\"prediction\"]\n",
        "            y_probas.append(y_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d8g7tm2VFyP"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_probas, axis=1)\n",
        "accuracy = np.sum(y_pred == y_test[:100]) / 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPdtKXXbVFyQ",
        "outputId": "198a316e-51ee-4744-82a1-c165358d60c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2zVcwXYVFyQ",
        "outputId": "a990da25-90b1-4053-a68d-aeec5f1a0712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting Model : projects/522977795627/locations/us-central1/models/4798114811986575360\n",
            "Delete Model  backing LRO: projects/522977795627/locations/us-central1/operations/598902403101622272\n",
            "Model deleted. . Resource name: projects/522977795627/locations/us-central1/models/4798114811986575360\n"
          ]
        }
      ],
      "source": [
        "mnist_model.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6LZ70CtVFyQ"
      },
      "source": [
        "GCS에서 만든 모든 디렉토리(즉, 디렉토리 이름의 접두사를 가진 모든 블롭)를 삭제해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82rmtTCOVFyQ",
        "outputId": "2c9c0b27-7edc-4bad-eef2-5fea74df6b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deleting BatchPredictionJob : projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n",
            "Delete BatchPredictionJob  backing LRO: projects/522977795627/locations/us-central1/operations/6699028098374959104\n",
            "BatchPredictionJob deleted. . Resource name: projects/522977795627/locations/us-central1/batchPredictionJobs/4346926367237996544\n"
          ]
        }
      ],
      "source": [
        "for prefix in [\"my_mnist_model/\", \"my_mnist_batch/\", \"my_mnist_predictions/\"]:\n",
        "    blobs = bucket.list_blobs(prefix=prefix)\n",
        "    for blob in blobs:\n",
        "        blob.delete()\n",
        "\n",
        "#bucket.delete()  # 버킷 자체를 삭제하려면 주석을 제거하고 실행하세요.\n",
        "batch_prediction_job.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aWy9ECgVFyQ"
      },
      "source": [
        "# 모바일 또는 임베디드 디바이스에 모델 배포하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-O3Sc0DVFyQ",
        "outputId": "faad2986-11a2-4b74-cb56-da7700ad00f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-10 09:03:52.237094: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2022-04-10 09:03:52.237108: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "2022-04-10 09:03:52.237830: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: my_mnist_model/0001\n",
            "2022-04-10 09:03:52.238869: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2022-04-10 09:03:52.238881: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: my_mnist_model/0001\n",
            "2022-04-10 09:03:52.242108: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2022-04-10 09:03:52.263868: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: my_mnist_model/0001\n",
            "2022-04-10 09:03:52.271298: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 33470 microseconds.\n",
            "2022-04-10 09:03:52.281694: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(str(model_path))\n",
        "tflite_model = converter.convert()\n",
        "with open(\"my_converted_savedmodel.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqtZBZ2bVFyR"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 케라스 모델을 변환하는 방법을 보여줍니다.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHCMe8ekVFyR"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXONZCdrVFyR",
        "outputId": "7df9e9bc-5507-45ca-a081-2593debddc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/wy/h39t6kb11pnbb0pzhksd_fqh0000gq/T/tmp6ffbc1qs/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/wy/h39t6kb11pnbb0pzhksd_fqh0000gq/T/tmp6ffbc1qs/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "2022-04-10 09:26:30.319286: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2022-04-10 09:26:30.319301: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "2022-04-10 09:26:30.319417: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/wy/h39t6kb11pnbb0pzhksd_fqh0000gq/T/tmp6ffbc1qs\n",
            "2022-04-10 09:26:30.320420: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2022-04-10 09:26:30.320431: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/wy/h39t6kb11pnbb0pzhksd_fqh0000gq/T/tmp6ffbc1qs\n",
            "2022-04-10 09:26:30.323773: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2022-04-10 09:26:30.345416: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/wy/h39t6kb11pnbb0pzhksd_fqh0000gq/T/tmp6ffbc1qs\n",
            "2022-04-10 09:26:30.354270: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 34852 microseconds.\n",
            "2022-04-10 09:26:30.392352: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor sequential/dense_1/MatMul because it has fewer than 1024 elements (1000).\n"
          ]
        }
      ],
      "source": [
        "tflite_model = converter.convert()\n",
        "with open(\"my_converted_keras_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI3RubYxVFyR"
      },
      "source": [
        "# 웹 페이지에서 모델 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuPe70DVFyR"
      },
      "source": [
        "이 섹션의 코드 예제는 웹 앱을 무료로 만들 수 있는 웹사이트인 glitch.com에서 호스팅됩니다.\n",
        "\n",
        "* https://homl.info/tfjscode: 사전 학습된 모델을 로드하고 이미지를 분류하는 간단한 TFJS 웹 앱입니다.\n",
        "* https://homl.info/tfjswpa: WPA로 설정된 동일한 웹 앱. 모바일 장치를 포함한 다양한 플랫폼에서 이 링크를 열어 보세요.\n",
        "** https://homl.info/wpacode: 이 WPA의 소스 코드입니다.\n",
        "* https://tensorflow.org/js: TFJS 라이브러리.\n",
        "** https://www.tensorflow.org/js/demos: 재미있는 데모 몇 가지를 소개합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4VfgmwVVFyR"
      },
      "source": [
        "# GPU를 사용하여 계산 속도 향상하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWEx4a31VFyR"
      },
      "source": [
        "텐서플로우가 GPU를 볼 수 있는지 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVJNYyroVFyR",
        "outputId": "e5daa069-3b41-49cd-dee2-efbbf0a42d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "physical_gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "physical_gpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h20yT_y6VFyR"
      },
      "source": [
        "텐서플로 스크립트에서 GPU \\#0과 \\#1(PCI 순서 기준)만 사용하려면 스크립트를 시작하기 전에 환경 변수 `CUDA_DEVICE_ORDER=PCI_BUS_ID`와 `CUDA_VISIBLE_DEVICES=0,1`을 설정합니다. 또는 스크립트 자체에서 텐서플로를 사용하기 전에 지정할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zNPhsERVFyS"
      },
      "source": [
        "## GPU RAM 관리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HItL_tIeVFyS"
      },
      "source": [
        "RAM 용량을 GPU당 2GB로 제한하려면:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByepjvQaVFyS"
      },
      "outputs": [],
      "source": [
        "#for gpu in physical_gpus:\n",
        "#    tf.config.set_logical_device_configuration(\n",
        "#        gpu,\n",
        "#        [tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
        "#    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKiDo2ciVFyS"
      },
      "source": [
        "점진적으로 텐서플로가 메모리를 점유하도록 하려면(프로세스가 종료될 때만 메모리를 해제합니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ2WN76YVFyS"
      },
      "outputs": [],
      "source": [
        "#for gpu in physical_gpus:\n",
        "#    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az0uZINuVFyS"
      },
      "source": [
        "이와 동일하게, 텐서플로를 사용하기 전에 `TF_FORCE_GPU_ALLOW_GROWTH` 환경 변수를 `true`로 설정할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU0QW2dEVFyS"
      },
      "source": [
        "물리적 GPU를 두 개의 논리적 GPU로 분할합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJfMvtwmVFyT"
      },
      "outputs": [],
      "source": [
        "#tf.config.set_logical_device_configuration(\n",
        "#    physical_gpus[0],\n",
        "#    [tf.config.LogicalDeviceConfiguration(memory_limit=2048),\n",
        "#     tf.config.LogicalDeviceConfiguration(memory_limit=2048)]\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZuKsErMVFyT",
        "outputId": "7049c814-01be-49f6-fb8e-94e6c010cd69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
        "logical_gpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHhdR7oKVFyT"
      },
      "source": [
        "## 디바이스에 연산 및 변수 배치하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW9RswfNVFyT"
      },
      "source": [
        "모든 변수 및 연산 배치를 기록하려면(이 작업은 텐서플로를 임포팅한 직후에 실행해야 합니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RVXD-xJVFyT"
      },
      "outputs": [],
      "source": [
        "#tf.get_logger().setLevel(\"DEBUG\")  # 디폴트 로그 수준은 INFO입니다.\n",
        "#tf.debugging.set_log_device_placement(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soMZkk53VFyT",
        "outputId": "0465ee9c-3213-41e3-f39f-0774ada29729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/job:localhost/replica:0/task:0/device:GPU:0'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = tf.Variable([1., 2., 3.])  # float32 변수는 GPU로 이동합니다.\n",
        "a.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daZNR01OVFyT",
        "outputId": "288233f9-aac0-448d-b798-1af4a8d4652b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/job:localhost/replica:0/task:0/device:CPU:0'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = tf.Variable([1, 2, 3])  # int32 변수는 CPU로 이동합니다.\n",
        "b.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVMtpGUTVFyU"
      },
      "source": [
        "`tf.device()` 컨텍스트를 사용하여 원하는 장치에 변수 및 연산을 수동으로 배치할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpJqrz-cVFyU",
        "outputId": "11f838a4-1c74-43a4-dcab-4683416d8d56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/job:localhost/replica:0/task:0/device:CPU:0'"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with tf.device(\"/cpu:0\"):\n",
        "    c = tf.Variable([1., 2., 3.])\n",
        "\n",
        "c.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kFjB8ByVFyU"
      },
      "source": [
        "존재하지 않거나 커널이 없는 장치를 지정하면 텐서플로는 자동으로 기본 장치를 사용합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne5CKMS5VFyU",
        "outputId": "996d47d1-571d-40c4-8136-519482ed0ab7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'/job:localhost/replica:0/task:0/device:GPU:0'\""
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 추가 코드\n",
        "\n",
        "with tf.device(\"/gpu:1234\"):\n",
        "    d = tf.Variable([1., 2., 3.])\n",
        "\n",
        "d.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gikk9azaVFyU"
      },
      "source": [
        "텐서플로에서 존재하지 않는 장치를 사용하려고 할 때 기본 장치로 되돌아가지 않고 예외를 발생시키려면:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxOJsmC6VFyU",
        "outputId": "185d0eb0-b705-402a-93f2-a836a4e2a2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Could not satisfy device specification '/job:localhost/replica:0/task:0/device:GPU:1000'. enable_soft_placement=0. Supported device types [CPU]. All available devices [/job:localhost/replica:0/task:0/device:CPU:0].\n"
          ]
        }
      ],
      "source": [
        "tf.config.set_soft_device_placement(False)\n",
        "\n",
        "# 추가 코드\n",
        "try:\n",
        "    with tf.device(\"/gpu:1000\"):\n",
        "        d = tf.Variable([1., 2., 3.])\n",
        "except tf.errors.InvalidArgumentError as ex:\n",
        "    print(ex)\n",
        "\n",
        "tf.config.set_soft_device_placement(True)  # 추가 코드 - 소프트 배치로 돌아가기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axTbpgvtVFyU"
      },
      "source": [
        "## 여러 디바이스에서 병렬 실행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ar1AawCVFyU"
      },
      "source": [
        "inter-op 또는 intra-op 스레드 수를 설정하려는 경우(CPU 포화를 방지하거나 완벽하게 재현 가능한 테스트 케이스를 실행하기 위해 텐서플로를 단일 스레드로 만들고자 하는 경우 유용할 수 있습니다):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u9Yrl-SVFyV"
      },
      "outputs": [],
      "source": [
        "#tf.config.threading.set_inter_op_parallelism_threads(10)\n",
        "#tf.config.threading.set_intra_op_parallelism_threads(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "uMH0X27cVFyV"
      },
      "source": [
        "# 여러 디바이스에서 모델 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbS0MW8VVFyV"
      },
      "source": [
        "## 분산 전략 API를 사용한 대규모 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlwMePdtVFyV"
      },
      "outputs": [],
      "source": [
        "# 추가 코드 - 케라스를 사용하여 MNIST용 CNN 모델을 생성합니다.\n",
        "def create_model():\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Reshape([28, 28, 1], input_shape=[28, 28],\n",
        "                                dtype=tf.uint8),\n",
        "        tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=10, activation=\"softmax\"),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBJa8Mc3VFyV"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()  # 일반적인 케라스 모델을 생성합니다.\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])  # 모델을 컴파일합니다.\n",
        "\n",
        "batch_size = 100  # 복제본 수로 나누어지는 것이 바람직합니다.\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQhapE_hVFyV",
        "outputId": "3ea45e32-9fb5-48d3-f163-debbf038eda3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.distribute.values.MirroredVariable"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(model.weights[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHjpfdYKVFyV",
        "outputId": "40334e50-512d-464d-f222-169065ce05ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "model.predict(X_new).round(2)  # 추가 코드 - 배치가 모든 복제본에 분할됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MS9hGg7HVFyW",
        "outputId": "2b2287a1-951e-4e1e-fb83-d24cf51fe10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_mirrored_model/assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensorflow.python.ops.resource_variable_ops.ResourceVariable"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 추가 코드 - 모델을 저장해도 분산 전략이 보존되지 않음을 보여줍니다.\n",
        "model.save(\"my_mirrored_model\", save_format=\"tf\")\n",
        "model = tf.keras.models.load_model(\"my_mirrored_model\")\n",
        "type(model.weights[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhQRaMguVFyW"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    model = tf.keras.models.load_model(\"my_mirrored_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRVoO84VVFyW",
        "outputId": "e7591f3a-af9a-4101-92d3-70cb703f0239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorflow.python.distribute.values.MirroredVariable\n"
          ]
        }
      ],
      "source": [
        "type(model.weights[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN3CledCVFyW"
      },
      "source": [
        "사용할 GPU 리스트를 지정하려는 경우:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cA4CHPHkVFyW",
        "outputId": "05fd42b0-f2ff-472d-a5f9-2793f365d7b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Some requested devices in `tf.distribute.Strategy` are not visible to TensorFlow: /job:localhost/replica:0/task:0/device:GPU:0,/job:localhost/replica:0/task:0/device:GPU:1\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akC4byspVFyW"
      },
      "source": [
        "기본 all-reduce 알고리즘을 변경하려는 경우:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh-lT0kdVFyW",
        "outputId": "54cf5c98-f503-402f-b407-8f824bc95875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.MirroredStrategy(\n",
        "    cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq3ZG2YsVFyX"
      },
      "source": [
        "`CentralStorageStrategy`을 사용하려는 경우:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-JeJwYMVFyX",
        "outputId": "593f93fa-d500-43e4-c9de-90cd70e9a67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:CPU:0'], variable_device = '/job:localhost/replica:0/task:0/device:CPU:0'\n"
          ]
        }
      ],
      "source": [
        "strategy = tf.distribute.experimental.CentralStorageStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C4ZCAWbVFyX"
      },
      "outputs": [],
      "source": [
        "# Google Colab에서 TPU로 훈련하기:\n",
        "#if \"google.colab\" in sys.modules and \"COLAB_TPU_ADDR\" in os.environ:\n",
        "#  tpu_address = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
        "#else:\n",
        "#  tpu_address = \"\"\n",
        "#resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address)\n",
        "#tf.config.experimental_connect_to_cluster(resolver)\n",
        "#tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRyn37DGVFyX"
      },
      "source": [
        "## 텐서플로 클러스터에서 모델 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6wg7-g7VFyX"
      },
      "source": [
        "텐서플로 클러스터는 일반적으로 서로 다른 컴퓨터에서 병렬로 실행되며 신경망 훈련이나 실행과 같은 작업을 완료하기 위해 서로 대화하는 텐서플로 프로세스의 그룹입니다. 클러스터의 각 TF 프로세스를 \"태스크\"(또는 \"TF 서버\")라고 합니다. IP 주소, 포트, 타입(역할 또는 작업이라고도 함)이 있습니다. 타입은 `\"worker\"`, `\"chief\"`, `\"ps\"`(파라미터 서버) 또는 `\"evaluator\"`가 될 수 있습니다:\n",
        "* **워커**는 일반적으로 하나 이상의 GPU가 있는 컴퓨터에서 계산을 수행합니다.\n",
        "* **치프**는 계산도 수행하지만, 텐서보드 로그 작성이나 체크포인트 저장과 같은 추가 작업도 처리합니다. 클러스터에는 하나의 치프가 있습니다. 정의되지 않은 경우 워커 #0이 치프가 됩니다.\n",
        "* **파라미터 서버**(ps)는 변수 값만 추적하며, 일반적으로 CPU 전용 머신에 있습니다.\n",
        "* **이밸류에이터**는 당연히 평가를 담당합니다. 일반적으로 클러스터에는 하나의 이밸류에이터가 있습니다.\n",
        "\n",
        "같은 유형의 태스크 집합을 흔히 \"작업(job)\"이라고 합니다. 예를 들어 \"워커\" 작업은 모든 워커 태스크의 집합입니다.\n",
        "\n",
        "텐서플로 클러스터를 시작하려면 먼저 클러스터를 정의해야 합니다. 즉, 모든 작업(IP 주소, TCP 포트 및 타입)을 지정해야 합니다. 예를 들어, 다음 클러스터 사양은 3개의 태스크(워커 2개, 파라미터 서버 1개)가 있는 클러스터를 정의합니다. 작업당 하나의 키가 있는 사전이며, 값은 태스크 주소 목록입니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5QYlq2OVFyX"
      },
      "outputs": [],
      "source": [
        "cluster_spec = {\n",
        "    \"worker\": [\n",
        "        \"machine-a.example.com:2222\",     # /job:worker/task:0\n",
        "        \"machine-b.example.com:2222\"      # /job:worker/task:1\n",
        "    ],\n",
        "    \"ps\": [\"machine-a.example.com:2221\"]  # /job:ps/task:0\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eMw3p8GVFyX"
      },
      "source": [
        "클러스터의 모든 태스크는 서버의 다른 모든 태스크와 통신할 수 있으므로 방화벽이 해당 포트에서 컴퓨터 간의 모든 통신을 승인하도록 구성해야 합니다(일반적으로 모든 컴퓨터에서 동일한 포트를 사용하는 것이 간단합니다).\n",
        "\n",
        "태스크가 시작되면 어떤 태스크인지 타입과 인덱스(태스크 인덱스는 태스크 ID라고도 함)를 알려주어야 합니다. 클러스터 사양과 현재 태스크의 타입 및 아이디를 모두 한 번에 지정하는 일반적인 방법은 프로그램을 시작하기 전에 `TF_CONFIG` 환경 변수를 설정하는 것입니다. 클러스터 사양(``cluster`` 키 아래)과 시작할 태스크의 타입 및 인덱스(``task`` 키 아래)가 포함된 JSON 인코딩된 딕셔너리여야 합니다. 예를 들어, 다음 `TF_CONFIG` 환경 변수는 위와 동일한 클러스터(워커 2개, 파라미터 서버 1개)를 정의하고, 시작할 태스크를 워커 \\#0으로 지정합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_rTAxUlVFyY"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": cluster_spec,\n",
        "    \"task\": {\"type\": \"worker\", \"index\": 0}\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6iYPbcFVFyY"
      },
      "source": [
        "일부 플랫폼(예: 구글 버텍스 AI)에서는 이 환경 변수를 자동으로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m0-G1zhVFyY"
      },
      "source": [
        "텐서플로의 `TFConfigClusterResolver` 클래스는 이 환경 변수에서 클러스터 구성을 읽습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNmFZBt-VFyY",
        "outputId": "1bc329bb-0490-4f7f-a896-e76038aeca82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClusterSpec({'ps': ['machine-a.example.com:2221'], 'worker': ['machine-a.example.com:2222', 'machine-b.example.com:2222']})"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "resolver.cluster_spec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFujWNXUVFyY",
        "outputId": "f8a415d7-cfea-435d-db1b-9deed53595f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'worker'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resolver.task_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KhEIZIRVFyY",
        "outputId": "e9e190ea-918a-493e-e3b7-2229b71cdc4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resolver.task_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UchJJ_e-VFyY"
      },
      "source": [
        "이제 로컬 컴퓨터에서 두 개의 워커 태스크를 가진 간단한 클러스터를 실행해 보겠습니다. `MultiWorkerMirroredStrategy`을 사용하여 두 태스크로 모델을 훈련하겠습니다.\n",
        "\n",
        "첫 번째 단계는 훈련 코드를 작성하는 것입니다. 이 코드를 사용해 두 워커에서 각각 고유한 프로세스로 실행하므로 별도의 파이썬 파일인 `my_mnist_multiworker_task.py`에 작성합니다. 코드는 비교적 간단하지만 주의해야 할 몇 가지 중요한 사항이 있습니다:\n",
        "* 텐서플로로 다른 작업을 수행하기 전에 `MultiWorkerMirroredStrategy`을 생성합니다.\n",
        "* 워커 중 하나만 텐서보드 로깅을 처리합니다. 앞서 언급했듯이 이 작업자를 *치프*라고 합니다. 명시적으로 정의되지 않은 경우 워커 #0이 치프가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5wca2YyVFyY",
        "outputId": "ac475391-f228-4778-9ad9-d526ba8301c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing my_mnist_multiworker_task.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_mnist_multiworker_task.py\n",
        "\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()  # 시작 부분에!\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "print(f\"Starting task {resolver.task_type} #{resolver.task_id}\")\n",
        "\n",
        "# 추가 코드 - MNIST 데이터셋 로드 및 분할\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Reshape([28, 28, 1], input_shape=[28, 28],\n",
        "                                dtype=tf.uint8),\n",
        "        tf.keras.layers.Rescaling(scale=1 / 255),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                               padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=10, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10)\n",
        "\n",
        "if resolver.task_id == 0:  # 치프는 모델을 올바른 위치에 저장합니다.\n",
        "    model.save(\"my_mnist_multiworker_model\", save_format=\"tf\")\n",
        "else:\n",
        "    tmpdir = tempfile.mkdtemp()  # 다른 워커는 임시 디렉터리에 저장합니다.\n",
        "    model.save(tmpdir, save_format=\"tf\")\n",
        "    tf.io.gfile.rmtree(tmpdir)  # 마지막에 이 디렉터리를 삭제할 수 있습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyPpRrL2VFyZ"
      },
      "source": [
        "실제 애플리케이션에서는 일반적으로 머신당 하나의 워커가 있지만, 이 예제에서는 동일한 머신에서 두 워커를 모두 실행하고 있으므로 두 워커 모두 사용 가능한 모든 GPU RAM(이 머신에 GPU가 있는 경우)을 사용하려고 시도하므로 메모리 부족(OOM) 오류가 발생할 수 있습니다. 이를 방지하기 위해 `CUDA_VISIBLE_DEVICES` 환경 변수를 사용하여 각 워커에 다른 GPU를 할당할 수 있습니다. 또는 `CUDA_VISIBLE_DEVICES`를 빈 문자열로 설정하여 간단히 GPU 지원을 비활성화할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axQRK0fhVFyZ"
      },
      "source": [
        "이제 각각 고유한 프로세스에서 두 워커를 시작할 준비가 되었습니다. 태스크 인덱스가 변경된 것을 확인할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHjSZiw1VFyZ"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "export CUDA_VISIBLE_DEVICES=''\n",
        "export TF_CONFIG='{\"cluster\": {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"]},\n",
        "                   \"task\": {\"type\": \"worker\", \"index\": 0}}'\n",
        "python my_mnist_multiworker_task.py > my_worker_0.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOd7b7jkVFyZ"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "export CUDA_VISIBLE_DEVICES=''\n",
        "export TF_CONFIG='{\"cluster\": {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"]},\n",
        "                   \"task\": {\"type\": \"worker\", \"index\": 1}}'\n",
        "python my_mnist_multiworker_task.py > my_worker_1.log 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwguA2F-VFyZ"
      },
      "source": [
        "**참고**: `AutoShardPolicy`에 대한 경고가 표시되면 무시해도 무방합니다. 자세한 내용은 [TF 이슈 #42146](https://github.com/tensorflow/tensorflow/issues/42146)을 참고하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oTt8nDlVFyZ"
      },
      "source": [
        "끝났습니다! 이제 텐서플로 클러스터가 실행 중이지만 별도의 프로세스에서 실행 중이므로 이 노트북에서는 볼 수 없습니다(하지만 진행 상황은 `my_worker_*.log`에서 확인할 수 있습니다).\n",
        "\n",
        "치프(워커 #0)가 텐서보드에 로그를 쓰기 때문에, 훈련 진행 상황을 보기 위해 텐서보드를 사용할 수 있습니다. 다음 셀을 실행한 다음, 설정 버튼(즉, 톱니바퀴 아이콘)을 클릭하고 \"Reload data\" 상자를 체크하여 텐서보드가 30초마다 자동으로 새로고침되도록 설정합니다. 첫 번째 훈련이 완료되고(몇 분 정도 소요될 수 있음) 텐서보드가 새로 고침되면 SCALARS 탭이 나타납니다. 이 탭을 클릭하면 모델의 훈련 진행 과정과 검증 정확도를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYFTn6yXVFyZ"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./my_mnist_multiworker_logs --port=6006"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsH23DuSVFya"
      },
      "outputs": [],
      "source": [
        "# strategy = tf.distribute.MultiWorkerMirroredStrategy(\n",
        "#     communication_options=tf.distribute.experimental.CommunicationOptions(\n",
        "#         implementation=tf.distribute.experimental.CollectiveCommunication.NCCL))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-XysUJVFya"
      },
      "source": [
        "## 버텍스 AI에서 대규모 훈련 작업 실행하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzjR9YISVFya"
      },
      "source": [
        "훈련 스크립트를 복사하되 `import os`를 추가하고 저장 경로를 `AIP_MODEL_DIR` 환경 변수가 가리키는 GCS 경로로 변경해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d4u1mtKVFya",
        "outputId": "d4c031c7-b1f3-4501-e3bc-bc19ea652584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing my_vertex_ai_training_task.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_vertex_ai_training_task.py\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()  # 시작 부분에!\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "\n",
        "if resolver.task_type == \"chief\":\n",
        "    model_dir = os.getenv(\"AIP_MODEL_DIR\")  # 버텍스 AI가 제공하는 경로\n",
        "    tensorboard_log_dir = os.getenv(\"AIP_TENSORBOARD_LOG_DIR\")\n",
        "    checkpoint_dir = os.getenv(\"AIP_CHECKPOINT_DIR\")\n",
        "else:\n",
        "    tmp_dir = Path(tempfile.mkdtemp())  # 다른 워커는 임시 디렉터리를 사용합니다.\n",
        "    model_dir = tmp_dir / \"model\"\n",
        "    tensorboard_log_dir = tmp_dir / \"logs\"\n",
        "    checkpoint_dir = tmp_dir / \"ckpt\"\n",
        "\n",
        "callbacks = [tf.keras.callbacks.TensorBoard(tensorboard_log_dir),\n",
        "             tf.keras.callbacks.ModelCheckpoint(checkpoint_dir)]\n",
        "\n",
        "# 추가 코드 - MNIST 데이터셋 로드 및 준비\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# 추가 코드 - 분산 전략을 사용하여 케라스 모델을 빌드하고 컴파일합니다.\n",
        "with strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Reshape([28, 28, 1], input_shape=[28, 28],\n",
        "                                dtype=tf.uint8),\n",
        "        tf.keras.layers.Lambda(lambda X: X / 255),\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                               padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                               padding=\"same\"),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=10, activation=\"softmax\"),\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10,\n",
        "          callbacks=callbacks)\n",
        "model.save(model_dir, save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYMAUq6xVFya"
      },
      "outputs": [],
      "source": [
        "custom_training_job = aiplatform.CustomTrainingJob(\n",
        "    display_name=\"my_custom_training_job\",\n",
        "    script_path=\"my_vertex_ai_training_task.py\",\n",
        "    container_uri=\"gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest\",\n",
        "    model_serving_container_image_uri=server_image,\n",
        "    requirements=[\"gcsfs==2022.3.0\"],  # 필요 없음, 이것은 단지 예일 뿐입니다.\n",
        "    staging_bucket=f\"gs://{bucket_name}/staging\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe_rzzvJVFya",
        "outputId": "14afb27c-ef23-4bb0-f0fc-2381499bdcaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training script copied to:\n",
            "gs://my_bucket/aiplatform-2022-04-14-10:08:24.124-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
            "Training Output directory:\n",
            "gs://my_bucket/aiplatform-custom-training-2022-04-14-10:08:25.226 \n",
            "View Training:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5407999068506947584?project=522977795627\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_PENDING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "View backing custom job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6685701948726837248?project=522977795627\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob run completed. Resource name: projects/522977795627/locations/us-central1/trainingPipelines/5407999068506947584\n",
            "Model available at projects/522977795627/locations/us-central1/models/9094548856498028544\n"
          ]
        }
      ],
      "source": [
        "mnist_model2 = custom_training_job.run(\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    replica_count=2,\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8I1Nxs8VFyb"
      },
      "source": [
        "정리합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvcJVmwZVFyb"
      },
      "outputs": [],
      "source": [
        "mnist_model2.delete()\n",
        "custom_training_job.delete()\n",
        "blobs = bucket.list_blobs(prefix=f\"gs://{bucket_name}/staging/\")\n",
        "for blob in blobs:\n",
        "    blob.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sniORFuVFyb"
      },
      "source": [
        "# 버텍스 AI의 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjUAxCNtVFyb",
        "outputId": "878f2c27-1cac-4bcc-ed28-927bf7f3a4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing my_vertex_ai_trial.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_vertex_ai_trial.py\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_hidden\", type=int, default=2)\n",
        "parser.add_argument(\"--n_neurons\", type=int, default=256)\n",
        "parser.add_argument(\"--learning_rate\", type=float, default=1e-2)\n",
        "parser.add_argument(\"--optimizer\", default=\"adam\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_model(args):\n",
        "    with tf.distribute.MirroredStrategy().scope():\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8))\n",
        "        for _ in range(args.n_hidden):\n",
        "            model.add(tf.keras.layers.Dense(args.n_neurons, activation=\"relu\"))\n",
        "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "        opt = tf.keras.optimizers.get(args.optimizer)\n",
        "        opt.learning_rate = args.learning_rate\n",
        "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt,\n",
        "                      metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "# 추가 코드 - 데이터셋 로드 및 분할\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "# 추가 코드 - AIP_* 환경 변수를 사용하고 콜백을 만듭니다.\n",
        "import os\n",
        "model_dir = os.getenv(\"AIP_MODEL_DIR\")\n",
        "tensorboard_log_dir = os.getenv(\"AIP_TENSORBOARD_LOG_DIR\")\n",
        "checkpoint_dir = os.getenv(\"AIP_CHECKPOINT_DIR\")\n",
        "trial_id = os.getenv(\"CLOUD_ML_TRIAL_ID\")\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(tensorboard_log_dir)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n",
        "callbacks = [tensorboard_cb, early_stopping_cb]\n",
        "\n",
        "model = build_model(args)\n",
        "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
        "                    epochs=10, callbacks=callbacks)\n",
        "model.save(model_dir, save_format=\"tf\")  # 추가 코드\n",
        "\n",
        "import hypertune\n",
        "\n",
        "hypertune = hypertune.HyperTune()\n",
        "hypertune.report_hyperparameter_tuning_metric(\n",
        "    hyperparameter_metric_tag=\"accuracy\",  # 보고할 지표의 이름\n",
        "    metric_value=max(history.history[\"val_accuracy\"]),  # 최대 정확도 값\n",
        "    global_step=model.optimizer.iterations.numpy(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_RyhTU0VFyb",
        "outputId": "ad8bd41c-55ee-45df-aeaa-94c76835e82b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training script copied to:\n",
            "gs://homl3-mybucket5/staging/aiplatform-2022-04-18-18:14:02.860-aiplatform_custom_trainer_script-0.1.tar.gz.\n"
          ]
        }
      ],
      "source": [
        "trial_job = aiplatform.CustomJob.from_local_script(\n",
        "    display_name=\"my_search_trial_job\",\n",
        "    script_path=\"my_vertex_ai_trial.py\",  # 훈련 스크립트 경로\n",
        "    container_uri=\"gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest\",\n",
        "    staging_bucket=f\"gs://{bucket_name}/staging\",\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=2,  # 이 예제에서는 각 트라이얼에 2개의 GPU가 있습니다.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwqanly9VFyb",
        "outputId": "c1374e88-0e76-4050-cf07-d0a0ee0490ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating HyperparameterTuningJob\n",
            "HyperparameterTuningJob created. Resource name: projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568\n",
            "To use this HyperparameterTuningJob in another session:\n",
            "hpt_job = aiplatform.HyperparameterTuningJob.get('projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568')\n",
            "View HyperparameterTuningJob:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5825136187899117568?project=522977795627\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_RUNNING\n",
            "HyperparameterTuningJob projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568 current state:\n",
            "JobState.JOB_STATE_SUCCEEDED\n",
            "HyperparameterTuningJob run completed. Resource name: projects/522977795627/locations/us-central1/hyperparameterTuningJobs/5825136187899117568\n"
          ]
        }
      ],
      "source": [
        "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
        "\n",
        "hp_job = aiplatform.HyperparameterTuningJob(\n",
        "    display_name=\"my_hp_search_job\",\n",
        "    custom_job=trial_job,\n",
        "    metric_spec={\"accuracy\": \"maximize\"},\n",
        "    parameter_spec={\n",
        "        \"learning_rate\": hpt.DoubleParameterSpec(min=1e-3, max=10, scale=\"log\"),\n",
        "        \"n_neurons\": hpt.IntegerParameterSpec(min=1, max=300, scale=\"linear\"),\n",
        "        \"n_hidden\": hpt.IntegerParameterSpec(min=1, max=10, scale=\"linear\"),\n",
        "        \"optimizer\": hpt.CategoricalParameterSpec([\"sgd\", \"adam\"]),\n",
        "    },\n",
        "    max_trial_count=100,\n",
        "    parallel_trial_count=20,\n",
        ")\n",
        "hp_job.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaDCcWu6VFyb"
      },
      "outputs": [],
      "source": [
        "def get_final_metric(trial, metric_id):\n",
        "    for metric in trial.final_measurement.metrics:\n",
        "        if metric.metric_id == metric_id:\n",
        "            return metric.value\n",
        "\n",
        "trials = hp_job.trials\n",
        "trial_accuracies = [get_final_metric(trial, \"accuracy\") for trial in trials]\n",
        "best_trial = trials[np.argmax(trial_accuracies)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCt9NWjpVFyc",
        "outputId": "a1219223-94c0-447a-9ea0-b5eb39e57ada"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.977400004863739"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(trial_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR0d5UnSVFyc",
        "outputId": "8239662b-cf8e-47db-be18-15a1bf632b0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'98'"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_trial.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys_lvgbLVFyc",
        "outputId": "1690d27d-85d2-4d47-bbaa-14f38366daaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[parameter_id: \"learning_rate\"\n",
              "value {\n",
              "  number_value: 0.001\n",
              "}\n",
              ", parameter_id: \"n_hidden\"\n",
              "value {\n",
              "  number_value: 8.0\n",
              "}\n",
              ", parameter_id: \"n_neurons\"\n",
              "value {\n",
              "  number_value: 216.0\n",
              "}\n",
              ", parameter_id: \"optimizer\"\n",
              "value {\n",
              "  string_value: \"adam\"\n",
              "}\n",
              "]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_trial.parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EjBOfRMVFyc"
      },
      "source": [
        "# 추가 자료 - 버텍스 AI의 분산 케라스 튜너"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdoTyP82VFyc"
      },
      "source": [
        "버텍스 AI의 하이퍼파라미터 튜닝 서비스를 사용하는 대신, 10장에서 소개한 [케라스 튜너](https://keras.io/keras_tuner/)를 사용하여 버텍스 AI VM에서 실행할 수 있습니다. 케라스 튜너는 하이퍼파라미터 탐색을 여러 머신에 분산하여 간단하게 확장할 수 있는 방법을 제공합니다: 각 머신에서 세 개의 환경 변수를 설정한 다음 일반 케라스 튜너 코드를 실행하기만 하면 됩니다. 모든 머신에서 똑같은 스크립트를 사용할 수 있습니다. 머신 중 한 대는 치프 역할을 하고 다른 머신은 워커 역할을 합니다. 각 워커는 오라클 역할을 하는 치프에게 어떤 하이퍼파라미터 값을 시도할지 요청하고, 치프는 이 하이퍼파라미터 값을 사용하여 모델을 훈련시킨 다음, 최종적으로 모델의 성능을 치프에게 보고하면 치프는 다음에 워커가 시도할 하이퍼파라미터 값을 결정할 수 있습니다.\n",
        "\n",
        "각 머신에서 설정해야 하는 세 가지 환경 변수는 다음과 같습니다:\n",
        "\n",
        "* `KERASTUNER_TUNER_ID`: 치프 머신은 `\"chief\"`이고 워커 머신은 `\"worker0\"`, `\"worker1\"` 등과 같은 고유 식별자입니다.\n",
        "* `KERASTUNER_ORACLE_IP`: 치프 머신의 IP 주소 또는 호스트 이름입니다. 치프 자체는 일반적으로 `\"0.0.0.0\"`을 사용하여 머신의 모든 IP 주소에서 수신해야 합니다.\n",
        "* `KERASTUNER_ORACLE_PORT`: 치프가 수신 대기할 TCP 포트입니다.\n",
        "\n",
        "분산 케라스 튜너는 모든 머신 집합에서 사용할 수 있습니다. 버텍스 AI 머신에서 실행하려면 일반 훈련 작업을 생성하고 훈련 스크립트를 수정하여 세 가지 환경 변수를 적절히 설정한 후 케라스 튜너를 사용하면 됩니다.\n",
        "\n",
        "예를 들어, 아래 스크립트는 이전과 마찬가지로 먼저 버텍스 AI가 자동으로 설정하는 `TF_CONFIG` 환경 변수를 파싱합니다. `\"chief\"` 타입의 태스크 주소를 찾아서 IP 주소 또는 호스트 이름과 TCP 포트를 추출합니다. 그런 다음 튜너 ID를 태스크 타입과 태스크 인덱스로 정의합니다(예: `\"worker0\"`). 튜너 ID가 `\"chief0\"`이면 `\"chief\"`로 변경하고 IP를 `\"0.0.0.0\"`으로 설정하면 해당 컴퓨터의 모든 IPv4 주소에서 수신 대기하게 됩니다. 그런 다음 케라스 튜너에 대한 환경 변수를 정의합니다. 다음으로 스크립트는 10장에서와 마찬가지로 튜너를 생성하여 탐색을 수행한 다음 마지막으로 버텍스 AI가 지정한 위치에 최적의 모델을 저장합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gOrP79ZVFyc",
        "outputId": "47b01298-7b18-4a8b-f6b5-3a938e67e780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing my_keras_tuner_search.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_keras_tuner_search.py\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "tf_config = json.loads(os.environ[\"TF_CONFIG\"])\n",
        "\n",
        "chief_ip, chief_port = tf_config[\"cluster\"][\"chief\"][0].rsplit(\":\", 1)\n",
        "tuner_id = f'{tf_config[\"task\"][\"type\"]}{tf_config[\"task\"][\"index\"]}'\n",
        "if tuner_id == \"chief0\":\n",
        "    tuner_id = \"chief\"\n",
        "    chief_ip = \"0.0.0.0\"\n",
        "    # 추가 코드 - 치프는 많은 작업을 수행하지 않으므로 동일한 컴퓨터에서 워커를 실행하여\n",
        "    # 컴퓨팅 리소스를 최적화할 수 있습니다. 이렇게 하려면\n",
        "    # TF_CONFIG 환경 변수를 조정하여 태스크 유형을 \"worker\"로 설정하고 태스크 인덱스를\n",
        "    # 고유한 값으로 설정한 후 치프가 또 다른 프로세스를 시작하도록 하면 됩니다.\n",
        "    # 다음 몇 줄의 주석 처리를 해제하고 시도해 보세요:\n",
        "    # import subprocess\n",
        "    # import sys\n",
        "    # tf_config[\"task\"][\"type\"] = \"workerX\"  # 치프 머신의 워커\n",
        "    # os.environ[\"TF_CONFIG\"] = json.dumps(tf_config)\n",
        "    # subprocess.Popen([sys.executable] + sys.argv,\n",
        "    #                  stdout=sys.stdout, stderr=sys.stderr)\n",
        "\n",
        "os.environ[\"KERASTUNER_TUNER_ID\"] = tuner_id\n",
        "os.environ[\"KERASTUNER_ORACLE_IP\"] = chief_ip\n",
        "os.environ[\"KERASTUNER_ORACLE_PORT\"] = chief_port\n",
        "\n",
        "from pathlib import Path\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "\n",
        "gcs_path = \"/gcs/my_bucket/my_hp_search\"  # 버킷 이름으로 바꾸기\n",
        "\n",
        "def build_model(hp):\n",
        "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
        "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
        "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2,\n",
        "                             sampling=\"log\")\n",
        "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8))\n",
        "    for _ in range(n_hidden):\n",
        "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "hyperband_tuner = kt.Hyperband(\n",
        "    build_model, objective=\"val_accuracy\", seed=42,\n",
        "    max_epochs=10, factor=3, hyperband_iterations=2,\n",
        "    distribution_strategy=tf.distribute.MirroredStrategy(),\n",
        "    directory=gcs_path, project_name=\"mnist\")\n",
        "\n",
        "# extra code – Load and split the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "tensorboard_log_dir = os.environ[\"AIP_TENSORBOARD_LOG_DIR\"] + \"/\" + tuner_id\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(tensorboard_log_dir)\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n",
        "hyperband_tuner.search(X_train, y_train, epochs=10,\n",
        "                       validation_data=(X_valid, y_valid),\n",
        "                       callbacks=[tensorboard_cb, early_stopping_cb])\n",
        "\n",
        "if tuner_id == \"chief\":\n",
        "    best_hp = hyperband_tuner.get_best_hyperparameters()[0]\n",
        "    best_model = hyperband_tuner.hypermodel.build(best_hp)\n",
        "    best_model.save(os.getenv(\"AIP_MODEL_DIR\"), save_format=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThpfJhRtVFyd"
      },
      "source": [
        "참고로 버텍스 AI는 오픈 소스 [GCS 퓨즈 어댑터](https://cloud.google.com/storage/docs/gcs-fuse)를 사용하여 `/gcs` 디렉터리를 GCS에 자동으로 마운트합니다. 이렇게 하면 워커와 치프 간에 공유 디렉터리가 제공되며, 이는 케라스 튜너에 필요합니다. 또한 배포 전략을 `MirroredStrategy`으로 설정했습니다. 이렇게 하면 각 워커가 자신의 머신에 있는 모든 GPU를 사용할 수 있습니다(GPU가 두 개 이상 있는 경우)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bd7yE9nVFyd"
      },
      "source": [
        "`gcs/my_bucket/`를 <code>/gcs/<i>{bucket_name}</i>/</code>로 바꿉니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNDrhUYdVFyd"
      },
      "outputs": [],
      "source": [
        "with open(\"my_keras_tuner_search.py\") as f:\n",
        "    script = f.read()\n",
        "\n",
        "with open(\"my_keras_tuner_search.py\", \"w\") as f:\n",
        "    f.write(script.replace(\"/gcs/my_bucket/\", f\"/gcs/{bucket_name}/\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqEDdR4IVFyd"
      },
      "source": [
        "이제 이전 섹션에서와 똑같이 이 스크립트를 기반으로 사용자 정의 훈련 작업을 시작하기만 하면 됩니다. `requirements` 목록에 `keras-tuner`를 추가하는 것을 잊지 마세요:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5uMNBiDVFyd"
      },
      "outputs": [],
      "source": [
        "hp_search_job = aiplatform.CustomTrainingJob(\n",
        "    display_name=\"my_hp_search_job\",\n",
        "    script_path=\"my_keras_tuner_search.py\",\n",
        "    container_uri=\"gcr.io/cloud-aiplatform/training/tf-gpu.2-4:latest\",\n",
        "    model_serving_container_image_uri=server_image,\n",
        "    requirements=[\"keras-tuner~=1.1.2\"],\n",
        "    staging_bucket=f\"gs://{bucket_name}/staging\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDe_0b6WVFyd",
        "outputId": "3062c727-0e39-4184-9405-a4a019b53664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training script copied to:\n",
            "gs://my_bucket/staging/aiplatform-2022-04-15-13:34:32.591-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
            "Training Output directory:\n",
            "gs://my_bucket/staging/aiplatform-custom-training-2022-04-15-13:34:34.453 \n",
            "View Training:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8601543785521872896?project=522977795627\n",
            "View backing custom job:\n",
            "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5022607048831926272?project=522977795627\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896 current state:\n",
            "PipelineState.PIPELINE_STATE_RUNNING\n",
            "CustomTrainingJob run completed. Resource name: projects/522977795627/locations/us-central1/trainingPipelines/8601543785521872896\n",
            "Model available at projects/522977795627/locations/us-central1/models/8176544832480168612\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mnist_model3 = hp_search_job.run(\n",
        "    machine_type=\"n1-standard-4\",\n",
        "    replica_count=3,\n",
        "    accelerator_type=\"NVIDIA_TESLA_K80\",\n",
        "    accelerator_count=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVueoD4IVFye"
      },
      "source": [
        "모델을 찾았습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opovykC9VFye"
      },
      "source": [
        "정리:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImHUNUPUVFye"
      },
      "outputs": [],
      "source": [
        "mnist_model3.delete()\n",
        "hp_search_job.delete()\n",
        "blobs = bucket.list_blobs(prefix=f\"gs://{bucket_name}/staging/\")\n",
        "for blob in blobs:\n",
        "    blob.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOnvNUY2VFye"
      },
      "source": [
        "# 추가 자료 - AutoML을 사용하여 모델 훈련하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7egsPY4VFye"
      },
      "source": [
        "먼저 MNIST 데이터셋을 PNG 이미지로 내보내고, 각 이미지 파일과 분할(훈련, 검증 또는 테스트), 레이블을 나타내는 `import.csv`를 준비해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MHPWghVFye",
        "outputId": "8900513c-d723-45d7-be50-77f2c5a5b264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70000/70000"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist_path = Path(\"datasets/mnist\")\n",
        "mnist_path.mkdir(parents=True, exist_ok=True)\n",
        "idx = 0\n",
        "with open(mnist_path / \"import.csv\", \"w\") as import_csv:\n",
        "    for split, X, y in zip((\"training\", \"validation\", \"test\"),\n",
        "                           (X_train, X_valid, X_test),\n",
        "                           (y_train, y_valid, y_test)):\n",
        "        for image, label in zip(X, y):\n",
        "            print(f\"\\r{idx + 1}/70000\", end=\"\")\n",
        "            filename = f\"{idx:05d}.png\"\n",
        "            plt.imsave(mnist_path / filename, np.tile(image, 3))\n",
        "            line = f\"{split},gs://{bucket_name}/mnist/{filename},{label}\\n\"\n",
        "            import_csv.write(line)\n",
        "            idx += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPipbXJ8VFye"
      },
      "source": [
        "이 데이터셋을 GCS에 업로드해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc3RXmfVVFye",
        "outputId": "1728b1d3-8b6d-44ee-df83-fd9705b93706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploaded datasets/mnist                                              \n"
          ]
        }
      ],
      "source": [
        "upload_directory(bucket, mnist_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5WtBg_bVFyf"
      },
      "source": [
        "이제 버텍스 AI에서 관리용 이미지 데이터셋을 만들어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_d7f2wUVFyf",
        "outputId": "9b9be52c-27f8-48d5-819a-9072b5db6ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating ImageDataset\n",
            "Create ImageDataset backing LRO: projects/522977795627/locations/us-central1/datasets/7532459492777132032/operations/3812233931370004480\n",
            "ImageDataset created. Resource name: projects/522977795627/locations/us-central1/datasets/7532459492777132032\n",
            "To use this ImageDataset in another session:\n",
            "ds = aiplatform.ImageDataset('projects/522977795627/locations/us-central1/datasets/7532459492777132032')\n",
            "Importing ImageDataset data: projects/522977795627/locations/us-central1/datasets/7532459492777132032\n",
            "Import ImageDataset data backing LRO: projects/522977795627/locations/us-central1/datasets/7532459492777132032/operations/3010593197698056192\n",
            "ImageDataset data imported. Resource name: projects/522977795627/locations/us-central1/datasets/7532459492777132032\n"
          ]
        }
      ],
      "source": [
        "from aiplatform.schema.dataset.ioformat.image import single_label_classification\n",
        "\n",
        "mnist_dataset = aiplatform.ImageDataset.create(\n",
        "    display_name=\"mnist-dataset\",\n",
        "    gcs_source=[f\"gs://{bucket_name}/mnist/import.csv\"],\n",
        "    project=project_id,\n",
        "    import_schema_uri=single_label_classification,\n",
        "    sync=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw9Uy5TPVFyf"
      },
      "source": [
        "이 데이터셋에 대해 AutoML 학습 작업을 생성합니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D5g74g1VFyf"
      },
      "source": [
        "**TODO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Ai4FvYpKVFyf"
      },
      "source": [
        "# 연습문제 해답"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAf4fPN5VFyf"
      },
      "source": [
        "## 1. to 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnLyD5xMVFyf"
      },
      "source": [
        "부록 A 참조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRo_LlvQVFyf"
      },
      "source": [
        "## 9.\n",
        "_문제: (원하는 어떤 모델이든) 모델을 훈련하고 TF 서빙이나 구글 버텍스 AI 플랫폼에 배포해보세요. REST API나 gRPC API를 사용해 쿼리하는 클라이언트 코드를 작성해보세요. 모델을 업데이트하고 새로운 버전을 배포해보세요. 클라이언트 코드가 새로운 버전으로 쿼리할 것입니다. 첫 번째 버전으로 롤백해보세요._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA16G_wCVFyf"
      },
      "source": [
        "<a href=\"#텐서플로-모델-서빙하기\">텐서플로 모델 서빙하기</a> 절에 있는 단계를 따라해 보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoGwY-UMVFyg"
      },
      "source": [
        "# 10.\n",
        "_문제: 하나의 머신에 여러 개의 GPU에서 `MirroredStrategy` 전략으로 모델을 훈련해보세요(GPU를 준비하지 못하면 코랩의 GPU 런타임을 사용하여 가상 GPU 2개를 만들 수 있습니다). `CentralStorageStrategy` 전략으로 모델을 다시 훈련하고 훈련 시간을 비교해보세요._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvoUvXYJVFyg"
      },
      "source": [
        "[여러 디바이스에서 모델 훈련하기](#여러-디바이스에서-모델-훈련하기) 절에 있는 단계를 따라해 보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLTko9_OVFyg"
      },
      "source": [
        "# 11.\n",
        "_문제: 케라스 튜너 또는 버텍스 AI의 하이퍼파라미터 튜닝 서비스를 사용하여 버텍스 AI에서 원하는 모델을 세부 튜닝해 보세요._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP347D6UVFyg"
      },
      "source": [
        "이 책의 _케라스 튜너를 사용한 하이퍼파라미터 튜닝_ 섹션에 있는 지침을 따르세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYqjiBKGVFyg"
      },
      "source": [
        "# 축하합니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH2LQUP2VFyg"
      },
      "source": [
        "책의 마지막에 도달했습니다! 도움이 되셨기를 바랍니다. 😊"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}