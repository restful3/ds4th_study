{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **챕터 8. 데이터셋 엔지니어링**  \n",
    "\n",
    "모델의 품질은 훈련 데이터의 품질에 따라 결정됩니다. 아무리 뛰어난 머신러닝(ML) 팀이 무한한 컴퓨팅 자원을 갖고 있어도, 데이터가 없으면 좋은 모델을 미세 조정할 수 없습니다. 데이터셋 엔지니어링의 목표는 주어진 예산 내에서 최적의 모델을 훈련할 수 있는 데이터셋을 만드는 것입니다.\n",
    "\n",
    "점점 더 많은 기업이 모델을 처음부터 개발하는 대신, AI 성능을 차별화하기 위해 데이터를 활용하고 있습니다. 모델이 점점 더 많은 데이터를 요구하면서, 데이터 처리 작업은 점점 더 복잡해지고 있으며, 이에 따라 인력과 인프라에 대한 투자가 증가하고 있습니다.¹\n",
    "\n",
    "데이터 작업은 사람들이 시간이 남을 때 수행하는 부수적인 작업에서, 전담된 역할로 진화했습니다. 현재 많은 AI 기업들은 데이터 라벨러, 데이터셋 제작자, 데이터 품질 엔지니어를 고용하여 엔지니어링 팀과 통합하거나 협력하는 방식으로 운영하고 있습니다.\n",
    "\n",
    "데이터 환경이 수많은 옵션으로 인해 혼란스럽다면, 데이터셋 환경은 더욱 복잡합니다. 데이터셋의 크기가 증가하고 있으며, 새로운 기법들이 끊임없이 등장하고 있습니다. 이 챕터에서는 데이터셋 환경에 대한 개요를 제공하고, 자체 데이터셋을 구축할 때 고려해야 할 사항들을 설명합니다.\n",
    "\n",
    "이 챕터는 데이터 수집부터 시작하여, \"어떤 데이터가 필요한가?\", \"얼마나 많은 데이터가 필요한가?\", \"데이터의 품질이 높다는 것은 무엇을 의미하는가?\" 등의 질문을 다룹니다. 이후 데이터 합성 및 처리 기법에 대해 논의합니다. 데이터 수집, 생성 및 처리는 선형적인 과정이 아니라, 종종 서로 왔다 갔다 하는 과정입니다.\n",
    "\n",
    "같은 모델이라도 훈련 방식에 따라 서로 다른 능력을 학습하도록 설계되므로, 훈련을 위한 데이터셋도 서로 다른 속성을 가집니다. 예를 들어, 사전 훈련(pre-training) 데이터의 경우, 데이터의 양은 보통 '토큰 수'로 측정됩니다. 반면, 지도 학습(finetuning)을 위한 데이터는 일반적으로 '예제 수'로 측정됩니다. 그러나 전반적인 데이터 구축 과정은 동일한 원리를 따릅니다. 이 챕터에서는 애플리케이션 개발자에게 더욱 중요한 '사후 훈련(post-training)' 데이터에 초점을 맞춥니다. 다만, 사전 훈련에서 얻을 수 있는 교훈도 사후 훈련에 유용할 수 있습니다.\n",
    "\n",
    "자동화할 수 있는 도구와 기법도 존재하지만, 결국 데이터 구축 과정은 대부분 힘들고, 지루하며, 많은 노력이 필요한 작업이 될 것입니다.\n",
    "\n",
    "**데이터 중심 AI 관점**\n",
    "\n",
    "AI 개발에서 데이터의 중요성이 커지면서 **데이터 중심 AI(data-centric AI)** 개념이 등장했으며, 이는 **모델 중심 AI(model-centric AI)** 와 대비됩니다.\n",
    "\n",
    "- **모델 중심 AI**: 모델 자체를 개선하여 AI 성능을 향상시키는 방법. 새로운 신경망 아키텍처를 설계하거나, 모델 크기를 확장하거나, 새로운 훈련 기법을 개발하는 방식이 포함됩니다.\n",
    "- **데이터 중심 AI**: 데이터 처리 기법을 개선하고, 고품질 데이터셋을 구축하여, 적은 자원으로 더 나은 모델을 훈련할 수 있도록 하는 접근 방식입니다.\n",
    "\n",
    "딥러닝 초창기에는 대부분의 AI 벤치마크가 모델 중심이었습니다. 예를 들어, ImageNet 데이터셋이 주어지면, 연구자들은 동일한 데이터셋을 이용해 최고의 모델을 개발하는 데 집중했습니다. 그러나 최근에는 데이터 중심 벤치마크도 증가하고 있습니다. 동일한 모델을 두고도, 데이터셋을 최적화하여 최상의 성능을 끌어내는 것이 목표입니다.\n",
    "\n",
    "2021년, Andrew Ng는 **데이터 중심 AI 대회(data-centric AI competition)** 를 개최했습니다. 참가자들은 동일한 기본 데이터셋을 사용하면서, 잘못된 라벨을 수정하거나, 추가적인 예제를 제공하거나, 데이터를 증강하는 방식으로 성능을 향상시키는 것이 목표였습니다.\n",
    "\n",
    "2023년에는 DataComp(Gadre et al., 2023)가 CLIP 모델을 훈련하기 위한 최적의 데이터셋을 구축하는 경진대회를 개최했습니다(Radford et al., 2021). 참가자들은 표준화된 스크립트를 사용하여 CLIP 모델을 훈련했으며, 평가 과정에서는 38개의 다운스트림 작업에서 모델의 성능을 분석했습니다. 2024년에도 유사한 대회가 개최되었으며, 4억 1,200만 개에서 780억 개의 파라미터를 가진 다양한 언어 모델을 위한 데이터셋을 평가하는 과정이 포함되었습니다(Li et al., 2024). \n",
    "\n",
    "이 외에도 대표적인 데이터 중심 AI 벤치마크로는 DataPerf (MLCommons, 2023) 및 **Eyuboglu & Karlás, 2022** 등이 있습니다.\n",
    "\n",
    "모델 중심과 데이터 중심 접근법은 연구 발전에 모두 중요한 역할을 합니다. 하지만, 의미 있는 기술 발전을 이루기 위해서는 모델뿐만 아니라 데이터 자체에 대한 지속적인 투자도 필요합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **데이터 정제 (Data Curation)**  \n",
    "\n",
    "모든 AI 모델의 문제가 데이터만으로 해결될 수 있는 것은 아니지만, 데이터는 종종 중요한 해결책이 됩니다. 적절한 데이터는 모델을 더욱 강력하고, 안전하며, 더 긴 문맥을 처리할 수 있도록 만들어줍니다. 반면, 품질이 낮은 데이터는 모델의 편향을 증가시키고, 환각(hallucination) 현상을 유발할 수 있습니다. 데이터 오류는 모델을 손상시키고 자원을 낭비하게 만듭니다.\n",
    "\n",
    "데이터 정제는 모델이 학습하는 방식과 이를 돕기 위해 활용할 수 있는 리소스를 이해하는 과학적 과정입니다. 데이터셋 구축자는 응용 연구자(application researchers) 및 모델 개발자들과 긴밀히 협력해야 합니다. 소규모 팀에서는 데이터 구축과 모델 훈련을 동일한 인력이 담당할 수도 있지만, 대규모 조직에서는 데이터 구축을 담당하는 전문 인력을 두는 경우가 많습니다.²\n",
    "\n",
    "어떤 데이터가 필요한지는 수행할 작업과 모델에 학습시키고자 하는 내용에 따라 달라집니다.  \n",
    "- **자기지도 학습(self-supervised finetuning)**: 연속적인 데이터(sequence data)가 필요합니다.  \n",
    "- **지시 기반 미세 조정(instruction finetuning)**: (지시문, 응답) 형식의 데이터가 필요합니다.  \n",
    "- **선호도 미세 조정(preference finetuning)**: (지시문, 승리 응답, 패배 응답) 형식의 데이터가 필요합니다.  \n",
    "- **보상 모델 학습(reward model training)**: 선호도 미세 조정과 동일한 데이터 형식을 사용하되, 각 예제에 대한 점수를 포함하는 ((지시문, 응답), 점수) 형식의 데이터가 필요합니다.  \n",
    "\n",
    "훈련 데이터는 모델이 학습하기 원하는 행동을 포함해야 합니다. 고품질 데이터 라벨링 작업은 항상 어려운 과정이며, 특히 **연쇄 추론(Chain-of-Thought, CoT) 방식의 추론**이나 **도구 활용(tool use)** 과 같은 복잡한 행동을 모델에 학습시키려 할 때 더욱 어렵습니다. 이를 이해하기 위해 몇 가지 예시를 살펴보겠습니다.\n",
    "\n",
    "**연쇄 추론 (Chain-of-Thought, CoT)**\n",
    "\n",
    "- **챕터 5**에서 설명한 바와 같이, CoT 프롬프트는 모델이 최종 답변을 생성하기 전에 문제를 단계별로 해결하도록 유도하는 기법입니다. 모델이 단계별 응답(step-by-step responses)을 생성하도록 학습하려면, 훈련 데이터에 CoT 응답이 포함되어야 합니다. **\"Scaling Instruction-Finetuned Language Models\" (Chun et al., 2024)** 논문에 따르면, 미세 조정 데이터에 단계별 응답을 포함하면 CoT 기반 작업에서 모델의 성능이 크게 향상되며, 특정 작업에서는 정확도가 거의 2배 향상됩니다.\n",
    "\n",
    "- **복잡한 단계별 응답을 생성하는 것은 지루하고 시간 소모적인 작업입니다.**  \n",
    "수학 문제의 해결 과정을 설명하는 것은 단순히 최종 답변을 제공하는 것보다 훨씬 어렵습니다. 이를 보여주기 위해, **Chun et al. (2024)** 에서 제시한 두 가지 예제를 살펴보겠습니다. 하나는 단순한 최종 답변을 포함한 것이고, 다른 하나는 CoT 방식으로 구성된 것입니다.\n",
    "\n",
    "    ```\n",
    "    예제 1: 단순 응답\n",
    "    **Instruction**: 다음 질문에 답하세요. 질소의 끓는점은 얼마인가요?  \n",
    "    **Response (without CoT)**: -320.4°F  \n",
    "\n",
    "    예제 2: CoT 기반 응답\n",
    "    **CoT Instruction**: 다음 질문에 단계별로 추론하여 답하세요.  \n",
    "    식당에는 원래 23개의 사과가 있었습니다. 점심으로 20개를 사용하고, 6개를 추가로 구매했습니다. 현재 사과는 몇 개 남아있나요?  \n",
    "    **Response (with CoT)**:  \n",
    "    1. 처음에 23개의 사과가 있었습니다.  \n",
    "    2. 점심으로 20개를 사용했습니다. 따라서 남은 사과는 23 - 20 = 3개입니다.  \n",
    "    3. 추가로 6개를 구매했습니다.  \n",
    "    4. 최종적으로 남은 사과의 개수는 3 + 6 = **9개**입니다.  \n",
    "    ```\n",
    "\n",
    "결과적으로, CoT 데이터셋은 일반적인 지시 기반(instruction-based) 데이터셋보다 **훨씬 희귀**합니다.\n",
    "\n",
    "**도구 활용 (Tool use)**\n",
    "\n",
    "- 사전 훈련 과정에서 모델이 방대한 양의 지식을 습득하기 때문에, 많은 모델이 직관적으로 특정 도구를 사용하는 방법을 알 수도 있습니다. 그러나 **모델의 도구 활용 능력(tool use ability)** 은 **도구 사용 예제(tool use examples)** 를 학습함으로써 향상될 수 있습니다. 일반적으로 도메인 전문가가 **도구 사용 데이터(tool use data)** 를 생성하는데, 각 프롬프트는 도구 사용이 필요한 작업을 나타내며, 모델의 응답은 해당 작업을 수행하기 위한 일련의 행동을 포함합니다. 예를 들어, 개인 비서를 수행하는 모델을 미세 조정하려면, 실제 전문 개인 비서에게 그들이 수행하는 작업 유형, 작업 수행 방식, 사용 도구 등을 조사할 수 있습니다. 그러나 인간 전문가에게 그들의 작업 방식을 설명하도록 요청하면, 기억 오류(faulty memory)나 중요하지 않다고 생각하는 과정이 누락될 가능성이 있습니다. 따라서, 인간이 해당 작업을 수행하는 방식을 직접 관찰하는 것이 정확성을 높이는 데 필수적입니다. \n",
    "\n",
    "- 그러나 인간에게 효율적인 것이 AI에게는 비효율적일 수 있으며, 그 반대의 경우도 마찬가지입니다. 결과적으로, 인간이 수행한 주석(annotations)이 AI 에이전트에게는 최적이 아닐 수도 있습니다. 예를 들어, 인간은 웹 인터페이스를 선호할 수 있지만, 모델은 API를 사용하는 것이 더 쉬울 수 있습니다. 어떤 정보를 검색할 때, 인간은 먼저 브라우저를 열고, 검색창에 쿼리를 복사하여 붙여넣고, 검색 결과를 클릭해 하나씩 확인하는 과정이 필요합니다. 반면에, 모델은 단순히 검색 API에 쿼리를 보내고 모든 결과를 한 번에 처리할 수 있습니다. 이러한 이유로, 많은 연구에서는 도구 사용 데이터를 생성하기 위해 시뮬레이션 및 기타 합성 기법을 활용하는 경우가 많습니다. 이에 대한 내용은 이 장에서 더 자세히 다룹니다.\n",
    "\n",
    "- 도구 사용 데이터는 특별한 형식을 필요로 할 수도 있습니다. 일반적인 대화 데이터에서는 사용자와 AI가 번갈아 가며 한 번에 하나의 메시지를 주고받습니다. 그러나 도구 사용의 경우, AI는 한 차례 응답에서 여러 개의 메시지를 생성해야 하며, 각 메시지는 서로 다른 대상으로 전송될 수 있습니다. 예를 들어, AI는 코드 인터프리터에 하나의 메시지를 보내고, 동시에 사용자에게 AI가 수행 중인 작업을 설명하는 또 다른 메시지를 보낼 수도 있습니다. 이를 지원하기 위해, Llama 3의 연구진(Dubey 외, 2024)은 다중 메시지 채팅 형식을 설계했습니다. 이 형식에서는 각 메시지의 출처와 목적지를 지정하는 메시지 헤더를 포함하고 있으며, 인간과 AI의 차례가 시작되는 지점을 나타내는 특별한 종료 토큰도 포함되어 있습니다.\n",
    "\n",
    "대화 인터페이스를 활용하는 애플리케이션의 데이터를 준비할 때, 단일 턴(single-turn) 데이터가 필요한지, 다중 턴(multi-turn) 데이터가 필요한지, 혹은 둘 다 필요한지를 고려해야 합니다. 단일 턴 데이터는 모델이 개별 지시에 응답하는 방법을 학습하는 데 유용합니다. 반면, 다중 턴 데이터는 모델이 작업을 해결하는 방식을 학습하는 데 도움을 줍니다. 많은 실제 작업에서는 여러 차례의 질문과 답변이 필요합니다. 예를 들어, 사용자가 질문을 했을 때, 모델은 작업을 수행하기 전에 사용자의 의도를 먼저 명확히 해야 할 수도 있습니다. 모델이 응답한 후, 사용자는 추가적인 정보나 수정 사항을 제공할 수도 있습니다.\n",
    "\n",
    "단일 턴 데이터는 더 단순하고, 따라서 더 쉽게 얻을 수 있습니다. 반면, 다중 턴 데이터는 특정 시나리오를 설계하거나 더 복잡한 상호작용을 필요로 하는 경우가 많습니다.\n",
    "\n",
    "데이터 큐레이션은 단순히 새로운 데이터를 생성하여 모델이 새로운 행동을 학습하도록 하는 것뿐만 아니라, 기존 데이터를 제거하여 모델이 잘못된 행동을 잊도록 하는 과정도 포함합니다. 예를 들어, ChatGPT와 같은 챗봇을 개발하는 팀에서 챗봇이 다소 오만하게 행동하여 사용자들을 짜증 나게 하며, 불필요하게 토큰을 소비하게 만든다는 불만이 제기되었다고 가정해 보겠습니다. 사용자가 어떤 진술이 사실인지 확인해 달라고 요청했을 때, 챗봇이 “그 진술은 맞지만, 스타일을 좀 더 개선할 수 있습니다.”라고 응답하며 원하지 않은 방식으로 문장을 다시 작성해 준다면, 이는 문제가 될 수 있습니다.\n",
    "\n",
    "조사를 진행한 결과, 학습 데이터에 원치 않는 제안이 포함된 주석이 여러 개 발견되었습니다. 따라서 이러한 예제들을 제거하도록 요청하고, 불필요한 재작성 없이 사실 검증을 수행하는 새로운 예제들을 추가하도록 요청하게 됩니다.\n",
    "\n",
    "각 애플리케이션은 서로 다른 특성을 가진 데이터를 필요로 할 수 있습니다. 또한, 학습의 각 단계에서는 서로 다른 데이터 믹스를 요구합니다. 그러나 데이터 큐레이션은 전반적으로 세 가지 기준을 따릅니다: **데이터 품질(data quality), 데이터 커버리지(data coverage), 그리고 데이터 양(data quantity)** 입니다.\n",
    "\n",
    "이 개념을 직관적으로 이해하기 위해 모델 학습을 요리에 비유할 수 있습니다. 모델에 제공되는 데이터는 요리에 사용되는 재료라고 볼 수 있습니다. 데이터 품질은 재료의 품질과 같으며, 재료가 상하면 좋은 음식을 만들 수 없습니다. 데이터 커버리지는 올바른 비율의 재료를 갖추는 것과 같으며(예: 설탕이 너무 많거나 너무 적어서는 안 됨), 데이터 양은 사용해야 할 재료의 총량과 관련이 있습니다. 이제 이러한 개념을 더 자세히 살펴보겠습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 품질 (Data Quality)\n",
    "\n",
    "소량의 고품질 데이터는 대량의 노이즈가 포함된 데이터보다 더 나은 성능을 발휘할 수 있습니다. 예를 들어, Yi 모델 패밀리의 개발자들은 10,000개의 신중하게 설계된 명령어가 수십만 개의 노이즈가 포함된 명령어보다 더 우수하다는 것을 발견했습니다 (Young 외, 2024).\n",
    "\n",
    "유사하게, **“LIMA: Less Is More for Alignment”** (Zhou 외, 2023) 연구에서는, 65B(650억) 매개변수를 가진 Llama 모델을 1,000개의 신중하게 구성된 프롬프트와 응답을 사용해 미세 조정(finetuning)하면, 인간 평가 기준으로 GPT-4보다 동등하거나 더 선호되는 답변을 43%의 확률로 생성할 수 있다는 결과를 발표했습니다. 그러나 데이터 예제가 너무 적으면, LIMA가 제품 수준의 모델(product-grade model)만큼 강력하지 않다는 단점이 있습니다.\n",
    "\n",
    "Llama 3 연구진도 동일한 결론에 도달했습니다. 특히, 인간이 생성한 데이터는 오류 및 불일치에 더 취약하다는 사실을 발견했습니다. 이는 특히 **안전 정책(safety policy)** 과 같이 미묘한 규칙이 필요한 경우 더욱 두드러졌습니다. 이러한 문제를 해결하기 위해, 연구진은 AI 기반의 주석 도구를 활용하여 데이터 품질을 보장하는 방법을 개발했습니다.\n",
    "\n",
    "대부분의 사람들은 데이터 품질이 중요하다는 것을 이해하지만, 그렇다면 고품질 데이터란 무엇을 의미할까요? 간단히 말하면, 고품질 데이터란 사용자가 업무를 효율적이고 신뢰성 있게 수행하는 데 도움이 되는 데이터입니다. 그러나 구체적인 기준은 사용자마다 다를 수 있습니다. 일반적으로 데이터는 다음과 같은 여섯 가지 특성을 만족할 경우 고품질로 간주됩니다: **관련성(relevant), 작업 요구사항과의 정렬(aligned with task requirements), 일관성(consistency), 올바른 형식(correctly formatted), 고유성(unique), 규정 준수(compliant)**. 일부 특정한 사용 사례에서는 추가적인 요구사항이 있을 수도 있습니다.\n",
    "\n",
    "**관련성 (Relevant)**\n",
    "- 훈련 데이터의 예제는 모델이 수행할 작업과 관련이 있어야 합니다. 예를 들어, 작업이 오늘날의 법률 질문에 답하는 것이라면, 19세기의 법률 데이터셋은 관련성이 없을 수도 있습니다. 그러나 작업이 19세기의 법률 시스템에 대한 것이라면, 해당 데이터셋은 매우 관련성이 높다고 볼 수 있습니다.\n",
    "\n",
    "**작업 요구사항과의 정렬 (Aligned with task requirements)**\n",
    "- 주석(annotations)은 작업의 요구사항과 일치해야 합니다. 예를 들어, 작업이 사실적 정확성을 요구한다면, 주석은 사실적으로 정확해야 합니다. 작업이 창의성을 필요로 한다면, 주석은 창의적이어야 합니다. 작업이 단순히 점수뿐만 아니라 점수에 대한 근거도 요구한다면, 주석에는 점수뿐만 아니라 근거도 포함되어야 합니다. 그러나 작업이 간결한 답변을 요구한다면, 주석 역시 간결해야 합니다.\n",
    "\n",
    "- 나는 “정확(accurate)” 또는 “올바름(correct)” 대신 **“정렬(aligned)”** 이라는 단어를 사용했습니다. 왜냐하면 작업에 따라 정확하거나 올바른 응답이 반드시 사용자가 원하는 것이 아닐 수도 있기 때문입니다.\n",
    "\n",
    "**일관성 (Consistent)**\n",
    "- 주석은 예제 간 및 주석자(annotator) 간에 일관성이 있어야 합니다. 동일한 예제에 대해 두 명의 주석자에게 주석을 달도록 요청했을 때, 그들의 주석이 너무 다르면 안 됩니다. 예를 들어, 에세이를 1~5점으로 평가하는 작업이라면, 같은 점수를 받은 두 개의 에세이가 동일한 품질을 유지해야 합니다. 주석이 일관되지 않으면 모델이 혼란스러워하며 학습하기 어려워집니다.\n",
    "\n",
    "- 주석이 작업 요구사항과 일관성을 유지하도록 하려면, 명확한 **주석 지침(annotation guideline)** 을 마련하는 것이 필수적입니다.\n",
    "\n",
    "**올바른 형식 (Correctly formatted)**\n",
    "- 모든 예제는 모델이 기대하는 형식을 따라야 합니다. 불필요한 형식 태그는 모델의 학습을 방해할 수 있으며, 따라서 제거해야 합니다. 예를 들어, 웹사이트에서 제품 리뷰를 스크래핑(scraping)한 경우, HTML 태그를 제거해야 합니다. 또한 불필요한 공백, 줄바꿈, 일관되지 않은 대소문자 사용, 숫자 형식 등에 주의해야 합니다.\n",
    "\n",
    "**충분히 고유함 (Sufficiently unique)**\n",
    "- 이것은 데이터 내에서 **고유한(unique)** 예제를 유지하는 것과 관련이 있습니다. 모델 훈련의 맥락에서, 중복된 데이터는 편향을 유발하고 데이터 오염(data contamination)을 초래할 수 있습니다. 특정 사용 사례에서는 일정 수준의 중복을 허용할 수도 있기 때문에, “완전히(unique)”가 아니라 **“충분히 고유(sufficiently unique)”** 하다는 표현을 사용했습니다.\n",
    "\n",
    "**규정 준수 (Compliant)**\n",
    "- 데이터는 모든 관련 내부 및 외부 정책(법률 및 규정 포함)을 준수해야 합니다. 예를 들어, 모델을 훈련하는 데 **개인 식별 정보(PII, Personally Identifiable Information)** 를 사용할 수 없는 경우, 데이터 내에 PII가 포함되지 않아야 합니다.\n",
    "\n",
    "데이터를 생성하기 전에, 위의 특성이 각 사용자에게 어떤 의미를 가지는지 고민하는 것이 중요합니다. 이 섹션에서 논의된 기술들은 이러한 특성을 갖춘 데이터를 생성하는 것을 목표로 합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 커버리지 (Data Coverage)\n",
    "모델의 훈련 데이터는 모델이 해결해야 할 문제의 범위를 충분히 포함해야 합니다. 현실 세계의 사용자는 매우 다양한 문제를 가지고 있으며, 이를 표현하는 방식도 크게 다를 수 있습니다. 애플리케이션의 다양한 사용 패턴을 반영하는 데이터가 있어야 모델이 우수한 성능을 발휘할 수 있습니다. 따라서 **충분한 데이터 다양성(data diversity)** 을 확보하는 것이 중요하며, 많은 연구자들이 이를 **데이터 커버리지(data coverage)** 와 동일한 개념으로 간주합니다.\n",
    "\n",
    "예를 들어, 일부 사용자는 풍부한 참고 자료를 포함한 **상세한 지침(detailed instructions)** 을 구성하는 반면, 다른 사용자들은 **간결한 지침(short instructions)** 을 선호할 수도 있습니다. 따라서 모델의 미세 조정(finetuning)을 위한 데이터셋에는 **상세한 지침과 간결한 지침이 모두 포함**되어야 합니다. 또한, 사용자의 질의(query)에 **철자 오류(typos)** 가 자주 포함된다면, 철자 오류가 있는 예제도 데이터에 포함하는 것이 좋습니다. 그리고 애플리케이션이 **여러 프로그래밍 언어**를 다룬다면, 훈련 데이터에는 **사용자가 중요하게 여기는 프로그래밍 언어**가 포함되어야 합니다.\n",
    "\n",
    "다양한 애플리케이션에는 다양한 차원의 다양성이 존재한다. 예를 들어, 프랑스어-영어 번역 도구는 언어적 다양성을 필요로 하지 않지만, 주제의 다양성, 문장의 길이, 화법 스타일의 다양성으로부터 이점을 얻을 수 있다. 반면, 글로벌 고객에게 제품을 추천하는 챗봇은 반드시 도메인 다양성을 필요로 하지는 않지만, 언어적 및 문화적 다양성이 중요할 것이다.\n",
    "\n",
    "챗봇과 같은 범용 애플리케이션의 경우, 미세 조정 데이터는 다양한 주제와 말하기 패턴을 대표해야 한다. **Ding 외(2023)** 는 챗봇 언어 모델의 성능을 더욱 향상시키는 가장 직접적인 방법이 **훈련 과정에서 사용되는 데이터의 품질과 다양성을 증가시키는 것**이라고 믿었다. **Nemotron(Adler 외, 2024)** 을 개발하기 위해, **NVIDIA 연구진은 작업(task) 다양성, 주제(topic) 다양성, 지시문(instruction) 다양성을 포함한 데이터셋을 구축했다**. 이 데이터셋에는 다양한 출력 형식, 출력 길이, 개방형(open-ended) 답변, 예/아니요(yes-or-no) 답변을 포함하는 지시문이 포함되었다.\n",
    "\n",
    "그러나 **“데이터 추가 딜레마(Data Addition Dilemma)”(Shen 외, 2024)** 연구에서는 경우에 따라 이질적인 데이터를 과도하게 추가하면 오히려 성능이 저하될 수 있다고 밝혔다.\n",
    "\n",
    "Meta는 **Llama 3**가 이전 **Llama 모델들과 아키텍처 측면에서는 큰 차이가 없지만, 성능 향상은 주로 데이터 품질 및 다양성의 향상과 훈련 규모 증가에서 비롯되었다**고 발표했다. **Llama 3 논문**은 **사전 훈련(pre-training), 지도 미세 조정(supervised finetuning), 선호도 미세 조정(preference finetuning)** 등 세 가지 주요 훈련 단계 전반에 걸쳐 **데이터 커버리지(data coverage)** 에 대한 세부 정보를 제공한다. 이 장에서는 **후기 훈련(post-training) 데이터** 에 초점을 맞추고 있지만, 동일한 모델의 전체 훈련 단계에서 **데이터 구성(data mix)** 을 비교하고 각 단계에서 고려해야 할 점을 강조하는 것이 유용할 수 있다.\n",
    "\n",
    "세 가지 훈련 단계에서 일관되게 유지되는 하나의 다양성 축은 **도메인 다양성(domain diversity)** 이지만, 정확히 **“다양성”이 의미하는 바는 각 단계마다 다를 수 있다**. 아래 **표 8-1**은 도메인별 데이터 비율을 정리한 것이다. (세부 주제, 예를 들어 **기하학(geometry)** 과 같은 수학의 하위 카테고리는 포함되지 않음) 후기 훈련 데이터는 표에 나타나지 않은 다른 다양성 축을 포함하기도 하는데, 예를 들어 **토큰 수(맥락 및 응답)**, **턴 수** 등이 있다. 또한 Llama 3는 후기 훈련을 위해 **합성 데이터(synthetic data)** 를 사용하므로, 또 하나의 고려 요소는 **인간이 생성한 데이터와 AI가 생성한 데이터의 비율**이다.\n",
    "\n",
    "**표 8-1. Llama 3의 훈련 단계별 최적의 도메인 구성**  \n",
    "\n",
    "| **도메인** | **사전 훈련** | **지도 미세 조정** | **선호도 미세 조정** |\n",
    "|------------|-------------|------------------|------------------|\n",
    "| 일반 지식 (영어) | 50% | 52.66% | 81.99% |\n",
    "| 수학 및 논리 추론 | 25% | 21.19% | 5.89% |\n",
    "| 코딩 | 17% | 14.89% | 6.93% |\n",
    "| 다국어 (Multilingual) | 8% | 3.01% | 5.19% |\n",
    "| 시험 유형 데이터 | X | 8.14% | X |\n",
    "| 긴 컨텍스트 데이터 | X | 0.11% | X |\n",
    "\n",
    "흥미로운 점은 **사전 훈련 및 지도 미세 조정 과정에서 수학, 논리 추론, 코딩 관련 토큰이 전체 훈련 데이터의 거의 절반을 차지한다는 것**이다. 인터넷 데이터에서 수학과 코딩이 차지하는 비율은 50%보다 훨씬 낮을 가능성이 높지만, **Llama 3 연구진은 모델을 훈련할 때 점점 더 작은 학습률로 점점 더 많은 코드 및 수학 데이터를 사용하는 방식(annealing)** 을 통해 **모델의 성능을 향상**시킬 수 있다고 밝혔다. 이는 **고품질의 코드 및 수학 데이터가 자연어 데이터보다 모델의 논리적 추론 능력을 강화하는 데 더 효과적이라는 일반적인 믿음**을 확인시켜 준다.\n",
    "\n",
    "또한, **선호도 미세 조정 과정에서 코드 및 수학 데이터의 비율이 12.82%(코드+수학)로 크게 감소** 한다. 이는 **사용자의 실제 선호도를 반영하는 것이 목표**이기 때문일 가능성이 높다.\n",
    "\n",
    "이제 질문이 하나 생긴다. **어떻게 올바른 데이터 믹스를 결정할 것인가?** 가장 간단한 접근법은 **실제 애플리케이션의 사용 패턴을 반영하는 데이터 믹스를 선택하는 것**이다. 또한 **실험을 통해 최적의 데이터 믹스를 찾을 수도 있다**. 예를 들어, **Meta는 “스케일링 법칙(scaling law)” 실험** 을 수행했다. 이 실험에서는 **여러 후보 데이터 믹스를 사용하여 소규모 모델을 훈련**한 후, 이를 기반으로 **대규모 모델의 성능을 예측**했다. 결과적으로 **실험에서 가장 좋은 성능을 보이는 데이터 믹스가 최종적으로 사용**되었다.\n",
    "\n",
    "데이터 다양성과 품질의 영향을 평가하기 위해, Zhou 외(2023)는 흥미로운 실험을 수행했다. 그들은 7B 파라미터 언어 모델을 동일한 크기(2,000개의 예제)지만 서로 다른 특성을 가진 세 가지 데이터셋으로 훈련시켰다. 첫 번째는 고품질이지만 다양성이 낮은 데이터셋이고, 두 번째는 다양성은 높지만 품질이 낮은 데이터셋이며, 세 번째는 다양성과 품질이 모두 높은 데이터셋이다. 그림 8-1은 이 세 가지 모델의 생성 품질을 보여준다.\n",
    "\n",
    "<img src=\"./images/fig_08_01.png\" width=\"800\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 양(Data Quantity)**  \n",
    "\n",
    "얼마나 많은 데이터가 필요한지는 얼마나 많은 돈이 필요한지를 묻는 것과 비슷하다. 상황에 따라 정답은 크게 달라진다. 한 극단적인 사례로, **Jeremy Howard**와 **Jonathan Whitaker**는 **대형 언어 모델(LLM)이 단 하나의 예제만으로도 학습할 수 있음을 보여주는 실험**을 진행했다. 반대편 극단에서는, **일부 연구팀이 수백만 개의 예제를 활용하여 모델을 미세 조정(finetuning)한 사례** 도 있다.\n",
    "\n",
    "수백만 개의 예제는 많아 보일 수도 있지만, **기본 모델(foundation model)을 처음부터 훈련하는 데 일반적으로 필요한 데이터량과 비교하면 매우 적은 수준** 이다. 예를 들어, **Llama 2와 Llama 3는 각각 2조(trillion) 토큰과 16조 토큰을 사용하여 훈련되었다**. 각 예제가 **2,000개의 토큰으로 이루어져 있다고 가정하면**, 이는 **각각 10억(1 billion) 개와 150억(15 billion) 개의 예제** 에 해당하는 규모이다.\n",
    "\n",
    ">**참고 사항(NOTE)**\n",
    ">\n",
    ">**\"이미 수백만 개의 예제가 있다면, 그냥 모델을 처음부터 훈련하는 것이 더 나은 선택이 아닐까?\"** 라는 의문이 들 수도 있다. 이런 경우, **모델을 처음부터 훈련하는 것이 성능 향상에 도움이 되는지 평가하는 것이 중요하다**. 일반적으로는 **사전 훈련된 모델을 기반으로 미세 조정(finetuning)하는 것이 처음부터 훈련하는 것보다 훨씬 효율적** 이지만, **특정한 상황에서는 미세 조정이 오히려 성능을 악화시킬 수도 있다**. 이러한 현상의 원인 중 하나가 바로 **“경화(ossification)”** 라는 현상이다.  \n",
    "즉, **사전 훈련 과정에서 모델의 가중치가 굳어버리면(freeze), 미세 조정 데이터를 활용한 추가 학습이 제대로 이루어지지 않을 수 있다** (Hernandez 외, 2021). 특히, **작은 모델일수록 경화 현상의 영향을 더 많이 받으며, 큰 모델보다 미세 조정 데이터에 적응하기 어려운 경우가 많다**.\n",
    "\n",
    "데이터 품질(data quality)과 데이터 다양성(data diversity) 외에도, 데이터 양에 영향을 미치는 세 가지 주요 요인이 있다:\n",
    "\n",
    "**미세 조정 기법(Finetuning techniques)**\n",
    "- 완전한 미세 조정(full finetuning)은 최상의 성능을 제공할 수 있지만, **LoRA**와 같은 PEFT(효율적인 미세 조정) 방법보다 **훨씬 더 많은 데이터가 필요**하다. 만약 **수만 개에서 수백만 개의 (지시문, 응답) 쌍을 보유하고 있다면**, 완전한 미세 조정을 시도해볼 수 있다. 그러나 **몇백 개에서 몇천 개 정도의 예제만 있다면**, PEFT 방법이 더 효과적일 수 있다.\n",
    "\n",
    "**작업의 복잡성(Task complexity)**\n",
    "- 제품 리뷰가 긍정적인지 부정적인지를 분류하는 것과 같은 단순한 작업은, 재무 보고서와 관련된 질문에 답하는 것과 같은 복잡한 작업보다 훨씬 적은 데이터만을 필요로 한다.\n",
    "\n",
    "**기본 모델의 성능(Base model’s performance)**\n",
    "- 기본 모델이 원하는 성능에 가까울수록, 필요한 예제 수도 줄어든다. 더 큰 기본 모델이 더 나은 성능을 낸다고 가정할 경우, 큰 모델을 미세 조정하는 데는 더 적은 예제가 필요할 수도 있다. 이는 사전 훈련(pre-training) 과정과는 반대되는 개념인데, 사전 훈련에서는 더 큰 모델일수록 더 많은 훈련 데이터가 필요하기 때문이다.\n",
    "\n",
    "**OpenAI의 미세 조정 가이드**에서는, **예제 수가 적을 경우(100개 정도)** 더 발전된 모델이 더 나은 미세 조정 성능을 제공한다는 결과를 보여준다. 이는 더 발전된 모델이 기본적으로 더 나은 성능을 내기 때문으로 보인다. 하지만 **550,000개의 예제를 사용하여 미세 조정을 진행한 후**, 실험에 참여한 **다섯 개의 모델이 모두 비슷한 성능을 보였다**. 이러한 결과는 **Figure 8-2**에서 확인할 수 있다.\n",
    "\n",
    "<img src=\"./images/fig_08_02.png\" width=\"800\">\n",
    "\n",
    "요약하자면, 적은 양의 데이터를 가지고 있다면 더 발전된 모델에 PEFT 방법을 사용하는 것이 좋을 수 있다. 반면 많은 양의 데이터가 있다면 작은 모델로 완전한 미세 조정을 수행하는 것이 좋다.\n",
    " \n",
    "대규모 데이터셋을 구축하는 데 투자하기 전에, 잘 만들어진 소규모 데이터셋(예: 50개의 예제)으로 시작하여 미세 조정이 모델을 개선할 수 있는지 확인해보는 것이 좋다. 이 작은 데이터셋으로도 원하는 성능을 달성할 수 있다면 더할 나위 없이 좋다. 명확한 성능 향상이 보인다면 더 많은 데이터로 성능을 더욱 개선할 수 있다는 것을 의미한다. 반면 작은 데이터로도 개선이 보이지 않는다면, 더 큰 데이터셋으로도 효과를 보기 어려울 것이다.\n",
    "\n",
    "그러나 작은 데이터셋으로 미세 조정을 수행하는 것이 모델의 성능을 향상시키지 않는다고 결론을 내리기 전에 주의해야 한다. 데이터 외에도 미세 조정의 결과에 영향을 미칠 수 있는 많은 요인이 있다. 예를 들어, 하이퍼파라미터 선택(예: 학습률이 너무 높거나 너무 낮은 경우), 데이터 품질, 잘못된 프롬프트 작성 등이 있다. 대부분의 경우, 50~100개의 예제를 사용하여 미세 조정을 수행하면 성능이 향상되는 것을 확인할 수 있다.\n",
    "\n",
    ">**팁(TIP)**\n",
    ">\n",
    ">처음에 품질이 낮거나 덜 관련성이 높은 데이터를 사용하여 모델을 미세 조정하면, 고품질 데이터의 필요량을 줄일 수 있다. 다음은 이러한 접근 방식의 세 가지 예제이다.\n",
    ">\n",
    ">자기지도 학습 → 지도 학습\n",
    ">\n",
    ">법률 질문에 답변하는 모델을 미세 조정하려고 한다. (질문, 답변) 데이터셋은 작지만, 법률 문서는 많이 가지고 있다. 이 경우, 먼저 법률 문서를 기반으로 자기지도 학습을 수행한 후, 이후에 (질문, 답변) 데이터셋을 사용하여 추가적인 미세 조정을 수행할 수 있다.\n",
    ">\n",
    ">덜 관련된 데이터 → 관련 데이터\n",
    ">\n",
    ">상품 리뷰 감성을 분류하는 모델을 미세 조정하고 싶지만, 상품 감성 데이터는 적고 트윗 감성 데이터는 많다고 가정하자. 이 경우, 먼저 트윗 감성 데이터를 사용하여 모델을 미세 조정한 후, 이후에 상품 감성 데이터를 활용하여 추가적인 미세 조정을 수행할 수 있다.\n",
    ">\n",
    ">합성 데이터 → 실제 데이터\n",
    ">\n",
    ">의료 보고서를 기반으로 질병을 예측하는 모델을 미세 조정하려고 하지만, 해당 작업의 민감한 특성으로 인해 사용할 수 있는 실제 데이터가 제한적이다. 이 경우, AI 모델을 활용하여 대량의 합성 데이터를 생성한 후, 먼저 합성 데이터로 모델을 미세 조정한 다음, 이후에 실제 의료 데이터를 활용하여 추가적인 미세 조정을 수행할 수 있다. 하지만 이 접근 방식은 올바르게 수행하기 어려울 수 있다. 두 단계의 미세 조정 과정에서 전이를 효과적으로 관리해야 하며, 이를 제대로 수행하지 못하면 단순히 고품질 데이터만을 사용하여 미세 조정을 수행했을 때보다 더 많은 컴퓨팅 자원을 사용하면서도 성능이 낮은 모델이 생성될 위험이 있다.\n",
    "\n",
    "작은 데이터셋을 사용하여 실험하면, 얼마나 더 많은 데이터가 필요한지 추정하는 데 도움이 될 수 있다. 모델을 현재 데이터셋의 일부(예: 25%, 50%, 100%)로 미세 조정하고, 데이터셋 크기에 따라 성능이 어떻게 변화하는지 그래프로 나타낼 수 있다. 데이터셋 크기가 증가할수록 성능이 급격히 향상된다면, 데이터를 두 배로 늘릴 경우 성능이 크게 향상될 가능성이 높다. 반면, 성능이 일정 수준에서 정체되는 패턴을 보인다면, 데이터를 두 배로 늘리더라도 성능 향상은 미미할 가능성이 크다. Figure 8-3에서는 이러한 관계를 보여주는 예제 그래프를 확인할 수 있다.\n",
    "\n",
    "<img src=\"./images/fig_08_03.png\" width=\"800\">\n",
    "\n",
    "Figure 8-3에 나타난 성능 향상 곡선은 일반적인 패턴을 따른다. 대부분의 경우, 추가적인 훈련 예제는 수익 감소 법칙(diminishing returns)을 따른다. 즉, 동일한 수의 예제가 추가되더라도 데이터셋이 커질수록 성능 향상 효과는 감소한다. 예를 들어, 처음 1,000개의 예제는 모델의 정확도를 10%포인트 향상시킬 수 있지만, 다음 1,000개의 예제는 오직 5%만 향상시킬 수 있다.\n",
    "\n",
    "더 많은 미세 조정 예제가 일반적으로 모델의 성능을 향상시키지만, 예제의 다양성 또한 중요한 요소로 작용한다. **“Scaling Instruction-Finetuned Language Models” (Chung et al., 2022)** 논문에서는 미세 조정 작업의 개수가 9개에서 282개로 증가할 때 모델 성능이 크게 향상된다는 결과를 보여준다. 그러나 282개 이상의 작업을 추가하면 성능 향상 효과가 점점 둔화되기 시작했으며, 1,836개의 작업까지는 여전히 긍정적인 영향이 있었지만 그 증가 폭은 점진적으로 감소했다(Figure 8-4 참고). 이는 모델이 미세 조정 과정에서 다양한 작업을 학습하는 것이 큰 이점을 제공할 수 있음을 시사한다.\n",
    "\n",
    "데이터의 다양성은 작업 유형(예: 요약 및 질문 응답), 주제 다양성(예: 패션, 금융, 기술), 그리고 기대되는 출력 형식(예: JSON 출력 또는 예/아니요 응답)에서 반영될 수 있다.\n",
    "\n",
    "<img src=\"./images/fig_08_04.png\" width=\"800\">\n",
    "\n",
    "미세 조정에 사용할 데이터의 양은 단순히 필요한 것뿐만 아니라 예산에 따라 결정된다. 예를 들어, 데이터 주석(annotation)에 사용할 예산이 $10,000이고, 각 예제의 주석 비용이 $2라면, 최대 5,000개의 예제를 확보할 수 있다. 또한 데이터와 컴퓨팅 예산을 균형 있게 조정해야 할 수도 있다. 데이터에 더 많은 비용을 투자하면 컴퓨팅에 사용할 예산이 줄어들고, 그 반대의 경우도 마찬가지다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 수집 및 주석 (Data Acquisition and Annotation)\n",
    "\n",
    "데이터 수집의 목표는 필요한 품질과 다양성을 갖춘 충분히 큰 데이터셋을 구축하는 것이다. 동시에 데이터 수집 과정은 사용자 개인정보를 존중하고, 관련 규정을 준수해야 한다. 데이터 수집에는 공개 데이터 활용, 독점 데이터 구매, 데이터 주석 작업, 데이터 합성 등의 방법이 포함된다. 또한 예산 내에서 특정 요구 사항을 충족하는 데이터셋을 최적의 방식으로 확보하는 방법을 연구하는 **데이터 수집 전략(data acquisition strategy)** 이라는 연구 분야가 점차 성장하고 있다.\n",
    "\n",
    "그러나 가장 중요한 데이터 소스는 일반적으로 **자신의 애플리케이션에서 직접 생성되는 데이터**이다. 만약 **사용자가 생성하는 데이터를 활용하여 지속적으로 제품을 개선하는 \"데이터 플라이휠(data flywheel)\"을 구축할 수 있다면**, 이는 **큰 이점**을 제공할 수 있다. 애플리케이션 데이터를 활용하는 것은 이상적인 접근법인데, 이는 모델이 수행해야 할 작업과 가장 잘 정렬되어 있기 때문이다. 즉, **사용자가 중요하게 여기는 데이터 분포(distribution)를 그대로 반영할 수 있으며, 이는 다른 데이터 소스를 통해서는 달성하기 어려운 목표이다**.  \n",
    "\n",
    "사용자가 생성하는 데이터는 **사용자가 직접 작성한 콘텐츠(user content)**, **사용자 행동에서 발생하는 시스템 생성 데이터(system-generated data)**, **사용자 피드백(user feedback)** 등이 될 수 있다. **사용자 피드백 시스템을 설계하는 방법은 Chapter 10에서 다룬다**.\n",
    "\n",
    "자체 데이터를 생성하기 전에, 먼저 사용할 수 있는 기존 데이터셋을 확인해야 한다. 데이터 마켓플레이스는 방대하며, 오픈 소스 데이터와 독점 데이터 모두를 제공한다. 운이 좋다면, 원하는 데이터셋을 바로 찾을 수도 있지만, 대부분의 경우에는 서로 다른 데이터 소스를 조합하는 방식이 필요하다. 데이터셋은 여러 개의 데이터 소스를 통해 다양한 수집 채널을 활용하여 구축될 수 있다. 예를 들어, (지시문, 응답) 데이터셋을 만드는 과정은 다음과 같을 수 있다.\n",
    "\n",
    "1. 원하는 특성을 갖춘 기존 데이터셋을 찾는다. 예를 들어, 10,000개의 예제가 포함된 유망한 데이터셋을 발견할 수도 있다.\n",
    "2. 품질이 낮은 지시문을 제거한다. 이 과정을 거치면 9,000개의 예제가 남는다.\n",
    "3. 품질이 낮은 응답을 포함한 지시문을 따로 분류한다. 예를 들어, 3,000개의 품질이 낮은 응답을 발견했다고 가정하면, 6,000개의 고품질 지시문 및 고품질 응답이 남는다.\n",
    "4. 3,000개의 낮은 품질의 지시문에 대해 수작업으로 응답을 작성한다. 이제 총 9,000개의 고품질 예제를 확보하게 된다.\n",
    "5. 특정 주제 X에 대한 데이터가 충분하지 않다고 판단되면, 해당 주제에 대한 100개의 지시문 템플릿을 수동으로 생성한다. 이후 AI 모델을 사용하여 이 10개의 템플릿을 기반으로 2,000개의 지시문을 합성(synthesize)한다.\n",
    "6. 생성된 2,000개의 합성 지시문을 수작업으로 주석 처리한다. 이제 데이터셋의 총 예제 수는 11,000개가 된다.\n",
    "\n",
    "물론, 이는 데이터셋 구축 과정의 단순화된 설명이다. 실제 데이터셋 큐레이션 과정에서는 훨씬 더 많은 단계가 포함되며, 여기서 생략된 부분이 많다. 예를 들어, 주석이 유용하지 않다는 것을 여러 단계에서 발견할 수도 있고, 그에 따라 주석 지침(annotation guidelines)을 업데이트하고 데이터를 다시 주석 처리해야 할 수도 있다. 더 나쁜 경우, 일부 주석이 사실적으로 부정확하다는 것을 발견하게 되어 추가 검증을 위해 별도의 주석자를 고용해야 할 수도 있다. 또한, 템플릿당 100개의 합성 지시문을 생성하는 것이 데이터 다양성을 해칠 수도 있어, 더 많은 템플릿을 만들어야 하거나 템플릿당 지시문 수를 줄여야 할 수도 있다. 이러한 문제들은 계속해서 발생할 수 있다.\n",
    "\n",
    ">**공개 데이터셋을 찾을 수 있는 리소스 (RESOURCES FOR PUBLICLY AVAILABLE DATASETS)**\n",
    ">\n",
    ">다음은 공개적으로 이용할 수 있는 데이터셋을 찾을 수 있는 몇 가지 리소스이다. 공개 데이터는 적극적으로 활용할 가치가 있지만, 절대적으로 신뢰해서는 안 된다. 데이터는 철저히 검토되고 검증되어야 한다.\n",
    ">\n",
    ">데이터를 사용하기 전에 반드시 해당 데이터셋의 라이선스를 확인해야 한다. 데이터를 제공하는 출처를 최대한 파악하려고 노력해야 한다. 어떤 데이터셋이 상업적 사용을 허용하는 라이선스를 가지고 있다고 하더라도, 일부 데이터는 그러한 허가를 받지 않은 출처에서 비롯될 가능성이 있기 때문이다.\n",
    ">\n",
    ">1. **Hugging Face**와 **Kaggle**에는 수십만 개의 데이터셋이 호스팅되어 있다.\n",
    ">2. **Google**의 **Dataset Search**는 훌륭하면서도 과소평가된 데이터 검색 도구이다.\n",
    ">3. **정부 기관**은 종종 오픈 데이터의 주요 제공자이다. **Data.gov**에는 수십만 개의 데이터셋이 있으며, **data.gov.in**에는 수만 개의 데이터셋이 있다.\n",
    ">4. **미시간 대학교(University of Michigan)의 사회 연구 기관(ICPSR)** 에서는 수만 개의 사회 연구 데이터를 제공한다.\n",
    ">5. **UC Irvine의 Machine Learning Repository**와 **OpenML**은 오래된 데이터셋 저장소 중 하나로, 각각 수천 개의 데이터셋을 보유하고 있다.\n",
    ">6. **The Open Data Network**에서는 수만 개의 데이터셋을 검색할 수 있다.\n",
    ">7. **클라우드 서비스 제공업체**도 종종 소규모 오픈 데이터셋을 호스팅한다. 그중 가장 주목할 만한 것은 **AWS의 Open Data**이다.\n",
    ">8. **머신러닝 프레임워크**들은 종종 작은 규모의 사전 구축된 데이터셋을 제공하며, **TensorFlow datasets**이 대표적인 예다.\n",
    ">9. **일부 평가 도구(evaluation harness tools)** 는 PEFT 미세 조정을 위한 충분히 큰 평가 벤치마크 데이터셋을 호스팅한다. 예를 들어, **Eleuther AI의 lm-evaluation-harness**는 400개 이상의 벤치마크 데이터셋을 제공하며, 각 데이터셋에는 평균 2,000개 이상의 예제가 포함되어 있다.\n",
    ">10. **The Stanford Large Network Dataset Collection**은 그래프 데이터셋을 위한 훌륭한 저장소이다.\n",
    "\n",
    "미세 조정을 위해 자체 데이터를 주석 처리해야 하는 경우가 많다. 주석 작업은 단순히 주석을 다는 과정이 어렵기 때문만이 아니라, 명확한 주석 지침(annotation guidelines)을 만드는 과정이 복잡하기 때문에 더욱 도전적인 작업이다. 예를 들어, 좋은 응답이 무엇인지, 그리고 그것이 왜 좋은 응답인지 명확하게 정의해야 한다. 응답이 사실적으로는 맞지만 도움이 되지 않는 경우는 어떻게 평가해야 하는가? 점수 3과 4를 받을 만한 응답의 차이는 무엇인가? 주석 지침은 수동 주석뿐만 아니라 AI 기반 주석을 위한 작업에서도 필요하다.\n",
    "\n",
    "LinkedIn을 포함한 일부 팀에서는 주석 지침이 AI 엔지니어링 파이프라인에서 가장 어려운 부분 중 하나였다고 보고했다. 많은 경우, 사람들이 주석 작업에 필요한 시간과 노력에 부담을 느껴 작업을 중도에 포기하고, 대신 모델이 스스로 올바른 응답을 찾아낼 것이라고 기대하는 경우가 많다. 일부 강력한 모델들은 가끔씩 이를 해낼 수 있지만, 모델이 올바른 응답을 스스로 도출할 것이라고 가정하는 것은 많은 애플리케이션에서 너무 큰 리스크를 수반할 수 있다.\n",
    "\n",
    "좋은 소식은 이러한 주석 지침이 평가 데이터(evaluation data)를 위한 지침과 동일하다는 점이다. 이는 **Chapter 4**에서 논의된 내용과 일맥상통하며, 평가 지침 및 평가 데이터를 신중하게 큐레이션하는 데 더 많은 시간을 투자해야 하는 또 하나의 이유가 된다. 운이 좋다면, 기존 평가 데이터를 보강하여 새로운 데이터를 합성하는 데 사용할 수도 있다. 다음 섹션에서는 이러한 방법에 대해 논의할 것이다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **데이터 증강 및 합성 (Data Augmentation and Synthesis)**  \n",
    "\n",
    "AI에서 데이터는 컴퓨팅 자원 및 인재와 함께 가장 어려운 도전 과제 중 하나이다. 업계 전체가 오랜 기간 동안 데이터를 프로그램적으로 생성하는 목표를 달성하기 위해 노력해 왔다. 일반적으로 사용되는 두 가지 접근법은 **데이터 증강(data augmentation)** 과 **데이터 합성(data synthesis)** 이다.\n",
    "\n",
    "- **데이터 증강**은 기존 데이터에서 새로운 데이터를 생성하는 과정이다. 예를 들어, 고양이의 실제 이미지를 좌우로 뒤집으면 동일한 고양이의 새로운 이미지를 만들 수 있다.\n",
    "- **데이터 합성**은 실제 데이터의 특성을 모방하는 방식으로 데이터를 생성하는 과정이다. 예를 들어, 마우스가 웹페이지를 탐색하는 방식을 시뮬레이션하여 봇(bot)의 움직임을 모델링하는 데이터를 생성할 수 있다.\n",
    "\n",
    "즉, 증강된 데이터는 실제 데이터에서 파생되지만, 합성된 데이터는 완전히 새로운 데이터이다. 그러나 데이터 증강과 합성의 궁극적인 목표가 모두 데이터 생성 자동화에 있기 때문에, 이 두 용어는 때때로 혼용되기도 한다. 본 장에서는 **데이터 합성(data synthesis)** 이라는 용어를 보다 포괄적으로 사용하여 두 개념을 함께 다룰 것이다.\n",
    "\n",
    "인위적으로 생성된 데이터는 소프트웨어 엔지니어링에서 오랜 역사를 가지고 있다. 원래는 테스트를 위한 가짜(fake) 데이터를 생성하는 용도로 사용되었다. 예를 들어, **Faker** 및 **Chance**와 같은 라이브러리는 이름, 주소, 전화번호, 이메일 주소 등의 데이터를 간단한 형식으로 생성할 수 있다. 예를 들어, 사용자가 배송 주소를 파싱(parsing)하는 프로그램을 만들었다고 가정해보자. 이때, 가짜 데이터 생성기를 사용하면 서로 다른 국가 및 주(state)에서 다양한 형식으로 주소를 생성하여 프로그램이 모든 형식을 올바르게 처리할 수 있는지 확인할 수 있다.\n",
    "\n",
    "현재 AI는 인간이 생성한 데이터와 구별할 수 없을 정도로 정교한 데이터를 생성할 수 있다. 따라서 의료 기록(doctor’s notes), 계약서, 금융 보고서, 제품 설명, 이미지, 동영상 광고 등 훨씬 복잡한 데이터를 합성할 수도 있다. 이를 통해 데이터 생성이 쉬워지고, 합성 데이터의 활용 사례가 더욱 늘어날 수 있다.\n",
    "\n",
    "그러나 합성 데이터가 인간이 생성하는 데이터의 필요성을 완전히 대체하지는 않는다. **“Limitations to AI-generated data”** 에서 논의된 바와 같이, 실제 많은 사용 사례에서 **인간이 생성한 데이터와 AI가 생성한 데이터를 혼합하는 것이 최적의 결과를 도출하는 방법**이 된다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 합성의 필요성 (Why Data Synthesis)**\n",
    "\n",
    "합성 데이터는 여러 가지 이유로 매력적인 선택지가 될 수 있다. 데이터 합성을 통해 데이터의 세 가지 핵심 요소인 **양(quantity), 범위(coverage), 품질(quality)** 을 향상시킬 수 있다. 또한, 개인정보 보호 문제를 완화하거나 모델을 압축(distill)하는 데에도 활용할 수 있다.\n",
    "\n",
    "**데이터 양을 증가시키기 위해**\n",
    "\n",
    "- 데이터 합성의 가장 큰 장점은 **대규모로 데이터를 생성할 수 있다는 것**이며, 이를 통해 AI 모델의 학습 및 테스트를 위한 풍부한 데이터를 제공할 수 있다. 이론적으로는 더 많은 데이터가 있을수록 모델이 더 넓은 범위의 작업에 대해 일반화할 수 있다. 특히, 현실 세계에서 데이터가 부족하거나 수집이 어려운 경우에는 합성 데이터가 매우 유용할 수 있다. 예를 들어, **희귀한 기상 조건(rare weather conditions), 심해 탐사(deep sea exploration), 자율주행 자동차(self-driving cars)의 사고 상황** 과 같은 데이터를 수집하는 것은 매우 어렵기 때문에, 합성 데이터를 활용하여 이러한 환경을 모방할 수 있다.\n",
    "\n",
    "**데이터 범위를 확장하기 위해**\n",
    "            \n",
    "- 모델의 성능을 향상시키거나 특정 동작을 표현하도록 하기 위해 목표로 하는 특성을 가진 데이터를 생성할 수 있다. 예를 들어, 매우 짧은 텍스트나 매우 긴 텍스트를 생성할 수 있다. 유해 문구 탐지 모델을 위해 유해한 문구가 포함된 대화를 생성할 수 있다. 반대로, 실제 데이터가 유해한 경우에는 안전한 데이터를 합성할 수도 있다. AI를 사용하여 적대적 예제를 합성하는 것이 특히 일반적이다. 또한 클래스 불균형 문제를 해결하기 위해 희소 클래스에 대한 데이터를 생성하는 것도 가능하다. \"TrueTeacher\"에서 설명된 바와 같이, Gekhman 등(2022)은 LLM을 사용하여 사실과 일치하지 않는 요약문을 생성한 다음, 이를 활용하여 사실 불일치를 탐지하는 모델을 학습시켰다.\n",
    "\n",
    "- Perez et al.(2022)의 논문 **\"Discovering Language Model Behaviors with Model-Written Evaluations\"** 에서 **Anthropic** 연구진은 **다양한 데이터 합성 기법**을 활용하여 **154가지 AI 행동을 평가할 수 있는 특정 데이터셋을 생성하는 방법**에 대해 논의했다. 이 연구에서 다룬 AI 행동에는 **성격 특성(personality traits), 정치적 견해(political views), 윤리적 입장(ethical stances), 사회적 편향(social biases)** 등이 포함되었다. 연구진은 **언어 모델(LM)이 생성한 데이터셋과 인간이 생성한 데이터셋을 직접 비교한 결과, \"LM이 작성한 데이터셋은 인간이 작성한 데이터셋의 품질에 근접하며, 경우에 따라 이를 초과하기도 한다\"** 고 결론지었다.  \n",
    "\n",
    "- 즉, **합성 데이터를 활용하면 기존 데이터가 부족한 영역을 보완하여 데이터 커버리지를 확장할 수 있다**.\n",
    "\n",
    "**데이터 품질 향상을 위해 (To increase data quality)**  \n",
    "\n",
    "- 합성 데이터는 일반적으로 인간이 생성한 데이터보다 품질이 낮다는 인식이 있지만, 경우에 따라 반대의 경우도 발생할 수 있다. 때때로, 인간이 가지고 있는 근본적인 한계로 인해 인간이 생성한 데이터의 품질이 AI가 생성한 데이터보다 낮을 수도 있다. 한 가지 예로, 도구 사용(tool use) 데이터를 들 수 있다. 인간과 AI는 근본적으로 작업 방식과 도구 선호도가 다르기 때문에, 인간이 생성한 데이터만으로는 특정 도구 사용 패턴을 완벽하게 반영하기 어려울 수 있다. 또 다른 예로, 복잡한 수학 문제를 생성하는 작업이 있다. AI는 평균적인 인간 전문가가 생각할 수 있는 수준을 훨씬 뛰어넘는 복잡한 문제를 생성할 수 있다.  \n",
    "\n",
    "- 일부 팀에서는 선호 데이터(preference data)를 생성하는 데 AI를 활용하기도 한다. 인간 개인별로는 일정한 선호 패턴을 유지할 수도 있지만, 다른 사람들 간의 선호도 차이는 매우 크며, 이는 단순한 개인 취향뿐만 아니라 기분(mood), 동기(motivation) 등 다양한 요인에 의해 영향을 받을 수 있다. 반면, AI가 생성한 선호도 평가는 훨씬 더 일관되고 신뢰할 수 있는 결과를 제공할 수 있다.  \n",
    "\n",
    "**개인정보 보호 문제 완화 (To mitigate privacy concerns)**  \n",
    "\n",
    "- 합성 데이터는 개인정보 보호 문제로 인해 인간이 생성한 데이터를 사용할 수 없는 경우 유일한 해결책이 될 수 있다. 예를 들어, 의료 분야(healthcare)에서는 법률적 제한으로 인해 환자의 실제 의료 기록을 AI 모델 학습에 사용하는 것이 어렵거나 불가능할 수 있다. 이런 경우, 민감한 정보를 포함하지 않는 합성 환자 기록(synthetic patient records)을 생성하여 모델을 훈련할 수 있다. 보험(insurance) 분야에서도 개인의 민감한 개인정보가 포함된 실제 청구 데이터 대신, 합성 데이터를 활용하여 모델을 훈련할 수 있다.  \n",
    "\n",
    "**모델 압축 및 지식 증류 (To distill models)**  \n",
    "\n",
    "- 때때로, 기존 모델의 행동을 모방하는 모델을 훈련해야 하는 경우가 있다. 이러한 경우, 더 저렴하고 빠른 모델(distilled model)을 생성하는 것이 목표이며, 이는 원본 모델과 유사한 성능을 유지해야 한다. 이를 위해, 원본 모델이 생성한 데이터를 활용하여 증류 모델을 훈련하는 방식이 사용된다.  \n",
    "\n",
    "이것들은 합성 데이터를 활용하는 많은 이유 중 일부에 불과하다. 합성 데이터의 명백한 장점 때문에 점점 더 많은 AI 모델이 합성 데이터를 사용하여 훈련되고 있으며, 데이터 합성을 위한 새로운 기법들이 지속적으로 개발되고 있다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **전통적인 데이터 합성 기법 (Traditional Data Synthesis Techniques)** \n",
    "\n",
    "데이터 합성은 AI에만 국한된 개념이 아니다. 소프트웨어 테스트, 게임, 로보틱스 등에서도 오랜 역사를 가지고 있다. 알고리즘을 사용하여 데이터를 생성하는 것은 **절차적 생성(procedural generation)** 이라고 하며, 이는 사람이 직접 데이터를 생성하는 **수작업 생성(manual generation)** 과는 구별된다. 절차적 생성은 주로 게임에서 레벨, 맵, 아이템, 캐릭터 등을 실시간으로 생성하는 데 사용되며, 이러한 데이터 생성 기술은 대부분 AI에도 적용될 수 있다.  \n",
    "\n",
    "전통적으로 데이터 합성과 증강에는 규칙 기반(rule-based) 접근 방식과 시뮬레이션(simulation) 방식이 사용되어 왔다. 최근에는 AI 자체를 활용하여 데이터를 합성하는 새로운 방법이 등장하면서 더 널리 활용되고 있다. 본 섹션에서는 이러한 전통적인 두 가지 데이터 합성 기법을 간략히 살펴본 뒤, 다음 섹션에서 AI 기반 데이터 합성 기법을 다룰 것이다.  \n",
    "\n",
    "**규칙 기반 데이터 합성 (Rule-based data synthesis)**\n",
    "\n",
    "가장 단순한 데이터 생성 방식은 **미리 정의된 규칙 및 템플릿(predefined rules and templates)을 활용하는 것이다**. 예를 들어, 신용카드 거래 데이터를 생성할 때, 거래 템플릿을 만들고 Faker 같은 무작위 생성기를 사용하여 각 필드를 채울 수 있다.  \n",
    "\n",
    "```\n",
    "Transaction ID: [고유 식별자]  \n",
    "Date: [MM/DD/YYYY]  \n",
    "Time: [HH:MM:SS]  \n",
    "Amount: [거래 금액]  \n",
    "Merchant Name: [가맹점/상점명]  \n",
    "Merchant Category: [카테고리 코드]  \n",
    "Location: [도시, 주, 국가]  \n",
    "Payment Method: [신용카드/직불카드/현금/온라인 결제]  \n",
    "Transaction Status: [완료/보류/실패]  \n",
    "Description: [거래 설명]  \n",
    "```\n",
    "\n",
    "금융 거래 데이터는 매우 민감하기 때문에, 많은 사기 탐지 모델들이 실제 데이터를 사용하기 전에 먼저 합성된 거래 데이터를 활용하여 모델의 타당성을 검증하는 과정을 거친다.  \n",
    "\n",
    "템플릿은 특정 구조를 따르는 문서를 생성할 때에도 유용하게 사용된다. 예를 들어, 송장, 이력서, 세금 신고서, 은행 명세서, 일정표, 제품 카탈로그, 계약서, 구성 파일 등의 문서를 생성할 때 템플릿을 사용할 수 있다. 또한, 템플릿은 특정 문법과 구문을 따르는 데이터를 생성하는 데에도 활용될 수 있다. 예를 들어, 정규 표현식이나 수학 방정식을 생성할 수도 있다. DeepMind는 올림피아드 수준의 기하학 모델인 AlphaGeometry를 훈련할 때 1억 개의 합성 예제를 사용했다(Trinh et al., 2024).  \n",
    "\n",
    "기존 데이터를 변형하여 새로운 데이터를 생성하는 방식도 있다. 예를 들어, 이미지 데이터의 경우 회전, 크기 조정, 일부 영역 제거 등의 변형을 적용할 수 있다. 고양이 사진을 좌우 반전해도 여전히 같은 고양이 사진이어야 하며, 축구 경기 장면의 일부를 잘라내더라도 여전히 축구 경기 사진이어야 한다. Krizhevsky et al.(2012)은 전설적인 AlexNet 논문에서 이 기법이 매우 유용함을 증명했으며, 이를 활용하여 ImageNet 데이터셋을 증강했다(Deng et al., 2009).  \n",
    "\n",
    "텍스트 데이터의 경우, 기존 문장에서 특정 단어를 비슷한 의미의 단어로 무작위 대체하는 방식이 가능하다. 단, 의미나 문장의 감정을 유지할 수 있어야 한다. 예를 들어, \"She’s a fantastic nurse.\"라는 문장을 \"She’s a great nurse.\"로 변형할 수 있다.  \n",
    "\n",
    "이러한 기법을 활용하면 데이터에 존재할 수 있는 잠재적 편향을 완화할 수도 있다. 예를 들어, 성별 편향이 우려되는 경우, \"nurse(간호사)\"라는 단어가 여성과 연관되는 반면 \"doctor(의사)\"라는 단어는 남성과 연관될 가능성이 있다. 이를 해결하기 위해 \"she\"를 \"he\"로, \"nurse\"를 \"doctor\"로 대체할 수 있다.  \n",
    "\n",
    "**Table 8-2: 데이터 증강을 통한 편향 완화**  \n",
    "\n",
    "| 원본 데이터 | 변형된 데이터 |  \n",
    "|------------|------------|  \n",
    "| She’s a fantastic nurse. | He’s a fantastic nurse. |  \n",
    "| | She’s a fantastic doctor. |  \n",
    "| The CEO of the firm, Mr. Alex Wang, … | The CEO of the firm, Ms. Alexa Wang, … |  \n",
    "| Today, my mom made a casserole for dinner. | Today, my dad made a casserole for dinner. |  \n",
    "| Emily has always loved the violin. | Mohammed has always loved the violin. |  \n",
    "\n",
    "이와 같은 단어 대체 기법은 사전을 이용하여 동의어를 찾거나, 단어 임베딩을 활용하여 유사한 단어를 찾는 방식으로 적용할 수 있다. 단순한 단어 치환을 넘어서, AI가 문장을 재구성하거나 번역하도록 요청하는 방식도 활용될 수 있다.  \n",
    "\n",
    "또 다른 흥미로운 변형 방식은 기존 데이터에 약간의 노이즈를 추가하는 것이다. 연구자들은 데이터 샘플을 미세하게 변형하면 AI 모델이 잘못된 분류를 하도록 속일 수 있음을 발견했다. 예를 들어, 배경에 작은 화이트 노이즈를 추가하면 배(ship) 사진이 자동차(car)로 잘못 분류될 수도 있다.  \n",
    "\n",
    "Su et al.(2017)의 \"One Pixel Attack for Fooling Deep Neural Networks\" 논문에서는 Kaggle CIFAR-10 테스트 데이터셋의 67.97%와 ImageNet 테스트 데이터셋의 16.04%가 단 한 개의 픽셀 변경만으로도 잘못 분류될 수 있음을 증명했다. 이러한 현상은 보안적인 측면에서 큰 위험이 될 수 있다. 공격자가 AI 모델을 속여 특정 사용자를 승인된 직원으로 인식하게 만들거나, 자율주행 자동차가 차선을 잘못 인식하여 사고를 유발하도록 조작할 가능성이 존재한다.\n",
    "\n",
    "교란된 데이터로 모델을 훈련시킬 수 있다. 교란은 모델의 성능을 향상시키고 공격에 대해 더 강건하게 만들 수 있다(Goodfellow et al., 2013 및 Moosavi-Dezfooli et al., 2015 참조). 2019년 Hendrycks와 Dietterich는 ImageNet 이미지에 밝기 변경, 눈 효과 추가, 대비 변경, 노이즈 추가 등 15가지 일반적인 시각적 왜곡을 적용하여 ImageNet-C와 ImageNet-P를 만들었다.\n",
    "\n",
    "교란은 텍스트에도 적용될 수 있다. 예를 들어, BERT를 훈련할 때 저자들은 토큰의 1.5%를 무작위 단어로 대체했다(Devlin et al., 2018). 이러한 교란이 성능을 약간 향상시키는 것으로 나타났다.\n",
    " \n",
    "시각적 데이터는 더 정교한 알고리즘을 사용하여 증강할 수 있다. Snap(2022)은 데이터의 암묵적 편향을 완화하고 대표되지 않은 엣지 케이스를 생성하기 위해 자산을 어떻게 증강하는지에 대한 훌륭한 사례 연구를 보여준다. 주어진 캐릭터에 대해, 그들은 피부색, 체형, 헤어스타일, 의상, 심지어 표정까지 다양하게 변형된 유사한 캐릭터들을 합성한다. 이렇게 증강된 자산들은 AI 모델을 훈련하는 데 사용된다.\n",
    "\n",
    "**시뮬레이션 (Simulation)**\n",
    "\n",
    "실제 환경에서 데이터를 수집하기 위해 실험을 수행하는 대신, 비용이 많이 들거나 위험한 상황에서는 시뮬레이션을 사용할 수 있다. 예를 들어, 자율주행 차량이 고속도로에서 말과 마주칠 경우 어떻게 반응하는지 실험하고 싶다고 가정해 보자. 실제로 고속도로에 말을 풀어놓고 테스트하는 것은 위험할 것이다. 대신, 이러한 상황을 가상 환경에서 시뮬레이션할 수 있다. 자율주행 시뮬레이션 엔진의 예로는 CARLA (Dosovitskiy et al., 2017), Waymo의 **SimulationCity**, Tesla의 **샌프란시스코 시뮬레이션**이 있다.  \n",
    "\n",
    "마찬가지로, 로봇이 커피를 따르는 동작을 학습하도록 훈련하고 싶다고 가정해 보자. 각 관절이 어떤 방식으로 움직여야 성공적으로 커피를 따를 수 있는지 정확히 알지 못할 수 있다. 이 경우, 다양한 관절 움직임을 시뮬레이션하고, 커피 따르기가 성공적으로 이루어진 경우만 선별하여 로봇 훈련에 사용할 수 있다.  \n",
    "\n",
    "시뮬레이션을 활용하면 비교적 저렴한 비용으로 여러 번의 실험을 수행할 수 있으며, 실제 환경에서 발생할 수 있는 사고나 물리적 손상을 피할 수 있다. 그러나 시뮬레이션에서 성공한 로봇이 반드시 실제 환경에서도 성공하는 것은 아니다. 반대로, 시뮬레이션에서 실패한 로봇은 실제 환경에서도 실패할 가능성이 높다. 시뮬레이션이 아무리 정교하더라도 현실의 단순화된 모델에 불과하다는 점을 염두에 두어야 한다. **Sim2Real**은 시뮬레이션에서 훈련된 알고리즘을 실제 환경으로 적용하는 연구 분야이다.  \n",
    "\n",
    "시뮬레이션은 AI 모델이 도구 사용법을 학습하는 데도 활용된다. 앞서 언급했듯이, 인간이 수행하는 행동이 AI에게 반드시 가장 효율적인 것은 아니다. 시뮬레이션은 인간이 간과할 수 있는 행동을 탐색할 수 있도록 돕는다. 주어진 질의(query)에 대해 다양한 행동을 시뮬레이션하고, 각 행동의 결과를 검증한 후 가장 효율적인 행동 순서를 선택할 수 있다. 이 최적의 행동 순서는 이후 해당 질의에 대한 AI 모델의 응답으로 사용된다.  \n",
    "\n",
    "시뮬레이션은 특히 드문 사건(rare events)의 데이터를 생성하는 데 유용하다. 예를 들어, 금융 분야에서는 기업이 성공적으로 상장(IPO)하거나 대규모 파산을 겪는 시나리오를 시뮬레이션하여 시장 영향을 연구할 수 있다. 제조업에서는 재료나 조립 과정에서 발생할 수 있는 결함을 시뮬레이션하여 데이터셋을 구축하고, 이를 통해 이상 탐지(anomaly detection) 및 품질 관리 모델을 훈련할 수 있다. 기후 과학자들은 지구의 대기 시스템을 시뮬레이션하여 온도 변화, 강수 패턴, 극한 기후 시나리오를 생성할 수 있다. 이러한 합성 데이터는 이후 AI 모델의 훈련에 사용되며, 다양한 기후 변화 시나리오에 대한 예측력을 향상시킨다.  \n",
    "\n",
    "규칙 기반 및 시뮬레이션 기반 기술은 여러 분야에서 유용하게 사용되어 왔다. 그러나 AI가 더 정교한 현실적이고 고품질의 데이터를 생성할 수 있게 되면서, 데이터 합성이 본격적으로 확산되었다. 이제 AI를 활용한 데이터 합성 기법에 대해 살펴보자.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AI 기반 데이터 합성 (AI-Powered Data Synthesis)**\n",
    "\n",
    "인간이 데이터를 생성할 수 있는 방법이 무수히 많은 것처럼, AI 또한 다양한 방식으로 데이터를 생성할 수 있다. 여기서 다루는 기법들은 포괄적인 목록이 아니지만, AI를 활용한 데이터 합성의 개요를 이해하는 데 도움이 될 것이다.  \n",
    "\n",
    "*강력한 AI 모델은 다양한 시뮬레이션을 가능하게 한다.* AI는 임의의 프로그램 실행 결과를 시뮬레이션할 수 있다. 예를 들어, **StableToolBench** (Guo et al., 2024)는 AI를 사용하여 실제 API를 호출하지 않고도 API의 동작을 시뮬레이션하는 방법을 보여준다. 특정 AI 모델이 API와 상호작용하도록 훈련하고 싶다고 가정해 보자. 이때 실제 API를 호출하는 대신 AI 모델이 예상되는 결과를 시뮬레이션할 수 있다. 이는 실제 API 호출이 비용이 많이 들거나 속도가 느려지는 문제를 방지할 수 있는 방법이다.  \n",
    "\n",
    "AI는 인간의 행동을 시뮬레이션할 수도 있다. 예를 들어, 체스를 두는 AI 봇을 훈련하고 싶다고 가정해 보자. 인간과 대국하는 경우 한 판을 두는 데 시간이 오래 걸릴 수 있다. 그러나 AI와 AI가 서로 대국하면 훨씬 빠르게 학습할 수 있다. OpenAI는 **Dota 2** AI 봇을 훈련할 때, 하루에 **약 180년 치의 게임 데이터를 학습할 수 있는 시뮬레이터**를 활용했다. 해당 AI 모델은 **self-play(자기 플레이)** 라는 기법을 사용하여 스스로 대전하면서 점진적으로 전략을 개선해 나갔다 (OpenAI, 2019).  \n",
    "\n",
    "유사하게, DeepMind는 **AlphaGo** 모델을 훈련할 때 **수백만 번의 바둑 게임을 자체 시뮬레이션**하는 방식으로 데이터를 생성하고 학습을 진행했다 (Silver et al., 2016).\n",
    "\n",
    "Self-play는 단순히 게임 봇뿐만 아니라 일반적인 에이전트(agent)에서도 유용하게 활용될 수 있다. 예를 들어, AI가 서로 협상하도록 설정한 후, 각기 다른 전략을 사용하여 어떤 전략이 더 효과적인지 비교할 수 있다. 또는 한 AI 모델이 고객으로, 다른 AI 모델이 고객 지원 담당자로 역할을 나누어 상호 작용할 수도 있다.  \n",
    "\n",
    "**AI의 패러프레이징(paraphrasing) 및 번역(translation) 능력을 활용하여 기존 데이터셋을 증강할 수 있다.** 예를 들어, \"How to reset my password?\"라는 질의가 주어졌을 때, AI는 이를 다음과 같이 변형할 수 있다.  \n",
    "\n",
    "1. \"I forgot my password.\"  \n",
    "2. \"How can I change my password?\"  \n",
    "3. \"Steps to reset passwords.\"  \n",
    "\n",
    "Yu et al. (2023)은 MATH 및 GSM-8K 데이터셋의 15,000개 예제를 다양한 방식으로 변환하여 MetaMath라는 새로운 데이터셋을 생성했다. 이 새로운 데이터셋은 총 40만 개의 예제로 확장되었으며, 이 데이터를 기반으로 훈련된 모델이 기존 벤치마크에서 더 큰 모델보다 우수한 성능을 보였다.  \n",
    "\n",
    "AI를 활용하여 리소스가 풍부한 언어(온라인에서 더 많이 이용 가능한 언어)의 데이터를 리소스가 부족한 언어로 번역하는 것도 일반적인 방법이다. 이를 통해 리소스가 적은 언어(예: 케추아어, 라오어)를 위한 소형 모델을 훈련하는 데 활용할 수 있다.  \n",
    "\n",
    "번역의 품질을 검증하는 방법 중 하나로 **역번역(back-translation)** 이 있다. 예를 들어, 원문 영어 문장을 X라 하고, 이를 번역한 라오어 문장을 Y라 하자. 다른 AI 모델을 사용하여 다시 Y를 영어로 번역한 문장을 X'라고 할 수 있다. 이후 X'와 원본 문장 X를 비교했을 때, 차이가 크다면 번역된 문장 Y가 부정확할 가능성이 높다.  \n",
    "\n",
    "AI는 자연어뿐만 아니라 프로그래밍 언어도 번역할 수 있다. 예를 들어, AI를 사용하여 한 프로그래밍 언어로 작성된 코드를 다른 언어로 변환할 수 있다. **Llama 3 연구진**은 SFT 데이터셋의 코드 번역을 다양한 프로그래밍 언어로 확장했다. 실제로 Llama 3 모델의 훈련 과정은 합성 데이터에 크게 의존하고 있으며, 연구진들은 유용한 데이터를 생성하기 위해 많은 창의적인 기법들을 적용했다.  \n",
    "\n",
    "예를 들어, AI를 사용하여 코드 스니펫(code snippet)에서 코드 설명 및 문서를 생성한 뒤, 다시 AI를 활용하여 이 문서에서 코드 스니펫을 재생성할 수도 있다. 이때, 재생성된 코드가 원본 코드와 충분히 유사할 경우에만 해당 설명 및 문서를 데이터셋에 포함시켜 모델을 훈련할 수 있다.  \n",
    "\n",
    "AI는 사전 훈련(pre-training)과 사후 훈련(post-training) 데이터 모두를 생성할 수 있지만, 합성 데이터는 의도적으로 사후 훈련에서 훨씬 더 많이 사용된다. 그 이유 중 하나는 사전 훈련의 목표가 모델의 지식을 확장하는 것인 반면, 사후 훈련은 기존 지식을 조정하는 것이기 때문이다. 즉, AI가 이미 존재하는 데이터를 다양한 형식으로 합성하는 것은 가능하지만, 완전히 새로운 지식을 합성하는 것은 더 어려울 수 있다.  \n",
    "\n",
    "그러나 인터넷에서 생성된 콘텐츠가 넘쳐나면서, 오직 인터넷 데이터에만 의존하는 모델들은 이미 기존의 합성 데이터에 의해 학습된 경우가 많다. 예를 들어, **Cosmopedia (Allal et al., 2024)** 는 250억 개의 데이터로 구성된 합성 데이터셋이며, **Mixtal-8x7B-Instruct-v0.1 (Jiang et al., 2024)** 는 합성된 교과서, 블로그 게시물, 스토리, 시, WikiHow 글들로 이루어져 있다.  \n",
    "\n",
    "사후 훈련을 위한 데이터 합성은 특히 선호도 조정(preference tuning) 및 인간 피드백 학습에 더욱 흔히 사용된다. 예를 들어, AI가 여러 응답 중 가장 선호되는 응답을 선택하도록 학습시키는 것은 **Chapter 3**에서 설명한 RLHF(강화 학습 기반 인간 피드백)과 관련이 있다. 그러나 이러한 과정에서 가장 어려운 점은 모델이 특정 응답을 선호하는 **위치 편향(first-position bias)** 을 가지는 경향이 있다는 것이다. 즉, 모델이 처음 등장한 응답을 더 선호할 가능성이 높다. 이를 방지하기 위해 **NVIDIA 연구진(NVIDIA, 2024)** 은 AI 판사가 같은 응답을 두 번 평가하도록 설정하고, 두 번째 평가에서는 응답의 순서를 바꿔 제시했다. 이후, AI 판사가 같은 응답을 선택한 경우에만 해당 데이터를 유효한 학습 데이터로 사용하도록 설정했다.  \n",
    "\n",
    "다음 섹션에서는 AI를 활용하여 감독 학습(supervised finetuning)을 위한 합성 데이터를 생성하는 방법을 살펴볼 것이다.\n",
    "\n",
    "**명령어 데이터 합성 (Instruction Data Synthesis)**\n",
    "\n",
    "명령어 미세 조정(instruction finetuning) 과정에서는 각 예제가 **명령어(instruction)와 응답(response)** 을 포함한다. AI는 명령어, 응답 또는 둘 다를 합성하는 데 사용할 수 있다. 예를 들어, AI를 이용하여 명령어를 생성하고 사람이 응답을 작성하도록 하거나, 반대로 사람이 명령어를 작성하고 AI가 응답을 생성할 수도 있다.  \n",
    "\n",
    "- **명령어 생성(instruction generation):** 특정 사용 사례를 충분히 포함할 수 있도록 명령어를 생성하려면, 먼저 데이터셋에 포함할 주제 목록, 키워드 또는 명령어 유형을 정의할 수 있다. 그런 다음, 이 목록에 있는 각 항목에 대해 템플릿을 생성하고 해당 템플릿을 기반으로 일정 개수의 명령어를 생성한다. 참고로, 이 과정에서 사용되는 **주제 목록과 템플릿 자체도 AI가 생성할 수 있다.**  \n",
    "\n",
    "- **응답 생성(response generation):** 하나의 명령어에 대해 하나 이상의 응답을 생성할 수 있다.  \n",
    "\n",
    "예를 들어, **UltraChat** (Ding et al., 2023)이라는 다중 턴(multi-turn) 대화 데이터셋을 생성하기 위해 연구진은 먼저 ChatGPT에게 **30개의 주제**를 생성하도록 요청했다. 이러한 주제들은 기술(technology), 음식과 음료(food and drink), 패션(fashion), 자연(nature), 교육(education), 금융(finance), 여행(travel) 등 다양한 일상적 영역을 포함했다. 이후, 연구진은 각 주제에 대해 ChatGPT가 **30~50개의 하위 주제(subtopics)** 를 생성하도록 했으며, 같은 모델을 사용하여 해당 하위 주제에 대한 **명령어와 대응되는 응답**을 생성했다.  \n",
    "\n",
    "유사하게, **Alpaca** (Taori et al., 2023) 모델을 훈련하기 위해 **Stanford 연구진**은 **Self-Instruct 시드 데이터셋**에서 **175개의 (명령어, 응답) 예제** 를 가져와 사용했다 (Wang et al., 2022). 해당 예제들은 다양한 활용 사례를 반영하도록 작성되었으며, 연구진은 이후 **GPT-3 모델(text-davinci-003)** 을 이용하여 **52,000개의 (명령어, 응답) 쌍을 추가적으로 생성** 했다. 이 과정은 **Figure 8-5** 에 시각적으로 나타나 있다.\n",
    "\n",
    "<img src=\"./images/fig_08_05.png\" width=\"800\">\n",
    "\n",
    "명령어 데이터를 합성하는 방법에는 다양한 창의적인 접근 방식이 있다. 예를 들어, 사람이 긴 콘텐츠를 작성하는 것이 짧은 콘텐츠를 작성하는 것보다 더 어려운 것처럼, AI가 고품질의 긴 응답을 생성하는 것도 짧은 명령어를 생성하는 것보다 더 어렵다. 응답이 길어질수록 AI가 환각(hallucination)을 일으킬 가능성이 높아진다. 그렇다면 **AI가 생성한 명령어에 대해 사람이 작성한 응답을 사용하는 방법은 어떨까?** Köksal et al. (2023), Li et al. (2023), Chen et al. (2023) 등의 연구자들은 **역방향 명령어(reverse instruction)** 접근 방식을 따른다. 이 방법은 이야기, 책, 위키피디아 문서와 같은 기존의 장문(high-quality long-form) 콘텐츠를 가져와 AI가 **해당 콘텐츠를 유도할 수 있는 명령어를 생성하도록 하는 방식**이다. 이를 통해 AI가 생성한 응답에서 발생할 수 있는 환각을 방지하면서도, **더 높은 품질의 명령어 데이터를 얻을 수 있다.**  \n",
    "\n",
    "또한, Li et al. (2023)은 **수작업으로 주석을 달지 않고도 점점 더 강력한 모델을 개발할 수 있는 역방향 명령어 방법**을 제안했다. 해당 방법의 과정은 다음과 같다.  \n",
    "\n",
    "1. 소량의 시드(seed) 예제를 사용하여 약한(weak) 모델을 훈련한다.  \n",
    "2. 이 약한 모델을 이용해 기존 고품질 콘텐츠에 대한 명령어를 생성하여 **고품질 명령어 데이터**를 만든다.  \n",
    "3. 새로 생성한 **고품질 명령어 데이터**를 사용하여 **약한 모델을 다시 미세 조정(finetuning)** 한다.  \n",
    "4. 원하는 성능이 나올 때까지 이 과정을 반복한다.  \n",
    "\n",
    "또 다른 창의적인 방법으로는 **긴 컨텍스트(long context) 이해를 위한 미세 조정(finetuning) 과정에서 합성 데이터(synthetic data)를 활용하는 것** 이다. 예를 들어, 현재 모델이 최대 **8K 토큰**을 처리할 수 있지만, **128K 토큰**을 처리하도록 만들고 싶다면, 다음과 같은 긴 컨텍스트 미세 조정 과정을 사용할 수 있다.  \n",
    "\n",
    "- 긴 문서를 **8K 토큰 이하의 짧은 청크(chunks)** 로 나눈다.  \n",
    "- 각 짧은 청크에 대해 **여러 개의 (질문, 답변) 쌍** 을 생성한다.  \n",
    "- 각 (질문, 답변) 쌍에서, 원본 긴 문서를 그대로 유지하지만, 질문의 길이는 모델이 처리할 수 있도록 조정한다. 이를 통해 모델이 **확장된(longer) 컨텍스트를 활용하여 질문에 답하는 방법을 학습** 하도록 만든다.\n",
    "\n",
    "Llama 3 논문(Dubey et al., 2024)의 세부 사항은 명령어 데이터 합성(instruction data synthesis)에 대한 훌륭한 사례 연구를 제공합니다. 이전에 Llama 3가 코드 번역(code translation) 및 코드 역번역(code back-translation)을 통해 합성 데이터를 생성하는 두 가지 방법을 설명한 바 있습니다. 이 두 가지 방법은 기존 코드 스니펫에서 더 많은 데이터를 생성합니다. 그러나 저자는 또한 AI를 사용하여 처음부터 코드 명령어 데이터를 합성하는 방법도 활용했습니다. 이 과정은 다음과 같습니다.\n",
    "\n",
    "1. AI를 사용하여 다양한 범주의 프로그래밍 문제 설명을 대량으로 생성합니다.\n",
    "2. 문제 설명과 프로그래밍 언어가 주어졌을 때, 해결책을 생성합니다. Dubey et al.은 일반적인 프로그래밍 규칙과 CoT(reasoning through chain-of-thought) 추론을 포함하는 것이 응답 품질을 향상시키는 데 도움이 된다는 사실을 발견했습니다.\n",
    "\n",
    "생성된 데이터의 품질을 보장하기 위해 엄격한 정확성 분석 및 오류 수정 파이프라인을 적용했습니다.\n",
    "\n",
    "1. 생성된 코드를 구문 분석기(parser) 및 린터(linter)를 통해 실행하여 누락된 import 문이나 초기화되지 않은 변수와 같은 구문 오류(syntactic errors)를 감지합니다.\n",
    "2. 유닛 테스트(unit test)를 사용하여 런타임 실행 오류(runtime execution errors)를 검사합니다. 흥미롭게도 연구진은 이 유닛 테스트조차도 AI를 사용하여 생성했습니다.\n",
    "3. 해결책이 어느 단계에서든 실패하면, 모델이 해당 코드를 수정하도록 프롬프트합니다. 프롬프트에는 원래의 문제 설명, 오류가 있는 해결책, 구문 분석기, 린터 및 유닛 테스트에서 반환된 피드백이 포함됩니다. 모든 검사를 통과한 경우에만 최종 지도 미세 조정(supervised finetuning) 데이터셋에 포함됩니다.\n",
    "\n",
    "코드 번역, 코드 역번역 및 코드 생성이라는 세 가지 방법을 결합한 Llama 3의 데이터 합성 워크플로우는 상당히 인상적입니다. 이 세 가지 방법이 함께 작동하는 방식을 요약하면 다음과 같습니다.\n",
    "\n",
    "1. AI를 사용하여 문제 설명을 생성합니다.\n",
    "2. AI를 사용하여 각 문제에 대한 해결책을 다양한 프로그래밍 언어로 생성합니다.\n",
    "3. AI를 사용하여 생성된 코드를 테스트할 유닛 테스트를 생성합니다.\n",
    "4. AI에게 생성된 코드의 오류를 찾도록 프롬프트합니다.\n",
    "5. AI를 사용하여 생성된 코드를 다양한 프로그래밍 언어로 번역합니다. 테스트를 통과하지 않은 번역된 코드는 제외합니다.\n",
    "6. AI를 사용하여 코드에 대한 대화를 생성하고 코드 설명과 문서를 추가합니다. 역번역(back-translation) 검증을 통과하지 않은 코드 설명 및 문서는 제외합니다.\n",
    "\n",
    "이러한 파이프라인을 활용하여 Dubey et al. 연구진은 지도 미세 조정을 위한 270만 개 이상의 합성 코드 관련 예제를 생성할 수 있었습니다.\n",
    "\n",
    "**데이터 검증(Data verification)**\n",
    "\n",
    "모델의 성능에서 데이터 품질의 중요성을 고려할 때, 데이터를 검증하는 방법이 반드시 필요합니다. AI가 생성한 데이터의 품질은 다른 AI 출력물을 평가하는 것과 동일한 방식으로 측정할 수 있으며, 기능적 정확성(functional correctness) 및 AI 심사(AI judges)를 통해 평가할 수 있습니다.\n",
    "\n",
    "이 섹션에서는 합성 데이터에 초점을 맞추지만, 대부분의 기술은 일반적인 훈련 데이터의 품질을 평가하는 데 사용할 수 있습니다.\n",
    "\n",
    "Chapter 4에서 설명한 평가 주도 개발(evaluation-driven development) 개념을 다시 떠올려 보면, 기업이 평가 가능한 애플리케이션을 더 많이 구축하는 경향이 있다는 점을 알 수 있습니다. 마찬가지로 사람들은 합성 데이터를 신뢰하기보다는 평가하려는 경향이 있습니다. 코딩은 가장 인기 있는 기초 모델(foundation model) 사용 사례 중 하나로, 기능적으로 평가할 수 있기 때문에 코딩 관련 예제는 가장 일반적인 합성 데이터 유형이 됩니다. Llama 3를 훈련하는 데 사용된 합성 데이터의 대부분은 코드 관련 데이터였습니다. 연구진이 합성 데이터를 생성하는 데 사용한 세 가지 방법은 모두 데이터가 프로그래밍적으로 검증될 수 있도록 합니다. 예를 들어, 코드 실행과 역번역을 통해 데이터가 검증됩니다.\n",
    "\n",
    "기능적으로 검증할 수 없는 합성 데이터의 경우, AI 검증기(AI verifiers)를 사용하는 것이 일반적입니다. AI 검증기는 범용 AI 심사 모델(general-purpose AI judge) 또는 특정 목적을 가진 검증기(specialized scorer)일 수 있습니다. 데이터 검증 문제를 다루는 다양한 방식이 존재합니다. 가장 단순한 형태로 AI 검증기는 각 생성된 예제에 대해 1점에서 5점까지의 점수를 할당하거나, 각 예제를 좋은 데이터인지 나쁜 데이터인지 분류할 수 있습니다. 또한, 기초 모델이 품질 요구 사항을 이해하도록 학습시키고, 데이터 예제가 이러한 요구 사항을 충족하는지 확인하도록 모델을 프롬프트할 수도 있습니다.\n",
    "\n",
    "데이터의 사실적 일관성을 검증하고자 한다면, Chapter 4에서 논의된 사실적 일관성 탐지 기법(factual inconsistency detection techniques)을 활용할 수 있습니다. 이러한 기술을 사용하면 환각(hallucination) 가능성이 높은 데이터 예제를 필터링할 수 있습니다.\n",
    "\n",
    "사용 사례와 생성된 데이터 유형에 따라 창의적인 방법을 사용할 수도 있습니다. 예를 들어, 합성 데이터가 실제 데이터를 모방하도록 하려면, 두 데이터를 구별하는 것이 얼마나 어려운지를 측정하여 품질을 평가할 수 있습니다. AI 콘텐츠 감지기를 훈련시켜 AI가 생성한 데이터를 식별할 수 있도록 할 수 있습니다. 만약 실제 데이터와 합성 데이터를 쉽게 구별할 수 있다면, 해당 합성 데이터는 품질이 낮은 것입니다. 또는, 합성 데이터를 고품질의 학술 논문처럼 만들고 싶다면, 생성된 논문이 NeurIPS(신경정보처리시스템 학술대회) 같은 권위 있는 학술대회에서 채택될 가능성을 예측하는 분류 모델을 훈련할 수 있습니다. 그런 다음, 명백한 거절 대상이 될 논문을 걸러낼 수 있습니다.  \n",
    "\n",
    "모델을 활용하여 생성된 각 예제의 주제를 감지하고, 주제와 관련 없는 예제를 제거할 수도 있습니다. 만약 모든 데이터가 유사한 패턴을 따라야 한다고 예상된다면, 이상 탐지 기법을 활용해 이상값을 식별할 수도 있습니다. 이상값 예제는 저품질일 가능성이 큽니다.  \n",
    "\n",
    "실제 데이터와 마찬가지로 합성 데이터도 휴리스틱(경험적 규칙)을 사용하여 필터링할 수 있습니다. 일반적으로, 너무 짧거나 빈 내용이 포함된 예제는 제거하는 것이 바람직합니다. 너무 긴 예제는 일부를 잘라내거나 제거할 수도 있습니다. 또한, 키워드, 사용자/작성자, 생성 날짜, 메타데이터, 출처 등에 따라 데이터를 필터링할 수도 있습니다. 예를 들어, **Self-Instruct** 연구(Wang et al., 2022)에서는 다음과 같은 휴리스틱을 이용해 생성된 예제를 필터링했습니다.  \n",
    "\n",
    "- 반복적인 예제  \n",
    "- 너무 길거나 너무 짧은 지시문  \n",
    "- 동일한 지시문을 사용했지만 다른 응답이 있는 경우  \n",
    "- 입력을 단순히 반복한 예제  \n",
    "\n",
    "합성 데이터를 평가하는 방법은 많지만, 평가 자체는 여전히 어려운 문제로 남아 있습니다. 다른 AI 응용 프로그램과 마찬가지로, AI가 생성한 데이터의 최종적인 품질 테스트는 실전에서의 성능입니다. 즉, 모델의 성능을 향상시키는 데 기여할 수 있는지가 핵심이며, 많은 모델이 이 테스트를 통과한 바 있습니다.  \n",
    "\n",
    "**AI 생성 데이터의 한계**\n",
    "\n",
    "합성 데이터의 유용성이 증가함에 따라, 인간이 직접 주석을 단 데이터가 더 이상 필요하지 않을 수도 있다는 가능성이 점점 현실적으로 다가오고 있습니다. 그러나 합성 데이터의 역할이 시간이 지나면서 더욱 커질 것이라 해도, 인간이 생성한 데이터를 완전히 대체할 수는 없습니다. 그 이유는 여러 가지가 있지만, 주요한 네 가지 이유는 다음과 같습니다.  \n",
    "\n",
    "**품질 관리**\n",
    "\n",
    "AI가 생성한 데이터는 품질이 낮을 수 있으며, 흔히 말하는 \"Garbage in, garbage out(쓰레기가 들어가면, 쓰레기가 나온다)\" 원칙이 그대로 적용됩니다. 앞서 언급했듯이, 사람들이 합성 데이터를 신뢰하려면 데이터의 품질을 검증할 수 있어야 합니다. 따라서 신뢰할 수 있는 평가 방법과 기준을 마련하는 것이 필수적입니다.  \n",
    "\n",
    "**피상적인 모방**\n",
    "\n",
    "**\"독점적인 LLM을 모방하는 것의 허상\"** (Guidbanche et al., 2023) 연구에서는, 합성 데이터가 원본 모델의 스타일을 모방하는 것처럼 보일 수 있지만, 실제 데이터가 가진 사실 관계나 일반화 능력을 충분히 학습하지 못할 가능성이 있다고 경고하고 있습니다.  \n",
    "\n",
    "더 나아가, 모방이 오히려 모델의 환각(hallucination)을 유발할 수도 있습니다. 예를 들어, 교사 모델이 복잡한 수학 문제를 해결할 수 있다고 가정해 보겠습니다. 학생 모델이 이 문제의 답만 학습하게 된다면, 실제로는 문제를 해결하는 능력을 기르지 못한 채 \"정답을 그대로 따라 하는\" 수준에 머물게 됩니다. **Guidbanche et al.(2023)** 연구에서는, 추론 능력을 향상시키기 위해서는 원본 모델의 품질을 높이는 것이 더욱 중요하다고 강조하고 있습니다.  \n",
    "\n",
    "**모델 붕괴 가능성**\n",
    "\n",
    "AI가 생성한 데이터로 AI 모델을 반복적으로 훈련할 경우, 성능이 점점 더 악화될 가능성이 있습니다. 일부 연구에서는 AI가 생성한 데이터를 반복적으로 사용할 경우 **비가역적인 결함(irreversible defects)** 이 발생할 수 있으며, 모델의 성능이 장기적으로 저하될 수 있다고 보고하고 있습니다. **\"생성된 데이터로 훈련하면 모델이 망각한다\"** (Shumailov et al., 2023) 연구에서는 이러한 현상을 **모델 붕괴(model collapse)** 라고 명명하였습니다. 연구에서는 Variational Autoencoders, Gaussian mixture models, LLMs 등 다양한 모델에서 모델 붕괴가 발생하는 사례를 확인하였으며, 이는 **사전 훈련(pre-training)과 후속 훈련(post-training)** 과정에서 모두 발생할 수 있다고 경고하고 있습니다.  \n",
    "\n",
    "AI 모델이 확률적으로 발생 가능성이 높은 이벤트(예: 암에 걸리지 않음)는 더 자주 생성하지만, 발생 가능성이 낮은 이벤트(예: 암에 걸림)는 덜 생성하는 경향이 있다는 것이 하나의 가능한 설명입니다. 여러 번의 반복을 거치면서, 발생 가능성이 높은 이벤트는 과대 대표되고, 반대로 발생 가능성이 낮은 이벤트는 생성된 데이터에서 점차 과소 대표됩니다. 이로 인해 모델이 시간이 지나면서 보다 일반적인 이벤트를 출력하는 경향이 강해지고, 희귀한 이벤트를 잊어버리는 문제가 발생합니다.\n",
    "\n",
    "**\"모델 붕괴는 피할 수 없는가?\"**(Gerstgrasser et al., 2024) 연구에서는, 훈련 데이터셋 전체가 합성 데이터일 경우 모델 붕괴가 불가피하지만, 합성 데이터와 실제 데이터를 혼합하면 이를 방지할 수 있다고 주장합니다. **Bertrand et al. (2023)** 및 **Dohmatob et al. (2024)** 또한 유사한 결과를 보였습니다. 하지만, 이들 연구 중 어느 것도 합성 데이터와 실제 데이터를 어느 비율로 혼합해야 하는지에 대한 명확한 권고안을 제시하지는 않았습니다.\n",
    "\n",
    "일부 연구에서는 대량의 합성 데이터를 사용하여 모델 성능을 향상시킬 수 있음을 보여주었습니다. 예를 들어, **\"Common 7B Language Models Already Possess Strong Math Capabilities\"** (Li et al., 2024) 연구는 Llama 2-7B 모델을 수학 문제에 대해 파인튜닝할 때, 합성 데이터가 실제 데이터만큼 효과적일 수 있음을 입증하였습니다. 실험 결과, 합성 데이터를 약 백만 개 샘플까지 확장했을 때도 성능이 포화되지 않았습니다. 비슷하게, **NVIDIA의 Nemotron-4 340B-Instruct(2024)** 모델은 **지시문 파인튜닝(instruction finetuning)과 선호도 파인튜닝(preference finetuning) 과정에서 98%의 합성 데이터를 사용** 하였습니다. 그러나 이러한 실험들은 단 한 번의 모델 반복(iteration)만을 수행한 것이기 때문에 추가적인 검증이 필요합니다.\n",
    "\n",
    "AI가 생성한 데이터는 기존의 편향을 지속시키거나 심지어 증폭할 수도 있습니다. **\"Data Feedback Loops: Model-driven Amplification of Dataset Biases\"** (Taori and Hashimoto, 2023) 연구에서는, 이전 모델이 생성한 데이터를 포함하는 데이터셋으로 모델을 훈련할 경우 기존에 존재하는 편향이 모델 내에서 더욱 강화될 수 있음을 입증하였습니다. 저자들은 모델의 출력이 원래의 훈련 데이터 분포 특성과 일치할수록 피드백 루프(feedback loop)가 더욱 안정적으로 유지되며, 이에 따라 편향 증폭의 위험이 최소화된다고 결론지었습니다.\n",
    "\n",
    "**데이터 출처 불명확성 (Obscure data lineage)**  \n",
    "\n",
    "AI 생성 데이터의 이 제한점은 더 미묘한 문제입니다. AI가 데이터를 생성하면 데이터의 출처(data lineage)가 불명확해집니다. AI 모델은 훈련 데이터의 영향을 받으며, 때때로 학습한 데이터를 사용자도 모르게 그대로 재생산할 수도 있습니다. 이는 몇 가지 위험을 초래할 수 있습니다. 예를 들어, 모델 X를 사용하여 데이터를 생성하고, 이 데이터를 다시 모델 훈련에 활용한다고 가정해 봅시다. 만약 모델 X가 저작권을 위반하는 데이터를 학습했다면, 해당 모델이 생성한 데이터도 저작권을 위반할 가능성이 있습니다.  \n",
    "\n",
    "또한, 모델의 성능을 평가하기 위해 벤치마크 B를 사용한다고 가정해 봅시다. 만약 모델 X가 벤치마크 B 데이터를 일부 학습했다면, 모델 X가 벤치마크 B에서 좋은 성능을 보인다 해도 그 결과는 오염된(contaminated) 것입니다. 명확한 데이터 출처가 없다면, 모델의 상업적 활용 가능성을 평가하거나 그 성능을 신뢰하는 것이 어려워집니다.  \n",
    "\n",
    "우리는 지금까지 AI를 활용한 데이터 생성 방법과 이를 평가하는 방법, 그리고 그 한계에 대해 논의했습니다. 다음 섹션에서는 AI 생성 데이터가 단순한 보조 수단이 아니라 필수적인 역할을 하는 데이터 합성의 한 가지 사례인 **모델 디스틸레이션(model distillation)** 에 대해 살펴보겠습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **모델 디스틸레이션 (Model Distillation)**  \n",
    "\n",
    "**모델 디스틸레이션(model distillation)**(지식 증류(knowledge distillation)라고도 함)은 작은 모델(학생)이 더 큰 모델(교사)을 모방하도록 훈련되는 방법입니다 (**Hinton et al., 2015**). 큰 모델의 지식이 작은 모델로 증류되므로 \"디스틸레이션(distillation)\"이라는 용어가 사용됩니다.  \n",
    "\n",
    "전통적으로, 모델 디스틸레이션의 목표는 배포를 위한 더 작은 모델을 만드는 것입니다. 큰 모델을 배포하는 것은 자원 집약적인 작업이 될 수 있습니다. 디스틸레이션을 통해 성능을 유지하면서도 더 작고 빠른 학생 모델을 만들 수 있습니다. 예를 들어, **DistilBERT**는 BERT 모델에서 디스틸된 모델로, BERT 모델의 크기를 40% 줄이면서도 언어 이해 능력의 97%를 유지하고, 속도는 60% 더 빠릅니다 (**Sanh et al., 2019**).  \n",
    "\n",
    "학생 모델은 **DistilBERT**처럼 처음부터 훈련될 수도 있고, 미리 훈련된 모델을 파인튜닝하여 학습될 수도 있습니다. 예를 들어, **Alpaca**가 그 예시입니다. 2023년, Taori et al.은 Llama-7B(70억 개의 매개변수를 가진 Llama 버전)를 **text-davinci-003**(1750억 개의 매개변수를 가진 모델)이 생성한 예제를 활용하여 파인튜닝하였습니다. 결과적으로 생성된 **Alpaca** 모델은 **text-davinci-003**과 유사한 동작을 보이면서도, 교사 모델의 4% 크기에 불과했습니다.  \n",
    "\n",
    ">**주의 (NOTE)**  \n",
    ">\n",
    ">모든 모델이 디스틸될 수 있는 것은 아닙니다. 많은 모델 라이선스에서는 해당 모델의 출력을 이용해 다른 모델을 훈련하는 것, 특히 경쟁 모델을 훈련하는 것을 금지하고 있습니다.  \n",
    "\n",
    "합성 지시문 데이터(synthetic instruction data)는 일반적으로 **LoRA**와 같은 어댑터 기반 기술과 함께 사용됩니다. 예를 들어, **BuzzFeed**는 **Flan-T5** 모델을 **LoRA** 기법과 OpenAI의 **text-davinci-003**이 생성한 예제를 사용하여 파인튜닝하였습니다. 이 과정에서 결과 모델의 **추론 비용이 80% 감소**했지만, 해당 모델의 성능이 얼마나 좋은지는 명확하지 않았습니다 (**2023**).  \n",
    "\n",
    "그러나 합성 데이터를 사용한 모든 훈련이 모델 디스틸레이션은 아닙니다. 모델 디스틸레이션은 교사 모델의 성능이 학생 모델의 **절대적인 기준(gold standard)** 이 되는 것을 의미합니다. 하지만, 더 크고 강력한 학생 모델을 훈련하는 데에도 합성 데이터를 사용할 수 있습니다.  \n",
    "\n",
    "**역방향 지시문(reverse instruction) 기반의 모델 부트스트래핑(model bootstrapping)** (**Li et al., 2023**)은 그 한 가지 예시입니다. 또 다른 사례는 **NVIDIA의 Nemotron-4**입니다. NVIDIA 연구팀은 먼저 **3400억 개의 매개변수**를 가진 대형 모델을 사전 훈련(pre-training)하였습니다. 그런 다음, **Mixtral-8x7B-Instruct-v0.1** (**Jiang et al., 2024**)이 생성한 **지시문 및 선호도 데이터**를 사용하여 추가 파인튜닝을 수행하였습니다. **Mixtral-8x7B-Instruct-v0.1**은 560억 개의 매개변수를 가진 mixture-of-experts 모델입니다. 결과적으로 생성된 학생 모델인 **Nemotron-4-340B-Instruct**는 다양한 태스크에서 교사 모델보다 뛰어난 성능을 보였습니다 (**NVIDIA, 2024**).  \n",
    "\n",
    "**Llama 3** 논문에서는, 더 뛰어난 모델이 생성한 데이터를 활용한 훈련이 모델 성능을 크게 향상시킬 수 있다고 언급하고 있습니다. 하지만 **무분별하게** AI가 생성한 데이터를 학습하는 것은 모델의 성능을 향상시키지 못할 뿐만 아니라, 오히려 성능을 저하시킬 수도 있습니다. 그러나 **합성 데이터의 품질을 검증하고, 검증된 데이터를 지속적으로 활용하는 메커니즘을 도입함으로써**, 연구진은 **생성된 데이터를 활용하여 모델의 성능을 지속적으로 향상**시킬 수 있었습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **데이터 처리 (Data Processing)**  \n",
    "\n",
    "데이터는 각 사용 사례의 요구 사항에 따라 처리되어야 합니다. 이 섹션에서는 데이터 처리 단계에 대한 몇 가지 참고 사항을 다룹니다.  \n",
    "\n",
    "나는 데이터셋의 세부 정보를 공개하는 연구 논문을 읽는 것이 도움이 된다고 생각합니다. 이러한 논문들은 연구자들이 데이터를 어떻게 선별(curated), 생성(generated), 그리고 처리(processed)했는지에 대한 유용한 팁을 종종 포함하고 있기 때문입니다.  \n",
    "\n",
    ">**TIP**  \n",
    ">\n",
    ">대량의 데이터를 처리하는 경우, 이러한 처리 단계는 몇 시간, 심지어 며칠이 걸릴 수도 있습니다. 다음은 처리 과정에서 효율성을 최적화하는 데 도움이 되는 몇 가지 팁입니다.  \n",
    ">\n",
    ">- **데이터 처리 단계의 순서를 유연하게 조정하세요.** 예를 들어, 개별 데이터를 정제하는 데 중복 제거(deduplication)보다 시간이 더 걸린다면, 중복 데이터를 먼저 제거한 후 정제하는 것이 좋습니다. 하지만 중복 제거가 저품질 데이터를 필터링하는 것보다 시간이 더 걸린다면, 먼저 저품질 데이터를 필터링하는 것이 더 효과적일 수 있습니다.  \n",
    ">\n",
    ">- **스크립트를 전체 데이터에 적용하기 전에 항상 시험 실행(trial run)을 수행하여 올바르게 작동하는지 검증하세요.**  \n",
    ">\n",
    ">- **원본 데이터를 변경하지 않도록 하세요.** 원본 데이터를 보관하는 것이 좋은 이유는 다음과 같습니다.  \n",
    ">  - 다른 팀이 다른 응용 프로그램에서 데이터를 다르게 처리해야 할 수도 있습니다.  \n",
    ">  - 스크립트에 버그가 있을 경우, 원본 데이터가 손상될 위험이 있습니다.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 검사 (Inspect Data)**  \n",
    "\n",
    "공개 데이터와 내부 데이터를 모두 수집한 후 원시(raw) 데이터셋을 얻었다고 가정해 보겠습니다. 가장 먼저 해야 할 일은 데이터를 검사하여 품질을 평가하는 것입니다. 데이터의 정보 및 통계를 확인하세요. 데이터의 출처는 어디인가요? 어떻게 처리되었나요? 이전에 어떤 용도로 사용되었나요?  \n",
    "\n",
    "토큰 분포(token distribution)를 플로팅하여 어떤 토큰이 자주 등장하는지 확인하고, 입력 길이(input lengths), 응답 길이(response lengths) 등의 분포를 분석하세요. 데이터가 특정한 특수 토큰을 사용하는지 확인해 볼 수도 있습니다. 데이터에 포함된 **주제(topic)와 언어(language)** 의 분포를 분석할 수도 있습니다. 이러한 주제와 언어가 해당 작업에 얼마나 관련이 있는지도 평가해야 합니다.  \n",
    "\n",
    "통계를 창의적으로 활용하여 데이터를 이해할 수도 있습니다. 예를 들어, **Microsoft 연구진(2023)** 은 **(동사, 직접 목적어, 명사) 쌍의 분포** 및 **응답 길이(response length)** 를 분석하여 **GPT-3과 GPT-4가 동일한 지시문을 처리할 때 어떤 차이를 보이는지** 비교하였습니다. 이러한 분석 방법은 단순히 데이터를 평가하는 것뿐만 아니라, 모델을 평가하는 데에도 유용할 수 있습니다. 이는 **그림 8-6(Figure 8-6)과 그림 8-7(Figure 8-7)** 에 제시된 바와 같습니다.\n",
    "\n",
    "<img src=\"./images/fig_08_06.png\" width=\"800\">\n",
    "\n",
    "<img src=\"./images/fig_08_07.png\" width=\"800\">\n",
    "\n",
    "GPT-4는 보다 **넓고 다양한 동사-명사 쌍을 포함**하며, 더 긴 응답을 생성하는 경향이 있습니다.  \n",
    "\n",
    "이러한 분포를 **데이터 출처, 시간, 주석자(annotator)** 등에 따라 플로팅해 보세요. 특정 질문 패턴이 더 긴/짧은 응답을 유도하는지 확인할 수 있나요? 높은/낮은 점수를 받는 특정한 패턴이 존재하나요? 이상값(outlier)이 있는가요? 이 이상값이 발생한 원인은 무엇이며, 이를 어떻게 처리해야 할까요?  \n",
    "\n",
    "점수가 정규 분포(normal distribution)를 따라야 한다면, **모든 주석자의 점수가 정규 분포를 따르는지** 확인하세요. 일부 주석자는 평균적으로 더 짧은 응답을 제공하거나 **높은 점수에 편향(bias)** 되는 경향이 있을 수도 있습니다. 이 경우, 해당 주석자의 주석을 어떻게 처리할지 결정해야 합니다.  \n",
    "\n",
    "각 예제에 대해 하나 이상의 주석(annotation)이 존재하는 경우, **주석자 간 불일치(inter-annotator disagreement)** 를 계산하세요. **충돌하는 주석이 포함된 예제를 확인하고 이를 해결해야 합니다.**  \n",
    "\n",
    "데이터 탐색을 위한 많은 도구들이 존재하지만, **수동 데이터 검사는 그 무엇으로도 대체될 수 없습니다.** 내가 참여한 모든 프로젝트에서, _\"단 15분 동안 데이터를 바라보는 것만으로도 수 시간의 문제 해결을 줄일 수 있는 통찰력을 얻을 수 있다\"_ 고 느꼈습니다. **Greg Brockman(OpenAI 공동 창립자)** 는 트윗에서 다음과 같이 언급했습니다. _\"데이터의 수동 검사는 기계 학습의 모든 활동 중에서 가장 높은 가치 대비 효율성을 갖고 있을 가능성이 크다.\"_\n",
    "\n",
    "데이터를 살펴보고 예제들이 의미가 있는지 확인하세요. 주석이 달린 데이터의 경우, 몇 가지 쿼리를 선택하여 직접 주석을 달아보고 기존 주석과 일치하는지 확인해 보세요. 이를 통해 주석의 신뢰성을 파악할 수 있습니다. 응답의 사실 여부를 확인하세요. 예제들은 얼마나 고유한가요? 동일한 쿼리에 대해 서로 다른 응답이 있는 예제가 있나요? 동일한 응답에 대해 서로 다른 쿼리가 있는 예제가 있나요?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **중복 데이터 제거 (Deduplicate Data)**  \n",
    "\n",
    "중복된 데이터는 데이터 분포를 왜곡하고 모델에 **편향(bias)** 을 유발할 수 있습니다. 예를 들어, **Table 8-3**과 같은 데이터셋을 상상해 보세요. 중복된 항목이 포함되면, **모델이 \"모든 빨간색 아이템은 비싸야 한다\"는 잘못된 결론을 내릴 위험이 있습니다.** 또한, 중복 데이터는 테스트 세트 오염(test set contamination)의 원인이 될 수도 있습니다. 만약 중복된 데이터를 학습 데이터(train set)와 테스트 데이터(test set)로 나눌 경우, **하나의 예제가 학습 세트와 테스트 세트에 동시에 포함될 가능성이 있습니다.**  \n",
    "\n",
    "**Table 8-3. 동일한 예제가 중복된 데이터셋 (회색으로 표시된 부분은 중복된 데이터)**  \n",
    "\n",
    "| ID  | 입력 (제품 설명) | 출력 (가격) |\n",
    "|----|------------------------|------------|\n",
    "| 1  | {item: 연필, color: 빨강} | $20 |\n",
    "| 2  | {item: 컴퍼스, color: 초록} | $2  |\n",
    "| 3  | {item: 연필, color: 빨강} | $20 |\n",
    "| 4  | {item: 연필, color: 빨강} | $20 |\n",
    "| 5  | {item: 연필, color: 초록} | $1  |\n",
    "\n",
    "여러 연구에서 **훈련 데이터의 중복이 모델 성능에 미치는 부정적인 영향**이 확인되었습니다. 예를 들어, **Lee et al. (2021)** 및 **Tirumala et al. (2023)** 연구가 이러한 영향을 분석한 바 있습니다. **Anthropic 연구**에서는 훈련 데이터의 0.1%를 100번 반복하는 것만으로도 **800억 개의 매개변수를 가진 모델의 성능이 400억 개 매개변수 모델 수준으로 저하될 수 있음**을 입증했습니다 (**Hernandez et al., 2022**). 중복된 데이터가 모델의 성능을 직접적으로 저하시키지 않더라도, **불필요한 시간과 계산 리소스를 낭비**할 수 있습니다.  \n",
    "\n",
    "데이터 유형에 따라 중복 데이터의 형태도 다양하며, 일부 중복 데이터는 탐지하기 어렵습니다. 예를 들어, 문서 데이터셋에서 발생할 수 있는 중복 유형은 다음과 같습니다.  \n",
    "\n",
    "- **전체 문서 중복 (Whole document duplications)**: 동일한 문서가 한 번 이상 등장하는 경우.  \n",
    "- **문서 내부 중복 (Intra-document duplications)**: 동일한 단락이 한 문서 내에서 두 번 이상 반복되는 경우.  \n",
    "- **문서 간 중복 (Cross-document duplications)**: 동일한 인기 있는 인용구가 여러 문서에서 반복되는 경우.  \n",
    "\n",
    "중복 여부를 판단하는 기준은 정의에 따라 달라질 수 있습니다. 예를 들어, **문서 수준(document level), 단락 수준(paragraph level), 문장 수준(sentence level), 또는 토큰 수준(token level)** 중 어디에서 중복을 탐지할 것인지 결정해야 합니다. 또한, 두 개의 텍스트가 **완전히 일치해야 중복으로 간주할지, 아니면 80% 이상의 유사성이 있으면 중복으로 볼지**도 고민해야 합니다. 리스트가 동일한 항목을 포함하지만 순서만 다를 경우에도 중복으로 간주할 것인가요?  \n",
    "\n",
    "중복 제거 작업은 **유사성 측정(similarity measurement)** 에 사용되는 동일한 기술을 활용할 수 있습니다 (**Chapter 3 참고**). 데이터 중복 제거는 또한 **아이덴티티 해석(identity resolution)** 에도 사용됩니다. 예를 들어, **두 개의 소셜 미디어 프로필이 동일한 인물인지 판별하는 데** 적용될 수 있습니다. 여기 몇 가지 구체적인 중복 제거 방법이 있습니다.  \n",
    "\n",
    "**페어와이즈 비교 (Pairwise comparison)**  \n",
    "- 각 예제의 유사도 점수를 데이터셋 내의 모든 다른 예제와 비교하여 계산합니다. 이를 위해 정확한 일치(exact match), n-그램 매칭(n-gram match), 퍼지 매칭(fuzzy match), 또는 의미적 유사도 점수(semantic similarity score, Chapter 3 참고)를 사용할 수 있습니다. 그러나 이 접근 방식은 대규모 데이터셋에서는 계산 비용이 많이 들 수 있습니다.  \n",
    "\n",
    "**해싱(Hashing)**  \n",
    "- 예제를 서로 다른 해시 버킷(bucket)으로 나누고, 동일한 버킷에 속하는 항목만 비교합니다. 해시 기반 중복 제거 기법에는 **MinHash** 및 **Bloom filter** 가 포함됩니다.  \n",
    "\n",
    "**차원 축소 (Dimensionality reduction)**  \n",
    "- 먼저 차원 축소(dimensionality reduction) 기법을 사용하여 데이터의 차원을 줄인 후, 페어와이즈 비교를 수행합니다. 벡터 검색(vector search)에 사용되는 많은 기술이 **Chapter 6**에서 다루어지고 있습니다.\n",
    "- 간단한 검색을 통해 중복 제거를 도와주는 많은 라이브러리를 찾을 수 있습니다. dupeGuru, Dedupe, datasketch, TextDistance, TheFuzz, deduplicate-text-datasets 등이 그 예시입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 정리 및 필터링 (Clean and Filter Data)**  \n",
    "\n",
    "데이터를 정리하고 필터링해야 **모델이 더 성능이 좋고 안전하게 동작**할 수 있습니다.  \n",
    "\n",
    "먼저, 불필요한 **포맷팅 토큰(formatting tokens)** 을 제거해야 합니다. 많은 공개 데이터셋이 인터넷에서 스크랩되기 때문에, **불필요한 HTML 태그** 가 많이 포함될 수 있습니다. 모델을 HTML 태그를 포함한 데이터로 학습할 것이 아니라면, 이를 제거하세요. **Databricks 연구**에 따르면, **불필요한 Markdown 및 HTML 토큰을 제거하면 모델의 정확도가 20% 향상되고 입력 토큰 길이가 60% 감소**하는 것으로 나타났습니다.  \n",
    "\n",
    "또한, **개인정보(PII), 민감한 데이터, 저작권 데이터, 유해 콘텐츠(toxic data)** 등을 포함하여, **정책에 부합하지 않는 데이터를 제거**해야 합니다. **Chapter 4**에서 설명된 기법이 이를 도울 수 있습니다. 사용이 허용되지 않은 필드(예: **우편번호(zip code), 이름(name), 성별(gender)** 등)를 삭제하세요.  \n",
    "\n",
    "**품질이 낮은 데이터도 제거해야 합니다.** 이를 위해 **\"Data verification\"** 에서 설명된 기법을 활용할 수 있습니다.  \n",
    "\n",
    "수동으로 데이터를 검사하는 것도 이 과정에서 매우 중요합니다. 데이터를 자세히 들여다보면 **일부 패턴을 발견할 수도 있으며, 이를 휴리스틱(heuristic) 방식으로 활용하여 저품질 데이터를 감지**할 수 있습니다. 저품질 데이터를 감지하는 방법은 명확하지 않을 수도 있습니다. 예를 들어, **Kern et al. (2024) 연구**에서는 **주석(annotations)이 세션 후반부에 추가된 경우 품질이 낮을 가능성이 높다**는 사실을 발견했습니다. 이는 **주석자가 피로를 느끼거나 집중력이 떨어지면서 데이터 품질이 저하되었기 때문**일 가능성이 높습니다.  \n",
    "\n",
    "만약 **컴퓨팅 리소스가 제한되어 있어 모든 데이터를 학습할 수 없다면**, 추가적인 필터링을 수행할 수 있습니다.  \n",
    "- **액티브 러닝(active learning)** 을 활용하여 **모델이 학습하는 데 가장 유용한 데이터만 선택**할 수 있습니다.  \n",
    "- **중요도 샘플링(importance sampling)** 을 사용하여 특정 작업에 가장 중요한 예제만 선택할 수도 있습니다.  \n",
    "\n",
    "**Sorsch et al. (2022) 연구**에서는, **좋은 데이터 프루닝(pruning) 지표** 를 발견하는 것이 **딥러닝의 리소스 비용을 크게 절감**할 수 있다고 결론지었습니다.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터 포맷 정리 (Format Data)**  \n",
    "\n",
    "중복 데이터를 제거하고 정리(cleaning)한 후에는, **모델이 기대하는 적절한 포맷으로 데이터를 변환해야 합니다.**  \n",
    "\n",
    "각 모델은 특정한 **토크나이저(tokenizer)** 를 사용하며, 특정한 **템플릿(template)** 으로 된 데이터를 기대합니다 (**Chapter 5 참고**). 만약 데이터를 **잘못된 템플릿으로 변환하면, 모델에서 이상한 버그가 발생할 수 있습니다.**  \n",
    "\n",
    "지도학습(supervised finetuning)을 수행하는 경우, 데이터 형식은 일반적으로 **(지시문(instruction), 응답(response))** 형태일 가능성이 큽니다. 지시문은 **(시스템 프롬프트(system prompt), 사용자 프롬프트(user prompt))** 로 추가 분해될 수도 있습니다.  \n",
    "\n",
    "프롬프트 엔지니어링(prompt engineering) 이후에 파인튜닝(finetuning) 단계로 넘어갔다면, **파인튜닝에서 사용하는 지시문이 프롬프트 엔지니어링에서 사용한 지시문과 다를 수 있습니다.**  \n",
    "- 파인튜닝에서는 **지시문을 상세하게 설명할 필요가 없으며, 예제 또한 포함할 필요가 없습니다.**  \n",
    "- 충분한 학습 예제가 존재하는 경우, **모델은 예제만으로도 해당 작업의 기대 동작을 학습할 수 있습니다.**  \n",
    "\n",
    "예를 들어, **음식 분류(food classification)** 모델을 훈련한다고 가정하고, 다음과 같은 **Three-shot instruction** 을 사용했다고 해봅시다.  \n",
    "\n",
    "```\n",
    "Label the following item as either edible or inedible.\n",
    "\n",
    "Item: burger  \n",
    "Label: edible  \n",
    "\n",
    "Item: car  \n",
    "Label: inedible  \n",
    "\n",
    "Item: mushroom  \n",
    "Label: edible  \n",
    "\n",
    "Item: {INPUT}  \n",
    "Label:  \n",
    "```\n",
    "\n",
    "**파인튜닝에서는 위 예제의 모든 항목이 학습 예제로 변환될 수 있습니다.** 파인튜닝에 사용할 **학습 데이터(training data)** 의 포맷은 **Table 8-4**와 같을 것입니다.\n",
    "\n",
    "**Table 8-4. 음식 분류 작업을 위한 예제 학습 데이터**  \n",
    "\n",
    "| **예제 ID** | **입력** | **출력** |  \n",
    "|------------|---------|---------|  \n",
    "| 1          | burger --> | edible |  \n",
    "| 2          | car --> | inedible |  \n",
    "| 3          | mushroom --> | edible |  \n",
    "| ...        | ...     | ...     |  \n",
    "\n",
    "모델이 파인튜닝(finetuning)된 후에는, 다음과 같이 **단순한 프롬프트(prompt)** 를 사용할 수 있습니다.  \n",
    "\n",
    "```\n",
    "{INPUT} -->  \n",
    "```\n",
    "\n",
    "이 프롬프트는 **기본 모델에서 사용한 프롬프트보다 훨씬 짧습니다.** 따라서, **입력 토큰 비용(input token cost)** 이 걱정된다면, **파인튜닝이 비용 절감의 한 가지 방법이 될 수 있습니다.**  \n",
    "\n",
    "**다양한 파인튜닝 데이터 형식이 모델의 성능에 영향을 줄 수 있습니다.** 따라서, **가장 적절한 형식을 찾기 위한 실험(experiments)** 이 유용할 수 있습니다.  \n",
    "\n",
    "파인튜닝된 모델을 사용할 때, **사용하는 프롬프트가 학습된 데이터의 형식과 일치하는지 반드시 확인하세요.** 예를 들어, 학습 데이터가 **\"burger -->\"** 형식을 사용한다고 가정하면, 다음과 같은 프롬프트는 문제가 될 수 있습니다.  \n",
    "\n",
    "- `\"burger\"` : **끝 화살표(--> )가 없음**  \n",
    "- `\"Item: burger -->\"` : **불필요한 접두어(prefix) 포함**  \n",
    "- `\"burger --> \"` : **공백이 추가됨**  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **요약 (Summary)**\n",
    "\n",
    "훈련 데이터를 생성하는 실제 과정은 매우 복잡하지만, 데이터셋을 만드는 원칙은 놀랍도록 간단합니다. 모델을 훈련할 데이터셋을 구축하려면 먼저 모델이 학습해야 할 동작을 고려한 후, 이러한 동작을 반영하는 데이터셋을 설계해야 합니다. 데이터의 중요성 때문에, 많은 팀이 적절한 데이터셋을 확보하는 동시에 개인정보 보호 및 규정을 준수하는 역할을 담당하는 전담 데이터 팀을 도입하고 있습니다.  \n",
    "\n",
    "필요한 데이터는 사용 사례뿐만 아니라 훈련 단계에 따라서도 달라집니다. 사전 훈련(pre-training)에서는 지도 학습(finetuning) 및 선호 조정(preferred finetuning)과는 다른 데이터가 필요합니다. 그러나 훈련 단계 전반에 걸친 데이터셋 설계는 **품질(quality), 범위(coverage), 양(quantity)** 이라는 세 가지 핵심 기준을 공유합니다.  \n",
    "\n",
    "모델이 얼마나 많은 데이터를 학습하는지가 주목받지만, **충분한 범위를 갖춘 고품질 데이터**도 그만큼 중요합니다. **적은 양의 고품질 데이터가 대량의 노이즈 데이터보다 더 나은 성능을 낼 수 있습니다.** 또한, 많은 팀이 데이터셋의 다양성을 높이는 것이 모델 성능 향상에 중요한 요소임을 발견했습니다.  \n",
    "\n",
    "고품질 데이터를 확보하는 것이 어려운 만큼, 많은 팀이 **합성 데이터(synthetic data)** 로 전환하고 있습니다. 프로그래밍적으로 데이터를 생성하는 것은 오랫동안 목표였지만, **AI가 현실적이고 복잡한 데이터를 생성할 수 있게 되면서 합성 데이터가 더욱 실용적인 해결책이 되었습니다.** 이번 장에서는 데이터 합성(synthesis) 기법과 특히 지도 학습을 위한 합성 데이터 생성 방법을 깊이 다루었습니다.  \n",
    "\n",
    "실제 데이터와 마찬가지로, 합성 데이터도 모델을 훈련하기 전에 **품질 검증(evaluation)** 이 필요합니다. AI가 생성한 데이터를 평가하는 것은 다른 AI 출력물을 평가하는 것만큼 까다롭습니다. 사람들은 신뢰할 수 있는 방식으로 평가할 수 있는 데이터를 더 선호하는 경향이 있습니다.  \n",
    "\n",
    "데이터는 어려운 주제입니다. **데이터셋 생성의 많은 과정이 자동화하기 어렵기 때문입니다.** 데이터를 주석(annotate)하는 것도 어렵지만, **주석 가이드라인(annotation guidelines)을 만드는 것은 더 어렵습니다.** 데이터 생성을 자동화하는 것은 어렵지만, **데이터 검증을 자동화하는 것은 더욱 어렵습니다.** 데이터 합성은 더 많은 데이터를 생성하는 데 도움이 되지만, **어떤 데이터를 원하는지 고민하는 과정은 자동화할 수 없습니다.** 주석 가이드라인을 만들거나, 세부 사항을 꼼꼼히 확인하는 작업도 쉽게 자동화할 수 없습니다.  \n",
    "\n",
    "그러나, **도전적인 문제는 창의적인 해결책을 유도합니다.** 이번 장을 연구하면서 가장 인상적이었던 점은 **데이터셋 설계 과정에 많은 창의성이 필요하다는 것**이었습니다. 사람들은 다양한 방식으로 데이터를 구성하고 평가합니다. 이번 장에서 다룬 데이터 합성과 검증 기법이 여러분의 데이터셋 설계에 **영감을 줄 수 있기를 바랍니다.**  \n",
    "\n",
    "이제 여러분이 훌륭한 데이터셋을 만들어서 **최고의 모델을 훈련**했다고 가정해봅시다. 그렇다면 **이 모델을 어떻게 서비스해야 할까요?** 다음 장에서는 **추론(inference)을 최적화하여 지연(latency)과 비용(cost)을 줄이는 방법** 을 다룰 것입니다.  \n",
    "\n",
    "---\n",
    "\n",
    "1. 데이터의 중요성이 증가하는 모습은 GPT-3에서 GPT-4로의 변화에서 잘 드러납니다. GPT-3(OpenAI, 2020)의 기여자 목록에서는 데이터 수집, 필터링, 중복 제거 및 학습 데이터의 중복 분석을 담당한 사람이 단 2명뿐이었습니다. 하지만 3년 후 GPT-4(OpenAI, 2023)에서는 데이터 처리와 관련하여 **80명**이 기여자로 인정받았습니다. 이 목록에는 OpenAI가 데이터 제공업체를 통해 계약한 데이터 주석자들은 포함되지 않았습니다. 단순해 보이는 **ChatML 포맷**에도 11명이 관여했으며, 이들 중 다수가 선임 연구원이었습니다. OpenAI 공동 창립자 중 한 명인 **Wojciech Zaremba**는 2016년 **AMA(Ask Me Anything)** 에서 대부분의 연구를 공개 데이터셋을 활용하여 수행할 계획이라고 밝힌 바 있습니다.  \n",
    "\n",
    "2. 방대한 데이터를 활용하는 경우, **데이터 준수(Data Compliance)** 를 관리하는 일만으로도 전담 직책이 필요할 수 있습니다.  \n",
    "\n",
    "3. 저는 글쓰기를 좋아하지만, 모든 사람의 의견을 하나의 정의로 압축하는 것은 정말 즐기지 않는 일 중 하나입니다. **IBM**은 데이터 품질을 **완전성(completeness), 고유성(uniqueness), 유효성(validity), 적시성(timeliness), 정확성(accuracy), 일관성(consistency), 목적 적합성(fitness for purpose)** 의 7가지 요소로 정의했습니다. **위키백과(Wikipedia)** 는 여기에 **접근성(accessibility), 비교 가능성(comparability), 신뢰성(credibility), 유연성(flexibility), 개연성(plausibility)** 을 추가했습니다. 많은 정의는 폭넓은 사용 사례에서의 데이터 품질을 다루고 있지만, 저는 여기서 **파인튜닝(finetuning)용 데이터 품질** 에 초점을 맞추고자 합니다.  \n",
    "\n",
    "4. 제가 기억하는 가장 골치 아픈 버그 중 하나는 **부동소수점(float) 데이터가 정수(integer)로 잘못 저장** 되면서 값이 반올림되어 예상치 못한 동작이 발생했던 경우입니다.  \n",
    "\n",
    "5. 데이터의 고유성과 직접적인 관련이 없더라도, **다른 누구도 가지지 않은 데이터**를 보유하는 것은 엄청난 가치를 가질 수 있습니다.  \n",
    "\n",
    "6. 제 책 **\"Designing Machine Learning Systems\"** 에서는 **약한 지도 학습(weak supervision), 준지도 학습(semi-supervision), 능동 학습(active learning)** 등 주석이 필요한 데이터 수요를 줄이는 다양한 기법들을 다뤘습니다.  \n",
    "\n",
    "7. 너무 많은 기업들이 **데이터 플라이휠(data flywheel)** 을 피치에서 언급하는 걸 보면서, 이제는 **데이터 플라이휠을 언급하지 않고 AI 스타트업을 시작하는 것이 불법인 것처럼 느껴질 정도**입니다.  \n",
    "\n",
    "8. 제 책 **\"Designing Machine Learning Systems\"** 에서는 4장에서 **데이터 증강(data augmentation)** 을 다루고 있습니다.  \n",
    "\n",
    "9. 본문에서 다루지 않았지만, 한 가지 명확한 예시는 **AI가 생성한 콘텐츠(AI-generated content)** 를 탐지하는 모델을 훈련할 때입니다. 이 경우, **AI가 생성한 데이터를 훈련 예제로 활용해야 합니다.**  \n",
    "\n",
    "10. 절차적 생성(procedural generation)이 가능하기 때문에 놀라운 게임들이 탄생할 수 있었습니다. **Minecraft**와 **No Man’s Sky** 같은 게임은 **노이즈 함수(noise functions)** 와 **프랙탈 알고리즘(fractal algorithms)** 을 활용하여 방대한 몰입형 세계를 생성합니다. **Dungeons & Dragons**에서는 **랜덤 던전, 퀘스트, 전투 생성**을 위해 절차적 생성을 사용할 수 있으며, 이 과정이 게임에 **예측 불가능성과 무한한 가능성**을 추가하여 더욱 매력적으로 만듭니다.  \n",
    "\n",
    "11. 이 개념의 함축적 의미는 **이론적으로는 모델이 스스로 지속적으로 개선될 수 있도록 훈련하는 것이 가능하다**는 것입니다. 하지만 **실제로 가능한지는 또 다른 이야기**입니다.  \n",
    "\n",
    "12. 연구자들은 **\"약 20%의 솔루션이 초기에는 잘못되었지만, 스스로 수정(self-correct)하는 모습을 보였다.\"** 즉, **모델이 실행 피드백(execution feedback)으로부터 학습하고 성능이 향상되었음을 나타냅니다.**  \n",
    "\n",
    "13. 같은 문제가 **사람이 직접 수행하는 데이터 주석(human annotation)** 에서도 발생할 수 있습니다. 만약 인간 주석자가 본인이 가진 지식을 활용하여 라벨을 지정하고, 모델이 이를 이해하지 못하는 경우, 이는 결국 **모델이 환각(hallucinate)하도록 학습시키는 것과 같습니다.**  \n",
    "\n",
    "14. 동일한 저자들이 **\"AI Models Collapse When Trained on Recursively Generated Data\" (Nature, July 2024)** 논문에서 이 개념을 추가로 설명했습니다.  \n",
    "\n",
    "15. **Mixtral** 같은 **Mixture-of-Experts(MoE) 모델**과 **Nemotron-4** 같은 **Dense 모델**의 매개변수(parameter) 개수를 비교하는 것은 공정하지 않지만, **스승(teacher) 모델인 Mixtral이 학생(student) 모델인 Nemotron-4보다 작다는 점은 여전히 사실입니다.**  \n",
    "\n",
    "16. 제가 만든 오픈소스 라이브러리 중 하나인 **lazyNLP**는 **중복 제거(deduplication)** 및 **중첩 예측(overlap estimation)** 을 지원하며 **Bloom 필터(Bloom filter)** 를 사용합니다.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
