{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. 데이터 수집","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n\ntrain = pd.read_csv(data_path + 'train.csv', index_col='id')\ntest = pd.read_csv(data_path + 'test.csv', index_col='id')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-25T06:11:42.022878Z","iopub.execute_input":"2023-03-25T06:11:42.023664Z","iopub.status.idle":"2023-03-25T06:11:55.801303Z","shell.execute_reply.started":"2023-03-25T06:11:42.023607Z","shell.execute_reply":"2023-03-25T06:11:55.800169Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 3. 데이터 전처리","metadata":{}},{"cell_type":"markdown","source":"데이터 합치기","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1) # 타깃값 제거","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:11:55.803033Z","iopub.execute_input":"2023-03-25T06:11:55.803415Z","iopub.status.idle":"2023-03-25T06:11:57.216859Z","shell.execute_reply.started":"2023-03-25T06:11:55.803378Z","shell.execute_reply":"2023-03-25T06:11:57.215181Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_features = all_data.columns # 전체 피처\nall_features","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:11:57.218406Z","iopub.execute_input":"2023-03-25T06:11:57.219027Z","iopub.status.idle":"2023-03-25T06:11:57.229973Z","shell.execute_reply.started":"2023-03-25T06:11:57.218984Z","shell.execute_reply":"2023-03-25T06:11:57.228495Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Index(['ps_ind_01', 'ps_ind_02_cat', 'ps_ind_03', 'ps_ind_04_cat',\n       'ps_ind_05_cat', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin',\n       'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin',\n       'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15', 'ps_ind_16_bin',\n       'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03',\n       'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat',\n       'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat',\n       'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_11',\n       'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15', 'ps_calc_01',\n       'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05', 'ps_calc_06',\n       'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10', 'ps_calc_11',\n       'ps_calc_12', 'ps_calc_13', 'ps_calc_14', 'ps_calc_15_bin',\n       'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin',\n       'ps_calc_20_bin'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"명목형 피처 원-핫 인코딩","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# 명목형 피처 추출\ncat_features = [feature for feature in all_features if 'cat' in feature] \n\nonehot_encoder = OneHotEncoder() # 원-핫 인코더 객체 생성\n# 인코딩\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features]) \n\nencoded_cat_matrix","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:11:57.233996Z","iopub.execute_input":"2023-03-25T06:11:57.234505Z","iopub.status.idle":"2023-03-25T06:11:59.878229Z","shell.execute_reply.started":"2023-03-25T06:11:57.234449Z","shell.execute_reply":"2023-03-25T06:11:59.875971Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<1488028x184 sparse matrix of type '<class 'numpy.float64'>'\n\twith 20832392 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"markdown","source":"필요 없는 피처 제거","metadata":{}},{"cell_type":"code","source":"# 추가로 제거할 피처\ndrop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', \n                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n\n# '1) 명목형 피처, 2) calc 분류의 피처, 3) 추가 제거할 피처'를 제외한 피처\nremaining_features = [feature for feature in all_features \n                      if ('cat' not in feature and \n                          'calc' not in feature and \n                          feature not in drop_features)]","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:11:59.880768Z","iopub.execute_input":"2023-03-25T06:11:59.881356Z","iopub.status.idle":"2023-03-25T06:11:59.889972Z","shell.execute_reply.started":"2023-03-25T06:11:59.881284Z","shell.execute_reply":"2023-03-25T06:11:59.888637Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from scipy import sparse\n\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data[remaining_features]),\n                               encoded_cat_matrix],\n                              format='csr')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:11:59.891573Z","iopub.execute_input":"2023-03-25T06:11:59.891939Z","iopub.status.idle":"2023-03-25T06:12:02.716954Z","shell.execute_reply.started":"2023-03-25T06:11:59.891903Z","shell.execute_reply":"2023-03-25T06:12:02.715429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"데이터 나누기","metadata":{}},{"cell_type":"code","source":"num_train = len(train) # 훈련 데이터 개수\n\n# 훈련 데이터와 테스트 데이터 나누기\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:02.721732Z","iopub.execute_input":"2023-03-25T06:12:02.722124Z","iopub.status.idle":"2023-03-25T06:12:03.529052Z","shell.execute_reply.started":"2023-03-25T06:12:02.722088Z","shell.execute_reply":"2023-03-25T06:12:03.527635Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 4. 모델링","metadata":{}},{"cell_type":"markdown","source":"정규화 지니계수 계산 함수","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    # 실제값과 예측값의 크기가 같은지 확인 (값이 다르면 오류 발생)\n    assert y_true.shape == y_pred.shape\n\n    n_samples = y_true.shape[0]                      # 데이터 개수\n    L_mid = np.linspace(1 / n_samples, 1, n_samples) # 대각선 값\n\n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()] # y_pred 크기순으로 y_true 값 정렬\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n    G_pred = np.sum(L_mid - L_pred)       # 예측 값에 대한 지니계수\n\n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()] # y_true 크기순으로 y_true 값 정렬\n    L_true = np.cumsum(true_order) / np.sum(true_order) # 로렌츠 곡선\n    G_true = np.sum(L_mid - L_true)       # 예측이 완벽할 때 지니계수\n\n    # 정규화된 지니계수\n    return G_pred / G_true","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:03.530769Z","iopub.execute_input":"2023-03-25T06:12:03.531215Z","iopub.status.idle":"2023-03-25T06:12:03.540640Z","shell.execute_reply.started":"2023-03-25T06:12:03.531179Z","shell.execute_reply":"2023-03-25T06:12:03.539113Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# XGBoost용 지니함수 계산함수는 반환값이 2개(평가지표명, 평가점수)\n# XGBoost용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:03.542631Z","iopub.execute_input":"2023-03-25T06:12:03.542988Z","iopub.status.idle":"2023-03-25T06:12:03.557085Z","shell.execute_reply.started":"2023-03-25T06:12:03.542955Z","shell.execute_reply":"2023-03-25T06:12:03.555665Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"xgb.DMatrix()로 베이지안 최적화용 데이터셋을 만들어 준다.","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n# 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, \n                                                      test_size=0.2, \n                                                      random_state=0)\n# 베이지안 최적화용 데이터셋\nbayes_dtrain = xgb.DMatrix(X_train, y_train)\nbayes_dvalid = xgb.DMatrix(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:03.563221Z","iopub.execute_input":"2023-03-25T06:12:03.564602Z","iopub.status.idle":"2023-03-25T06:12:04.232044Z","shell.execute_reply.started":"2023-03-25T06:12:03.564512Z","shell.execute_reply":"2023-03-25T06:12:04.230980Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"하이퍼파라미터 범위 설정","metadata":{}},{"cell_type":"code","source":"# 정석\n# # 베이지안 최적화를 위한 하이퍼파라미터 범위\n# param_bounds = {'max_depth': (4, 8),\n#                 'subsample': (0.6, 0.9),\n#                 'colsample_bytree': (0.7, 1.0),\n#                 'min_child_weight': (5, 7),\n#                 'gamma': (8, 11),\n#                 'reg_alpha': (7, 9),\n#                 'reg_lambda': (1.1, 1.5),\n#                 'scale_pos_weight': (1.4, 1.6)}\n\n# # 값이 고정된 하이퍼파라미터\n# fixed_params = {'objective': 'binary:logistic',\n#                 'learning_rate': 0.02,\n#                 'random_state': 1991}","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:04.237967Z","iopub.execute_input":"2023-03-25T06:12:04.241263Z","iopub.status.idle":"2023-03-25T06:12:04.248725Z","shell.execute_reply.started":"2023-03-25T06:12:04.241198Z","shell.execute_reply":"2023-03-25T06:12:04.247510Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# 수정\n# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {'max_depth': (5, 7),\n                'subsample': (0.6, 0.8),\n                'colsample_bytree': (0.8, 0.9),\n                'min_child_weight': (6, 7),\n                'gamma': (10, 11),\n                'reg_alpha': (8, 9),\n                'reg_lambda': (1.3, 1.4),\n                'scale_pos_weight': (1.4, 1.5)}\n\n# 값이 고정된 하이퍼파라미터\nfixed_params = {'objective': 'binary:logistic',\n                'learning_rate': 0.02,                                  .,;;0k0kkk0 kkkkk000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 , ,hkkh 00 \n                'random_state': 1991}","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:04.250201Z","iopub.execute_input":"2023-03-25T06:12:04.250974Z","iopub.status.idle":"2023-03-25T06:12:04.272301Z","shell.execute_reply.started":"2023-03-25T06:12:04.250933Z","shell.execute_reply":"2023-03-25T06:12:04.270459Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"베이지안 최적화용 평가지표 계산 함수 작성","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\n\n\n\ndef eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n                 reg_alpha, gamma, reg_lambda, scale_pos_weight):\n    '''최적화하려는 평가지표(지니계수) 계산 함수'''\n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {'max_depth': int(round(max_depth)),\n              'subsample': subsample,\n              'colsample_bytree': colsample_bytree,\n              'min_child_weight': min_child_weight,\n              'gamma': gamma,\n              'reg_alpha':reg_alpha,\n              'reg_lambda': reg_lambda,\n              'scale_pos_weight': scale_pos_weight}\n    # 값이 고정된 하이퍼파라미터도 추가\n    params.update(fixed_params)\n\n    print('하이퍼파라미터 :', params)    \n\n    # XGBoost 모델 훈련\n    \n    xgb_model = xgb.train(params=params, \n                          dtrain=bayes_dtrain,\n                          num_boost_round=2000,\n                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=False)\n\n    best_iter = xgb_model.best_iteration # 최적 반복 횟수\n    # 검증 데이터로 예측 수행\n    preds = xgb_model.predict(bayes_dvalid, \n                              iteration_range=(0, best_iter))\n    # 지니계수 계산\n    gini_score = eval_gini(y_valid, preds)\n    print(f'지니계수 : {gini_score}\\n')\n\n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:04.274299Z","iopub.execute_input":"2023-03-25T06:12:04.276311Z","iopub.status.idle":"2023-03-25T06:12:04.290188Z","shell.execute_reply.started":"2023-03-25T06:12:04.276233Z","shell.execute_reply":"2023-03-25T06:12:04.288798Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"최적화 수행 및 결과 확인","metadata":{}},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\n# 베이지안 최적화 객체 생성\noptimizer = BayesianOptimization(f=eval_function, \n                                 pbounds=param_bounds, \n                                 random_state=0)\n\n# 베이지안 최적화 수행\noptimizer.maximize(init_points=3, n_iter=6)\n\n# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max['params']\nprint(max_params)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T06:12:04.291997Z","iopub.execute_input":"2023-03-25T06:12:04.292873Z","iopub.status.idle":"2023-03-25T08:54:13.962130Z","shell.execute_reply.started":"2023-03-25T06:12:04.292820Z","shell.execute_reply":"2023-03-25T08:54:13.959170Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | scale_... | subsample |\n-------------------------------------------------------------------------------------------------------------------------\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.778354600156416, 'colsample_bytree': 0.8548813503927325, 'min_child_weight': 6.544883182996897, 'gamma': 10.71518936637242, 'reg_alpha': 8.423654799338905, 'reg_lambda': 1.3645894113066657, 'scale_pos_weight': 1.4437587211262692, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2846225977005399\n\n| \u001b[0m1        \u001b[0m | \u001b[0m0.2846   \u001b[0m | \u001b[0m0.8549   \u001b[0m | \u001b[0m10.72    \u001b[0m | \u001b[0m6.206    \u001b[0m | \u001b[0m6.545    \u001b[0m | \u001b[0m8.424    \u001b[0m | \u001b[0m1.365    \u001b[0m | \u001b[0m1.444    \u001b[0m | \u001b[0m0.7784   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6174258599403081, 'colsample_bytree': 0.896366276050103, 'min_child_weight': 6.528894919752904, 'gamma': 10.383441518825778, 'reg_alpha': 8.568044561093933, 'reg_lambda': 1.392559663829266, 'scale_pos_weight': 1.4071036058197885, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n지니계수 : 0.28389589534334453\n\n| \u001b[0m2        \u001b[0m | \u001b[0m0.2839   \u001b[0m | \u001b[0m0.8964   \u001b[0m | \u001b[0m10.38    \u001b[0m | \u001b[0m6.583    \u001b[0m | \u001b[0m6.529    \u001b[0m | \u001b[0m8.568    \u001b[0m | \u001b[0m1.393    \u001b[0m | \u001b[0m1.407    \u001b[0m | \u001b[0m0.6174   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.7561058352572911, 'colsample_bytree': 0.8020218397440326, 'min_child_weight': 6.870012148246819, 'gamma': 10.832619845547939, 'reg_alpha': 8.978618342232764, 'reg_lambda': 1.3799158564216722, 'scale_pos_weight': 1.4461479362252931, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n지니계수 : 0.2841696627464925\n\n| \u001b[0m3        \u001b[0m | \u001b[0m0.2842   \u001b[0m | \u001b[0m0.802    \u001b[0m | \u001b[0m10.83    \u001b[0m | \u001b[0m6.556    \u001b[0m | \u001b[0m6.87     \u001b[0m | \u001b[0m8.979    \u001b[0m | \u001b[0m1.38     \u001b[0m | \u001b[0m1.446    \u001b[0m | \u001b[0m0.7561   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.6667753691037088, 'colsample_bytree': 0.8614374862494786, 'min_child_weight': 6.74704564669168, 'gamma': 10.817415409224209, 'reg_alpha': 8.775919405079895, 'reg_lambda': 1.3703691498887276, 'scale_pos_weight': 1.4116403862275428, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2825190196652289\n\n| \u001b[0m4        \u001b[0m | \u001b[0m0.2825   \u001b[0m | \u001b[0m0.8614   \u001b[0m | \u001b[0m10.82    \u001b[0m | \u001b[0m6.419    \u001b[0m | \u001b[0m6.747    \u001b[0m | \u001b[0m8.776    \u001b[0m | \u001b[0m1.37     \u001b[0m | \u001b[0m1.412    \u001b[0m | \u001b[0m0.6668   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.7690155783567096, 'colsample_bytree': 0.8765861935025867, 'min_child_weight': 6.624782214679624, 'gamma': 10.651878489167856, 'reg_alpha': 8.705756109918921, 'reg_lambda': 1.3811150020734444, 'scale_pos_weight': 1.4708403613290768, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28493105508583977\n\n| \u001b[95m5        \u001b[0m | \u001b[95m0.2849   \u001b[0m | \u001b[95m0.8766   \u001b[0m | \u001b[95m10.65    \u001b[0m | \u001b[95m6.405    \u001b[0m | \u001b[95m6.625    \u001b[0m | \u001b[95m8.706    \u001b[0m | \u001b[95m1.381    \u001b[0m | \u001b[95m1.471    \u001b[0m | \u001b[95m0.769    \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.6308412679379533, 'colsample_bytree': 0.83643064288649, 'min_child_weight': 6.539999638446021, 'gamma': 10.51797225886217, 'reg_alpha': 8.930198181129049, 'reg_lambda': 1.3762685005779836, 'scale_pos_weight': 1.4334272347669137, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2839463068140855\n\n| \u001b[0m6        \u001b[0m | \u001b[0m0.2839   \u001b[0m | \u001b[0m0.8364   \u001b[0m | \u001b[0m10.52    \u001b[0m | \u001b[0m6.266    \u001b[0m | \u001b[0m6.54     \u001b[0m | \u001b[0m8.93     \u001b[0m | \u001b[0m1.376    \u001b[0m | \u001b[0m1.433    \u001b[0m | \u001b[0m0.6308   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.6620761291198162, 'colsample_bytree': 0.8605933910026189, 'min_child_weight': 6.996167101820936, 'gamma': 10.337808243365048, 'reg_alpha': 8.320429194969563, 'reg_lambda': 1.3640701478928907, 'scale_pos_weight': 1.4247231289657456, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28342292034365724\n\n| \u001b[0m7        \u001b[0m | \u001b[0m0.2834   \u001b[0m | \u001b[0m0.8606   \u001b[0m | \u001b[0m10.34    \u001b[0m | \u001b[0m6.464    \u001b[0m | \u001b[0m6.996    \u001b[0m | \u001b[0m8.32     \u001b[0m | \u001b[0m1.364    \u001b[0m | \u001b[0m1.425    \u001b[0m | \u001b[0m0.6621   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 5, 'subsample': 0.6174376278029394, 'colsample_bytree': 0.858771507354015, 'min_child_weight': 6.067661676778794, 'gamma': 10.131651500546607, 'reg_alpha': 8.975221523543922, 'reg_lambda': 1.3808912274792062, 'scale_pos_weight': 1.4608812586905784, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28380397639308513\n\n| \u001b[0m8        \u001b[0m | \u001b[0m0.2838   \u001b[0m | \u001b[0m0.8588   \u001b[0m | \u001b[0m10.13    \u001b[0m | \u001b[0m5.28     \u001b[0m | \u001b[0m6.068    \u001b[0m | \u001b[0m8.975    \u001b[0m | \u001b[0m1.381    \u001b[0m | \u001b[0m1.461    \u001b[0m | \u001b[0m0.6174   \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.7719811602033093, 'colsample_bytree': 0.886127374840979, 'min_child_weight': 6.5791525277017815, 'gamma': 10.435110925111482, 'reg_alpha': 8.600464217045577, 'reg_lambda': 1.3392759897023265, 'scale_pos_weight': 1.4350133466747808, 'objective': 'binary:logistic', 'learning_rate': 0.02, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28373820331350924\n\n| \u001b[0m9        \u001b[0m | \u001b[0m0.2837   \u001b[0m | \u001b[0m0.8861   \u001b[0m | \u001b[0m10.44    \u001b[0m | \u001b[0m5.797    \u001b[0m | \u001b[0m6.579    \u001b[0m | \u001b[0m8.6      \u001b[0m | \u001b[0m1.339    \u001b[0m | \u001b[0m1.435    \u001b[0m | \u001b[0m0.772    \u001b[0m |\n=========================================================================================================================\n{'colsample_bytree': 0.8765861935025867, 'gamma': 10.651878489167856, 'max_depth': 6.4046373479391105, 'min_child_weight': 6.624782214679624, 'reg_alpha': 8.705756109918921, 'reg_lambda': 1.3811150020734444, 'scale_pos_weight': 1.4708403613290768, 'subsample': 0.7690155783567096}\n","output_type":"stream"}]},{"cell_type":"code","source":"# max_depth는 트리 깊이를 의미하므로 정수형이어야하니 정수형으로 바꾸고, 고정 하이퍼파라미터도 추가한다.\n# 정수형 하이퍼파라미터 변환\nmax_params['max_depth'] = int(round(max_params['max_depth']))\n\n# 값이 고정된 하이퍼파라미터 추가\nmax_params.update(fixed_params)\nmax_params","metadata":{"execution":{"iopub.status.busy":"2023-03-25T08:54:13.964871Z","iopub.execute_input":"2023-03-25T08:54:13.965397Z","iopub.status.idle":"2023-03-25T08:54:13.978664Z","shell.execute_reply.started":"2023-03-25T08:54:13.965350Z","shell.execute_reply":"2023-03-25T08:54:13.976211Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'colsample_bytree': 0.8765861935025867,\n 'gamma': 10.651878489167856,\n 'max_depth': 6,\n 'min_child_weight': 6.624782214679624,\n 'reg_alpha': 8.705756109918921,\n 'reg_lambda': 1.3811150020734444,\n 'scale_pos_weight': 1.4708403613290768,\n 'subsample': 0.7690155783567096,\n 'objective': 'binary:logistic',\n 'learning_rate': 0.02,\n 'random_state': 1991}"},"metadata":{}}]},{"cell_type":"markdown","source":"모델 훈련 및 성능 검증","metadata":{}},{"cell_type":"code","source":"# OOF 방식을 이용해 XGBoost 모델을 훈련한다.\n\nfrom sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기 생성\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n\n# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0]) \n# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0]) \n\n# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    # 각 폴드를 구분하는 문구 출력\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n\n    # 훈련용 데이터, 검증용 데이터 설정\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n    # XGBoost 전용 데이터셋 생성 \n    dtrain = xgb.DMatrix(X_train, y_train)\n    dvalid = xgb.DMatrix(X_valid, y_valid)\n    dtest = xgb.DMatrix(X_test)\n    # XGBoost 모델 훈련\n    xgb_model = xgb.train(params=max_params, \n                          dtrain=dtrain,\n                          num_boost_round=2000,\n                          evals=[(dvalid, 'valid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=100)\n\n    # 모델 성능이 가장 좋을 때의 부스팅 반복 횟수 저장\n    best_iter = xgb_model.best_iteration\n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += xgb_model.predict(dtest,\n                                        iteration_range=(0, best_iter))/folds.n_splits\n\n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n    oof_val_preds[valid_idx] += xgb_model.predict(dvalid, \n                                                  iteration_range=(0, best_iter))\n\n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T08:54:13.981734Z","iopub.execute_input":"2023-03-25T08:54:13.982512Z","iopub.status.idle":"2023-03-25T10:24:26.706002Z","shell.execute_reply.started":"2023-03-25T08:54:13.982442Z","shell.execute_reply":"2023-03-25T10:24:26.704634Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"######################################## 폴드 1 / 폴드 5 ########################################\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalid-logloss:0.67671\tvalid-gini:0.16215\n[100]\tvalid-logloss:0.19194\tvalid-gini:0.24637\n[200]\tvalid-logloss:0.15849\tvalid-gini:0.27603\n[300]\tvalid-logloss:0.15515\tvalid-gini:0.28673\n[400]\tvalid-logloss:0.15462\tvalid-gini:0.29120\n[500]\tvalid-logloss:0.15445\tvalid-gini:0.29397\n[600]\tvalid-logloss:0.15440\tvalid-gini:0.29558\n[700]\tvalid-logloss:0.15434\tvalid-gini:0.29680\n[800]\tvalid-logloss:0.15435\tvalid-gini:0.29706\n[900]\tvalid-logloss:0.15431\tvalid-gini:0.29766\n[1000]\tvalid-logloss:0.15430\tvalid-gini:0.29821\n[1100]\tvalid-logloss:0.15428\tvalid-gini:0.29841\n[1200]\tvalid-logloss:0.15427\tvalid-gini:0.29875\n[1300]\tvalid-logloss:0.15425\tvalid-gini:0.29905\n[1400]\tvalid-logloss:0.15425\tvalid-gini:0.29931\n[1500]\tvalid-logloss:0.15424\tvalid-gini:0.29944\n[1600]\tvalid-logloss:0.15424\tvalid-gini:0.29970\n[1700]\tvalid-logloss:0.15424\tvalid-gini:0.29972\n[1800]\tvalid-logloss:0.15423\tvalid-gini:0.29968\n[1900]\tvalid-logloss:0.15425\tvalid-gini:0.29959\n[1907]\tvalid-logloss:0.15425\tvalid-gini:0.29959\n폴드 1 지니계수 : 0.2997595687316113\n\n######################################## 폴드 2 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67671\tvalid-gini:0.15090\n[100]\tvalid-logloss:0.19204\tvalid-gini:0.23586\n[200]\tvalid-logloss:0.15879\tvalid-gini:0.26075\n[300]\tvalid-logloss:0.15558\tvalid-gini:0.26977\n[400]\tvalid-logloss:0.15509\tvalid-gini:0.27436\n[500]\tvalid-logloss:0.15493\tvalid-gini:0.27713\n[600]\tvalid-logloss:0.15489\tvalid-gini:0.27840\n[700]\tvalid-logloss:0.15486\tvalid-gini:0.27943\n[800]\tvalid-logloss:0.15485\tvalid-gini:0.28027\n[900]\tvalid-logloss:0.15481\tvalid-gini:0.28100\n[1000]\tvalid-logloss:0.15479\tvalid-gini:0.28151\n[1100]\tvalid-logloss:0.15478\tvalid-gini:0.28199\n[1200]\tvalid-logloss:0.15477\tvalid-gini:0.28235\n[1300]\tvalid-logloss:0.15475\tvalid-gini:0.28276\n[1400]\tvalid-logloss:0.15473\tvalid-gini:0.28292\n[1500]\tvalid-logloss:0.15474\tvalid-gini:0.28288\n[1600]\tvalid-logloss:0.15473\tvalid-gini:0.28305\n[1700]\tvalid-logloss:0.15472\tvalid-gini:0.28336\n[1800]\tvalid-logloss:0.15473\tvalid-gini:0.28345\n[1900]\tvalid-logloss:0.15471\tvalid-gini:0.28366\n[1999]\tvalid-logloss:0.15472\tvalid-gini:0.28369\n폴드 2 지니계수 : 0.2836934657365612\n\n######################################## 폴드 3 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67670\tvalid-gini:0.15662\n[100]\tvalid-logloss:0.19189\tvalid-gini:0.24749\n[200]\tvalid-logloss:0.15846\tvalid-gini:0.27051\n[300]\tvalid-logloss:0.15512\tvalid-gini:0.27959\n[400]\tvalid-logloss:0.15464\tvalid-gini:0.28214\n[500]\tvalid-logloss:0.15457\tvalid-gini:0.28279\n[600]\tvalid-logloss:0.15453\tvalid-gini:0.28330\n[700]\tvalid-logloss:0.15450\tvalid-gini:0.28398\n[800]\tvalid-logloss:0.15448\tvalid-gini:0.28396\n[900]\tvalid-logloss:0.15447\tvalid-gini:0.28432\n[1000]\tvalid-logloss:0.15448\tvalid-gini:0.28450\n[1100]\tvalid-logloss:0.15447\tvalid-gini:0.28480\n[1200]\tvalid-logloss:0.15445\tvalid-gini:0.28482\n[1300]\tvalid-logloss:0.15445\tvalid-gini:0.28484\n[1400]\tvalid-logloss:0.15445\tvalid-gini:0.28490\n[1500]\tvalid-logloss:0.15445\tvalid-gini:0.28508\n[1600]\tvalid-logloss:0.15445\tvalid-gini:0.28498\n[1700]\tvalid-logloss:0.15445\tvalid-gini:0.28516\n[1800]\tvalid-logloss:0.15444\tvalid-gini:0.28504\n[1894]\tvalid-logloss:0.15443\tvalid-gini:0.28500\n폴드 3 지니계수 : 0.2851397581256475\n\n######################################## 폴드 4 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67670\tvalid-gini:0.17175\n[100]\tvalid-logloss:0.19182\tvalid-gini:0.23980\n[200]\tvalid-logloss:0.15855\tvalid-gini:0.26372\n[300]\tvalid-logloss:0.15533\tvalid-gini:0.27156\n[400]\tvalid-logloss:0.15487\tvalid-gini:0.27401\n[500]\tvalid-logloss:0.15478\tvalid-gini:0.27510\n[600]\tvalid-logloss:0.15474\tvalid-gini:0.27598\n[700]\tvalid-logloss:0.15471\tvalid-gini:0.27648\n[800]\tvalid-logloss:0.15469\tvalid-gini:0.27700\n[900]\tvalid-logloss:0.15467\tvalid-gini:0.27758\n[1000]\tvalid-logloss:0.15466\tvalid-gini:0.27774\n[1100]\tvalid-logloss:0.15466\tvalid-gini:0.27810\n[1200]\tvalid-logloss:0.15464\tvalid-gini:0.27839\n[1300]\tvalid-logloss:0.15464\tvalid-gini:0.27864\n[1400]\tvalid-logloss:0.15462\tvalid-gini:0.27894\n[1500]\tvalid-logloss:0.15463\tvalid-gini:0.27907\n[1600]\tvalid-logloss:0.15462\tvalid-gini:0.27921\n[1700]\tvalid-logloss:0.15461\tvalid-gini:0.27944\n[1800]\tvalid-logloss:0.15460\tvalid-gini:0.27948\n[1900]\tvalid-logloss:0.15461\tvalid-gini:0.27946\n[1999]\tvalid-logloss:0.15462\tvalid-gini:0.27943\n폴드 4 지니계수 : 0.27959451224952514\n\n######################################## 폴드 5 / 폴드 5 ########################################\n[0]\tvalid-logloss:0.67671\tvalid-gini:0.16953\n[100]\tvalid-logloss:0.19192\tvalid-gini:0.24650\n[200]\tvalid-logloss:0.15865\tvalid-gini:0.27309\n[300]\tvalid-logloss:0.15534\tvalid-gini:0.28375\n[400]\tvalid-logloss:0.15483\tvalid-gini:0.28770\n[500]\tvalid-logloss:0.15469\tvalid-gini:0.29021\n[600]\tvalid-logloss:0.15464\tvalid-gini:0.29173\n[700]\tvalid-logloss:0.15459\tvalid-gini:0.29272\n[800]\tvalid-logloss:0.15458\tvalid-gini:0.29340\n[900]\tvalid-logloss:0.15456\tvalid-gini:0.29363\n[1000]\tvalid-logloss:0.15455\tvalid-gini:0.29403\n[1100]\tvalid-logloss:0.15454\tvalid-gini:0.29442\n[1200]\tvalid-logloss:0.15452\tvalid-gini:0.29467\n[1300]\tvalid-logloss:0.15452\tvalid-gini:0.29479\n[1400]\tvalid-logloss:0.15450\tvalid-gini:0.29512\n[1500]\tvalid-logloss:0.15449\tvalid-gini:0.29524\n[1600]\tvalid-logloss:0.15449\tvalid-gini:0.29551\n[1700]\tvalid-logloss:0.15447\tvalid-gini:0.29585\n[1800]\tvalid-logloss:0.15446\tvalid-gini:0.29620\n[1900]\tvalid-logloss:0.15447\tvalid-gini:0.29631\n[1999]\tvalid-logloss:0.15446\tvalid-gini:0.29645\n폴드 5 지니계수 : 0.29642485982069267\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))","metadata":{"execution":{"iopub.status.busy":"2023-03-25T10:24:26.708030Z","iopub.execute_input":"2023-03-25T10:24:26.708829Z","iopub.status.idle":"2023-03-25T10:24:26.825639Z","shell.execute_reply.started":"2023-03-25T10:24:26.708780Z","shell.execute_reply":"2023-03-25T10:24:26.824335Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"OOF 검증 데이터 지니계수 : 0.28878246656069356\n","output_type":"stream"}]},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission_01.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T10:35:07.759072Z","iopub.execute_input":"2023-03-25T10:35:07.759532Z","iopub.status.idle":"2023-03-25T10:35:09.958060Z","shell.execute_reply.started":"2023-03-25T10:35:07.759496Z","shell.execute_reply":"2023-03-25T10:35:09.956522Z"},"trusted":true},"execution_count":22,"outputs":[]}]}