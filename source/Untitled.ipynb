{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6429feb3-053a-4723-a2ed-e077e587aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd3b0788-55c0-40a5-91cd-0422c999e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2966ef0d-8802-4dba-8df7-cffa6eef6882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš©ì: ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ì•„ìš”!\n",
      "AI: ë„¤, ë‚ ì”¨ê°€ ì¢‹ì€ ë‚ ì€ ê¸°ë¶„ì´ ì¢‹ì•„ì§€ì£ ! ì¦ê±°ìš´ í•˜ë£¨ ë³´ë‚´ì„¸ìš”. ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import Graph, StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ìƒíƒœ ì •ì˜\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    emotion: str\n",
    "    response: str\n",
    "\n",
    "# LLM ëª¨ë¸ ì´ˆê¸°í™” (OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤)\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# ê°ì • ë¶„ì„ í•¨ìˆ˜\n",
    "def analyze_emotion(state: State) -> State:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"ë‹¹ì‹ ì€ ê°ì • ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ì„í•˜ì„¸ìš”: {input}\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"input\": state[\"input\"]})\n",
    "    state[\"emotion\"] = result.content\n",
    "    return state\n",
    "\n",
    "# ì‘ë‹µ ìƒì„± í•¨ìˆ˜\n",
    "def generate_response(state: State) -> State:\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ê°ì •ì— ê¸°ë°˜í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "        ì…ë ¥: {input}\n",
    "        ê°ì •: {emotion}\n",
    "        ì‘ë‹µ:\"\"\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"input\": state[\"input\"], \"emotion\": state[\"emotion\"]})\n",
    "    state[\"response\"] = result.content\n",
    "    return state\n",
    "\n",
    "# ê·¸ë˜í”„ ì •ì˜\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"emotion_analyzer\", analyze_emotion)\n",
    "workflow.add_node(\"response_generator\", generate_response)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "workflow.set_entry_point(\"emotion_analyzer\")\n",
    "workflow.add_edge(\"emotion_analyzer\", \"response_generator\")\n",
    "workflow.set_finish_point(\"response_generator\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "chain = workflow.compile()\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_conversation(user_input: str):\n",
    "    state = {\"input\": user_input}\n",
    "    final_state = chain.invoke(state)\n",
    "    return final_state[\"response\"]\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆ\n",
    "if __name__ == \"__main__\":\n",
    "    user_input = \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ì•„ìš”!\"\n",
    "    response = run_conversation(user_input)\n",
    "    print(f\"ì‚¬ìš©ì: {user_input}\")\n",
    "    print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb40f0-3d62-4060-a5dd-0e5f496384ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
