{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2장: 텍스트 데이터 작업하기 (Working with Text Data)\n",
    "\n",
    "## 이 장에서 다루는 내용\n",
    "\n",
    "- 대규모 언어 모델 훈련을 위한 텍스트 준비\n",
    "- 텍스트를 단어와 하위 단어 토큰으로 분할\n",
    "- 텍스트 토큰화의 더 발전된 방법인 바이트 페어 인코딩\n",
    "- 슬라이딩 윈도우 접근 방식으로 훈련 예제 샘플링\n",
    "- 토큰을 대규모 언어 모델에 입력되는 벡터로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북에서 사용되는 패키지들:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.8.0\n",
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "# 사용할 라이브러리의 버전 확인\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 장에서는 LLM을 위한 입력 데이터를 \"준비\"하는 데이터 준비 및 샘플링을 다룹니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/01.webp?timestamp=1\" width=\"500px\">\n",
    "\n",
    "그림: LLM 데이터 준비의 전체 프로세스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 단어 임베딩 이해하기\n",
    "\n",
    "LLM을 포함한 심층 신경망 모델은 원시 텍스트를 직접 처리할 수 없습니다. 텍스트는 범주형이므로 신경망을 구현하고 훈련하는 데 사용되는 수학적 연산과 호환되지 않습니다. 따라서 단어를 연속값 벡터로 표현하는 방법이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 섹션에는 코드가 없습니다 - 개념 설명만 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩의 다양한 형태가 있습니다; 이 책에서는 텍스트 임베딩에 초점을 맞춥니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/02.webp\" width=\"500px\">\n",
    "\n",
    "그림: 다양한 데이터 형태의 임베딩 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLM은 고차원 공간에서 임베딩으로 작업합니다 (즉, 수천 차원)\n",
    "- 우리는 그런 고차원 공간을 시각화할 수 없으므로 (인간은 1, 2, 또는 3차원으로 생각함), 아래 그림은 2차원 임베딩 공간을 보여줍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/03.webp\" width=\"300px\">\n",
    "\n",
    "그림: 2차원 임베딩 공간에서의 단어 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 텍스트 토큰화\n",
    "\n",
    "이 섹션에서는 텍스트를 토큰화합니다. 즉, 텍스트를 개별 단어나 구두점 문자와 같은 더 작은 단위로 나눕니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/04.webp\" width=\"300px\">\n",
    "\n",
    "그림: 텍스트 토큰화 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리가 작업할 원시 텍스트를 로드합니다\n",
    "- [The Verdict by Edith Wharton](https://en.wikisource.org/wiki/The_Verdict)은 공개 도메인 단편 소설입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일 다운로드 (파일이 없는 경우)\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = \"the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "#### SSL 인증서 오류 해결방법\n",
    "\n",
    "- 일부 독자들이 VSCode나 Jupyter에서 `urllib.request.urlretrieve`를 실행할 때 ssl.SSLCertVerificationError: `SSL: CERTIFICATE_VERIFY_FAILED` 오류를 보고했습니다.\n",
    "- 이는 보통 Python의 인증서 번들이 오래된 것을 의미합니다.\n",
    "\n",
    "**해결 방법**\n",
    "\n",
    "- Python ≥ 3.9 사용; 다음 코드를 실행하여 Python 버전을 확인할 수 있습니다:\n",
    "```python\n",
    "import sys\n",
    "print(sys.__version__)\n",
    "```\n",
    "- 인증서 번들 업그레이드:\n",
    "  - pip: `pip install --upgrade certifi`\n",
    "  - uv: `uv pip install --upgrade certifi`\n",
    "- 업그레이드 후 Jupyter 커널을 재시작하세요.\n",
    "- 여전히 `ssl.SSLCertVerificationError`가 발생하면 [GitHub에서 자세한 정보](https://github.com/rasbt/LLMs-from-scratch/pull/403)를 참조하세요.\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문자 수: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일 읽기\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"총 문자 수:\", len(raw_text))\n",
    "print(raw_text[:99])  # 처음 99자 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 목표는 이 텍스트를 LLM을 위해 토큰화하고 임베딩하는 것입니다\n",
    "- 나중에 위의 텍스트에 적용할 수 있는 간단한 샘플 텍스트를 기반으로 한 간단한 토큰화기를 개발해보겠습니다\n",
    "- 다음 정규 표현식은 공백으로 분할합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "# 정규 표현식을 사용한 기본 토큰화\n",
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)  # 공백으로 분할\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리는 공백뿐만 아니라 쉼표와 마침표로도 분할하고 싶으므로, 정규 표현식을 수정해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "# 구두점을 포함한 분할\n",
    "result = re.split(r'([,.]|\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 보시는 바와 같이 이것은 빈 문자열을 생성하므로 제거해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "# 각 항목에서 공백을 제거하고 빈 문자열을 필터링합니다\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이것은 꽤 좋아 보이지만, 마침표, 물음표 등과 같은 다른 유형의 구두점도 처리해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 구두점 처리\n",
    "text = \"Hello, world. Is this-- a test?\"\n",
    "\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 꽤 좋아졌으므로 원시 텍스트에 이 토큰화를 적용할 준비가 되었습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/05.webp\" width=\"350px\">\n",
    "\n",
    "그림: 토큰화 과정의 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트에 토큰화 적용\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(preprocessed[:30])  # 처음 30개 토큰 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 토큰 수를 계산해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 토큰을 토큰 ID로 변환하기\n",
    "\n",
    "다음으로, 나중에 임베딩 레이어를 통해 처리할 수 있는 토큰 ID로 텍스트 토큰을 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/06.webp\" width=\"500px\">\n",
    "\n",
    "그림: 토큰을 ID로 변환하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이러한 토큰들로부터 모든 고유한 토큰으로 구성된 어휘(vocabulary)를 구축할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘 구축\n",
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰을 정수로 매핑하는 어휘 사전 생성\n",
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래는 이 어휘의 처음 50개 항목입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘의 처음 50개 항목 출력\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래에서는 작은 어휘를 사용하여 짧은 샘플 텍스트의 토큰화를 보여줍니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/07.webp?123\" width=\"500px\">\n",
    "\n",
    "그림: 작은 어휘를 사용한 토큰화 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 모든 것을 토큰화기 클래스로 정리해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 토큰화기 클래스 구현\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"텍스트를 토큰 ID 리스트로 인코딩\"\"\"\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        \"\"\"토큰 ID 리스트를 텍스트로 디코딩\"\"\"\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # 지정된 구두점 앞의 공백을 제거\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `encode` 함수는 텍스트를 토큰 ID로 변환합니다\n",
    "- `decode` 함수는 토큰 ID를 다시 텍스트로 변환합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/08.webp?123\" width=\"500px\">\n",
    "\n",
    "그림: 토큰화기의 인코딩/디코딩 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 토큰화기를 사용하여 텍스트를 정수로 인코딩(즉, 토큰화)할 수 있습니다\n",
    "- 이 정수들은 나중에 LLM의 입력으로 임베딩될 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화기 테스트\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정수를 다시 텍스트로 디코딩할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩 테스트\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 후 바로 디코딩 테스트 (원본과 비교)\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 특수 컨텍스트 토큰 추가하기\n",
    "\n",
    "알 수 없는 단어를 위한 \"특수\" 토큰과 텍스트의 끝을 나타내는 토큰을 추가하는 것이 유용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/09.webp?123\" width=\"500px\">\n",
    "\n",
    "그림: 특수 토큰들의 용도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 토큰화기는 LLM에게 추가적인 컨텍스트를 제공하기 위해 특수 토큰을 사용합니다:\n",
    "\n",
    "- `[BOS]` (beginning of sequence): 텍스트의 시작을 표시\n",
    "- `[EOS]` (end of sequence): 텍스트가 끝나는 곳을 표시 (보통 서로 관련 없는 여러 텍스트를 연결할 때 사용)\n",
    "- `[PAD]` (padding): 배치 크기가 1보다 큰 경우 LLM을 훈련할 때 사용 (여러 텍스트를 같은 길이로 맞춤)\n",
    "- `[UNK]`: 어휘에 포함되지 않은 단어를 나타냄\n",
    "\n",
    "GPT-2는 복잡성을 줄이기 위해 위에서 언급한 토큰들이 필요하지 않고 `<|endoftext|>` 토큰만 사용합니다.\n",
    "GPT-2는 어휘에 없는 단어에 대해 `<UNK>` 토큰을 사용하지 않고, 대신 바이트 페어 인코딩(BPE) 토큰화기를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 개의 독립적인 텍스트 소스 사이에 `<|endoftext|>` 토큰을 사용합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/10.webp\" width=\"500px\">\n",
    "\n",
    "그림: 텍스트 사이에 endoftext 토큰 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 텍스트를 토큰화하면 어떻게 되는지 살펴보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘에 없는 단어가 포함된 텍스트 토큰화 시도\n",
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"Hello, do you like tea. Is this-- a test?\"\n",
    "\n",
    "try:\n",
    "    tokenizer.encode(text)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e} - 이 단어는 어휘에 없습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 결과는 \"Hello\"라는 단어가 어휘에 포함되어 있지 않기 때문에 오류를 생성합니다\n",
    "- 이런 경우를 처리하기 위해 알 수 없는 단어를 나타내는 `\"<|unk|>\"`과 같은 특수 토큰을 어휘에 추가할 수 있습니다\n",
    "- 이미 어휘를 확장하고 있으므로, GPT-2 훈련에서 텍스트의 끝을 나타내는데 사용되는 `\"<|endoftext|>\"`라는 또 다른 토큰을 추가해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수 토큰이 포함된 새로운 어휘 생성\n",
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 어휘 크기 확인\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 5개 항목 확인 (특수 토큰들 포함)\n",
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 새로운 `<unk>` 토큰을 언제 어떻게 사용하는지 알 수 있도록 토큰화기를 적절히 조정해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수 토큰을 처리하는 개선된 토큰화기\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"텍스트를 토큰 ID로 인코딩 (알 수 없는 단어는 <|unk|>로 처리)\"\"\"\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        \"\"\"토큰 ID를 텍스트로 디코딩\"\"\"\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # 지정된 구두점 앞의 공백을 제거\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수정된 토큰화기로 텍스트를 토큰화해보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개선된 토큰화기 테스트\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 테스트\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩 테스트\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 바이트페어 인코딩 (BytePair Encoding)\n",
    "\n",
    "- GPT-2는 토큰화기로 바이트페어 인코딩(BPE)을 사용합니다\n",
    "- 이는 모델이 미리 정의된 어휘에 없는 단어들을 더 작은 하위 단어 단위나 개별 문자로 분해할 수 있게 합니다\n",
    "- 예를 들어, GPT-2의 어휘에 \"unfamiliarword\"라는 단어가 없다면, 훈련된 BPE 병합에 따라 [\"unfam\", \"iliar\", \"word\"] 또는 다른 하위 단어 분해로 토큰화할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 BPE 토큰화기는 여기서 찾을 수 있습니다: [https://github.com/openai/gpt-2/blob/master/src/encoder.py](https://github.com/openai/gpt-2/blob/master/src/encoder.py)\n",
    "- 이 장에서는 OpenAI의 오픈소스 [tiktoken](https://github.com/openai/tiktoken) 라이브러리의 BPE 토큰화기를 사용합니다. 이는 계산 성능을 향상시키기 위해 핵심 알고리즘을 Rust로 구현했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken 설치 (필요한 경우)\n",
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiktoken 라이브러리 가져오기 및 버전 확인\n",
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 토큰화기 로드\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE 토큰화기 테스트\n",
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코딩 테스트\n",
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BPE 토큰화기는 알 수 없는 단어를 하위 단어와 개별 문자로 분해합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/11.webp\" width=\"300px\">\n",
    "\n",
    "그림: BPE 토큰화의 하위 단어 분해 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 슬라이딩 윈도우로 데이터 샘플링하기\n",
    "\n",
    "- 우리는 LLM이 한 번에 한 단어씩 생성하도록 훈련하므로, 시퀀스의 다음 단어가 예측할 타겟을 나타내는 훈련 데이터를 준비해야 합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/12.webp\" width=\"400px\">\n",
    "\n",
    "그림: 다음 단어 예측을 위한 입력-타겟 쌍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트를 토큰화\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 텍스트 청크에 대해 입력과 타겟이 필요합니다\n",
    "- 모델이 다음 단어를 예측하기를 원하므로, 타겟은 한 위치만큼 오른쪽으로 이동된 입력입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 텍스트 청크 생성\n",
    "enc_sample = enc_text[50:]\n",
    "\n",
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하나씩, 예측은 다음과 같이 보일 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 단계별 예측 과정 보기\n",
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 ID를 실제 단어로 변환하여 보기\n",
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어텐션 메커니즘을 다룬 후에 다음 장에서 다음 단어 예측을 처리할 것입니다\n",
    "- 지금은 입력 데이터셋을 반복하고 하나씩 이동된 입력과 타겟을 반환하는 간단한 데이터 로더를 구현하겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch 설치 및 가져오기 (설치 팁은 부록 A 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 가져오기 및 버전 확인\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- +1씩 위치를 변경하는 슬라이딩 윈도우 접근법을 사용합니다:\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/13.webp?123\" width=\"500px\">\n",
    "\n",
    "그림: 슬라이딩 윈도우 데이터 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력 텍스트 데이터셋에서 청크를 추출하는 데이터셋과 데이터로더를 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 데이터셋 클래스 구현\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # 전체 텍스트를 토큰화\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "        assert len(token_ids) > max_length, \"토큰화된 입력의 수는 최소 max_length+1과 같아야 합니다\"\n",
    "\n",
    "        # 슬라이딩 윈도우를 사용하여 책을 max_length의 겹치는 시퀀스로 청크화\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 생성 함수\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # 토큰화기 초기화\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # 데이터셋 생성\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # 데이터로더 생성\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컨텍스트 크기가 4인 LLM에 대해 배치 크기 1로 데이터로더를 테스트해보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일 읽기\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 테스트 (배치 크기 1, 컨텍스트 크기 4)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 배치 확인\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래와 같이 컨텍스트 길이(여기서는 4)와 동일한 스트라이드를 사용한 예시:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/14.webp\" width=\"500px\">\n",
    "\n",
    "그림: 스트라이드가 컨텍스트 길이와 같은 경우의 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배치된 출력도 생성할 수 있습니다\n",
    "- 여기서 스트라이드를 증가시켜 배치 간에 겹치지 않도록 합니다. 더 많은 겹침은 과적합 증가로 이어질 수 있기 때문입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 크기 8로 테스트\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"입력:\")\n",
    "print(inputs)\n",
    "print(\"\\n타겟:\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 토큰 임베딩 생성하기\n",
    "\n",
    "- 데이터는 이미 거의 LLM을 위해 준비되었습니다\n",
    "- 마지막으로 임베딩 레이어를 사용하여 토큰을 연속 벡터 표현으로 임베딩해보겠습니다\n",
    "- 일반적으로 이러한 임베딩 레이어는 LLM 자체의 일부이며 모델 훈련 중에 업데이트(훈련)됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/15.webp\" width=\"400px\">\n",
    "\n",
    "그림: 토큰 임베딩 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (토큰화 후) 입력 ID 2, 3, 5, 1을 가진 다음 네 가지 입력 예시가 있다고 가정해보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 입력 ID\n",
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간단함을 위해 6개 단어만의 작은 어휘와 크기 3의 임베딩을 생성한다고 가정해보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 레이어 생성\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이는 6x3 가중치 행렬을 생성합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 레이어의 가중치 확인\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원-핫 인코딩에 익숙한 분들을 위해, 위의 임베딩 레이어 접근법은 본질적으로 원-핫 인코딩 후 완전 연결 레이어에서 행렬 곱셈을 수행하는 것의 더 효율적인 구현일 뿐입니다\n",
    "- 임베딩 레이어가 원-핫 인코딩 및 행렬 곱셈 접근법과 동등한 더 효율적인 구현이기 때문에, 역전파를 통해 최적화할 수 있는 신경망 레이어로 볼 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ID 3인 토큰을 3차원 벡터로 변환하려면 다음과 같이 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 토큰 임베딩\n",
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 결과는 `embedding_layer` 가중치 행렬의 4번째 행입니다\n",
    "- 위의 네 `input_ids` 값을 모두 임베딩하려면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 토큰 임베딩\n",
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩 레이어는 본질적으로 룩업 연산입니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/16.webp?123\" width=\"500px\">\n",
    "\n",
    "그림: 임베딩 레이어의 룩업 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 단어 위치 인코딩하기\n",
    "\n",
    "- 임베딩 레이어는 입력 시퀀스에서 위치에 관계없이 ID를 동일한 벡터 표현으로 변환합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/17.webp\" width=\"400px\">\n",
    "\n",
    "그림: 위치와 무관한 토큰 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위치 임베딩은 토큰 임베딩 벡터와 결합되어 대규모 언어 모델의 입력 임베딩을 형성합니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/18.webp\" width=\"500px\">\n",
    "\n",
    "그림: 토큰 임베딩과 위치 임베딩의 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 바이트페어 인코더는 50,257개의 어휘 크기를 가집니다:\n",
    "- 입력 토큰을 256차원 벡터 표현으로 인코딩한다고 가정해보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 크기의 토큰 임베딩 레이어\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터로더에서 데이터를 샘플링하면, 각 배치의 토큰을 256차원 벡터로 임베딩합니다\n",
    "- 각각 4개의 토큰을 가진 배치 크기 8이 있다면, 이는 8 x 4 x 256 텐서가 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터로 토큰 임베딩 테스트\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"토큰 ID:\")\n",
    "print(inputs)\n",
    "print(\"\\n입력 크기:\")\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 임베딩 생성\n",
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)\n",
    "\n",
    "# 임베딩이 어떻게 보이는지 확인하려면 아래 줄의 주석을 제거하고 실행하세요\n",
    "# print(token_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPT-2는 절대 위치 임베딩을 사용하므로, 단순히 다른 임베딩 레이어를 생성합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 임베딩 레이어 생성\n",
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "\n",
    "# 임베딩 레이어 가중치를 보려면 아래 줄의 주석을 제거하고 실행하세요\n",
    "# print(pos_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 임베딩 생성\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n",
    "\n",
    "# 임베딩이 어떻게 보이는지 확인하려면 아래 줄의 주석을 제거하고 실행하세요\n",
    "# print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLM에서 사용되는 입력 임베딩을 생성하려면, 토큰 임베딩과 위치 임베딩을 단순히 더합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 입력 임베딩 생성 (토큰 + 위치 임베딩)\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)\n",
    "\n",
    "# 임베딩이 어떻게 보이는지 확인하려면 아래 줄의 주석을 제거하고 실행하세요\n",
    "# print(input_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력 처리 워크플로우의 초기 단계에서, 입력 텍스트는 개별 토큰으로 분할됩니다\n",
    "- 이 분할 후, 이러한 토큰은 미리 정의된 어휘를 기반으로 토큰 ID로 변환됩니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch02_compressed/19.webp\" width=\"400px\">\n",
    "\n",
    "그림: 전체 텍스트 처리 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요약 및 핵심 사항\n",
    "\n",
    "이 장에서 구현한 데이터 로더의 간결한 버전은 [./dataloader.ipynb](./dataloader.ipynb) 코드 노트북을 참조하세요. 이는 향후 장에서 GPT 모델을 훈련하는 데 필요할 것입니다.\n",
    "\n",
    "연습 문제 해답은 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)를 참조하세요.\n",
    "\n",
    "GPT-2 토큰화기를 처음부터 구현하고 훈련하는 방법에 관심이 있다면 [Byte Pair Encoding (BPE) Tokenizer From Scratch](../02_bonus_bytepair-encoder/compare-bpe-tiktoken.ipynb) 노트북을 참조하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
