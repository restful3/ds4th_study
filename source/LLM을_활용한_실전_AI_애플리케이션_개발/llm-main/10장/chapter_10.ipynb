{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqusGuvMrhfP"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.40.1 datasets==2.19.0 sentence-transformers==2.7.0 faiss-cpu==1.8.0 llama-index==0.10.34 llama-index-embeddings-huggingface==0.2.0 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.1 문장 임베딩을 활용한 단어 간 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bERp0FI_rlWK"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "smodel = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "dense_embeddings = smodel.encode(['학교', '공부', '운동'])\n",
    "cosine_similarity(dense_embeddings) # 코사인 유사도\n",
    "# array([[1.0000001 , 0.5950744 , 0.32537547],\n",
    "#       [0.5950744 , 1.0000002 , 0.54595673],\n",
    "#       [0.32537547, 0.54595673, 0.99999976]], dtype=float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.2 원핫 인코딩의 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcMwxBo6rmbI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "word_dict = {\"school\": np.array([[1, 0, 0]]),\n",
    "\"study\": np.array([[0, 1, 0]]),\n",
    "\"workout\": np.array([[0, 0, 1]])\n",
    "}\n",
    "\n",
    "# 두 단어 사이의 코사인 유사도 계산하기\n",
    "cosine_school_study = cosine_similarity(word_dict[\"school\"], word_dict['study']) # 0\n",
    "cosine_school_workout = cosine_similarity(word_dict['school'], word_dict['workout']) # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.3 Sentence-Transformers 라이브러리로 바이 인코더 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXcPv_Otrpqk"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "# 사용할 BERT 모델\n",
    "word_embedding_model = models.Transformer('klue/roberta-base')\n",
    "# 풀링 층 차원 입력하기\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "# 두 모듈 결합하기\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.4 코드로 살펴보는 평균 모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xua7CHzorrWs"
   },
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.5 코드로 살펴보는 최대 모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9GFRCtZrt4P"
   },
   "outputs": [],
   "source": [
    "def max_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    token_embeddings[input_mask_expanded == 0] = -1e9\n",
    "    return torch.max(token_embeddings, 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.6 한국어 문장 임베딩 모델로 입력 문장 사이의 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r64uO9xrvJd"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "embs = model.encode(['잠이 안 옵니다',\n",
    "                     '졸음이 옵니다',\n",
    "                     '기차가 옵니다'])\n",
    "\n",
    "cos_scores = util.cos_sim(embs, embs)\n",
    "print(cos_scores)\n",
    "# tensor([[1.0000, 0.6410, 0.1887],\n",
    "#         [0.6410, 1.0000, 0.2730],\n",
    "#         [0.1887, 0.2730, 1.0000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.7 CLIP 모델을 활용한 이미지와 텍스트 임베딩 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFpBCDhMrwxM"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "img_embs = model.encode([Image.open('dog.jpg'), Image.open('cat.jpg')])\n",
    "text_embs = model.encode(['A dog on grass', 'Brown cat on yellow background'])\n",
    "\n",
    "cos_scores = util.cos_sim(img_embs, text_embs)\n",
    "print(cos_scores)\n",
    "# tensor([[0.2771, 0.1509],\n",
    "#         [0.2071, 0.3180]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.8 실습에 사용할 모델과 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOrKBXzYryjQ"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc', split='train')\n",
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.9 실습 데이터에서 1,000개만 선택하고 문장 임베딩으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PPCKioTr0VT"
   },
   "outputs": [],
   "source": [
    "klue_mrc_dataset = klue_mrc_dataset.train_test_split(train_size=1000, shuffle=False)['train']\n",
    "embeddings = sentence_model.encode(klue_mrc_dataset['context'])\n",
    "embeddings.shape\n",
    "# 출력 결과\n",
    "# (1000, 768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.10 KNN 검색 인덱스를 생성하고 문장 임베딩 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJsY0g30r2BQ"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "# 인덱스 만들기\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "# 인덱스에 임베딩 저장하기\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.11 의미 검색의 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC5XgbD7r3LR"
   },
   "outputs": [],
   "source": [
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "query_embedding = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "\n",
    "for idx in indices[0]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은   (정답)\n",
    "# 연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그 (오답)\n",
    "# 연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그 (오답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.12 의미 검색의 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGe6VK4dr4cT"
   },
   "outputs": [],
   "source": [
    "query = klue_mrc_dataset[3]['question'] # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "query_embedding = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "\n",
    "for idx in indices[0]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 (오답)\n",
    "# 태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 (오답)\n",
    "# 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스 (정답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.13 라마인덱스에서 Sentence-Transformers 임베딩 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rEKVpB7r7YC"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, ServiceContext\n",
    "from llama_index.core import Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "# 로컬 모델 활용하기\n",
    "# service_context = ServiceContext.from_defaults(embed_model=\"local\")\n",
    "\n",
    "text_list = klue_mrc_dataset[:100]['context']\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "index_llama = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.14 BM25 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2n3JJ2br_Aa"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from transformers import PreTrainedTokenizer\n",
    "from collections import defaultdict\n",
    "\n",
    "class BM25:\n",
    "  def __init__(self, corpus:List[List[str]], tokenizer:PreTrainedTokenizer):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.corpus = corpus\n",
    "    self.tokenized_corpus = self.tokenizer(corpus, add_special_tokens=False)['input_ids']\n",
    "    self.n_docs = len(self.tokenized_corpus)\n",
    "    self.avg_doc_lens = sum(len(lst) for lst in self.tokenized_corpus) / len(self.tokenized_corpus)\n",
    "    self.idf = self._calculate_idf()\n",
    "    self.term_freqs = self._calculate_term_freqs()\n",
    "\n",
    "  def _calculate_idf(self):\n",
    "    idf = defaultdict(float)\n",
    "    for doc in self.tokenized_corpus:\n",
    "      for token_id in set(doc):\n",
    "        idf[token_id] += 1\n",
    "    for token_id, doc_frequency in idf.items():\n",
    "      idf[token_id] = math.log(((self.n_docs - doc_frequency + 0.5) / (doc_frequency + 0.5)) + 1)\n",
    "    return idf\n",
    "\n",
    "  def _calculate_term_freqs(self):\n",
    "    term_freqs = [defaultdict(int) for _ in range(self.n_docs)]\n",
    "    for i, doc in enumerate(self.tokenized_corpus):\n",
    "      for token_id in doc:\n",
    "        term_freqs[i][token_id] += 1\n",
    "    return term_freqs\n",
    "\n",
    "  def get_scores(self, query:str, k1:float = 1.2, b:float=0.75):\n",
    "    query = self.tokenizer([query], add_special_tokens=False)['input_ids'][0]\n",
    "    scores = np.zeros(self.n_docs)\n",
    "    for q in query:\n",
    "      idf = self.idf[q]\n",
    "      for i, term_freq in enumerate(self.term_freqs):\n",
    "        q_frequency = term_freq[q]\n",
    "        doc_len = len(self.tokenized_corpus[i])\n",
    "        score_q = idf * (q_frequency * (k1 + 1)) / ((q_frequency) + k1 * (1 - b + b * (doc_len / self.avg_doc_lens)))\n",
    "        scores[i] += score_q\n",
    "    return scores\n",
    "\n",
    "  def get_top_k(self, query:str, k:int):\n",
    "    scores = self.get_scores(query)\n",
    "    top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "    top_k_scores = scores[top_k_indices]\n",
    "    return top_k_scores, top_k_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.15 BM25 점수 계산 확인해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oB3Ro5wtsAcL"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "\n",
    "bm25 = BM25(['안녕하세요', '반갑습니다', '안녕 서울'], tokenizer)\n",
    "bm25.get_scores('안녕')\n",
    "# array([0.44713859, 0.        , 0.52354835])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.16 BM25 검색 결과의 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fBHx5U5sBiG"
   },
   "outputs": [],
   "source": [
    "# BM25 검색 준비\n",
    "bm25 = BM25(klue_mrc_dataset['context'], tokenizer)\n",
    "\n",
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다 (오답)\n",
    "# 인구 비율당 노벨상을 세계에서 가장 많이 받은 나라, 과학 논문을 가장 많이 쓰고 의료 특 (오답)\n",
    "# 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은  (정답)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.17 BM25 검색 결과의 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA8336HjsC4n"
   },
   "outputs": [],
   "source": [
    "query = klue_mrc_dataset[3]['question']  # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스 (정답)\n",
    "# ;메카동(メカドン)                                                      (오답)\n",
    "# :성우 : 나라하시 미키(ならはしみき)\n",
    "# 길가에 버려져 있던 낡은 느티나\n",
    "# ;메카동(メカドン)                                                      (오답)\n",
    "# :성우 : 나라하시 미키(ならはしみき)\n",
    "# 길가에 버려져 있던 낡은 느티나"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.18 상호 순위 조합 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM-kCJ0LsEMM"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def reciprocal_rank_fusion(rankings:List[List[int]], k=5):\n",
    "    rrf = defaultdict(float)\n",
    "    for ranking in rankings:\n",
    "        for i, doc_id in enumerate(ranking, 1):\n",
    "            rrf[doc_id] += 1.0 / (k + i)\n",
    "    return sorted(rrf.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.19 예시 데이터에 대한 상호 순위 조합 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8l18YDEDsFaq"
   },
   "outputs": [],
   "source": [
    "rankings = [[1, 4, 3, 5, 6], [2, 1, 3, 6, 4]]\n",
    "reciprocal_rank_fusion(rankings)\n",
    "\n",
    "# [(1, 0.30952380952380953),\n",
    "#  (3, 0.25),\n",
    "#  (4, 0.24285714285714285),\n",
    "#  (6, 0.2111111111111111),\n",
    "#  (2, 0.16666666666666666),\n",
    "#  (5, 0.1111111111111111)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.20 하이브리드 검색 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heGbTstMsG4v"
   },
   "outputs": [],
   "source": [
    "def dense_vector_search(query:str, k:int):\n",
    "  query_embedding = sentence_model.encode([query])\n",
    "  distances, indices = index.search(query_embedding, k)\n",
    "  return distances[0], indices[0]\n",
    "\n",
    "def hybrid_search(query, k=20):\n",
    "  _, dense_search_ranking = dense_vector_search(query, 100)\n",
    "  _, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "  results = reciprocal_rank_fusion([dense_search_ranking, bm25_search_ranking], k=k)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 10.21 예시 데이터에 대한 하이브리드 검색 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K17VRLmQsISX"
   },
   "outputs": [],
   "source": [
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "print(\"검색 쿼리 문장: \", query)\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "print(\"=\" * 80)\n",
    "query = klue_mrc_dataset[3]['question'] # 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "print(\"검색 쿼리 문장: \", query)\n",
    "\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "  print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 검색 쿼리 문장:  이번 연도에는 언제 비가 많이 올까?\n",
    "# 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은  (정답)\n",
    "# 갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다  (오답)\n",
    "# 연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그 (오답)\n",
    "# ================================================================================\n",
    "# 검색 쿼리 문장:  로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
    "# 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스 (정답)\n",
    "# 1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음 (오답)\n",
    "# 1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음 (오답)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
