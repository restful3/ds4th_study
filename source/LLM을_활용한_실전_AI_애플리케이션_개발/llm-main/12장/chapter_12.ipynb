{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io5yC7HEZ1R7"
   },
   "outputs": [],
   "source": [
    "!pip install pinecone-client==3.2.2 sentence-transformers==2.7.0 datasets==2.19.0 faiss-cpu==1.8.0 transformers==4.40.1 openai==1.25.2 llama-index==0.10.34 llama-index-vector-stores-pinecone==0.1.6  -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.1 실습 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLQNQWA3aCs5"
   },
   "outputs": [],
   "source": [
    "!wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\n",
    "!tar -xf sift.tar.gz\n",
    "!mkdir data/sift1M -p\n",
    "!mv sift/* data/sift1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.2 실습 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOw5mNMvaD78"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_memory_usage_mb():\n",
    "    process = psutil.Process()\n",
    "    memory_info = process.memory_info()\n",
    "    return memory_info.rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMkJKJk0b43y"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import faiss\n",
    "from faiss.contrib.datasets import DatasetSIFT1M\n",
    "\n",
    "ds = DatasetSIFT1M()\n",
    "\n",
    "xq = ds.get_queries()\n",
    "xb = ds.get_database()\n",
    "gt = ds.get_groundtruth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.3 데이터가 늘어날 때 색인/검색 시간, 메모리 사용량 변화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gzCFRawaFJx"
   },
   "outputs": [],
   "source": [
    "k=1\n",
    "d = xq.shape[1]\n",
    "nq = 1000\n",
    "xq = xq[:nq]\n",
    "\n",
    "for i in range(1, 10, 2):\n",
    "    start_memory = get_memory_usage_mb()\n",
    "    start_indexing = time.time()\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(xb[:(i+1)*100000])\n",
    "    end_indexing = time.time()\n",
    "    end_memory = get_memory_usage_mb()\n",
    "\n",
    "    t0 = time.time()\n",
    "    D, I = index.search(xq, k)\n",
    "    t1 = time.time()\n",
    "    print(f\"데이터 {(i+1)*100000}개:\")\n",
    "    print(f\"색인: {(end_indexing - start_indexing) * 1000 :.3f} ms ({end_memory - start_memory:.3f} MB) 검색: {(t1 - t0) * 1000 / nq :.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.4 파라미터 m의 변경에 따른 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zb3vnINRaIIo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k=1\n",
    "d = xq.shape[1]\n",
    "nq = 1000\n",
    "xq = xq[:nq]\n",
    "\n",
    "for m in [8, 16, 32, 64]:\n",
    "    index = faiss.IndexHNSWFlat(d, m)\n",
    "    time.sleep(3)\n",
    "    start_memory = get_memory_usage_mb()\n",
    "    start_index = time.time()\n",
    "    index.add(xb)\n",
    "    end_memory = get_memory_usage_mb()\n",
    "    end_index = time.time()\n",
    "    print(f\"M: {m} - 색인 시간: {end_index - start_index} s, 메모리 사용량: {end_memory - start_memory} MB\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    D, I = index.search(xq, k)\n",
    "    t1 = time.time()\n",
    "\n",
    "    recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)\n",
    "    print(f\"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.5 ef_construction을 변화시킬 때 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BykMqAxZaJ6s"
   },
   "outputs": [],
   "source": [
    "k=1\n",
    "d = xq.shape[1]\n",
    "nq = 1000\n",
    "xq = xq[:nq]\n",
    "\n",
    "for ef_construction in [40, 80, 160, 320]:\n",
    "    index = faiss.IndexHNSWFlat(d, 32)\n",
    "    index.hnsw.efConstruction = ef_construction\n",
    "    time.sleep(3)\n",
    "    start_memory = get_memory_usage_mb()\n",
    "    start_index = time.time()\n",
    "    index.add(xb)\n",
    "    end_memory = get_memory_usage_mb()\n",
    "    end_index = time.time()\n",
    "    print(f\"efConstruction: {ef_construction} - 색인 시간: {end_index - start_index} s, 메모리 사용량: {end_memory - start_memory} MB\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    D, I = index.search(xq, k)\n",
    "    t1 = time.time()\n",
    "\n",
    "    recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)\n",
    "    print(f\"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.6 ef_search 변경에 따른 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liqWz0wtaLaF"
   },
   "outputs": [],
   "source": [
    "for ef_search in [16, 32, 64, 128]:\n",
    "    index.hnsw.efSearch = ef_search\n",
    "    t0 = time.time()\n",
    "    D, I = index.search(xq, k)\n",
    "    t1 = time.time()\n",
    "\n",
    "    recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)\n",
    "    print(f\"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.7 파인콘 계정 연결 및 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xy2XEyoIaNE3"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = \"자신의 API 키를 입력\"\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "pc.create_index(\"llm-book\", spec=ServerlessSpec(\"aws\", \"us-east-1\"), dimension=768)\n",
    "index = pc.Index('llm-book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.8 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4RfV7mQaOIn"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# 임베딩 모델 불러오기\n",
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "# 데이터셋 불러오기\n",
    "klue_dp_train = load_dataset('klue', 'dp', split='train[:100]')\n",
    "\n",
    "embeddings = sentence_model.encode(klue_dp_train['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.9 파인콘 입력을 위한 데이터 형태 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHivDiO4aP_O"
   },
   "outputs": [],
   "source": [
    "# 파이썬 기본 데이터 타입으로 변경\n",
    "embeddings = embeddings.tolist()\n",
    "# {\"id\": 문서 ID(str), \"values\": 벡터 임베딩(List[float]), \"metadata\": 메타 데이터(dict) ) 형태로 데이터 준비\n",
    "insert_data = []\n",
    "for idx, (embedding, text) in enumerate(zip(embeddings, klue_dp_train['sentence'])):\n",
    "  insert_data.append({\"id\": str(idx), \"values\": embedding, \"metadata\": {'text': text}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.10 임베딩 데이터를 인덱스에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSE4THwWaRD6"
   },
   "outputs": [],
   "source": [
    "upsert_response = index.upsert(vectors = insert_data, namespace='llm-book-sub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.11 인덱스 검색하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dlnlavs2aSWp"
   },
   "outputs": [],
   "source": [
    "query_response = index.query(\n",
    "    namespace='llm-book-sub', # 검색할 네임스페이스\n",
    "    top_k=10, # 몇 개의 결과를 반환할지\n",
    "    include_values=True, # 벡터 임베딩 반환 여부\n",
    "    include_metadata=True, # 메타 데이터 반환 여부\n",
    "    vector=embeddings[0] # 검색할 벡터 임베딩\n",
    ")\n",
    "query_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.12 파인콘에서 문서 수정 및 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSwygvhaaTpz"
   },
   "outputs": [],
   "source": [
    "new_text = '변경할 새로운 텍스트'\n",
    "new_embedding = sentence_model.encode(new_text).tolist()\n",
    "# 업데이트\n",
    "update_response = index.update(\n",
    "    id= '기존_문서_id',\n",
    "    values=new_embedding,\n",
    "    set_metadata={'text': new_text},\n",
    "    namespace='llm-book-sub'\n",
    ")\n",
    "\n",
    "# 삭제\n",
    "delete_response = index.delete(ids=['기존_문서_id'], namespace='llm-book-sub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.13 라마인덱스에서 다른 벡터 데이터베이스 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yM97AyjaU_s"
   },
   "outputs": [],
   "source": [
    "# 파인콘 기본 설정\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "pc.create_index(\n",
    "    \"quickstart\", dimension=1536, metric=\"euclidean\", spec=ServerlessSpec(\"aws\", \"us-east-1\")\n",
    ")\n",
    "pinecone_index = pc.Index(\"quickstart\")\n",
    "\n",
    "# 라마인덱스에 파인콘 인덱스 연결\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.14 실습 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEGfqJNCaXOQ"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"poloclub/diffusiondb\", \"2m_first_1k\", split='train')\n",
    "\n",
    "example_index = 867\n",
    "original_image = dataset[example_index]['image']\n",
    "original_prompt = dataset[example_index]['prompt']\n",
    "print(original_prompt)\n",
    "\n",
    "# cute fluffy baby cat rabbit lion hybrid mixed creature character concept,\n",
    "# with long flowing mane blowing in the wind, long peacock feather tail,\n",
    "# wearing headdress of tribal peacock feathers and flowers, detailed painting,\n",
    "# renaissance, 4 k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.15 GPT-4o 요청에 사용할 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2iYGTqKaY9A"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def make_base64(image):\n",
    "  buffered = BytesIO()\n",
    "  image.save(buffered, format=\"JPEG\")\n",
    "  img_str = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "  return img_str\n",
    "\n",
    "def generate_description_from_image_gpt4(prompt, image64):\n",
    "  headers = {\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {client.api_key}\"\n",
    "  }\n",
    "  payload = {\n",
    "      \"model\": \"gpt-4o\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{image64}\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 300\n",
    "  }\n",
    "  response_oai = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "  result = response_oai.json()['choices'][0]['message']['content']\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.16 이미지 설명 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base64 = make_base64(original_image)\n",
    "described_result = generate_description_from_image_gpt4(\"Describe provided image\", image_base64)\n",
    "described_result\n",
    "# The image depicts a digitally created, fantastical creature that combines features of different animals. It has the body and face of a lion, with a rich, golden mane that transitions into an array of vibrant, peacock-like feathers. The feathers themselves are full of brilliant colors, primarily blues and greens, with \"eyes\" that mimic the look of a peacock's plumage. The creature is sitting down and facing forward with a calm and majestic expression.\n",
    "# The creature is set against a picturesque backdrop that resembles a lush, blooming meadow or garden, with rolling green hills in the distance and a blue sky above. The colors are rich and the composition is balanced, emphasizing the surreal and regal aspect of the creature. It's an imaginative piece that blends the natural elements of these animals in a mystical way.\n",
    "# 이 이미지는 다양한 동물의 특징을 결합한 디지털로 창조된 환상적인 생물을 묘사합니다. 이 동물은 사자의 몸과 얼굴을 하고 있으며, 풍성한 황금빛 갈기가 공작새와 같은 생생한 깃털로 변합니다. 깃털은 주로 파란색과 녹색의 화려한 색상으로 가득하며, 공작의 깃털을 닮은 '눈'이 있습니다. 이 생물은 차분하고 장엄한 표정으로 앉아서 정면을 바라보고 있습니다.\n",
    "# 이 생물은 무성하고 꽃이 만발한 초원이나 정원을 연상시키는 그림 같은 배경을 배경으로 멀리 푸른 언덕이 펼쳐져 있고 위로는 푸른 하늘이 펼쳐져 있습니다. 색상이 풍부하고 구도가 균형 잡혀 있어 초현실적이고 당당한 생물의 모습을 강조합니다. 동물의 자연적 요소를 신비로운 방식으로 혼합한 상상력이 돋보이는 작품입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.17 클라이언트 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Q_yTQktjd4D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = pinecone_api_key # '자신의 파인콘 API 키 입력'\n",
    "openai_api_key = '자신의 OpenAI API 키 입력'\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.18 인덱스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X27yCOYOadL6"
   },
   "outputs": [],
   "source": [
    "print(pc.list_indexes())\n",
    "\n",
    "index_name = \"llm-multimodal\"\n",
    "try:\n",
    "  pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=512,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "      \"aws\", \"us-east-1\"\n",
    "    )\n",
    "  )\n",
    "  print(pc.list_indexes())\n",
    "except:\n",
    "  print(\"Index already exists\")\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.19 프롬프트 텍스트를 텍스트 임베딩 모델을 활용해 임베딩 벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxXdiG_iaefA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, CLIPTextModelWithProjection\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "text_model = CLIPTextModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "tokens = tokenizer(dataset['prompt'], padding=True, return_tensors=\"pt\", truncation=True)\n",
    "batch_size = 16\n",
    "text_embs = []\n",
    "for start_idx in trange(0, len(dataset), batch_size):\n",
    "    with torch.no_grad():\n",
    "        outputs = text_model(input_ids = tokens['input_ids'][start_idx:start_idx+batch_size],\n",
    "                        attention_mask = tokens['attention_mask'][start_idx:start_idx+batch_size])\n",
    "        text_emb_tmp = outputs.text_embeds\n",
    "    text_embs.append(text_emb_tmp)\n",
    "text_embs = torch.cat(text_embs, dim=0)\n",
    "text_embs.shape # (1000, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.20 텍스트 임베딩 벡터를 파인콘 인덱스에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lPEIx46agAD"
   },
   "outputs": [],
   "source": [
    "input_data = []\n",
    "for id_int, emb, prompt in zip(range(0, len(dataset)), text_embs.tolist(), dataset['prompt']):\n",
    "  input_data.append(\n",
    "      {\n",
    "          \"id\": str(id_int),\n",
    "          \"values\": emb,\n",
    "          \"metadata\": {\n",
    "              \"prompt\": prompt\n",
    "          }\n",
    "      }\n",
    "  )\n",
    "\n",
    "index.upsert(\n",
    "  vectors=input_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.21 이미지 임베딩을 사용한 유사 프롬프트 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ckpz3Tybahcs"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, CLIPVisionModelWithProjection\n",
    "\n",
    "vision_model = CLIPVisionModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "inputs = processor(images=original_image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = vision_model(**inputs)\n",
    "image_embeds = outputs.image_embeds\n",
    "\n",
    "search_results = index.query(\n",
    "  vector=image_embeds[0].tolist(),\n",
    "  top_k=3,\n",
    "  include_values=False,\n",
    "  include_metadata=True\n",
    ")\n",
    "searched_idx = int(search_results['matches'][0]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.22 이미지 임베딩을 사용해 검색한 유사 프롬프트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWEgdFDZajBi"
   },
   "outputs": [],
   "source": [
    "search_results\n",
    "\n",
    "# {'matches': [{'id': '918',\n",
    "#               'metadata': {'prompt': 'cute fluffy bunny cat lion hybrid mixed '\n",
    "#                                      'creature character concept, with long '\n",
    "#                                      'flowing mane blowing in the wind, long '\n",
    "#                                      'peacock feather tail, wearing headdress '\n",
    "#                                      'of tribal peacock feathers and flowers, '\n",
    "#                                      'detailed painting, renaissance, 4 k '},\n",
    "#               'score': 0.372838408,\n",
    "#               'values': []},\n",
    "#              {'id': '867',\n",
    "#               'metadata': {'prompt': 'cute fluffy baby cat rabbit lion hybrid '\n",
    "#                                      'mixed creature character concept, with '\n",
    "#                                      'long flowing mane blowing in the wind, '\n",
    "#                                      'long peacock feather tail, wearing '\n",
    "#                                      'headdress of tribal peacock feathers and '\n",
    "#                                      'flowers, detailed painting, renaissance, '\n",
    "#                                      '4 k '},\n",
    "#               'score': 0.371655703,\n",
    "#               'values': []},\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.23 프롬프트로 이미지를 생성하고 저장하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsm70VsZakiW"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def generate_image_dalle3(prompt):\n",
    "  response_oai = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=str(prompt),\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "  )\n",
    "  result = response_oai.data[0].url\n",
    "  return result\n",
    "\n",
    "def get_generated_image(image_url):\n",
    "  generated_image = requests.get(image_url).content\n",
    "  image_filename = 'gen_img.png'\n",
    "  with open(image_filename, \"wb\") as image_file:\n",
    "      image_file.write(generated_image)\n",
    "  return Image.open(image_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.24 준비한 3개의 프롬프트로 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdd4ugvNal-I"
   },
   "outputs": [],
   "source": [
    "# GPT-4o가 만든 프롬프트로 이미지 생성\n",
    "gpt_described_image_url = generate_image_dalle3(described_result)\n",
    "gpt4o_prompt_image = get_generated_image(gpt_described_image_url)\n",
    "gpt4o_prompt_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yWKHa0KlN4C"
   },
   "outputs": [],
   "source": [
    "# 원본 프롬프트로 이미지 생성\n",
    "original_prompt_image_url = generate_image_dalle3(original_prompt)\n",
    "original_prompt_image = get_generated_image(original_prompt_image_url)\n",
    "original_prompt_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFvSBFvPlHE0"
   },
   "outputs": [],
   "source": [
    "# 이미지 임베딩으로 검색한 유사 프롬프트로 이미지 생성\n",
    "searched_prompt_image_url = generate_image_dalle3(dataset[searched_idx]['prompt'])\n",
    "searched_prompt_image = get_generated_image(searched_prompt_image_url)\n",
    "searched_prompt_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 12.25 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9weSwugIanYV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images = [original_image, gpt4o_prompt_image, original_prompt_image, searched_prompt_image]\n",
    "titles = ['(a)', '(b)', '(c)', '(d)']\n",
    "\n",
    "fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
