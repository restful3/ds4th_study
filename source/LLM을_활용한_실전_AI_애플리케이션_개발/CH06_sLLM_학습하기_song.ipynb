{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 sLLM 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.40.1 bitsandbytes==0.43.1 accelerate==0.29.3 datasets==2.19.0 tiktoken==0.6.0 huggingface_hub==0.22.2 autotrain-advanced==0.7.77 -qqq\n",
    "# !pip install --upgrade huggingface-hub -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성능 평가 파이프라인 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL 성능 프롬프트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.2. SQL 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(ddl, question, query=''):\n",
    "    prompt = f\"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "\n",
    "### DDL:\n",
    "{ddl}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### SQL:\n",
    "{query}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4 평가 프롬프트와 코드 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.4. 평가를 위한 요청 jsonl 작성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def make_requests_for_gpt_evaluation(df, filename, dir='results'):\n",
    "  \"\"\"\n",
    "  GPT 평가를 위한 요청 파일을 생성하는 함수\n",
    "  \n",
    "  Args:\n",
    "      df: 평가 데이터가 포함된 데이터프레임\n",
    "      filename: 저장할 파일 이름 \n",
    "      dir: 저장할 디렉토리 경로 (기본값: 'results')\n",
    "  \"\"\"\n",
    "  # 디렉토리가 없으면 생성\n",
    "  if not Path(dir).exists():\n",
    "      Path(dir).mkdir(parents=True)\n",
    "      \n",
    "  # 프롬프트 리스트 생성\n",
    "  prompts = []\n",
    "  for idx, row in df.iterrows():\n",
    "      prompts.append(\"\"\"Based on below DDL and Question, evaluate gen_sql can resolve Question. If gen_sql and gt_sql do equal job, return \"yes\" else return \"no\". Output JSON Format: {\"resolve_yn\": \"\"}\"\"\" + f\"\"\"\n",
    "\n",
    "DDL: {row['context']}\n",
    "Question: {row['question']}\n",
    "gt_sql: {row['answer']}\n",
    "gen_sql: {row['gen_sql']}\"\"\"\n",
    ")\n",
    "\n",
    "  # GPT-4 요청을 위한 job 리스트 생성\n",
    "  jobs = [{\"model\": \"gpt-4-turbo-preview\", \"response_format\" : { \"type\": \"json_object\" }, \"messages\": [{\"role\": \"system\", \"content\": prompt}]} for prompt in prompts]\n",
    "  \n",
    "  # 파일에 job을 jsonl 형식으로 저장\n",
    "  with open(Path(dir, filename), \"w\") as f:\n",
    "      for job in jobs:\n",
    "          json_string = json.dumps(job)\n",
    "          f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.5. 비동기 요청 명령"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"자신의 OpenAI API 키 입력\"\n",
    "\n",
    "python api_request_parallel_processor.py \\\n",
    "  --requests_filepath {요청 파일 경로} \\\n",
    "  --save_filepath {생성할 결과 파일 경로} \\\n",
    "  --request_url https://api.openai.com/v1/chat/completions \\\n",
    "  --max_requests_per_minute 300 \\\n",
    "  --max_tokens_per_minute 100000 \\\n",
    "  --token_encoding_name cl100k_base \\\n",
    "  --max_attempts 5 \\\n",
    "  --logging_level 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.6. 결과 jsonl 파일을 csv로 변환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def change_jsonl_to_csv(input_file, output_file, prompt_column=\"prompt\", response_column=\"response\"):\n",
    "#     prompts = []\n",
    "#     responses = []\n",
    "#     with open(input_file, 'r') as json_file:\n",
    "#         for data in json_file:\n",
    "#             prompts.append(json.loads(data)[0]['messages'][0]['content'])\n",
    "#             responses.append(json.loads(data)[1]['choices'][0]['message']['content'])\n",
    "\n",
    "#     df = pd.DataFrame({prompt_column: prompts, response_column: responses})\n",
    "#     df.to_csv(output_file, index=False)\n",
    "#     return df\n",
    "\n",
    "def change_jsonl_to_csv(input_file, output_file, prompt_column=\"prompt\", response_column=\"response\"):\n",
    "    prompts = []\n",
    "    responses = []\n",
    "    with open(input_file, 'r') as json_file:\n",
    "        for line in json_file:\n",
    "            # 각 줄은 배열 형태로 요청과 응답을 포함\n",
    "            data = json.loads(line)\n",
    "            # 첫 번째 요소(인덱스 0)가 요청 정보\n",
    "            prompts.append(data[0][\"messages\"][0][\"content\"])\n",
    "            # 두 번째 요소(인덱스 1)가 응답 정보\n",
    "            responses.append(data[1][\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    df = pd.DataFrame({prompt_column: prompts, response_column: responses})\n",
    "    df.to_csv(output_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습: 미세 조정 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기초 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/restful3/anaconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# PyTorch와 Transformers 라이브러리 임포트\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 추론 파이프라인 생성 함수 정의\n",
    "def make_inference_pipeline(model_id):\n",
    "  # 토크나이저 로드\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "  # 4비트 양자화를 적용한 모델 로드 \n",
    "  model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "  # 텍스트 생성 파이프라인 생성\n",
    "  pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "  return pipe\n",
    "\n",
    "# Yi-Ko-6B 모델 ID 설정\n",
    "model_id = 'beomi/Yi-Ko-6B'\n",
    "# 추론 파이프라인 생성\n",
    "hf_pipe = make_inference_pipeline(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"SELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\\n\\n### SQL 봇의 결과:\\nSELECT COUNT(*) FROM players WHERE\"}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SQL 생성을 위한 예제 프롬프트\n",
    "example = \"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "\n",
    "### DDL:\n",
    "CREATE TABLE players (\n",
    "  player_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "  username VARCHAR(255) UNIQUE NOT NULL,\n",
    "  email VARCHAR(255) UNIQUE NOT NULL,\n",
    "  password_hash VARCHAR(255) NOT NULL,\n",
    "  date_joined DATETIME NOT NULL,\n",
    "  last_login DATETIME\n",
    ");\n",
    "\n",
    "### Question:\n",
    "사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.\n",
    "\n",
    "### SQL:\n",
    "\"\"\"\n",
    "\n",
    "# 모델을 사용하여 SQL 쿼리 생성\n",
    "hf_pipe(example, do_sample=False,\n",
    "    return_full_text=False, max_length=512, truncation=True)\n",
    "#  SELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\n",
    "\n",
    "# ### SQL 봇:\n",
    "# SELECT COUNT(*) FROM players WHERE username LIKE '%admin%';\n",
    "\n",
    "# ### SQL 봇의 결과:\n",
    "# SELECT COUNT(*) FROM players WHERE username LIKE '%admin%'; (생략)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.8. 기초 모델 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터셋 라이브러리 임포트\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # ko_text2sql 데이터셋의 테스트 세트 불러오기\n",
    "# df = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")['test']\n",
    "# # pandas DataFrame으로 변환\n",
    "# df = df.to_pandas()\n",
    "\n",
    "# # 각 데이터에 대해 프롬프트 생성\n",
    "# for idx, row in df.iterrows():\n",
    "#   # context와 question을 조합하여 프롬프트 생성\n",
    "#   prompt = make_prompt(row['context'], row['question'])\n",
    "#   # 생성된 프롬프트를 DataFrame에 저장\n",
    "#   df.loc[idx, 'prompt'] = prompt\n",
    "\n",
    "# # 모델을 사용하여 SQL 쿼리 생성\n",
    "# gen_sqls = hf_pipe(df['prompt'].tolist(), do_sample=False,\n",
    "#                    return_full_text=False, max_length=512, truncation=True)\n",
    "# # 생성된 SQL 쿼리 추출\n",
    "# gen_sqls = [x[0]['generated_text'] for x in gen_sqls]\n",
    "# # 생성된 SQL을 DataFrame에 저장\n",
    "# df['gen_sql'] = gen_sqls\n",
    "\n",
    "# # GPT 평가를 위한 JSONL 파일 생성\n",
    "# eval_filepath = \"./results/text2sql_evaluation.jsonl\"\n",
    "# make_requests_for_gpt_evaluation(df, eval_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 라이브러리 임포트\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ko_text2sql 데이터셋의 테스트 세트 불러오기\n",
    "df = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")['test']\n",
    "# pandas DataFrame으로 변환\n",
    "df = df.to_pandas()\n",
    "\n",
    "# 각 데이터에 대해 프롬프트 생성 (tqdm 추가)\n",
    "for idx, row in df.iterrows():\n",
    "  # context와 question을 조합하여 프롬프트 생성\n",
    "  prompt = make_prompt(row['context'], row['question'])\n",
    "  # 생성된 프롬프트를 DataFrame에 저장\n",
    "  df.loc[idx, 'prompt'] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청크 크기 설정\n",
    "CHUNK_SIZE = 10  # 필요에 따라 조정하세요\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "gen_sqls_list = []\n",
    "\n",
    "# 데이터를 청크로 나누어 모델로 SQL 쿼리 생성 (진행 상황 표시)\n",
    "for i in tqdm(range(0, len(df), CHUNK_SIZE), desc=\"SQL 쿼리 생성 중\"):\n",
    "    # 현재 청크의 프롬프트 가져오기\n",
    "    prompts_chunk = df['prompt'][i:i+CHUNK_SIZE].tolist()\n",
    "    \n",
    "    # 빈 리스트면 건너뛰기\n",
    "    if not prompts_chunk:\n",
    "        continue\n",
    "        \n",
    "    # 모델을 사용하여 현재 청크의 SQL 쿼리 생성\n",
    "    chunk_results = hf_pipe(prompts_chunk, do_sample=False,\n",
    "                           return_full_text=False, max_length=512, truncation=True)\n",
    "    \n",
    "    # 생성된 SQL 쿼리 추출 후 리스트에 추가\n",
    "    chunk_gen_sqls = [x[0]['generated_text'] for x in chunk_results]\n",
    "    gen_sqls_list.extend(chunk_gen_sqls)\n",
    "\n",
    "# 생성된 SQL을 DataFrame에 저장\n",
    "df['gen_sql'] = gen_sqls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 평가를 위한 JSONL 파일 생성\n",
    "eval_filepath = \"text2sql_evaluation.jsonl\"\n",
    "make_requests_for_gpt_evaluation(df, eval_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Starting request #3\n",
      "INFO:root:Starting request #4\n",
      "INFO:root:Starting request #5\n",
      "INFO:root:Starting request #6\n",
      "INFO:root:Starting request #7\n",
      "INFO:root:Starting request #8\n",
      "INFO:root:Starting request #9\n",
      "INFO:root:Starting request #10\n",
      "INFO:root:Starting request #11\n",
      "INFO:root:Starting request #12\n",
      "INFO:root:Starting request #13\n",
      "INFO:root:Starting request #14\n",
      "INFO:root:Starting request #15\n",
      "INFO:root:Starting request #16\n",
      "INFO:root:Starting request #17\n",
      "INFO:root:Starting request #18\n",
      "INFO:root:Starting request #19\n",
      "INFO:root:Starting request #20\n",
      "INFO:root:Starting request #21\n",
      "INFO:root:Starting request #22\n",
      "INFO:root:Starting request #23\n",
      "INFO:root:Starting request #24\n",
      "INFO:root:Starting request #25\n",
      "INFO:root:Starting request #26\n",
      "INFO:root:Starting request #27\n",
      "INFO:root:Starting request #28\n",
      "INFO:root:Starting request #29\n",
      "INFO:root:Starting request #30\n",
      "INFO:root:Starting request #31\n",
      "INFO:root:Starting request #32\n",
      "INFO:root:Starting request #33\n",
      "INFO:root:Starting request #34\n",
      "INFO:root:Starting request #35\n",
      "INFO:root:Starting request #36\n",
      "INFO:root:Starting request #37\n",
      "INFO:root:Starting request #38\n",
      "INFO:root:Starting request #39\n",
      "INFO:root:Starting request #40\n",
      "INFO:root:Starting request #41\n",
      "INFO:root:Starting request #42\n",
      "INFO:root:Starting request #43\n",
      "INFO:root:Starting request #44\n",
      "INFO:root:Starting request #45\n",
      "INFO:root:Starting request #46\n",
      "INFO:root:Starting request #47\n",
      "INFO:root:Starting request #48\n",
      "INFO:root:Starting request #49\n",
      "INFO:root:Starting request #50\n",
      "INFO:root:Starting request #51\n",
      "INFO:root:Starting request #52\n",
      "INFO:root:Starting request #53\n",
      "INFO:root:Starting request #54\n",
      "INFO:root:Starting request #55\n",
      "INFO:root:Starting request #56\n",
      "INFO:root:Starting request #57\n",
      "INFO:root:Starting request #58\n",
      "INFO:root:Starting request #59\n",
      "INFO:root:Starting request #60\n",
      "INFO:root:Starting request #61\n",
      "INFO:root:Starting request #62\n",
      "INFO:root:Starting request #63\n",
      "INFO:root:Starting request #64\n",
      "INFO:root:Starting request #65\n",
      "INFO:root:Starting request #66\n",
      "INFO:root:Starting request #67\n",
      "INFO:root:Starting request #68\n",
      "INFO:root:Starting request #69\n",
      "INFO:root:Starting request #70\n",
      "INFO:root:Starting request #71\n",
      "INFO:root:Starting request #72\n",
      "INFO:root:Starting request #73\n",
      "INFO:root:Starting request #74\n",
      "INFO:root:Starting request #75\n",
      "INFO:root:Starting request #76\n",
      "INFO:root:Starting request #77\n",
      "INFO:root:Starting request #78\n",
      "INFO:root:Starting request #79\n",
      "INFO:root:Starting request #80\n",
      "INFO:root:Starting request #81\n",
      "INFO:root:Starting request #82\n",
      "INFO:root:Starting request #83\n",
      "INFO:root:Starting request #84\n",
      "INFO:root:Starting request #85\n",
      "INFO:root:Starting request #86\n",
      "INFO:root:Starting request #87\n",
      "INFO:root:Starting request #88\n",
      "INFO:root:Starting request #89\n",
      "INFO:root:Starting request #90\n",
      "INFO:root:Starting request #91\n",
      "INFO:root:Starting request #92\n",
      "INFO:root:Starting request #93\n",
      "INFO:root:Starting request #94\n",
      "INFO:root:Starting request #95\n",
      "INFO:root:Starting request #96\n",
      "INFO:root:Starting request #97\n",
      "INFO:root:Starting request #98\n",
      "INFO:root:Starting request #99\n",
      "INFO:root:Starting request #100\n",
      "INFO:root:Starting request #101\n",
      "INFO:root:Starting request #102\n",
      "INFO:root:Starting request #103\n",
      "INFO:root:Starting request #104\n",
      "INFO:root:Starting request #105\n",
      "INFO:root:Starting request #106\n",
      "INFO:root:Starting request #107\n",
      "INFO:root:Starting request #108\n",
      "INFO:root:Starting request #109\n",
      "INFO:root:Starting request #110\n",
      "INFO:root:Starting request #111\n",
      "INFO:root:Parallel processing complete. Results saved to results/text2sql_result.jsonl\n"
     ]
    }
   ],
   "source": [
    "result_filepath = \"text2sql_result.jsonl\"\n",
    "\n",
    "# GPT-4 평가 수행\n",
    "!python api_request_parallel_processor.py \\\n",
    "--requests_filepath results/{eval_filepath}  \\\n",
    "--save_filepath results/{result_filepath} \\\n",
    "--request_url https://api.openai.com/v1/chat/completions \\\n",
    "--max_requests_per_minute 100 \\\n",
    "--max_tokens_per_minute 20000 \\\n",
    "--token_encoding_name cl100k_base \\\n",
    "--max_attempts 5 \\\n",
    "--logging_level 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text2sql_evaluation.jsonl'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확한 답변 개수: 48/284 (16.90%)\n"
     ]
    }
   ],
   "source": [
    "base_eval = change_jsonl_to_csv(f\"results/{result_filepath}\", \"results/yi_ko_6b_eval.csv\", \"prompt\", \"resolve_yn\")\n",
    "base_eval['resolve_yn'] = base_eval['resolve_yn'].apply(lambda x: json.loads(x)['resolve_yn'])\n",
    "num_correct_answers = base_eval.query(\"resolve_yn == 'yes'\").shape[0]\n",
    "print(f\"정확한 답변 개수: {num_correct_answers}/{len(base_eval)} ({num_correct_answers/len(base_eval)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미세 조정 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.9. 학습 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 라이브러리 임포트\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ko_text2sql 데이터셋 불러오기 \n",
    "df_sql = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")[\"train\"]\n",
    "# pandas DataFrame으로 변환\n",
    "df_sql = df_sql.to_pandas()\n",
    "# 결측치 제거 및 랜덤 셔플링 \n",
    "df_sql = df_sql.dropna().sample(frac=1, random_state=42)\n",
    "# db_id가 1인 데이터 제외\n",
    "df_sql = df_sql.query(\"db_id != 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행에 대해 프롬프트 생성\n",
    "for idx, row in df_sql.iterrows():\n",
    "  df_sql.loc[idx, 'text'] = make_prompt(row['context'], row['question'], row['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 디렉토리가 없는 경우에만 생성\n",
    "import os\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터를 CSV 파일로 저장\n",
    "df_sql.to_csv('data/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.10. 미세 조정 명령어\n",
    "\n",
    ">**autotrain-advanced**\n",
    ">- Hugging Face에서 제공하는 CLI 기반의 모델 학습 도구입니다.\n",
    ">- 복잡한 코드 작성 없이 명령어만으로 모델 학습을 수행할 수 있습니다.\n",
    ">- LoRA, QLoRA 등 다양한 파라미터 튜닝 기법을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:40\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m343\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n",
      "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2025-03-16 11:40:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: train, inference, deploy, func, backend, version, config\u001b[0m\n",
      "Saving the dataset (1/1 shards): 100%|█| 33876/33876 [00:00<00:00, 570728.33 exa\n",
      "Saving the dataset (1/1 shards): 100%|█| 33876/33876 [00:00<00:00, 606340.70 exa\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:41\u001b[0m | \u001b[36mautotrain.backend\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:41\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m327\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.clm', '--training_config', 'yi-ko-6b-text2sql/training_params.json']\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:41\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1m{'model': 'beomi/Yi-Ko-6B', 'project_name': 'yi-ko-6b-text2sql', 'data_path': 'yi-ko-6b-text2sql/autotrain-data', 'train_split': 'train', 'valid_split': None, 'add_eos_token': False, 'block_size': 1024, 'model_max_length': 1024, 'padding': None, 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'evaluation_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 1, 'batch_size': 8, 'warmup_ratio': 0.1, 'gradient_accumulation': 8, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': 'autotrain_prompt', 'text_column': 'autotrain_text', 'rejected_text_column': 'autotrain_rejected_text', 'push_to_hub': False, 'username': None, 'token': None}\u001b[0m\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mStarting SFT training...\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m352\u001b[0m - \u001b[1mTrain data: Dataset({\n",
      "    features: ['db_id', 'context', 'question', 'answer', 'autotrain_text'],\n",
      "    num_rows: 33876\n",
      "})\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m423\u001b[0m - \u001b[1mconfiguring logging steps\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m436\u001b[0m - \u001b[1mLogging steps: 25\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_training_args\u001b[0m:\u001b[36m441\u001b[0m - \u001b[1mconfiguring training args\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_block_size\u001b[0m:\u001b[36m504\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:45\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mloading model config...\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:46\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mloading model...\u001b[0m\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:09<00:00,  1.95s/it]\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:56\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mmodel dtype: torch.float16\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:56\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
      "/home/restful3/anaconda3/envs/llm/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 11:40:56\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_train_begin\u001b[0m:\u001b[36m231\u001b[0m - \u001b[1mStarting to train...\u001b[0m\n",
      " 17%|██████▉                                 | 25/145 [23:21<1:52:12, 56.10s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 12:04:17\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.653, 'grad_norm': 0.20487475395202637, 'learning_rate': 0.00018461538461538463, 'epoch': 0.17226528854435832}\u001b[0m\n",
      "{'loss': 0.653, 'grad_norm': 0.20487475395202637, 'learning_rate': 0.00018461538461538463, 'epoch': 0.17}\n",
      " 34%|█████████████▊                          | 50/145 [46:43<1:28:46, 56.07s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 12:27:39\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.24, 'grad_norm': 0.11317414045333862, 'learning_rate': 0.00014615384615384615, 'epoch': 0.34453057708871665}\u001b[0m\n",
      "{'loss': 0.24, 'grad_norm': 0.11317414045333862, 'learning_rate': 0.00014615384615384615, 'epoch': 0.34}\n",
      " 52%|███████████████████▋                  | 75/145 [1:10:05<1:05:26, 56.09s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 12:51:02\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.1996, 'grad_norm': 0.11216730624437332, 'learning_rate': 0.0001076923076923077, 'epoch': 0.5167958656330749}\u001b[0m\n",
      "{'loss': 0.1996, 'grad_norm': 0.11216730624437332, 'learning_rate': 0.0001076923076923077, 'epoch': 0.52}\n",
      " 69%|██████████████████████████▉            | 100/145 [1:33:27<42:04, 56.10s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 13:14:24\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.1906, 'grad_norm': 0.10175755620002747, 'learning_rate': 6.923076923076924e-05, 'epoch': 0.6890611541774333}\u001b[0m\n",
      "{'loss': 0.1906, 'grad_norm': 0.10175755620002747, 'learning_rate': 6.923076923076924e-05, 'epoch': 0.69}\n",
      " 86%|█████████████████████████████████▌     | 125/145 [1:56:49<18:41, 56.08s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 13:37:46\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'loss': 0.1842, 'grad_norm': 0.09620615839958191, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.8613264427217916}\u001b[0m\n",
      "{'loss': 0.1842, 'grad_norm': 0.09620615839958191, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.86}\n",
      "100%|███████████████████████████████████████| 145/145 [2:15:31<00:00, 56.09s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 13:56:28\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m226\u001b[0m - \u001b[1m{'train_runtime': 8131.2471, 'train_samples_per_second': 1.142, 'train_steps_per_second': 0.018, 'train_loss': 0.27798462736195534, 'epoch': 0.9991386735572783}\u001b[0m\n",
      "{'train_runtime': 8131.2471, 'train_samples_per_second': 1.142, 'train_steps_per_second': 0.018, 'train_loss': 0.27798462736195534, 'epoch': 1.0}\n",
      "100%|███████████████████████████████████████| 145/145 [2:15:31<00:00, 56.08s/it]\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2025-03-16 13:56:28\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mpost_training_steps\u001b[0m:\u001b[36m263\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "base_model = 'beomi/Yi-Ko-6B'\n",
    "finetuned_model = './models/yi-ko-6b-text2sql'\n",
    "\n",
    "!autotrain llm \\\n",
    "--train \\\n",
    "--model {base_model} \\\n",
    "--project-name {finetuned_model} \\\n",
    "--data-path data/ \\\n",
    "--text-column text \\\n",
    "--lr 2e-4 \\\n",
    "--batch-size 8 \\\n",
    "--epochs 1 \\\n",
    "--block-size 1024 \\\n",
    "--warmup-ratio 0.1 \\\n",
    "--lora-r 16 \\\n",
    "--lora-alpha 32 \\\n",
    "--lora-dropout 0.05 \\\n",
    "--weight-decay 0.01 \\\n",
    "--gradient-accumulation 8 \\\n",
    "--mixed-precision fp16 \\\n",
    "--use-peft \\\n",
    "--quantization int4 \\\n",
    "--trainer sft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.11. LoRA 어댑터 결합 및 허깅페이스 허브 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/restful3/anaconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "# 모델 이름과 디바이스 설정\n",
    "model_name = base_model\n",
    "finetuned_model = './models/yi-ko-6b-text2sql'\n",
    "\n",
    "device_map = {\"\": 0}  # GPU 0번 디바이스 사용\n",
    "\n",
    "# 기초 모델 불러오기\n",
    "# - low_cpu_mem_usage: CPU 메모리 사용량 최소화\n",
    "# - return_dict: 모델 출력을 딕셔너리 형태로 반환\n",
    "# - torch_dtype: FP16 정밀도 사용\n",
    "# - device_map: GPU 디바이스 매핑\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "# LoRA 어댑터를 기초 모델에 결합\n",
    "model = PeftModel.from_pretrained(base_model, finetuned_model)\n",
    "model = model.merge_and_unload()  # LoRA 가중치를 기초 모델에 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 설정\n",
    "# - trust_remote_code: 원격 코드 신뢰 옵션 활성화\n",
    "# - pad_token: 패딩 토큰을 EOS 토큰으로 설정\n",
    "# - padding_side: 오른쪽 패딩 적용\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "\n",
      "model-00002-of-00003.safetensors:   0%|          | 508k/4.93G [00:00<19:16, 4.27MB/s]\n",
      "model-00002-of-00003.safetensors:   0%|          | 3.46M/4.93G [00:00<15:05, 5.45MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 4.41M/4.93G [00:00<14:57, 5.49MB/s]\n",
      "model-00002-of-00003.safetensors:   0%|          | 5.06M/4.93G [00:01<14:43, 5.58MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   0%|          | 7.09M/4.93G [00:01<21:43, 3.78MB/s]\n",
      "model-00002-of-00003.safetensors:   0%|          | 11.0M/4.93G [00:01<08:15, 9.94MB/s]\n",
      "model-00002-of-00003.safetensors:   0%|          | 14.6M/4.93G [00:02<05:11, 15.8MB/s]\n",
      "model-00002-of-00003.safetensors:   0%|          | 22.6M/4.93G [00:02<05:26, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|          | 26.2M/4.93G [00:02<04:16, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|          | 30.0M/4.93G [00:02<03:38, 22.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 32.8M/4.93G [00:03<05:25, 15.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 35.0M/4.93G [00:04<11:53, 6.87MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 43.7M/4.93G [00:05<07:59, 10.2MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|          | 47.3M/4.93G [00:05<05:43, 14.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|          | 49.3M/4.93G [00:05<08:31, 9.55MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|          | 52.5M/4.93G [00:06<06:30, 12.5MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 61.7M/4.93G [00:06<04:11, 19.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 64.1M/4.93G [00:06<06:01, 13.5MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 68.1M/4.93G [00:06<04:37, 17.6MB/s]\n",
      "model-00002-of-00003.safetensors:   1%|▏         | 71.2M/4.93G [00:06<04:02, 20.0MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 74.4M/4.93G [00:07<03:41, 21.9MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 77.0M/4.93G [00:07<03:33, 22.8MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 80.0M/4.93G [00:07<05:30, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 83.5M/4.93G [00:07<04:36, 17.6MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 86.0M/4.93G [00:07<04:26, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 88.3M/4.93G [00:07<04:15, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 95.8M/4.93G [00:08<03:40, 21.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 98.1M/4.93G [00:08<09:31, 8.46MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 99.9M/4.93G [00:09<12:36, 6.39MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   2%|▏         | 101M/4.93G [00:10<18:05, 4.45MB/s] \n",
      "model-00002-of-00003.safetensors:   2%|▏         | 109M/4.93G [00:10<07:09, 11.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 126M/4.93G [00:11<03:58, 20.1MB/s]\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 137M/4.93G [00:12<04:27, 17.9MB/s]\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 140M/4.93G [00:12<03:41, 21.6MB/s]\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 144M/4.93G [00:12<03:26, 23.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 153M/4.93G [00:12<04:03, 19.6MB/s]\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 155M/4.93G [00:13<03:51, 20.6MB/s]\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 158M/4.93G [00:13<03:37, 21.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   3%|▎         | 166M/4.93G [00:13<04:14, 18.8MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▎         | 173M/4.93G [00:14<03:29, 22.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▎         | 176M/4.93G [00:14<03:30, 22.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▎         | 184M/4.93G [00:14<04:08, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 187M/4.93G [00:14<03:51, 20.5MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 189M/4.93G [00:14<03:48, 20.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 192M/4.93G [00:15<04:23, 18.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 194M/4.93G [00:15<09:14, 8.54MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 195M/4.93G [00:16<18:07, 4.36MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 201M/4.93G [00:17<10:07, 7.80MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 203M/4.93G [00:17<08:21, 9.43MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 206M/4.93G [00:17<06:43, 11.7MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 208M/4.93G [00:17<09:29, 8.29MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 212M/4.93G [00:18<06:17, 12.5MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 214M/4.93G [00:18<05:44, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 216M/4.93G [00:18<05:17, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 219M/4.93G [00:18<04:37, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:   4%|▍         | 222M/4.93G [00:18<03:57, 19.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 224M/4.93G [00:19<08:56, 8.79MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 227M/4.93G [00:19<07:06, 11.0MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 230M/4.93G [00:19<05:43, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 239M/4.93G [00:19<03:35, 21.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 242M/4.93G [00:20<05:10, 15.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 244M/4.93G [00:20<05:05, 15.3MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▍         | 246M/4.93G [00:20<04:55, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 254M/4.93G [00:20<03:35, 21.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 256M/4.93G [00:20<06:06, 12.8MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 264M/4.93G [00:21<04:39, 16.7MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 267M/4.93G [00:21<03:53, 20.0MB/s]\n",
      "model-00002-of-00003.safetensors:   5%|▌         | 270M/4.93G [00:21<03:15, 23.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 273M/4.93G [00:21<04:50, 16.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 287M/4.93G [00:22<02:52, 27.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 290M/4.93G [00:22<05:38, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:   6%|▌         | 304M/4.93G [00:23<03:09, 24.4MB/s]\n",
      "model-00002-of-00003.safetensors:   6%|▋         | 319M/4.93G [00:24<03:06, 24.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 322M/4.93G [00:24<05:10, 14.9MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 324M/4.93G [00:24<04:49, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 327M/4.93G [00:24<04:34, 16.8MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 333M/4.93G [00:24<04:22, 17.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 338M/4.93G [00:28<27:07, 2.82MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 340M/4.93G [00:28<21:10, 3.62MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 342M/4.93G [00:29<17:17, 4.43MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 347M/4.93G [00:29<09:21, 8.17MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 351M/4.93G [00:29<06:37, 11.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 353M/4.93G [00:29<07:36, 10.0MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 355M/4.93G [00:29<06:44, 11.3MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 363M/4.93G [00:30<04:23, 17.3MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 366M/4.93G [00:30<03:51, 19.8MB/s]\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 368M/4.93G [00:30<04:10, 18.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   7%|▋         | 370M/4.93G [00:30<06:15, 12.2MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 384M/4.93G [00:31<04:55, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 389M/4.93G [00:31<03:32, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 392M/4.93G [00:31<03:20, 22.6MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 395M/4.93G [00:31<03:18, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 397M/4.93G [00:31<03:18, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 400M/4.93G [00:32<03:34, 21.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 409M/4.93G [00:32<03:32, 21.3MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 411M/4.93G [00:32<03:25, 22.0MB/s]\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 414M/4.93G [00:32<03:27, 21.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   8%|▊         | 416M/4.93G [00:33<05:58, 12.6MB/s]\n",
      "model-00002-of-00003.safetensors:   9%|▊         | 421M/4.93G [00:33<04:50, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:   9%|▊         | 427M/4.93G [00:33<03:55, 19.2MB/s]\n",
      "model-00002-of-00003.safetensors:   9%|▊         | 429M/4.93G [00:33<03:42, 20.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 432M/4.93G [00:34<05:45, 13.0MB/s]\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 446M/4.93G [00:34<02:52, 26.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 449M/4.93G [00:34<04:21, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 451M/4.93G [00:35<04:16, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 461M/4.93G [00:35<02:59, 24.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:   9%|▉         | 464M/4.93G [00:35<04:36, 16.2MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|▉         | 474M/4.93G [00:36<03:16, 22.7MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|▉         | 476M/4.93G [00:36<03:12, 23.2MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|▉         | 479M/4.93G [00:36<03:26, 21.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  10%|▉         | 481M/4.93G [00:36<05:37, 13.2MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|▉         | 490M/4.93G [00:37<04:05, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|▉         | 493M/4.93G [00:37<03:44, 19.8MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|█         | 495M/4.93G [00:37<03:35, 20.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  10%|█         | 498M/4.93G [00:37<05:35, 13.2MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|█         | 500M/4.93G [00:37<05:03, 14.6MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|█         | 507M/4.93G [00:38<04:03, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|█         | 509M/4.93G [00:38<03:57, 18.6MB/s]\n",
      "model-00002-of-00003.safetensors:  10%|█         | 512M/4.93G [00:38<03:34, 20.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  10%|█         | 516M/4.93G [00:39<06:08, 12.0MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 519M/4.93G [00:39<05:17, 13.9MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 522M/4.93G [00:39<04:21, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 525M/4.93G [00:39<03:41, 19.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  11%|█         | 532M/4.93G [00:39<04:08, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 535M/4.93G [00:39<03:49, 19.2MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 537M/4.93G [00:40<03:36, 20.3MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 540M/4.93G [00:40<03:39, 20.1MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 542M/4.93G [00:40<03:36, 20.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  11%|█         | 544M/4.93G [00:40<06:46, 10.8MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 547M/4.93G [00:40<05:24, 13.5MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 550M/4.93G [00:41<05:13, 14.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  11%|█         | 551M/4.93G [00:41<05:04, 14.4MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█         | 553M/4.93G [00:41<05:14, 13.9MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█▏        | 557M/4.93G [00:41<04:37, 15.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  11%|█▏        | 560M/4.93G [00:41<06:16, 11.6MB/s]\n",
      "model-00002-of-00003.safetensors:  11%|█▏        | 561M/4.93G [00:41<06:07, 11.9MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 569M/4.93G [00:42<04:03, 17.9MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 571M/4.93G [00:42<04:06, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 573M/4.93G [00:42<04:09, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 576M/4.93G [00:42<03:51, 18.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 586M/4.93G [00:43<03:39, 19.9MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 589M/4.93G [00:43<03:14, 22.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 592M/4.93G [00:43<05:00, 14.5MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 595M/4.93G [00:43<04:21, 16.6MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 597M/4.93G [00:44<04:14, 17.1MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 606M/4.93G [00:44<03:04, 23.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 608M/4.93G [00:44<04:53, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 612M/4.93G [00:44<03:47, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  12%|█▏        | 615M/4.93G [00:44<03:38, 19.7MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 625M/4.93G [00:45<05:10, 13.9MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 629M/4.93G [00:45<03:45, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 632M/4.93G [00:45<03:24, 21.0MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 635M/4.93G [00:45<03:07, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 638M/4.93G [00:46<03:28, 20.6MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 646M/4.93G [00:46<04:57, 14.4MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 648M/4.93G [00:47<04:45, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 650M/4.93G [00:47<04:32, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 652M/4.93G [00:47<04:29, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 654M/4.93G [00:47<04:24, 16.2MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 656M/4.93G [00:47<04:14, 16.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 661M/4.93G [00:47<04:52, 14.6MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 663M/4.93G [00:47<04:10, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  13%|█▎        | 665M/4.93G [00:48<03:59, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▎        | 667M/4.93G [00:48<03:55, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▎        | 669M/4.93G [00:48<03:59, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▎        | 671M/4.93G [00:48<04:03, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▎        | 676M/4.93G [00:48<04:42, 15.1MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 682M/4.93G [00:49<03:35, 19.8MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 684M/4.93G [00:49<03:22, 21.0MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 687M/4.93G [00:49<03:10, 22.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 694M/4.93G [00:49<04:15, 16.6MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 696M/4.93G [00:49<03:54, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 699M/4.93G [00:50<03:40, 19.2MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 701M/4.93G [00:50<03:35, 19.7MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 703M/4.93G [00:50<03:35, 19.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 706M/4.93G [00:50<06:00, 11.7MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 708M/4.93G [00:50<04:56, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 711M/4.93G [00:50<04:17, 16.4MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 713M/4.93G [00:50<03:56, 17.9MB/s]\n",
      "model-00002-of-00003.safetensors:  14%|█▍        | 715M/4.93G [00:51<03:49, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 718M/4.93G [00:51<03:40, 19.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 720M/4.93G [00:51<06:38, 10.6MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 722M/4.93G [00:51<05:35, 12.6MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 725M/4.93G [00:51<04:44, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 728M/4.93G [00:51<04:14, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 736M/4.93G [00:52<03:12, 21.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 738M/4.93G [00:52<04:44, 14.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  15%|█▍        | 740M/4.93G [00:52<04:42, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 749M/4.93G [00:53<02:59, 23.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 752M/4.93G [00:53<04:35, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 754M/4.93G [00:53<04:08, 16.8MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 757M/4.93G [00:53<04:12, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  15%|█▌        | 765M/4.93G [00:53<03:26, 20.2MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 767M/4.93G [00:54<03:17, 21.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 770M/4.93G [00:54<05:32, 12.5MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 776M/4.93G [00:54<03:52, 17.9MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 778M/4.93G [00:54<03:49, 18.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 780M/4.93G [00:54<03:51, 18.0MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 782M/4.93G [00:55<04:03, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 784M/4.93G [00:55<06:46, 10.2MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 788M/4.93G [00:55<04:55, 14.0MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 791M/4.93G [00:55<04:08, 16.7MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 793M/4.93G [00:55<03:41, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 798M/4.93G [00:56<03:23, 20.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  16%|█▌        | 800M/4.93G [00:56<05:06, 13.5MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▋        | 803M/4.93G [00:56<04:25, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  16%|█▋        | 814M/4.93G [00:56<02:36, 26.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 829M/4.93G [00:57<02:19, 29.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 847M/4.93G [00:58<02:11, 31.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 851M/4.93G [01:01<15:06, 4.51MB/s]\n",
      "model-00002-of-00003.safetensors:  17%|█▋        | 863M/4.93G [01:01<06:25, 10.6MB/s]\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 865M/4.93G [01:01<06:42, 10.1MB/s]\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 870M/4.93G [01:02<05:01, 13.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 873M/4.93G [01:02<04:46, 14.2MB/s]\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 875M/4.93G [01:02<04:28, 15.1MB/s]\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 893M/4.93G [01:03<02:38, 25.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 896M/4.93G [01:03<04:17, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 906M/4.93G [01:03<03:41, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:  18%|█▊        | 909M/4.93G [01:04<03:09, 21.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  19%|█▊        | 922M/4.93G [01:04<03:03, 21.9MB/s]\n",
      "model-00002-of-00003.safetensors:  19%|█▊        | 925M/4.93G [01:04<02:54, 23.0MB/s]\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 927M/4.93G [01:05<03:00, 22.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 941M/4.93G [01:05<02:46, 23.9MB/s]\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 944M/4.93G [01:05<02:50, 23.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 953M/4.93G [01:06<03:18, 20.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  19%|█▉        | 958M/4.93G [01:06<03:02, 21.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 965M/4.93G [01:07<03:25, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 969M/4.93G [01:07<02:48, 23.6MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 972M/4.93G [01:07<02:48, 23.5MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 975M/4.93G [01:07<02:55, 22.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 977M/4.93G [01:08<07:06, 9.27MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 979M/4.93G [01:08<06:22, 10.3MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|█▉        | 986M/4.93G [01:08<04:18, 15.3MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|██        | 990M/4.93G [01:08<03:23, 19.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  20%|██        | 992M/4.93G [01:09<06:05, 10.8MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|██        | 998M/4.93G [01:09<04:45, 13.8MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|██        | 1.00G/4.93G [01:09<04:26, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|██        | 1.00G/4.93G [01:09<04:07, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|██        | 1.01G/4.93G [01:09<03:41, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  20%|██        | 1.01G/4.93G [01:10<03:28, 18.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.02G/4.93G [01:10<03:52, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.02G/4.93G [01:10<03:45, 17.4MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.02G/4.93G [01:10<03:25, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.02G/4.93G [01:11<03:16, 19.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.02G/4.93G [01:13<26:15, 2.48MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.03G/4.93G [01:14<15:04, 4.32MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.03G/4.93G [01:14<11:33, 5.63MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.03G/4.93G [01:14<08:40, 7.49MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.04G/4.93G [01:15<07:18, 8.90MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.04G/4.93G [01:15<06:32, 9.92MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.04G/4.93G [01:15<05:17, 12.3MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.05G/4.93G [01:15<04:43, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██        | 1.05G/4.93G [01:15<04:19, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██▏       | 1.05G/4.93G [01:15<04:05, 15.8MB/s]\n",
      "model-00002-of-00003.safetensors:  21%|██▏       | 1.06G/4.93G [01:16<03:20, 19.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.07G/4.93G [01:16<02:46, 23.3MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.07G/4.93G [01:16<02:33, 25.2MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.07G/4.93G [01:16<02:35, 24.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.08G/4.93G [01:17<04:20, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.08G/4.93G [01:17<04:00, 16.0MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.08G/4.93G [01:17<03:47, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.09G/4.93G [01:18<03:40, 17.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.09G/4.93G [01:18<03:59, 16.0MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.10G/4.93G [01:18<03:35, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.10G/4.93G [01:18<03:25, 18.6MB/s]\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.10G/4.93G [01:18<03:10, 20.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  22%|██▏       | 1.11G/4.93G [01:19<03:46, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.11G/4.93G [01:19<03:39, 17.4MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.11G/4.93G [01:19<03:12, 19.9MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.12G/4.93G [01:19<03:02, 20.9MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.12G/4.93G [01:19<02:56, 21.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.13G/4.93G [01:20<03:51, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.13G/4.93G [01:20<02:29, 25.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.14G/4.93G [01:21<03:49, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.14G/4.93G [01:21<03:43, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.15G/4.93G [01:21<03:24, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.15G/4.93G [01:21<02:57, 21.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.15G/4.93G [01:22<04:56, 12.8MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.15G/4.93G [01:22<04:28, 14.1MB/s]\n",
      "model-00002-of-00003.safetensors:  23%|██▎       | 1.16G/4.93G [01:22<03:57, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▎       | 1.17G/4.93G [01:22<02:52, 21.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  24%|██▎       | 1.17G/4.93G [01:22<04:42, 13.4MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▎       | 1.17G/4.93G [01:23<03:46, 16.6MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.17G/4.93G [01:23<03:32, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.18G/4.93G [01:23<03:21, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.18G/4.93G [01:23<02:52, 21.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.18G/4.93G [01:23<04:39, 13.4MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.19G/4.93G [01:23<04:01, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.19G/4.93G [01:24<03:39, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.20G/4.93G [01:24<02:40, 23.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.20G/4.93G [01:24<04:32, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.20G/4.93G [01:24<03:56, 15.8MB/s]\n",
      "model-00002-of-00003.safetensors:  24%|██▍       | 1.21G/4.93G [01:25<04:00, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.22G/4.93G [01:25<04:39, 13.3MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.22G/4.93G [01:25<03:52, 16.0MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.22G/4.93G [01:26<03:47, 16.3MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.22G/4.93G [01:26<03:32, 17.4MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.23G/4.93G [01:26<02:57, 20.9MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▍       | 1.23G/4.93G [01:26<02:51, 21.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  25%|██▌       | 1.24G/4.93G [01:26<03:36, 17.1MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▌       | 1.24G/4.93G [01:26<03:03, 20.2MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▌       | 1.24G/4.93G [01:27<02:53, 21.3MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▌       | 1.25G/4.93G [01:27<02:38, 23.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  25%|██▌       | 1.25G/4.93G [01:27<04:02, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  25%|██▌       | 1.26G/4.93G [01:27<02:59, 20.5MB/s]\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.26G/4.93G [01:28<02:32, 24.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.27G/4.93G [01:28<03:59, 15.3MB/s]\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.28G/4.93G [01:28<02:29, 24.6MB/s]\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.28G/4.93G [01:28<02:14, 27.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.28G/4.93G [01:29<03:41, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.29G/4.93G [01:29<02:51, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  26%|██▌       | 1.29G/4.93G [01:29<02:32, 23.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.31G/4.93G [01:30<02:34, 23.5MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.31G/4.93G [01:30<02:29, 24.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.32G/4.93G [01:31<04:06, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.32G/4.93G [01:31<03:57, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.32G/4.93G [01:31<03:47, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.33G/4.93G [01:31<03:27, 17.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.34G/4.93G [01:32<02:57, 20.3MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.34G/4.93G [01:32<02:43, 22.0MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.34G/4.93G [01:32<02:45, 21.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.35G/4.93G [01:32<04:42, 12.7MB/s]\n",
      "model-00002-of-00003.safetensors:  27%|██▋       | 1.35G/4.93G [01:33<03:11, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.36G/4.93G [01:33<02:44, 21.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.36G/4.93G [01:33<04:13, 14.1MB/s]\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.37G/4.93G [01:34<02:33, 23.2MB/s]\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.38G/4.93G [01:34<02:34, 23.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.38G/4.93G [01:34<04:21, 13.6MB/s]\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.38G/4.93G [01:34<03:50, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.39G/4.93G [01:35<02:22, 24.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  28%|██▊       | 1.40G/4.93G [01:35<02:06, 27.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  29%|██▊       | 1.41G/4.93G [01:36<02:51, 20.5MB/s]\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.42G/4.93G [01:36<01:58, 29.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.43G/4.93G [01:36<03:08, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.43G/4.93G [01:37<03:09, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.43G/4.93G [01:37<02:49, 20.7MB/s]\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.44G/4.93G [01:37<02:36, 22.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.44G/4.93G [01:37<04:16, 13.6MB/s]\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.45G/4.93G [01:38<02:50, 20.4MB/s]\n",
      "model-00002-of-00003.safetensors:  29%|██▉       | 1.45G/4.93G [01:38<02:34, 22.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  30%|██▉       | 1.46G/4.93G [01:38<04:09, 14.0MB/s]\n",
      "model-00002-of-00003.safetensors:  30%|██▉       | 1.47G/4.93G [01:39<02:41, 21.5MB/s]\n",
      "model-00002-of-00003.safetensors:  30%|██▉       | 1.47G/4.93G [01:39<02:31, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:  30%|██▉       | 1.47G/4.93G [01:39<02:28, 23.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.48G/4.93G [01:39<02:09, 26.6MB/s]\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.49G/4.93G [01:40<02:04, 27.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.49G/4.93G [01:40<03:23, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.49G/4.93G [01:40<03:10, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  30%|███       | 1.50G/4.93G [01:40<02:16, 25.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.51G/4.93G [01:41<03:42, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.51G/4.93G [01:41<03:28, 16.4MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.52G/4.93G [01:41<03:15, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.52G/4.93G [01:41<02:46, 20.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.52G/4.93G [01:42<04:39, 12.2MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.53G/4.93G [01:42<03:00, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███       | 1.53G/4.93G [01:42<02:39, 21.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  31%|███▏      | 1.55G/4.93G [01:43<02:39, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███▏      | 1.55G/4.93G [01:43<02:32, 22.2MB/s]\n",
      "model-00002-of-00003.safetensors:  31%|███▏      | 1.55G/4.93G [01:43<02:21, 23.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.56G/4.93G [01:44<03:33, 15.8MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.56G/4.93G [01:44<03:09, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.56G/4.93G [01:44<03:01, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.57G/4.93G [01:44<02:47, 20.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.58G/4.93G [01:45<02:45, 20.2MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.58G/4.93G [01:45<02:36, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.58G/4.93G [01:45<02:31, 22.1MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.58G/4.93G [01:45<02:24, 23.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.59G/4.93G [01:45<03:16, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.59G/4.93G [01:46<03:14, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.59G/4.93G [01:46<03:01, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.60G/4.93G [01:46<02:36, 21.3MB/s]\n",
      "model-00002-of-00003.safetensors:  32%|███▏      | 1.60G/4.93G [01:46<02:27, 22.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.61G/4.93G [01:46<02:24, 23.0MB/s]\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.61G/4.93G [01:47<02:17, 24.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  33%|███▎      | 1.62G/4.93G [01:47<03:53, 14.2MB/s]\n",
      "model-00002-of-00003.safetensors:  34%|███▍      | 1.70G/4.93G [01:51<02:30, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▍      | 1.71G/4.93G [01:51<02:03, 26.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|███▍      | 1.71G/4.93G [01:51<03:12, 16.7MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▍      | 1.72G/4.93G [01:52<02:20, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▍      | 1.73G/4.93G [01:52<02:12, 24.2MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.73G/4.93G [01:52<02:21, 22.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.73G/4.93G [01:52<03:56, 13.5MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.74G/4.93G [01:53<03:06, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.74G/4.93G [01:53<02:44, 19.4MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.74G/4.93G [01:53<02:40, 19.9MB/s]\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.74G/4.93G [01:53<02:45, 19.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.75G/4.93G [01:54<07:13, 7.36MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  35%|███▌      | 1.75G/4.93G [01:54<06:13, 8.53MB/s]\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.76G/4.93G [01:54<02:43, 19.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.76G/4.93G [01:55<04:03, 13.0MB/s]\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.76G/4.93G [01:55<03:31, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.77G/4.93G [01:55<03:22, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.78G/4.93G [01:55<02:09, 24.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.78G/4.93G [01:56<02:58, 17.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  36%|███▌      | 1.79G/4.93G [01:56<02:27, 21.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  36%|███▋      | 1.80G/4.93G [01:57<02:49, 18.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.81G/4.93G [01:57<02:26, 21.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.81G/4.93G [01:57<03:34, 14.6MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.81G/4.93G [01:57<03:15, 16.0MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.81G/4.93G [01:58<03:03, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.82G/4.93G [01:58<02:13, 23.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.83G/4.93G [01:58<03:24, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.83G/4.93G [01:58<03:18, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.83G/4.93G [01:59<03:23, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.83G/4.93G [01:59<03:12, 16.1MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.84G/4.93G [01:59<02:39, 19.4MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.84G/4.93G [01:59<03:13, 16.0MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.85G/4.93G [01:59<02:53, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.85G/4.93G [02:00<02:54, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  37%|███▋      | 1.85G/4.93G [02:00<02:47, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.85G/4.93G [02:00<02:35, 19.8MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.85G/4.93G [02:00<02:31, 20.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.86G/4.93G [02:00<03:16, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.86G/4.93G [02:01<02:55, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.87G/4.93G [02:01<02:41, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.87G/4.93G [02:01<02:21, 21.7MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.87G/4.93G [02:01<02:21, 21.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.88G/4.93G [02:01<02:13, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.88G/4.93G [02:01<02:07, 24.0MB/s]\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.89G/4.93G [02:02<02:29, 20.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.90G/4.93G [02:02<02:49, 17.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  38%|███▊      | 1.90G/4.93G [02:02<02:36, 19.5MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▊      | 1.90G/4.93G [02:03<02:30, 20.1MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▊      | 1.90G/4.93G [02:03<02:21, 21.5MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▊      | 1.91G/4.93G [02:03<02:48, 18.0MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▊      | 1.91G/4.93G [02:03<02:36, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.91G/4.93G [02:03<02:30, 20.1MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.92G/4.93G [02:03<02:26, 20.6MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.92G/4.93G [02:03<02:26, 20.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.92G/4.93G [02:04<03:25, 14.6MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.93G/4.93G [02:04<02:58, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.93G/4.93G [02:04<02:50, 17.6MB/s]\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.93G/4.93G [02:04<02:34, 19.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  39%|███▉      | 1.95G/4.93G [02:05<01:57, 25.4MB/s]\n",
      "model-00002-of-00003.safetensors:  40%|███▉      | 1.95G/4.93G [02:05<01:46, 28.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  40%|███▉      | 1.96G/4.93G [02:06<03:13, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:  40%|███▉      | 1.96G/4.93G [02:06<02:56, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  40%|████      | 1.98G/4.93G [02:07<01:58, 24.9MB/s]\n",
      "model-00002-of-00003.safetensors:  40%|████      | 1.98G/4.93G [02:07<01:51, 26.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  40%|████      | 1.99G/4.93G [02:07<02:51, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.01G/4.93G [02:08<02:00, 24.3MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.01G/4.93G [02:08<01:51, 26.2MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.02G/4.93G [02:08<01:45, 27.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.02G/4.93G [02:09<02:18, 21.0MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.02G/4.93G [02:09<02:08, 22.6MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.03G/4.93G [02:09<02:07, 22.9MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.03G/4.93G [02:09<02:13, 21.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  41%|████      | 2.03G/4.93G [02:10<03:32, 13.6MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████▏     | 2.04G/4.93G [02:10<03:23, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████▏     | 2.04G/4.93G [02:10<03:15, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████▏     | 2.04G/4.93G [02:10<03:16, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  41%|████▏     | 2.04G/4.93G [02:10<03:17, 14.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  41%|████▏     | 2.05G/4.93G [02:10<03:27, 13.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.05G/4.93G [02:11<04:47, 10.0MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.05G/4.93G [02:11<04:42, 10.2MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.05G/4.93G [02:11<04:17, 11.2MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.06G/4.93G [02:11<02:06, 22.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.06G/4.93G [02:12<03:27, 13.8MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.07G/4.93G [02:12<03:24, 14.0MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.07G/4.93G [02:12<02:15, 21.1MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.08G/4.93G [02:12<01:59, 23.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.09G/4.93G [02:13<02:35, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.09G/4.93G [02:13<02:26, 19.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.09G/4.93G [02:13<02:36, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  42%|████▏     | 2.09G/4.93G [02:13<03:01, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.11G/4.93G [02:14<02:02, 23.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.11G/4.93G [02:15<03:05, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.12G/4.93G [02:15<02:47, 16.8MB/s]\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.12G/4.93G [02:15<02:43, 17.3MB/s]\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.13G/4.93G [02:15<02:07, 21.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.13G/4.93G [02:16<03:33, 13.1MB/s]\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.13G/4.93G [02:16<03:23, 13.8MB/s]\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.13G/4.93G [02:16<03:04, 15.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.14G/4.93G [02:16<02:25, 19.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  43%|████▎     | 2.14G/4.93G [02:17<04:00, 11.6MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▎     | 2.15G/4.93G [02:17<03:08, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▎     | 2.15G/4.93G [02:17<02:44, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.16G/4.93G [02:17<01:51, 25.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.16G/4.93G [02:18<03:06, 14.9MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.17G/4.93G [02:18<02:39, 17.3MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.17G/4.93G [02:18<02:17, 20.1MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.17G/4.93G [02:18<02:00, 23.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.18G/4.93G [02:18<02:50, 16.2MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.18G/4.93G [02:18<02:31, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.18G/4.93G [02:18<02:27, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.18G/4.93G [02:19<02:21, 19.4MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.19G/4.93G [02:19<02:01, 22.6MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.19G/4.93G [02:19<03:09, 14.5MB/s]\n",
      "model-00002-of-00003.safetensors:  44%|████▍     | 2.20G/4.93G [02:19<02:37, 17.4MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.20G/4.93G [02:19<02:26, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.20G/4.93G [02:19<02:26, 18.6MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.20G/4.93G [02:20<02:24, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.21G/4.93G [02:20<02:21, 19.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.21G/4.93G [02:20<03:48, 12.0MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.21G/4.93G [02:20<03:03, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.21G/4.93G [02:20<02:55, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▍     | 2.22G/4.93G [02:21<02:48, 16.1MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.22G/4.93G [02:21<02:25, 18.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.22G/4.93G [02:21<03:47, 11.9MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.23G/4.93G [02:21<02:51, 15.8MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.23G/4.93G [02:21<02:50, 15.8MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.24G/4.93G [02:22<02:21, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:  45%|████▌     | 2.24G/4.93G [02:22<02:21, 19.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.25G/4.93G [02:23<02:26, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.25G/4.93G [02:23<02:15, 19.7MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.25G/4.93G [02:23<02:11, 20.4MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.26G/4.93G [02:23<02:12, 20.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.26G/4.93G [02:23<03:00, 14.8MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.26G/4.93G [02:23<02:28, 18.0MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.27G/4.93G [02:24<02:26, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.27G/4.93G [02:24<02:38, 16.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.27G/4.93G [02:24<02:54, 15.3MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.27G/4.93G [02:24<04:25, 10.0MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.28G/4.93G [02:24<03:04, 14.4MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.28G/4.93G [02:24<02:49, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▌     | 2.28G/4.93G [02:25<02:40, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  46%|████▋     | 2.29G/4.93G [02:25<02:11, 20.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  46%|████▋     | 2.29G/4.93G [02:25<02:40, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.30G/4.93G [02:25<02:14, 19.6MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.30G/4.93G [02:26<02:08, 20.5MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.30G/4.93G [02:26<02:02, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.30G/4.93G [02:26<01:59, 22.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.31G/4.93G [02:26<03:36, 12.1MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.31G/4.93G [02:26<03:24, 12.8MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.31G/4.93G [02:26<03:18, 13.2MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.31G/4.93G [02:27<02:48, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.31G/4.93G [02:27<02:40, 16.4MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.32G/4.93G [02:27<02:40, 16.3MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.32G/4.93G [02:27<02:25, 18.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.32G/4.93G [02:27<04:10, 10.4MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.33G/4.93G [02:28<02:35, 16.7MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.33G/4.93G [02:28<02:28, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.33G/4.93G [02:28<02:21, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.33G/4.93G [02:28<02:17, 18.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  47%|████▋     | 2.34G/4.93G [02:29<04:36, 9.38MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.34G/4.93G [02:29<04:08, 10.4MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.35G/4.93G [02:30<03:47, 11.4MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.35G/4.93G [02:30<03:28, 12.4MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.35G/4.93G [02:30<03:12, 13.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.35G/4.93G [02:30<04:54, 8.77MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.36G/4.93G [02:30<03:07, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.36G/4.93G [02:31<02:49, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.37G/4.93G [02:31<02:05, 20.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.37G/4.93G [02:31<02:10, 19.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.37G/4.93G [02:31<02:50, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.38G/4.93G [02:32<02:20, 18.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.38G/4.93G [02:32<02:18, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.38G/4.93G [02:32<02:25, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.38G/4.93G [02:32<03:58, 10.7MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.39G/4.93G [02:32<02:58, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.39G/4.93G [02:32<02:49, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  48%|████▊     | 2.39G/4.93G [02:33<02:36, 16.2MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▊     | 2.39G/4.93G [02:33<02:28, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▊     | 2.40G/4.93G [02:33<02:14, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▊     | 2.40G/4.93G [02:33<03:47, 11.2MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▊     | 2.40G/4.93G [02:33<03:04, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▊     | 2.41G/4.93G [02:33<02:56, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.41G/4.93G [02:34<02:48, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.41G/4.93G [02:34<02:58, 14.1MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.41G/4.93G [02:34<02:58, 14.2MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.41G/4.93G [02:34<02:27, 17.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.42G/4.93G [02:34<03:40, 11.4MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.42G/4.93G [02:34<03:05, 13.5MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.42G/4.93G [02:35<03:04, 13.6MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.42G/4.93G [02:35<03:25, 12.2MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.43G/4.93G [02:35<02:46, 15.1MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.43G/4.93G [02:35<02:19, 17.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.44G/4.93G [02:36<02:24, 17.3MB/s]\n",
      "model-00002-of-00003.safetensors:  49%|████▉     | 2.44G/4.93G [02:36<02:10, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.44G/4.93G [02:36<02:06, 19.7MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.45G/4.93G [02:36<02:00, 20.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.45G/4.93G [02:37<02:19, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.46G/4.93G [02:37<01:54, 21.7MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|████▉     | 2.46G/4.93G [02:37<01:51, 22.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.47G/4.93G [02:37<02:39, 15.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.47G/4.93G [02:38<02:39, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.47G/4.93G [02:38<02:37, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.47G/4.93G [02:38<02:32, 16.2MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.48G/4.93G [02:38<02:16, 18.0MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.48G/4.93G [02:38<02:04, 19.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.48G/4.93G [02:39<04:32, 9.01MB/s]\n",
      "model-00002-of-00003.safetensors:  50%|█████     | 2.48G/4.93G [02:39<03:49, 10.7MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.49G/4.93G [02:39<02:12, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.50G/4.93G [02:39<01:56, 20.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.50G/4.93G [02:40<03:06, 13.0MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.51G/4.93G [02:40<01:47, 22.5MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.51G/4.93G [02:41<02:48, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.52G/4.93G [02:41<02:26, 16.5MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.52G/4.93G [02:41<02:15, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.52G/4.93G [02:41<01:58, 20.3MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████     | 2.53G/4.93G [02:41<01:57, 20.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  51%|█████▏    | 2.53G/4.93G [02:42<02:52, 13.9MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████▏    | 2.53G/4.93G [02:42<02:38, 15.1MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████▏    | 2.54G/4.93G [02:42<02:25, 16.4MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████▏    | 2.54G/4.93G [02:42<02:11, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:  51%|█████▏    | 2.54G/4.93G [02:42<02:15, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.54G/4.93G [02:42<02:14, 17.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.54G/4.93G [02:43<05:38, 7.07MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.55G/4.93G [02:43<04:32, 8.77MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.55G/4.93G [02:43<04:07, 9.64MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.55G/4.93G [02:43<03:48, 10.5MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.56G/4.93G [02:44<02:04, 19.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.56G/4.93G [02:44<03:33, 11.1MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.56G/4.93G [02:44<02:57, 13.4MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.57G/4.93G [02:44<01:39, 23.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.58G/4.93G [02:45<02:46, 14.1MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.58G/4.93G [02:45<02:07, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.59G/4.93G [02:45<01:49, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  52%|█████▏    | 2.59G/4.93G [02:45<01:37, 24.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.59G/4.93G [02:46<02:29, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.60G/4.93G [02:46<01:36, 24.1MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.61G/4.93G [02:46<01:25, 27.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.61G/4.93G [02:47<02:25, 15.9MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.61G/4.93G [02:47<02:29, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.62G/4.93G [02:47<01:44, 22.2MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.63G/4.93G [02:47<02:42, 14.2MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.63G/4.93G [02:48<02:28, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.63G/4.93G [02:48<02:01, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.63G/4.93G [02:48<01:53, 20.3MB/s]\n",
      "model-00002-of-00003.safetensors:  53%|█████▎    | 2.64G/4.93G [02:48<01:46, 21.5MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▎    | 2.65G/4.93G [02:48<02:08, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▎    | 2.65G/4.93G [02:49<01:54, 19.9MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▎    | 2.65G/4.93G [02:49<01:40, 22.6MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.66G/4.93G [02:49<01:27, 26.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.66G/4.93G [02:49<01:54, 19.8MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.67G/4.93G [02:50<01:37, 23.3MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.67G/4.93G [02:50<01:36, 23.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.67G/4.93G [02:50<02:26, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.68G/4.93G [02:50<01:56, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.69G/4.93G [02:50<01:37, 23.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  54%|█████▍    | 2.69G/4.93G [02:51<02:48, 13.3MB/s]\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 2.46G/2.46G [02:51<00:00, 14.4MB/s]\n",
      "model-00002-of-00003.safetensors:  55%|█████▍    | 2.70G/4.93G [02:51<01:36, 23.1MB/s]\n",
      "model-00002-of-00003.safetensors:  55%|█████▍    | 2.70G/4.93G [02:51<01:27, 25.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  55%|█████▌    | 2.72G/4.93G [02:52<01:20, 27.7MB/s]\n",
      "model-00002-of-00003.safetensors:  55%|█████▌    | 2.72G/4.93G [02:52<01:10, 31.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  55%|█████▌    | 2.74G/4.93G [02:53<01:15, 29.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.74G/4.93G [02:53<01:50, 19.9MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.75G/4.93G [02:53<01:22, 26.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.75G/4.93G [02:54<02:04, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.76G/4.93G [02:54<01:45, 20.6MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.76G/4.93G [02:54<01:35, 22.8MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.77G/4.93G [02:54<01:19, 27.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.77G/4.93G [02:54<02:03, 17.6MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▌    | 2.77G/4.93G [02:55<01:48, 20.0MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▋    | 2.78G/4.93G [02:55<01:35, 22.5MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▋    | 2.78G/4.93G [02:55<01:17, 27.8MB/s]\n",
      "model-00002-of-00003.safetensors:  56%|█████▋    | 2.79G/4.93G [02:55<01:56, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.79G/4.93G [02:55<01:41, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.79G/4.93G [02:55<01:30, 23.6MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.80G/4.93G [02:55<01:20, 26.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.81G/4.93G [02:56<01:36, 22.0MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.81G/4.93G [02:56<01:26, 24.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.81G/4.93G [02:56<01:23, 25.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.82G/4.93G [02:57<01:41, 20.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.82G/4.93G [02:57<01:41, 20.8MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.83G/4.93G [02:57<01:37, 21.6MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.83G/4.93G [02:57<01:29, 23.4MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.83G/4.93G [02:57<02:22, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  57%|█████▋    | 2.84G/4.93G [02:58<02:13, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.84G/4.93G [02:58<02:09, 16.2MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.85G/4.93G [02:58<01:36, 21.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.85G/4.93G [02:58<02:18, 15.1MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.85G/4.93G [02:58<01:47, 19.4MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.86G/4.93G [02:59<01:16, 27.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.86G/4.93G [02:59<01:50, 18.8MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.87G/4.93G [02:59<01:35, 21.6MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.88G/4.93G [02:59<01:09, 29.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.88G/4.93G [03:00<01:59, 17.1MB/s]\n",
      "model-00002-of-00003.safetensors:  58%|█████▊    | 2.89G/4.93G [03:00<01:43, 19.7MB/s]\n",
      "model-00002-of-00003.safetensors:  59%|█████▊    | 2.89G/4.93G [03:00<01:33, 21.8MB/s]\n",
      "model-00002-of-00003.safetensors:  59%|█████▊    | 2.89G/4.93G [03:00<01:27, 23.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  59%|█████▊    | 2.90G/4.93G [03:01<02:12, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:  59%|█████▉    | 2.90G/4.93G [03:01<01:47, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  59%|█████▉    | 2.91G/4.93G [03:01<01:19, 25.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  59%|█████▉    | 2.91G/4.93G [03:01<01:50, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  59%|█████▉    | 2.92G/4.93G [03:01<01:32, 21.9MB/s]\n",
      "model-00002-of-00003.safetensors:  59%|█████▉    | 2.93G/4.93G [03:02<01:13, 27.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|█████▉    | 2.94G/4.93G [03:02<01:11, 27.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|█████▉    | 2.96G/4.93G [03:03<01:14, 26.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|█████▉    | 2.96G/4.93G [03:03<01:43, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  60%|██████    | 2.96G/4.93G [03:04<01:34, 20.9MB/s]\n",
      "model-00002-of-00003.safetensors:  60%|██████    | 2.97G/4.93G [03:04<01:11, 27.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  60%|██████    | 2.98G/4.93G [03:04<01:53, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 2.99G/4.93G [03:05<01:20, 24.1MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 2.99G/4.93G [03:05<01:15, 25.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.00G/4.93G [03:05<01:26, 22.3MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.00G/4.93G [03:05<01:22, 23.5MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.01G/4.93G [03:06<01:24, 22.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.01G/4.93G [03:06<02:25, 13.2MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.01G/4.93G [03:06<02:00, 16.0MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.01G/4.93G [03:06<01:43, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.02G/4.93G [03:06<01:30, 21.1MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████    | 3.02G/4.93G [03:06<01:28, 21.7MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████▏   | 3.02G/4.93G [03:07<01:26, 22.2MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████▏   | 3.03G/4.93G [03:07<02:12, 14.5MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████▏   | 3.03G/4.93G [03:07<02:03, 15.4MB/s]\n",
      "model-00002-of-00003.safetensors:  61%|██████▏   | 3.03G/4.93G [03:07<01:54, 16.7MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.05G/4.93G [03:08<01:32, 20.5MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.05G/4.93G [03:08<01:14, 25.4MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.05G/4.93G [03:08<01:07, 27.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.06G/4.93G [03:09<01:26, 21.6MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.07G/4.93G [03:09<01:19, 23.5MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.07G/4.93G [03:09<01:14, 25.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.07G/4.93G [03:09<02:33, 12.1MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.08G/4.93G [03:10<02:06, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.08G/4.93G [03:10<01:49, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  62%|██████▏   | 3.08G/4.93G [03:10<01:40, 18.4MB/s]\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.09G/4.93G [03:10<01:24, 21.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.09G/4.93G [03:10<02:10, 14.2MB/s]\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.10G/4.93G [03:11<01:17, 23.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.10G/4.93G [03:11<01:46, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.12G/4.93G [03:11<01:04, 28.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.12G/4.93G [03:12<01:40, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  63%|██████▎   | 3.13G/4.93G [03:12<01:09, 25.9MB/s]\n",
      "model-00002-of-00003.safetensors:  64%|██████▎   | 3.13G/4.93G [03:12<01:03, 28.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▎   | 3.14G/4.93G [03:13<01:24, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.15G/4.93G [03:13<01:08, 26.2MB/s]\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.15G/4.93G [03:13<01:02, 28.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.15G/4.93G [03:15<05:58, 4.97MB/s]\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.16G/4.93G [03:15<04:51, 6.09MB/s]\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.16G/4.93G [03:15<03:59, 7.40MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.17G/4.93G [03:16<02:37, 11.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  64%|██████▍   | 3.18G/4.93G [03:17<01:45, 16.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▍   | 3.20G/4.93G [03:17<01:04, 26.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▍   | 3.20G/4.93G [03:18<01:28, 19.5MB/s]\n",
      "model-00002-of-00003.safetensors:  65%|██████▌   | 3.21G/4.93G [03:18<01:06, 26.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  65%|██████▌   | 3.22G/4.93G [03:18<01:49, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  65%|██████▌   | 3.22G/4.93G [03:18<01:31, 18.8MB/s]\n",
      "model-00002-of-00003.safetensors:  65%|██████▌   | 3.22G/4.93G [03:19<01:23, 20.5MB/s]\n",
      "model-00002-of-00003.safetensors:  65%|██████▌   | 3.23G/4.93G [03:19<01:03, 26.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.23G/4.93G [03:19<01:34, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.24G/4.93G [03:19<01:30, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.24G/4.93G [03:19<01:26, 19.7MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.25G/4.93G [03:20<01:13, 23.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.25G/4.93G [03:20<01:48, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.26G/4.93G [03:20<01:04, 26.0MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▌   | 3.26G/4.93G [03:20<00:57, 29.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██████▋   | 3.27G/4.93G [03:21<01:28, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▋   | 3.27G/4.93G [03:21<01:20, 20.6MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▋   | 3.28G/4.93G [03:21<01:21, 20.3MB/s]\n",
      "model-00002-of-00003.safetensors:  66%|██████▋   | 3.28G/4.93G [03:21<01:34, 17.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  66%|██████▋   | 3.28G/4.93G [03:22<02:23, 11.6MB/s]\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.28G/4.93G [03:22<01:55, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.29G/4.93G [03:22<01:03, 25.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.30G/4.93G [03:23<01:24, 19.4MB/s]\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.31G/4.93G [03:23<01:01, 26.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.31G/4.93G [03:23<01:25, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.32G/4.93G [03:23<01:10, 22.8MB/s]\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.32G/4.93G [03:24<00:55, 28.8MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  67%|██████▋   | 3.33G/4.93G [03:24<01:29, 18.0MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.33G/4.93G [03:24<01:13, 21.8MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.34G/4.93G [03:24<00:57, 27.9MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.34G/4.93G [03:25<01:18, 20.3MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.35G/4.93G [03:25<01:03, 24.8MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.35G/4.93G [03:25<00:58, 27.2MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.36G/4.93G [03:25<00:53, 29.4MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.36G/4.93G [03:25<00:52, 30.2MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.36G/4.93G [03:25<01:23, 18.8MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.37G/4.93G [03:25<01:16, 20.4MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.37G/4.93G [03:26<01:13, 21.3MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.37G/4.93G [03:26<01:13, 21.3MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.37G/4.93G [03:26<01:12, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.38G/4.93G [03:26<01:49, 14.2MB/s]\n",
      "model-00002-of-00003.safetensors:  68%|██████▊   | 3.38G/4.93G [03:26<01:34, 16.4MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▊   | 3.38G/4.93G [03:26<01:24, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▊   | 3.39G/4.93G [03:27<01:06, 23.4MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▊   | 3.39G/4.93G [03:27<01:35, 16.1MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.40G/4.93G [03:27<01:19, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.40G/4.93G [03:27<01:14, 20.7MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.41G/4.93G [03:27<00:52, 29.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.41G/4.93G [03:28<01:20, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.41G/4.93G [03:28<01:16, 19.9MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.42G/4.93G [03:28<01:15, 20.2MB/s]\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.42G/4.93G [03:28<01:05, 23.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  69%|██████▉   | 3.42G/4.93G [03:29<01:37, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|██████▉   | 3.44G/4.93G [03:29<00:51, 29.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  70%|██████▉   | 3.44G/4.93G [03:30<02:15, 11.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  70%|██████▉   | 3.45G/4.93G [03:30<01:24, 17.6MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|██████▉   | 3.45G/4.93G [03:30<01:16, 19.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.46G/4.93G [03:31<01:38, 15.0MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.46G/4.93G [03:31<01:30, 16.3MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.47G/4.93G [03:31<01:24, 17.3MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.47G/4.93G [03:31<01:21, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.47G/4.93G [03:31<01:18, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.47G/4.93G [03:32<02:06, 11.6MB/s]\n",
      "model-00002-of-00003.safetensors:  70%|███████   | 3.47G/4.93G [03:32<01:41, 14.4MB/s]\n",
      "model-00002-of-00003.safetensors:  71%|███████   | 3.49G/4.93G [03:32<01:00, 23.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████   | 3.50G/4.93G [03:33<01:25, 16.8MB/s]\n",
      "model-00002-of-00003.safetensors:  71%|███████   | 3.50G/4.93G [03:33<01:08, 21.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████   | 3.51G/4.93G [03:34<00:59, 23.7MB/s]\n",
      "model-00002-of-00003.safetensors:  71%|███████▏  | 3.52G/4.93G [03:34<00:55, 25.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████▏  | 3.52G/4.93G [03:35<01:24, 16.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  71%|███████▏  | 3.53G/4.93G [03:35<01:20, 17.4MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.53G/4.93G [03:35<01:20, 17.5MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.54G/4.93G [03:35<01:00, 23.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.54G/4.93G [03:35<01:35, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.54G/4.93G [03:36<01:22, 16.9MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.55G/4.93G [03:36<00:56, 24.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.55G/4.93G [03:36<01:20, 17.1MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.56G/4.93G [03:36<01:05, 20.9MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.56G/4.93G [03:36<01:00, 22.7MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.57G/4.93G [03:37<00:47, 28.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.57G/4.93G [03:37<01:16, 17.9MB/s]\n",
      "model-00002-of-00003.safetensors:  72%|███████▏  | 3.57G/4.93G [03:37<01:11, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.58G/4.93G [03:37<00:55, 24.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.58G/4.93G [03:38<02:04, 10.8MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.59G/4.93G [03:38<01:52, 12.0MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.59G/4.93G [03:38<01:42, 13.1MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.59G/4.93G [03:38<01:35, 14.1MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.60G/4.93G [03:39<01:01, 21.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.61G/4.93G [03:39<01:00, 22.0MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.61G/4.93G [03:39<00:54, 24.1MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.62G/4.93G [03:39<00:54, 24.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.62G/4.93G [03:40<01:10, 18.6MB/s]\n",
      "model-00002-of-00003.safetensors:  73%|███████▎  | 3.63G/4.93G [03:40<01:01, 21.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  74%|███████▎  | 3.63G/4.93G [03:40<01:01, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  74%|███████▎  | 3.63G/4.93G [03:40<01:04, 20.2MB/s]\n",
      "model-00002-of-00003.safetensors:  74%|███████▎  | 3.63G/4.93G [03:41<01:32, 14.0MB/s]\n",
      "model-00002-of-00003.safetensors:  74%|███████▎  | 3.64G/4.93G [03:41<01:27, 14.9MB/s]\n",
      "model-00002-of-00003.safetensors:  74%|███████▎  | 3.64G/4.93G [03:41<01:19, 16.3MB/s]\n",
      "model-00002-of-00003.safetensors:  74%|███████▍  | 3.65G/4.93G [03:41<00:52, 24.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  74%|███████▍  | 3.66G/4.93G [03:42<01:00, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  74%|███████▍  | 3.66G/4.93G [03:42<00:55, 23.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  74%|███████▍  | 3.67G/4.93G [03:43<00:50, 25.0MB/s]\n",
      "model-00002-of-00003.safetensors:  75%|███████▍  | 3.68G/4.93G [03:43<00:46, 26.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  75%|███████▍  | 3.68G/4.93G [03:43<01:08, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  75%|███████▍  | 3.69G/4.93G [03:43<00:51, 24.2MB/s]\n",
      "model-00002-of-00003.safetensors:  75%|███████▍  | 3.70G/4.93G [03:44<00:46, 26.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  75%|███████▍  | 3.70G/4.93G [03:44<01:12, 17.0MB/s]\n",
      "model-00002-of-00003.safetensors:  75%|███████▌  | 3.71G/4.93G [03:44<00:46, 26.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  75%|███████▌  | 3.71G/4.93G [03:45<01:07, 18.2MB/s]\n",
      "model-00002-of-00003.safetensors:  75%|███████▌  | 3.72G/4.93G [03:45<00:55, 21.8MB/s]\n",
      "model-00002-of-00003.safetensors:  75%|███████▌  | 3.73G/4.93G [03:45<00:40, 29.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.73G/4.93G [03:45<01:01, 19.6MB/s]\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.73G/4.93G [03:45<00:54, 22.3MB/s]\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.74G/4.93G [03:46<00:42, 28.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.75G/4.93G [03:46<01:03, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.75G/4.93G [03:46<01:01, 19.2MB/s]\n",
      "model-00002-of-00003.safetensors:  76%|███████▌  | 3.76G/4.93G [03:46<00:45, 25.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  76%|███████▋  | 3.77G/4.93G [03:47<00:47, 24.7MB/s]\n",
      "model-00002-of-00003.safetensors:  76%|███████▋  | 3.77G/4.93G [03:47<00:45, 25.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.78G/4.93G [03:48<01:00, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.78G/4.93G [03:48<00:54, 21.0MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.79G/4.93G [03:48<00:52, 21.7MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.79G/4.93G [03:48<00:51, 22.3MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.79G/4.93G [03:48<01:22, 13.8MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.80G/4.93G [03:49<01:12, 15.7MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.80G/4.93G [03:49<01:13, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.80G/4.93G [03:49<00:53, 21.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.82G/4.93G [03:50<00:44, 24.8MB/s]\n",
      "model-00002-of-00003.safetensors:  77%|███████▋  | 3.82G/4.93G [03:50<00:42, 26.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.83G/4.93G [03:50<00:58, 18.8MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.83G/4.93G [03:50<00:49, 22.4MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.84G/4.93G [03:51<00:48, 22.6MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.84G/4.93G [03:51<00:48, 22.8MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.85G/4.93G [03:51<00:55, 19.5MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.85G/4.93G [03:51<00:50, 21.7MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.85G/4.93G [03:51<00:48, 22.5MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.85G/4.93G [03:51<00:46, 23.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.86G/4.93G [03:52<00:57, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.86G/4.93G [03:52<00:55, 19.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.86G/4.93G [03:52<00:56, 19.1MB/s]\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.87G/4.93G [03:52<00:56, 19.0MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  78%|███████▊  | 3.87G/4.93G [03:53<01:23, 12.7MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▊  | 3.88G/4.93G [03:53<00:47, 22.2MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▊  | 3.88G/4.93G [03:53<00:47, 22.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.89G/4.93G [03:53<00:52, 20.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.89G/4.93G [03:55<03:24, 5.10MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.90G/4.93G [03:55<01:27, 11.9MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.90G/4.93G [03:55<01:04, 15.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.91G/4.93G [03:56<01:00, 17.1MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.91G/4.93G [03:56<00:54, 18.9MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.92G/4.93G [03:56<00:48, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.92G/4.93G [03:56<00:46, 22.0MB/s]\n",
      "model-00002-of-00003.safetensors:  79%|███████▉  | 3.92G/4.93G [03:56<01:09, 14.5MB/s]\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.92G/4.93G [03:57<00:58, 17.3MB/s]\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.93G/4.93G [03:57<00:55, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.93G/4.93G [03:57<00:50, 20.0MB/s]\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.94G/4.93G [03:57<00:44, 22.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.94G/4.93G [03:57<01:12, 13.8MB/s]\n",
      "model-00002-of-00003.safetensors:  80%|███████▉  | 3.94G/4.93G [03:57<01:07, 14.7MB/s]\n",
      "model-00002-of-00003.safetensors:  80%|████████  | 3.95G/4.93G [03:58<00:39, 24.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 3.98G/4.93G [03:59<00:27, 35.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 3.99G/4.93G [04:01<01:56, 8.15MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 3.99G/4.93G [04:01<01:37, 9.66MB/s]\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 4.00G/4.93G [04:01<01:10, 13.2MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 4.00G/4.93G [04:01<01:16, 12.1MB/s]\n",
      "model-00002-of-00003.safetensors:  81%|████████  | 4.00G/4.93G [04:01<01:02, 14.9MB/s]\n",
      "model-00002-of-00003.safetensors:  81%|████████▏ | 4.01G/4.93G [04:02<00:43, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  81%|████████▏ | 4.02G/4.93G [04:02<00:41, 22.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.03G/4.93G [04:02<00:39, 23.2MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.03G/4.93G [04:03<00:37, 24.3MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.03G/4.93G [04:03<01:02, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.04G/4.93G [04:03<00:53, 16.8MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.04G/4.93G [04:03<00:47, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.04G/4.93G [04:03<00:44, 20.2MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.04G/4.93G [04:03<00:41, 21.3MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.05G/4.93G [04:04<00:42, 20.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.05G/4.93G [04:04<01:04, 13.7MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.06G/4.93G [04:04<00:42, 20.6MB/s]\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.06G/4.93G [04:04<00:38, 22.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  82%|████████▏ | 4.07G/4.93G [04:05<00:48, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.07G/4.93G [04:05<00:40, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.08G/4.93G [04:05<00:38, 22.4MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.08G/4.93G [04:05<00:40, 21.1MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.08G/4.93G [04:06<01:03, 13.5MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.08G/4.93G [04:06<00:54, 15.7MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.09G/4.93G [04:06<00:49, 17.2MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.09G/4.93G [04:06<00:45, 18.6MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.09G/4.93G [04:06<00:37, 22.1MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.10G/4.93G [04:07<00:53, 15.6MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.10G/4.93G [04:07<00:49, 16.8MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.10G/4.93G [04:07<00:44, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.11G/4.93G [04:07<00:30, 26.6MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.11G/4.93G [04:07<00:42, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  83%|████████▎ | 4.12G/4.93G [04:07<00:37, 22.0MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▎ | 4.12G/4.93G [04:08<00:32, 25.2MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▎ | 4.12G/4.93G [04:08<00:30, 26.6MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▎ | 4.13G/4.93G [04:08<00:29, 27.7MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▎ | 4.13G/4.93G [04:08<00:44, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▍ | 4.13G/4.93G [04:08<00:36, 21.7MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▍ | 4.14G/4.93G [04:08<00:34, 23.4MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▍ | 4.14G/4.93G [04:08<00:32, 24.2MB/s]\n",
      "model-00002-of-00003.safetensors:  84%|████████▍ | 4.16G/4.93G [04:09<00:26, 29.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  85%|████████▍ | 4.17G/4.93G [04:10<00:28, 27.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  85%|████████▍ | 4.18G/4.93G [04:10<00:41, 18.3MB/s]\n",
      "model-00002-of-00003.safetensors:  85%|████████▍ | 4.19G/4.93G [04:10<00:29, 25.8MB/s]\n",
      "model-00002-of-00003.safetensors:  85%|████████▍ | 4.19G/4.93G [04:11<00:25, 29.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  85%|████████▌ | 4.20G/4.93G [04:11<00:34, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  85%|████████▌ | 4.20G/4.93G [04:11<00:31, 23.4MB/s]\n",
      "model-00002-of-00003.safetensors:  85%|████████▌ | 4.21G/4.93G [04:11<00:29, 24.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.22G/4.93G [04:12<00:24, 29.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.24G/4.93G [04:13<00:23, 29.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.24G/4.93G [04:13<00:35, 19.5MB/s]\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.25G/4.93G [04:13<00:32, 21.2MB/s]\n",
      "model-00002-of-00003.safetensors:  86%|████████▌ | 4.26G/4.93G [04:14<00:24, 28.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  86%|████████▋ | 4.26G/4.93G [04:14<00:39, 17.1MB/s]\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.27G/4.93G [04:15<00:30, 22.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.27G/4.93G [04:15<00:36, 17.9MB/s]\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.29G/4.93G [04:15<00:22, 28.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.29G/4.93G [04:16<00:33, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.30G/4.93G [04:16<00:22, 28.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.31G/4.93G [04:16<00:33, 19.0MB/s]\n",
      "model-00002-of-00003.safetensors:  87%|████████▋ | 4.32G/4.93G [04:17<00:24, 25.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.32G/4.93G [04:17<00:25, 24.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.33G/4.93G [04:17<00:31, 19.3MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.33G/4.93G [04:17<00:28, 21.5MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.33G/4.93G [04:17<00:27, 22.2MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.33G/4.93G [04:18<00:25, 23.3MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.34G/4.93G [04:18<00:41, 14.3MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.34G/4.93G [04:18<00:38, 15.3MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.34G/4.93G [04:18<00:35, 16.6MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.34G/4.93G [04:18<00:32, 18.5MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.35G/4.93G [04:18<00:27, 21.1MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.35G/4.93G [04:19<00:44, 13.2MB/s]\n",
      "model-00002-of-00003.safetensors:  88%|████████▊ | 4.36G/4.93G [04:19<00:22, 25.2MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▊ | 4.37G/4.93G [04:20<00:31, 18.1MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▊ | 4.37G/4.93G [04:20<00:26, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▊ | 4.38G/4.93G [04:20<00:23, 23.3MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▊ | 4.38G/4.93G [04:20<00:22, 24.4MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.38G/4.93G [04:20<00:22, 24.9MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.39G/4.93G [04:20<00:35, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.39G/4.93G [04:21<00:33, 16.1MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.40G/4.93G [04:21<00:28, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.40G/4.93G [04:21<00:25, 21.4MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.40G/4.93G [04:21<00:32, 16.4MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.41G/4.93G [04:22<00:26, 19.8MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.41G/4.93G [04:22<00:24, 21.0MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.41G/4.93G [04:22<00:24, 21.4MB/s]\n",
      "model-00002-of-00003.safetensors:  89%|████████▉ | 4.42G/4.93G [04:22<00:24, 21.5MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.42G/4.93G [04:22<00:40, 12.9MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.42G/4.93G [04:22<00:33, 15.2MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.42G/4.93G [04:22<00:28, 17.8MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.43G/4.93G [04:23<00:24, 21.1MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.43G/4.93G [04:23<00:21, 24.0MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.43G/4.93G [04:23<00:32, 15.5MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.44G/4.93G [04:23<00:28, 17.7MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|████████▉ | 4.44G/4.93G [04:23<00:26, 18.8MB/s]\n",
      "model-00002-of-00003.safetensors:  90%|█████████ | 4.44G/4.93G [04:23<00:23, 20.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  90%|█████████ | 4.46G/4.93G [04:24<00:18, 25.6MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  90%|█████████ | 4.46G/4.93G [04:24<00:17, 26.5MB/s]\n",
      "\u001b[A\n",
      "model-00002-of-00003.safetensors:  91%|█████████ | 4.47G/4.93G [04:25<00:19, 23.6MB/s]\n",
      "model-00001-of-00003.safetensors: 100%|██████████| 4.96G/4.96G [04:25<00:00, 18.7MB/s]\n",
      "model-00002-of-00003.safetensors: 100%|██████████| 4.93G/4.93G [04:42<00:00, 17.5MB/s]\n",
      "\n",
      "\n",
      "Upload 3 LFS files: 100%|██████████| 3/3 [04:42<00:00, 94.18s/it] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/restful3/yi-ko-6b-text2sql/commit/61cb2e93496790272a686c3b2441dc1303fcdd37', commit_message='Upload tokenizer', commit_description='', oid='61cb2e93496790272a686c3b2441dc1303fcdd37', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 허깅페이스 허브에 모델과 토크나이저 업로드\n",
    "# - use_temp_dir=False: 임시 디렉토리 사용하지 않음\n",
    "\n",
    "# 허깅페이스 허브에 모델과 토크나이저 업로드\n",
    "hub_model_id = 'restful3/yi-ko-6b-text2sql'\n",
    "model.push_to_hub(hub_model_id, use_temp_dir=True)  # use_temp_dir를 True로 변경\n",
    "tokenizer.push_to_hub(hub_model_id, use_temp_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 미세 조정한 모델로 예시 데이터에 대한 SQL 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 라이브러리 임포트\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 추론 파이프라인 생성 함수 정의\n",
    "def make_inference_pipeline(model_id):\n",
    "  # 토크나이저 로드\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "  # 4비트 양자화를 적용한 모델 로드 \n",
    "  model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "  # 텍스트 생성 파이프라인 생성\n",
    "  pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "  return pipe\n",
    "\n",
    "def make_prompt(ddl, question, query=''):\n",
    "    prompt = f\"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "\n",
    "### DDL:\n",
    "{ddl}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### SQL:\n",
    "{query}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"restful3/yi-ko-6b-text2sql\"\n",
    "hf_pipe = make_inference_pipeline(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko_text2sql 데이터셋의 테스트 세트 불러오기\n",
    "df = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")['test']\n",
    "# pandas DataFrame으로 변환\n",
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터에 대해 프롬프트 생성 (tqdm 추가)\n",
    "for idx, row in df.iterrows():\n",
    "  # context와 question을 조합하여 프롬프트 생성\n",
    "  prompt = make_prompt(row['context'], row['question'])\n",
    "  # 생성된 프롬프트를 DataFrame에 저장\n",
    "  df.loc[idx, 'prompt'] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SQL 쿼리 생성 중:  83%|████████▎ | 10/12 [01:39<00:19,  9.60s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "SQL 쿼리 생성 중: 100%|██████████| 12/12 [01:53<00:00,  9.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# 청크 크기 설정\n",
    "CHUNK_SIZE = 10  # 필요에 따라 조정하세요\n",
    "\n",
    "# 결과를 저장할 리스트\n",
    "gen_sqls_list = []\n",
    "\n",
    "# 데이터를 청크로 나누어 모델로 SQL 쿼리 생성 (진행 상황 표시)\n",
    "for i in tqdm(range(0, len(df), CHUNK_SIZE), desc=\"SQL 쿼리 생성 중\"):\n",
    "    # 현재 청크의 프롬프트 가져오기\n",
    "    prompts_chunk = df['prompt'][i:i+CHUNK_SIZE].tolist()\n",
    "    \n",
    "    # 빈 리스트면 건너뛰기\n",
    "    if not prompts_chunk:\n",
    "        continue\n",
    "        \n",
    "    # 모델을 사용하여 현재 청크의 SQL 쿼리 생성\n",
    "    chunk_results = hf_pipe(prompts_chunk, do_sample=False,\n",
    "                           return_full_text=False, max_length=512, truncation=True)\n",
    "    \n",
    "    # 생성된 SQL 쿼리 추출 후 리스트에 추가\n",
    "    chunk_gen_sqls = [x[0]['generated_text'] for x in chunk_results]\n",
    "    gen_sqls_list.extend(chunk_gen_sqls)\n",
    "\n",
    "# 생성된 SQL을 DataFrame에 저장\n",
    "df['gen_sql'] = gen_sqls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예제 6.13. 미세 조정한 모델 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def make_requests_for_gpt_evaluation(df, filename, dir='results'):\n",
    "  \"\"\"\n",
    "  GPT 평가를 위한 요청 파일을 생성하는 함수\n",
    "  \n",
    "  Args:\n",
    "      df: 평가 데이터가 포함된 데이터프레임\n",
    "      filename: 저장할 파일 이름 \n",
    "      dir: 저장할 디렉토리 경로 (기본값: 'results')\n",
    "  \"\"\"\n",
    "  # 디렉토리가 없으면 생성\n",
    "  if not Path(dir).exists():\n",
    "      Path(dir).mkdir(parents=True)\n",
    "      \n",
    "  # 프롬프트 리스트 생성\n",
    "  prompts = []\n",
    "  for idx, row in df.iterrows():\n",
    "      prompts.append(\"\"\"Based on below DDL and Question, evaluate gen_sql can resolve Question. If gen_sql and gt_sql do equal job, return \"yes\" else return \"no\". Output JSON Format: {\"resolve_yn\": \"\"}\"\"\" + f\"\"\"\n",
    "\n",
    "DDL: {row['context']}\n",
    "Question: {row['question']}\n",
    "gt_sql: {row['answer']}\n",
    "gen_sql: {row['gen_sql']}\"\"\"\n",
    ")\n",
    "\n",
    "  # GPT-4 요청을 위한 job 리스트 생성\n",
    "  jobs = [{\"model\": \"gpt-4-turbo-preview\", \"response_format\" : { \"type\": \"json_object\" }, \"messages\": [{\"role\": \"system\", \"content\": prompt}]} for prompt in prompts]\n",
    "  \n",
    "  # 파일에 job을 jsonl 형식으로 저장\n",
    "  with open(Path(dir, filename), \"w\") as f:\n",
    "      for job in jobs:\n",
    "          json_string = json.dumps(job)\n",
    "          f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가를 위한 requests.jsonl 생성\n",
    "ft_eval_filepath = \"text2sql_evaluation_finetuned.jsonl\"\n",
    "ft_result_filepath = \"text2sql_result_finetuned.jsonl\"\n",
    "\n",
    "make_requests_for_gpt_evaluation(df, ft_eval_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting request #0\n",
      "INFO:root:Starting request #1\n",
      "INFO:root:Starting request #2\n",
      "INFO:root:Starting request #3\n",
      "INFO:root:Starting request #4\n",
      "INFO:root:Starting request #5\n",
      "INFO:root:Starting request #6\n",
      "INFO:root:Starting request #7\n",
      "INFO:root:Starting request #8\n",
      "INFO:root:Starting request #9\n",
      "INFO:root:Starting request #10\n",
      "INFO:root:Starting request #11\n",
      "INFO:root:Starting request #12\n",
      "INFO:root:Starting request #13\n",
      "INFO:root:Starting request #14\n",
      "INFO:root:Starting request #15\n",
      "INFO:root:Starting request #16\n",
      "INFO:root:Starting request #17\n",
      "INFO:root:Starting request #18\n",
      "INFO:root:Starting request #19\n",
      "INFO:root:Starting request #20\n",
      "INFO:root:Starting request #21\n",
      "INFO:root:Starting request #22\n",
      "INFO:root:Starting request #23\n",
      "INFO:root:Starting request #24\n",
      "INFO:root:Starting request #25\n",
      "INFO:root:Starting request #26\n",
      "INFO:root:Starting request #27\n",
      "INFO:root:Starting request #28\n",
      "INFO:root:Starting request #29\n",
      "INFO:root:Starting request #30\n",
      "INFO:root:Starting request #31\n",
      "INFO:root:Starting request #32\n",
      "INFO:root:Starting request #33\n",
      "INFO:root:Starting request #34\n",
      "INFO:root:Starting request #35\n",
      "INFO:root:Starting request #36\n",
      "INFO:root:Starting request #37\n",
      "INFO:root:Starting request #38\n",
      "INFO:root:Starting request #39\n",
      "INFO:root:Starting request #40\n",
      "INFO:root:Starting request #41\n",
      "INFO:root:Starting request #42\n",
      "INFO:root:Starting request #43\n",
      "INFO:root:Starting request #44\n",
      "INFO:root:Starting request #45\n",
      "INFO:root:Starting request #46\n",
      "INFO:root:Starting request #47\n",
      "INFO:root:Starting request #48\n",
      "INFO:root:Starting request #49\n",
      "INFO:root:Starting request #50\n",
      "INFO:root:Starting request #51\n",
      "INFO:root:Starting request #52\n",
      "INFO:root:Starting request #53\n",
      "INFO:root:Starting request #54\n",
      "INFO:root:Starting request #55\n",
      "INFO:root:Starting request #56\n",
      "INFO:root:Starting request #57\n",
      "INFO:root:Starting request #58\n",
      "INFO:root:Starting request #59\n",
      "INFO:root:Starting request #60\n",
      "INFO:root:Starting request #61\n",
      "INFO:root:Starting request #62\n",
      "INFO:root:Starting request #63\n",
      "INFO:root:Starting request #64\n",
      "INFO:root:Starting request #65\n",
      "INFO:root:Starting request #66\n",
      "INFO:root:Starting request #67\n",
      "INFO:root:Starting request #68\n",
      "INFO:root:Starting request #69\n",
      "INFO:root:Starting request #70\n",
      "INFO:root:Starting request #71\n",
      "INFO:root:Starting request #72\n",
      "INFO:root:Starting request #73\n",
      "INFO:root:Starting request #74\n",
      "INFO:root:Starting request #75\n",
      "INFO:root:Starting request #76\n",
      "INFO:root:Starting request #77\n",
      "INFO:root:Starting request #78\n",
      "INFO:root:Starting request #79\n",
      "INFO:root:Starting request #80\n",
      "INFO:root:Starting request #81\n",
      "INFO:root:Starting request #82\n",
      "INFO:root:Starting request #83\n",
      "INFO:root:Starting request #84\n",
      "INFO:root:Starting request #85\n",
      "INFO:root:Starting request #86\n",
      "INFO:root:Starting request #87\n",
      "INFO:root:Starting request #88\n",
      "INFO:root:Starting request #89\n",
      "INFO:root:Starting request #90\n",
      "INFO:root:Starting request #91\n",
      "INFO:root:Starting request #92\n",
      "INFO:root:Starting request #93\n",
      "INFO:root:Starting request #94\n",
      "INFO:root:Starting request #95\n",
      "INFO:root:Starting request #96\n",
      "INFO:root:Starting request #97\n",
      "INFO:root:Starting request #98\n",
      "INFO:root:Starting request #99\n",
      "INFO:root:Starting request #100\n",
      "INFO:root:Starting request #101\n",
      "INFO:root:Starting request #102\n",
      "INFO:root:Starting request #103\n",
      "INFO:root:Starting request #104\n",
      "INFO:root:Starting request #105\n",
      "INFO:root:Starting request #106\n",
      "INFO:root:Starting request #107\n",
      "INFO:root:Starting request #108\n",
      "INFO:root:Starting request #109\n",
      "INFO:root:Starting request #110\n",
      "INFO:root:Starting request #111\n",
      "INFO:root:Parallel processing complete. Results saved to results/text2sql_result_finetuned.jsonl\n"
     ]
    }
   ],
   "source": [
    "# GPT-4 평가 수행\n",
    "!python api_request_parallel_processor.py \\\n",
    "  --requests_filepath results/{ft_eval_filepath} \\\n",
    "  --save_filepath results/{ft_result_filepath} \\\n",
    "  --request_url https://api.openai.com/v1/chat/completions \\\n",
    "  --max_requests_per_minute 100 \\\n",
    "  --max_tokens_per_minute 30000 \\\n",
    "  --token_encoding_name cl100k_base \\\n",
    "  --max_attempts 5 \\\n",
    "  --logging_level 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_jsonl_to_csv(input_file, output_file, prompt_column=\"prompt\", response_column=\"response\"):\n",
    "    prompts = []\n",
    "    responses = []\n",
    "    with open(input_file, 'r') as json_file:\n",
    "        for line in json_file:\n",
    "            # 각 줄은 배열 형태로 요청과 응답을 포함\n",
    "            data = json.loads(line)\n",
    "            # 첫 번째 요소(인덱스 0)가 요청 정보\n",
    "            prompts.append(data[0][\"messages\"][0][\"content\"])\n",
    "            # 두 번째 요소(인덱스 1)가 응답 정보\n",
    "            responses.append(data[1][\"choices\"][0][\"message\"][\"content\"])\n",
    "\n",
    "    df = pd.DataFrame({prompt_column: prompts, response_column: responses})\n",
    "    df.to_csv(output_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확한 답변 개수: 63/112 (56.25%)\n"
     ]
    }
   ],
   "source": [
    "base_eval = change_jsonl_to_csv(f\"results/{ft_result_filepath}\", \"results/yi_ko_6b_eval.csv\", \"prompt\", \"resolve_yn\")\n",
    "base_eval['resolve_yn'] = base_eval['resolve_yn'].apply(lambda x: json.loads(x)['resolve_yn'])\n",
    "num_correct_answers = base_eval.query(\"resolve_yn == 'yes'\").shape[0]\n",
    "print(f\"정확한 답변 개수: {num_correct_answers}/{len(base_eval)} ({num_correct_answers/len(base_eval)*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
