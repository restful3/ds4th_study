{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dfbb04-2b37-4f8f-820d-a7b8a265fbfb",
   "metadata": {},
   "source": [
    "# **AutoGen Quick Start**\n",
    "* https://microsoft.github.io/autogen/stable//user-guide/agentchat-user-guide/tutorial/models.html#azure-openai  \n",
    "\n",
    "먼저 같은 폴더에 \".env\" 파일을 생성하고 아래 정보를 기록.  \n",
    "\n",
    "AZURE_OPENAI_API_KEY = \"azure openai api key\"  \n",
    "LLM_API_VERSION = \"llm api version\"  \n",
    "LLM_DEPLOYMENT = \"llm deployment\"  \n",
    "LLM_MODEL_VERSION = \"llm model version\"  \n",
    "LLM_ENDPOINT = \"llm endpoint\"  \n",
    "LLM_NAME = \"llm name\"  \n",
    "LLM_TEMP = 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e309352d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e7e502",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL OK\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "        azure_deployment = os.environ[\"LLM_DEPLOYMENT\"],\n",
    "        azure_endpoint = os.environ[\"LLM_ENDPOINT\"],\n",
    "        openai_api_version = os.environ[\"LLM_API_VERSION\"],\n",
    "        openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        model_version= os.environ[\"LLM_MODEL_VERSION\"],\n",
    "        temperature = 0.1,\n",
    ")\n",
    "\n",
    "#Azure text embedding\n",
    "########################################################\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large-1\",\n",
    "    # dimensions: Optional[int] = None, # Can specify dimensions with new text-embedding-3 models\n",
    "    azure_endpoint=\"https://dev.dxengws.apim.lgedx.biz/shared-embedding\", #If not provided, will read env variable AZURE_OPENAI_ENDPOINT\n",
    "    # api_key=... # Can provide an API key directly. If missing read env variable AZURE_OPENAI_API_KEY\n",
    "    # openai_api_version=..., # If not provided, will read env variable AZURE_OPENAI_API_VERSION\n",
    ")\n",
    "########################################################\n",
    "print(\"ALL OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "323475f2-40f7-4885-b5ff-c7f2aa215181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='stop' content='The capital of France is **Paris**.' usage=RequestUsage(prompt_tokens=15, completion_tokens=10) cached=False logprobs=None thought=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3378011/2276180793.py:26: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-11-20. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to gpt-4o-2024-11-20 to enhance token/cost estimation and suppress this warning.\n",
      "  result = await model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n"
     ]
    }
   ],
   "source": [
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.auth.azure import AzureTokenProvider\n",
    "\n",
    "# from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "## 사용하려는 모델을 미리 설치해야함\n",
    "## pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\"\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# # Create the token provider\n",
    "# token_provider = AzureTokenProvider(\n",
    "#     DefaultAzureCredential(),\n",
    "#     \"https://cognitiveservices.azure.com/.default\",\n",
    "# )\n",
    "\n",
    "model_client  = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment = os.environ[\"LLM_DEPLOYMENT\"],\n",
    "    model = os.environ[\"LLM_NAME\"],\n",
    "    api_version= os.environ[\"LLM_API_VERSION\"],\n",
    "    azure_endpoint= os.environ[\"LLM_ENDPOINT\"],\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"] # For key-based authentication.\n",
    ")\n",
    "\n",
    "result = await model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)\n",
    "await az_model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daccf61-68dd-49bd-9284-6ed62780486f",
   "metadata": {},
   "source": [
    "## 에이젼트가 사용할 툴 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7176eff2-1722-4bdc-9aea-61a297f4db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client  = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment = os.environ[\"LLM_DEPLOYMENT\"],\n",
    "    model = os.environ[\"LLM_NAME\"],\n",
    "    api_version= os.environ[\"LLM_API_VERSION\"],\n",
    "    azure_endpoint= os.environ[\"LLM_ENDPOINT\"],\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"] # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4e9a8dc-4386-45c2-af4b-df531469de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function tool that the agent can use.\n",
    "# For this example, we use a fake weather tool for demonstration purposes.\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e0da93d-e239-44f6-bbd3-3741fd385408",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_stock_price(company_name: str) -> str:\n",
    "    \"\"\"Get the stock price of given company.\"\"\"\n",
    "    return f\"The current stock price of {company_name} is 12345678900 won.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e09be4-c282-4d08-89c2-94346762fbbd",
   "metadata": {},
   "source": [
    "### Agent 생성\n",
    "\n",
    "\n",
    "### reflect_on_tool_use 파라미터\n",
    "    \n",
    "reflect_on_tool_use는 AssistantAgent의 생성자에서 설정할 수 있는 불리언(Boolean) 파라미터입니다. 이 파라미터는 에이전트가 도구를 사용한 후 그 결과에 대해 추가적인 추론을 수행할지 여부를 결정합니다.\n",
    "\n",
    "* True인 경우: 에이전트는 도구 호출 및 결과에 대해 추가적인 모델 추론을 수행하여 최종 응답을 생성합니다. 이는 도구 사용 결과를 요약하거나, 더 자세한 분석을 제공하는 데 유용합니다.\n",
    "* False인 경우: 에이전트는 도구 호출 결과를 직접 응답으로 반환합니다. 이 경우 도구에서 반환된 결과가 자연어 형태인지, 다른 에이전트가 특정 스키마를 기대하는지 주의해야 합니다.\n",
    "\n",
    "기본적으로 output_content_type이 설정되면 reflect_on_tool_use는 True로 설정되고, 그렇지 않으면 False로 설정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db0fe9b0-3b14-462b-ba5b-b1f8f744b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an AssistantAgent with the model, tool, system message, and reflection enabled.\n",
    "# The system message instructs the agent via natural language.\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather, get_stock_price],\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    reflect_on_tool_use=True, # 도구 사용 결과에 대해 reflection을 수행하도록 설정\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "648e8944-ae4c-4b48-90f2-96c1ad4cba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_rW6EOmmH2yZRGmmLraGjEfTT', arguments='{\"city\":\"New York\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='get_weather', call_id='call_rW6EOmmH2yZRGmmLraGjEfTT', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The weather in New York is currently 73 degrees and sunny.\n",
      "---------- TextMessage (user) ----------\n",
      "What is the current stock price of AI odyssey company?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_4a1qzft8Aosib9H9tOeVqXyF', arguments='{\"company_name\":\"AI Odyssey\"}', name='get_stock_price')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The current stock price of AI Odyssey is 12345678900 won.', name='get_stock_price', call_id='call_4a1qzft8Aosib9H9tOeVqXyF', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The current stock price of AI Odyssey is 12,345,678,900 won.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent and stream the messages to the console.\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"What is the weather in New York?\"))\n",
    "\n",
    "    await Console(agent.run_stream(task=\"What is the current stock price of AI odyssey company?\"))\n",
    "    # Close the connection to the model client.    \n",
    "    await model_client.close()\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0140a478-e989-4af3-a0bd-119e33603ef8",
   "metadata": {},
   "source": [
    "### Test #1. Tool 함수의 이름을 보고 호출하는 것인가?  \n",
    "이름을 엉뚱하게 바꾸어 보자.  get_weather --> do_addition_of_given_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84f029c9-0a5d-49c8-bdb5-a43477e05196",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client  = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment = os.environ[\"LLM_DEPLOYMENT\"],\n",
    "    model = os.environ[\"LLM_NAME\"],\n",
    "    api_version= os.environ[\"LLM_API_VERSION\"],\n",
    "    azure_endpoint= os.environ[\"LLM_ENDPOINT\"],\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"] # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e2f534d-68e3-40b8-921f-8db8b9e1b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function tool that the agent can use.\n",
    "# For this example, we use a fake weather tool for demonstration purposes.\n",
    "# async def get_weather(city: str) -> str:\n",
    "#     \"\"\"Get the weather for a given city.\"\"\"\n",
    "#     return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "async def do_addition_of_given_number(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9116b924-0bb8-4713-b8c9-13e76391e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_stock_price(company_name: str) -> str:\n",
    "    \"\"\"Get the stock price of given company.\"\"\"\n",
    "    return f\"The current stock price of {company_name} is 12345678900 won.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb85c9d1-5587-48c3-92d3-586655b43070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an AssistantAgent with the model, tool, system message, and reflection enabled.\n",
    "# The system message instructs the agent via natural language.\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[do_addition_of_given_number, get_stock_price],  ##!!!! 이름 변경\n",
    "    system_message=\"You are a helpful assistant.If you can't answer the question, just say I can't answer your question.\",\n",
    "    reflect_on_tool_use=True, # 도구 사용 결과에 대해 reflection을 수행하도록 설정\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ec36a55-bd45-4863-9b23-d6728650ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_VP47CcGzuC3ivojEBNwDLoD3', arguments='{\"city\":\"New York\"}', name='do_addition_of_given_number')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='do_addition_of_given_number', call_id='call_VP47CcGzuC3ivojEBNwDLoD3', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The weather in New York is 73 degrees and sunny.\n",
      "---------- TextMessage (user) ----------\n",
      "What is the current stock price of AI odyssey company?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_zNBj03z3PmOACdH5DivqUI8w', arguments='{\"company_name\":\"AI odyssey\"}', name='get_stock_price')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The current stock price of AI odyssey is 12345678900 won.', name='get_stock_price', call_id='call_zNBj03z3PmOACdH5DivqUI8w', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The current stock price of AI Odyssey is 12,345,678,900 won.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent and stream the messages to the console.\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"What is the weather in New York?\"))\n",
    "\n",
    "    await Console(agent.run_stream(task=\"What is the current stock price of AI odyssey company?\"))\n",
    "    # Close the connection to the model client.    \n",
    "    await model_client.close()\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()\n",
    "\n",
    "### Tool 호출 잘함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36061bc7-fa6e-4c3c-996a-18d5dfbad044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff42daaa-d9bb-4422-8ff1-2b0d42e35fc9",
   "metadata": {},
   "source": [
    "### Test #2. Tool 함수 내부의 doc string 보고 호출하는 것인가?  \n",
    "doc string 내용을 엉뚱하게 바꾸어 보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d04bf15-4d6b-4e0b-982d-a370911f0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client  = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment = os.environ[\"LLM_DEPLOYMENT\"],\n",
    "    model = os.environ[\"LLM_NAME\"],\n",
    "    api_version= os.environ[\"LLM_API_VERSION\"],\n",
    "    azure_endpoint= os.environ[\"LLM_ENDPOINT\"],\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"] # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a18a9456-36f0-4b25-9ada-567ae6f5ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function tool that the agent can use.\n",
    "# For this example, we use a fake weather tool for demonstration purposes.\n",
    "# async def get_weather(city: str) -> str:\n",
    "#     \"\"\"Get the weather for a given city.\"\"\"\n",
    "#     return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the poplulations for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "172dddec-ad68-4c03-aed0-b8cdb5cd39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_stock_price(company_name: str) -> str:\n",
    "    \"\"\"Get the doors of given company.\"\"\"\n",
    "    return f\"The current stock price of {company_name} is 12345678900 won.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f060d4f-41f7-456f-8fb0-eb9696c926a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an AssistantAgent with the model, tool, system message, and reflection enabled.\n",
    "# The system message instructs the agent via natural language.\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather, get_stock_price],  ##!!!! 이름 변경\n",
    "    system_message=\"You are a helpful assistant.If you can't answer the question, just say I can't answer your question.\",\n",
    "    reflect_on_tool_use=True, # 도구 사용 결과에 대해 reflection을 수행하도록 설정\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46bde4f8-d788-42f4-bdb8-78a9fd0e04bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_9BVDpy16WtHB4Hc5fLvwYN3x', arguments='{\"city\":\"New York\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='get_weather', call_id='call_9BVDpy16WtHB4Hc5fLvwYN3x', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The weather in New York is 73 degrees and sunny.\n",
      "---------- TextMessage (user) ----------\n",
      "What is the current stock price of AI odyssey company?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_ReHPXgmaVNjcp780YnesAfEC', arguments='{\"company_name\":\"AI odyssey\"}', name='get_stock_price')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The current stock price of AI odyssey is 12345678900 won.', name='get_stock_price', call_id='call_ReHPXgmaVNjcp780YnesAfEC', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The current stock price of AI Odyssey is 12,345,678,900 won.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent and stream the messages to the console.\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"What is the weather in New York?\"))\n",
    "\n",
    "    await Console(agent.run_stream(task=\"What is the current stock price of AI odyssey company?\"))\n",
    "    # Close the connection to the model client.    \n",
    "    await model_client.close()\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()\n",
    "\n",
    "### Tool 호출 잘함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1ebb0-524f-4cce-a5de-1c7b06bd8956",
   "metadata": {},
   "source": [
    "---\n",
    "**AutoGen Tool Calling 판단 기준**  \n",
    "    \n",
    "autogen 프레임워크에서 tool을 사용하기 위해 LLM은 다음 정보들을 활용합니다:  \n",
    "\n",
    "* 함수 이름:  tool의 이름은 LLM이 어떤 tool을 호출할지 결정하는 데 중요한 역할을 합니다.  \n",
    "Description (설명): tool의 목적과 사용법에 대한 설명을 제공하여 LLM이 tool을 이해하고 적절하게 호출하도록 돕습니다. 이 설명은 tool을 agent에 등록할 때 제공됩니다.  \n",
    "* Type Hints (타입 힌트): 함수의 인자와 반환 값에 대한 타입 힌트는 LLM이 tool의 사용법을 이해하는 데 도움을 줍니다.  \n",
    "* Tool Schema:  함수 시그니처와 타입 힌트로부터 자동 생성되는 tool 스키마는 LLM이 tool을 어떻게 사용해야 하는지에 대한 구조화된 정보를 제공합니다.  \n",
    "* Docstring: Ollama LLM과 같은 특정 LLM은 tool을 인지하기 위해 Python과 유사한 구문으로 작성된 docstring이 필요할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0a471-044b-4e91-b1f7-145c707fc197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agent",
   "language": "python",
   "name": ".llm-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
