{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"13.2 흉부 엑스선 기반 폐렴 진단 탐색적 데이터 분석","metadata":{}},{"cell_type":"markdown","source":"13.2.1 데이터 둘러보기","metadata":{}},{"cell_type":"code","source":"# 데이터 경로\ndata_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\n\n# 훈련, 검증, 테스트 데이터 경로 설정\ntrain_path = data_path + 'train/'\nvalid_path = data_path + 'val/'\ntest_path = data_path + 'test/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nprint(f'훈련 데이터 개수 : {len(glob(train_path + \"*/*\"))}')\nprint(f'검증 데이터 개수 : {len(glob(valid_path + \"*/*\"))}')\nprint(f'테스트 데이터 개수 : {len(glob(test_path + \"*/*\"))}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_normal_imgs = []    # 모든 정상 이미지를 담을 리스트 초기화\nall_pneumonia_imgs = [] # 모든 폐렴 이미지를 담을 리스트 초기화\n\nfor cat in ['train/', 'val/', 'test/']:\n    data_cat_path = data_path + cat\n    # 정상, 폐렴 이미지 경로\n    normal_imgs = glob(data_cat_path + 'NORMAL/*')\n    pneumonia_imgs = glob(data_cat_path + 'PNEUMONIA/*')\n    # 정상, 폐렴 이미지 경로를 리스트에 추가\n    all_normal_imgs.extend(normal_imgs)\n    all_pneumonia_imgs.extend(pneumonia_imgs)\n\nprint(f'정상 흉부 이미지 개수 : {len(all_normal_imgs)}')\nprint(f'폐렴 흉부 이미지 개수 : {len(all_pneumonia_imgs)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.2.2 데이터 시각화","metadata":{}},{"cell_type":"markdown","source":"타깃값 분포","metadata":{}},{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmpl.rc('font', size=15)\nplt.figure(figsize=(7, 7))\n\nlabel = ['Normal', 'Pneumonia'] # 타깃값 레이블\n# 타깃값 분포 파이 그래프\nplt.pie([len(all_normal_imgs), len(all_pneumonia_imgs)], \n        labels=label, \n        autopct='%.1f%%');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이미지 출력","metadata":{}},{"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nimport cv2\n\ndef show_image(img_paths, rows=2, cols=3): \n    assert len(img_paths) <= rows*cols # 이미지가 행/열 개수보다 많으면 오류 발생\n    \n    mpl.rc('font', size=8)\n    plt.figure(figsize=(15, 8)) \n    grid = gridspec.GridSpec(rows, cols) # 서브플롯 배치\n\n    # 이미지 출력\n    for idx, img_path in enumerate(img_paths):\n        image = cv2.imread(img_path) # 이미지 파일 읽기\n        ax = plt.subplot(grid[idx])\n        ax.imshow(image) # 이미지 출력","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 정상 엑스선 이미지 경로(마지막 6장)\nnum_of_imgs = 6\nnormal_img_paths = all_normal_imgs[-num_of_imgs:]\n\n# 이미지 출력\nshow_image(normal_img_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 폐렴 엑스선 이미지 경로(마지막 6장)\npneumonia_img_paths = all_pneumonia_imgs[-num_of_imgs:]\n\n# 이미지 출력\nshow_image(pneumonia_img_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13.3 흉부 엑스선 기반 폐렴 진단 베이스라인 모델","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:16:18.176865Z","iopub.execute_input":"2023-04-21T08:16:18.177330Z","iopub.status.idle":"2023-04-21T08:16:18.182888Z","shell.execute_reply.started":"2023-04-21T08:16:18.177292Z","shell.execute_reply":"2023-04-21T08:16:18.181534Z"}}},{"cell_type":"markdown","source":"13.3.1 시드 값 고정 및 GPU 장비 설정","metadata":{}},{"cell_type":"markdown","source":"시드값 고정","metadata":{}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.3.2 데이터 준비","metadata":{}},{"cell_type":"code","source":"# 데이터 경로\ndata_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\n\n# 훈련, 검증, 테스트 데이터 경로 설정\ntrain_path = data_path + 'train/'\nvalid_path = data_path + 'val/'\ntest_path = data_path + 'test/'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터 증강을 위한 이미지 변환기 정의","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([\n                          transforms.Resize((250, 250)),      # 이미지 크기 조정 \n                          transforms.CenterCrop(180),         # 중앙 이미지 확대\n                          transforms.RandomHorizontalFlip(0.5), # 좌우 대칭\n                          transforms.RandomVerticalFlip(0.2), # 상하 대칭\n                          transforms.RandomRotation(20),      # 이미지 회전\n                          transforms.ToTensor(),              # 텐서 객체로 변환\n                          transforms.Normalize((0.485, 0.456, 0.406), \n                                               (0.229, 0.224, 0.225))]) # 정규화\n\n# 테스트 데이터용 변환기\ntransform_test = transforms.Compose([\n                          transforms.Resize((250, 250)),\n                          transforms.CenterCrop(180),\n                          transforms.ToTensor(),\n                          transforms.Normalize((0.485, 0.456, 0.406), \n                                               (0.229, 0.224, 0.225))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터셋 및 데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\n\n# 훈련 데이터셋\ndatasets_train = ImageFolder(root=train_path, transform=transform_train)\n# 검증 데이터셋\ndatasets_valid = ImageFolder(root=valid_path, transform=transform_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\n# 제너레이터 시드값 고정\ng = torch.Generator()\ng.manual_seed(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 8\n\nloader_train = DataLoader(dataset=datasets_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nloader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.3.3 모델 생성","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n# 모델 생성\nmodel = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2) \n# 장비 할당\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('모델 파라미터 개수 :', sum(param.numel() for param in model.parameters()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.3.4 모델 훈련 및 성능 검증","metadata":{}},{"cell_type":"markdown","source":"손실 함수와 옵티마이저 설정","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score # 정확도 계산 함수\nfrom sklearn.metrics import recall_score   # 재현율 계산 함수\nfrom sklearn.metrics import f1_score       # F1 점수 계산 함수\nfrom tqdm.notebook import tqdm             # 진행률 표시 막대\n\ndef train(model, loader_train, loader_valid, criterion, optimizer, \n          scheduler=None, epochs=10, save_file='model_state_dict.pth'):\n    \n    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n\n    # 총 에폭만큼 반복\n    for epoch in range(epochs):\n        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n        \n        # == [ 훈련 ] ==============================================\n        model.train()        # 모델을 훈련 상태로 설정\n        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n        # '반복 횟수'만큼 반복 \n        for images, labels in tqdm(loader_train):\n            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            # 옵티마이저 내 기울기 초기화\n            optimizer.zero_grad()\n            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n            outputs = model(images)\n            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n            loss = criterion(outputs, labels)\n            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n            epoch_train_loss += loss.item() \n            loss.backward()       # 역전파 수행\n            optimizer.step()      # 가중치 갱신\n            if scheduler != None: # 스케줄러 학습률 갱신 \n                scheduler.step() \n\n        # 훈련 데이터 손실값 출력\n        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n        \n        # == [ 검증 ] ==============================================\n        model.eval()         # 모델을 평가 상태로 설정 \n        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n        preds_list = []      # 예측값 저장용 리스트 초기화\n        true_list = []       # 실젯값 저장용 리스트 초기화\n        \n        with torch.no_grad(): # 기울기 계산 비활성화\n            for images, labels in loader_valid:\n                images = images.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                epoch_valid_loss += loss.item()\n                \n                # 예측값 및 실제값 \n                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n                true = labels.cpu().numpy() \n    \n                preds_list.extend(preds)\n                true_list.extend(true)\n                \n        # 정확도, 재현율, F1 점수 계산\n        val_accuracy = accuracy_score(true_list, preds_list)\n        val_recall = recall_score(true_list, preds_list)\n        val_f1_score = f1_score(true_list, preds_list)\n\n        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n        # == [ 최적 모델 가중치 찾기 ] ==============================\n        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n        if epoch_valid_loss <= valid_loss_min: \n            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n            # 모델 가중치를 파일로 저장 \n            torch.save(model.state_dict(), save_file) \n            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n    return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"훈련 및 성능 검증","metadata":{}},{"cell_type":"code","source":"# 모델 훈련\nmodel_state_dict = train(model=model,\n                         loader_train=loader_train, \n                         loader_valid=loader_valid,\n                         criterion=criterion, \n                         optimizer=optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 최적 가중치 불러오기\nmodel.load_state_dict(model_state_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.3.5 예측 및 평가 결과","metadata":{}},{"cell_type":"code","source":"datasets_test = ImageFolder(root=test_path, transform=transform_test)\n\nloader_test = DataLoader(dataset=datasets_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"예측","metadata":{}},{"cell_type":"code","source":"def predict(model, loader_test, return_true=False):\n    model.eval()    # 모델을 평가 상태로 설정\n    preds_list = [] # 예측값 저장용 리스트 초기화\n    true_list = []  # 실제값 저장용 리스트 초기화\n\n    with torch.no_grad(): # 기울기 계산 비활성\n        for images, labels in loader_test:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            \n            preds = torch.max(outputs.cpu(), dim=1)[1].numpy() # 예측값\n            true = labels.cpu().numpy() # 실제값 \n\n            preds_list.extend(preds)\n            true_list.extend(true)\n\n    if return_true:\n        return true_list, preds_list\n    else:\n        return preds_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_list, preds_list = predict(model=model, \n                                loader_test=loader_test, \n                                return_true=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"평가 결과","metadata":{}},{"cell_type":"code","source":"print('#'*5, '최종 예측 결과 평가 점수', '#'*5)\nprint(f'정확도 : {accuracy_score(true_list, preds_list):.4f}')\nprint(f'재현율 : {recall_score(true_list, preds_list):.4f}')\nprint(f'F1 점수 : {f1_score(true_list, preds_list):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13.4 흉부 엑스선 기반 폐렴 진단 성능 개선","metadata":{}},{"cell_type":"markdown","source":"시드값 고정 및 GPU 장비 설정","metadata":{}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터 준비","metadata":{}},{"cell_type":"code","source":"# 데이터 경로\ndata_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\n\n# 훈련, 검증, 테스트 데이터 경로 설정\ntrain_path = data_path + 'train/'\nvalid_path = data_path + 'val/'\ntest_path = data_path + 'test/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터 증강을 위한 이미지 변환기 정의","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([\n                          transforms.Resize((250, 250)),      # 이미지 크기 조정 \n                          transforms.CenterCrop(180),         # 중앙 이미지 확대\n                          transforms.RandomHorizontalFlip(0.5), # 좌우 대칭\n                          transforms.RandomVerticalFlip(0.2), # 상하 대칭\n                          transforms.RandomRotation(20),      # 이미지 회전\n                          transforms.ToTensor(),              # 텐서 객체로 변환\n                          transforms.Normalize((0.485, 0.456, 0.406), \n                                               (0.229, 0.224, 0.225))]) # 정규화\n\n# 테스트 데이터용 변환기\ntransform_test = transforms.Compose([\n                          transforms.Resize((250, 250)),\n                          transforms.CenterCrop(180),\n                          transforms.ToTensor(),\n                          transforms.Normalize((0.485, 0.456, 0.406), \n                                               (0.229, 0.224, 0.225))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"데이터셋 및 데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\n\n# 훈련 데이터셋\ndatasets_train = ImageFolder(root=train_path, transform=transform_train)\n# 검증 데이터셋\ndatasets_valid = ImageFolder(root=valid_path, transform=transform_test) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 8\n\nloader_train = DataLoader(dataset=datasets_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nloader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.4.1 모델 생성 및 훈련","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_list =[] # 모델 저장용 리스트","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\n# 모델 생성\nefficientnet_b1 = EfficientNet.from_pretrained('efficientnet-b1', num_classes=2) \nefficientnet_b2 = EfficientNet.from_pretrained('efficientnet-b2', num_classes=2)\nefficientnet_b3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes=2) \n\n# 장비 할당\nefficientnet_b1 = efficientnet_b1.to(device)\nefficientnet_b2 = efficientnet_b2.to(device)\nefficientnet_b3 = efficientnet_b3.to(device)\n\n# 리스트에 모델 저장\nmodels_list.append(efficientnet_b1)\nmodels_list.append(efficientnet_b2)\nmodels_list.append(efficientnet_b3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx, model in enumerate(models_list):\n    num_parmas = sum(param.numel() for param in model.parameters())\n    print(f'모델{idx+1} 파라미터 개수 : {num_parmas}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"손실 함수, 옵티마이저, 스케줄러 설정","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer1 = torch.optim.AdamW(models_list[0].parameters(), lr=0.0006, weight_decay=0.001)\noptimizer2 = torch.optim.AdamW(models_list[1].parameters(), lr=0.0006, weight_decay=0.001)\noptimizer3 = torch.optim.AdamW(models_list[2].parameters(), lr=0.0006, weight_decay=0.001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_cosine_schedule_with_warmup\n\nepochs = 20 # 총 에폭\n\n# 스케줄러\nscheduler1 = get_cosine_schedule_with_warmup(optimizer1, \n                                    num_warmup_steps=len(loader_train)*3, \n                                    num_training_steps=len(loader_train)*epochs)\n\nscheduler2 = get_cosine_schedule_with_warmup(optimizer2, \n                                    num_warmup_steps=len(loader_train)*3, \n                                    num_training_steps=len(loader_train)*epochs)\n\nscheduler3 = get_cosine_schedule_with_warmup(optimizer3, \n                                    num_warmup_steps=len(loader_train)*3, \n                                    num_training_steps=len(loader_train)*epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델 훈련 및 성능 검증","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:39:43.980198Z","iopub.execute_input":"2023-04-21T08:39:43.981304Z","iopub.status.idle":"2023-04-21T08:39:43.990092Z","shell.execute_reply.started":"2023-04-21T08:39:43.981252Z","shell.execute_reply":"2023-04-21T08:39:43.987002Z"}}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score # 정확도 계산 함수\nfrom sklearn.metrics import recall_score   # 재현율 계산 함수\nfrom sklearn.metrics import f1_score       # F1 점수 계산 함수\nfrom tqdm.notebook import tqdm             # 진행률 표시 막대\n\ndef train(model, loader_train, loader_valid, criterion, optimizer, \n          scheduler=None, epochs=10, save_file='model_state_dict.pth'):\n    \n    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n\n    # 총 에폭만큼 반복\n    for epoch in range(epochs):\n        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n        \n        # == [ 훈련 ] ==============================================\n        model.train()        # 모델을 훈련 상태로 설정\n        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n        # '반복 횟수'만큼 반복 \n        for images, labels in tqdm(loader_train):\n            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            # 옵티마이저 내 기울기 초기화\n            optimizer.zero_grad()\n            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n            outputs = model(images)\n            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n            loss = criterion(outputs, labels)\n            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n            epoch_train_loss += loss.item() \n            loss.backward()       # 역전파 수행\n            optimizer.step()      # 가중치 갱신\n            if scheduler != None: # 스케줄러 학습률 갱신 \n                scheduler.step() \n\n        # 훈련 데이터 손실값 출력\n        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n        \n        # == [ 검증 ] ==============================================\n        model.eval()         # 모델을 평가 상태로 설정 \n        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n        preds_list = []      # 예측값 저장용 리스트 초기화\n        true_list = []       # 실젯값 저장용 리스트 초기화\n        \n        with torch.no_grad(): # 기울기 계산 비활성화\n            for images, labels in loader_valid:\n                images = images.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                epoch_valid_loss += loss.item()\n                \n                # 예측값 및 실제값 \n                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n                true = labels.cpu().numpy() \n    \n                preds_list.extend(preds)\n                true_list.extend(true)\n                \n        # 정확도, 재현율, F1 점수 계산\n        val_accuracy = accuracy_score(true_list, preds_list)\n        val_recall = recall_score(true_list, preds_list)\n        val_f1_score = f1_score(true_list, preds_list)\n\n        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n        # == [ 최적 모델 가중치 찾기 ] ==============================\n        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n        if epoch_valid_loss <= valid_loss_min: \n            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n            # 모델 가중치를 파일로 저장 \n            torch.save(model.state_dict(), save_file) \n            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n    return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 첫 번째 모델 훈련\nmodel_state_dict = train(model=models_list[0],\n                         loader_train=loader_train, \n                         loader_valid=loader_valid,\n                         criterion=criterion, \n                         optimizer=optimizer1,\n                         scheduler=scheduler1,\n                         epochs=epochs)\n\n# 첫 번째 모델에 최적 가중치 적용\nmodels_list[0].load_state_dict(model_state_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 두 번째 모델 훈련\nmodel_state_dict = train(model=models_list[1],\n                         loader_train=loader_train, \n                         loader_valid=loader_valid,\n                         criterion=criterion, \n                         optimizer=optimizer2,\n                         scheduler=scheduler2,\n                         epochs=epochs)\n\n# 두 번째 모델에 최적 가중치 적용\nmodels_list[1].load_state_dict(model_state_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 세 번째 모델 훈련\nmodel_state_dict = train(model=models_list[2],\n                         loader_train=loader_train, \n                         loader_valid=loader_valid,\n                         criterion=criterion, \n                         optimizer=optimizer3,\n                         scheduler=scheduler3,\n                         epochs=epochs)\n\n# 세 번째 모델에 최적 가중치 적용\nmodels_list[2].load_state_dict(model_state_dict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"13.4.2 예측 및 평가 결과","metadata":{}},{"cell_type":"code","source":"datasets_test = ImageFolder(root=test_path, transform=transform_test)\n\nloader_test = DataLoader(dataset=datasets_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델별 예측","metadata":{}},{"cell_type":"code","source":"def predict(model, loader_test, return_true=False):\n    model.eval()    # 모델을 평가 상태로 설정\n    preds_list = [] # 예측값 저장용 리스트 초기화\n    true_list = []  # 실제값 저장용 리스트 초기화\n\n    with torch.no_grad(): # 기울기 계산 비활성\n        for images, labels in loader_test:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            \n            preds = torch.max(outputs.cpu(), dim=1)[1].numpy() # 예측값\n            true = labels.cpu().numpy() # 실제값 \n\n            preds_list.extend(preds)\n            true_list.extend(true)\n\n    if return_true:\n        return true_list, preds_list\n    else:\n        return preds_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true_list, preds_list1 = predict(model=models_list[0], \n                                 loader_test=loader_test, \n                                 return_true=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_list2 = predict(model=models_list[1], \n                      loader_test=loader_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_list3 = predict(model=models_list[2], \n                      loader_test=loader_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('#'*5, 'efficientnet-b1 모델 예측 결과 평가 점수', '#'*5)\nprint(f'정확도 : {accuracy_score(true_list, preds_list1):.4f}')\nprint(f'재현율 : {recall_score(true_list, preds_list1):.4f}')\nprint(f'F1 점수 : {f1_score(true_list, preds_list1):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('#'*5, 'efficientnet-b2 모델 예측 결과 평가 점수', '#'*5)\nprint(f'정확도 : {accuracy_score(true_list, preds_list2):.4f}')\nprint(f'재현율 : {recall_score(true_list, preds_list2):.4f}')\nprint(f'F1 점수 : {f1_score(true_list, preds_list2):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('#'*5, 'efficientnet-b3 모델 예측 결과 평가 점수', '#'*5)\nprint(f'정확도 : {accuracy_score(true_list, preds_list3):.4f}')\nprint(f'재현율 : {recall_score(true_list, preds_list3):.4f}')\nprint(f'F1 점수 : {f1_score(true_list, preds_list3):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"앙상블 예측","metadata":{}},{"cell_type":"code","source":"ensemble_preds = []\n\nfor i in range(len(preds_list1)):\n    pred_element = np.round((preds_list1[i] + preds_list2[i] + preds_list3[i])/3)\n    ensemble_preds.append(pred_element)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"평가 결과","metadata":{}},{"cell_type":"code","source":"print('#'*5, '최종 앙상블 결과 평가 점수', '#'*5)\nprint(f'정확도 : {accuracy_score(true_list, ensemble_preds):.4f}')\nprint(f'재현율 : {recall_score(true_list, ensemble_preds):.4f}')\nprint(f'F1 점수 : {f1_score(true_list, ensemble_preds):.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 최종 앙상블 결과 평가 점수 #####\n정확도 : 0.8974\n재현율 : 0.9923\nF1 점수 : 0.9236","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}