{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **제1장. 기초 모델을 활용한 AI 애플리케이션 구축 소개**\n",
    "\n",
    "2020년 이후의 AI를 한 단어로 묘사해야 한다면, 그것은 **규모**일 것입니다. ChatGPT, Google의 Gemini, Midjourney와 같은 애플리케이션 뒤에 있는 AI 모델들은 세계 전력의 상당 부분을 소비할 정도로 거대한 규모를 자랑하며, 이 모델들을 훈련하기 위한 공개적인 인터넷 데이터가 고갈될 위험에 처해 있습니다.\n",
    "\n",
    "AI 모델의 규모 확대는 두 가지 주요 결과를 초래했습니다. 첫째, AI 모델은 점점 더 강력해지고 다양한 작업을 수행할 수 있게 되어 더 많은 애플리케이션을 가능하게 합니다. 이를 통해 더 많은 사람들이 AI를 활용해 생산성을 높이고, 경제적 가치를 창출하며, 삶의 질을 향상시킬 수 있습니다.\n",
    "\n",
    "둘째, 대규모 언어 모델(LLM)을 훈련시키는 데는 데이터, 컴퓨팅 자원, 전문 인력이 필요하며, 이는 소수의 조직만이 감당할 수 있습니다. 이러한 상황은 **서비스로서의 모델(model as a service)** 이라는 개념을 탄생시켰습니다. 이는 소수의 조직이 개발한 모델을 서비스 형태로 제공하는 것을 말하며, 이를 통해 애플리케이션을 구축하려는 사람들은 모델을 직접 구축하는 초기 투자 없이 이를 활용할 수 있게 되었습니다.\n",
    "\n",
    "결론적으로, AI 애플리케이션에 대한 수요는 증가한 반면, AI 애플리케이션을 구축하는 진입 장벽은 낮아졌습니다. 이는 **AI 엔지니어링(AI engineering)**—즉, 쉽게 이용 가능한 모델을 기반으로 애플리케이션을 구축하는 과정—을 가장 빠르게 성장하는 공학 분야 중 하나로 변모시켰습니다.\n",
    "\n",
    "기계 학습(ML) 모델을 기반으로 애플리케이션을 구축하는 것은 새로운 개념이 아닙니다. LLM이 주목받기 전에도 AI는 이미 상품 추천, 사기 탐지, 고객 이탈 예측 등의 많은 애플리케이션에 활용되고 있었습니다. AI 애플리케이션을 상용화하는 데 필요한 많은 원칙은 여전히 동일하지만, 대규모로 쉽게 이용 가능한 모델의 새로운 세대는 새로운 가능성과 도전을 제시하며, 이것이 이 책의 중심 주제입니다.\n",
    "\n",
    "이 장에서는 AI 엔지니어링의 폭발적 성장을 이끈 핵심 촉매인 기초 모델에 대한 개요로 시작합니다. 이후, AI가 잘하는 것과 아직 잘하지 못하는 것을 보여주는 다양한 성공 사례를 다룹니다. AI의 능력이 매일 확장됨에 따라 그 미래 가능성을 예측하는 것이 점점 더 어려워지고 있지만, 기존의 애플리케이션 패턴은 오늘날의 기회를 발견하고 AI가 미래에 어떻게 계속 사용될지에 대한 단서를 제공할 수 있습니다.\n",
    "\n",
    "마지막으로, 기초 모델과 함께 변화한 AI 스택에 대한 개요를 제공하며, 변하지 않은 것, 그리고 오늘날 AI 엔지니어의 역할이 전통적인 ML 엔지니어의 역할과 어떻게 다른지를 설명합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 엔지니어링의 부상\n",
    "\n",
    "기본 모델은 대규모 언어 모델에서 시작되었으며, 이는 다시 언어 모델에서 기원했습니다. ChatGPT와 GitHub의 Copilot과 같은 애플리케이션은 최근의 현상이지만, 언어 모델 자체는 70년이 넘는 역사를 가지고 있습니다. 이 섹션에서는 언어 모델에서 AI 엔지니어링으로의 발전을 가능하게 한 주요 혁신을 추적합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 언어 모델에서 대규모 언어 모델로\n",
    "\n",
    "언어 모델을 확장할 수 있게 한 핵심 기술은 **자기 지도 학습(self-supervision)** 입니다. 이 섹션에서는 언어 모델과 자기 지도 학습이 무엇을 의미하는지 간략히 설명합니다. 이미 이 주제에 익숙하다면 이 섹션을 건너뛰어도 좋습니다.\n",
    "\n",
    "---\n",
    "\n",
    "**언어 모델**\n",
    "\n",
    "언어 모델은 하나 이상의 언어에 대한 통계적 정보를 인코딩합니다. 직관적으로, 이러한 정보는 특정 맥락에서 단어가 나타날 확률을 알려줍니다. 예를 들어, \"내가 가장 좋아하는 색은 __입니다(My favorite color is __)\"라는 맥락에서, 영어를 인코딩한 언어 모델은 \"blue(파란색)\"를 \"car(자동차)\"보다 더 자주 예측해야 합니다.\n",
    "\n",
    "언어의 통계적 특성은 수 세기 전에 발견되었습니다. 1905년에 발표된 이야기 **\"춤추는 남자들(The Adventure of the Dancing Men)\"** 에서, 셜록 홈즈는 영어의 간단한 통계 정보를 활용해 신비한 막대 그림 시퀀스를 해독했습니다. 영어에서 가장 많이 사용되는 글자가 'E'라는 점을 바탕으로, 홈즈는 가장 흔한 막대 그림이 'E'를 나타내야 한다고 추론했습니다.\n",
    "\n",
    "그 후, 클로드 섀넌(Claude Shannon)은 더 정교한 통계 기법을 사용해 제2차 세계대전 동안 적의 메시지를 해독했습니다. 그는 영어 모델링 방법에 대한 연구를 1951년 그의 기념비적인 논문 **\"인쇄된 영어의 예측과 엔트로피(Prediction and Entropy of Printed English)\"** 에 발표했습니다. 이 논문에서 소개된 개념(예: 엔트로피)은 오늘날 언어 모델링에서도 여전히 사용되고 있습니다.\n",
    "\n",
    "초기에는 언어 모델이 하나의 언어만 처리했습니다. 그러나 오늘날에는 많은 언어 모델이 여러 언어를 다룰 수 있습니다.\n",
    "\n",
    "언어 모델의 기본 단위는 **토큰(token)** 입니다. 토큰은 문자, 단어, 또는 단어의 일부(예: \"-tion\")일 수 있으며, 이는 모델에 따라 달라집니다. 예를 들어, ChatGPT의 기반이 되는 GPT-4 모델은 \"I can't wait to build AI applications(나는 AI 애플리케이션을 구축하기를 기다릴 수 없다)\"라는 구문을 9개의 토큰으로 분리합니다. **\"can't\"** 라는 단어는 두 개의 토큰(**can**과 **'t**)으로 나뉩니다. OpenAI의 다양한 모델이 텍스트를 어떻게 토큰화하는지 확인하려면 [OpenAI Tokenizer](https://platform.openai.com/tokenizer)를 방문하세요.\n",
    "\n",
    "<img src=\"images/fig_01_01.png\" width=800>\n",
    "\n",
    "텍스트를 토큰으로 나누는 과정을 **토크나이제이션(tokenization)** 이라고 합니다. GPT-4의 경우, 평균 토큰은 단어 길이의 약 ¾ 정도입니다. 따라서 100개의 토큰은 대략 75개의 단어에 해당합니다.  \n",
    "\n",
    "모델이 사용할 수 있는 모든 토큰의 집합을 **모델의 어휘(vocabulary)** 라고 합니다. 소수의 토큰으로 많은 고유 단어를 구성할 수 있는데, 이는 알파벳의 몇 개의 글자로 많은 단어를 만들 수 있는 방식과 유사합니다. Mixtral 8x7B 모델의 어휘 크기는 32,000입니다. OpenAI의 토크나이제이션 라이브러리인 **tiktoken**에 따르면, GPT-4의 어휘 크기는 100,256입니다.  \n",
    "토크나이제이션 방식과 어휘 크기는 모델 개발자가 결정하며, 이 결정에 대한 내용은 6장에서 더 자세히 논의됩니다.\n",
    "\n",
    "다음은 제공된 텍스트의 한국어 번역입니다:\n",
    "\n",
    ">**참고**  \n",
    ">\n",
    ">언어 모델이 **단어(word)** 나 **문자(character)** 대신 **토큰(token)** 을 단위로 사용하는 이유는 다음 세 가지 주요 이유 때문입니다:\n",
    ">\n",
    ">1. 문자와 비교했을 때, 토큰은 단어를 더 의미 있는 구성 요소로 나눌 수 있게 합니다. 예를 들어, \"cooking(요리하다)\"은 \"cook(요리)\"과 \"ing\"로 나눌 수 있으며, 두 구성 요소 모두 원래 단어의 의미를 어느 정도 포함하고 있습니다.\n",
    ">\n",
    ">2. 고유한 단어보다 고유한 토큰의 수가 적기 때문에, 이는 모델의 어휘 크기를 줄여 모델을 더 효율적으로 만듭니다(2장에서 논의됨).\n",
    ">\n",
    ">3. 토큰은 또한 모델이 새로운 단어를 처리하는 데 도움을 줍니다. 예를 들어, \"chatgpting\"이라는 새로 만든 단어는 \"chatgpt\"와 \"ing\"로 나눌 수 있어 모델이 그 구조를 이해할 수 있게 합니다. 토큰은 단어보다 더 적은 단위를 가지면서도 문자보다 더 많은 의미를 유지하도록 균형을 맞춥니다.\n",
    "\n",
    "\n",
    "언어 모델에는 두 가지 주요 유형이 있습니다: **마스킹 언어 모델(masked language model)** 과 **자가 회귀 언어 모델(autoregressive language model)** 입니다.\n",
    "\n",
    "**마스킹 언어 모델(masked language model)**\n",
    "- **마스킹 언어 모델**은 문장에서 누락된 단어를 예측하도록 훈련됩니다. 예를 들어, \"My favorite __ is blue(내가 가장 좋아하는 __은 파란색입니다)\"에서 빈칸 앞뒤의 문맥을 사용해 빈칸에 들어갈 단어를 예측할 수 있습니다. 마스킹 언어 모델의 예로는 BERT(Devlin 외, 2018)가 있습니다. 현재 작성 시점에서 마스킹 언어 모델은 주로 감정 분석이나 텍스트 분류와 같은 작업에 사용됩니다.\n",
    "\n",
    "**자가 회귀 언어 모델(autoregressive language model)**\n",
    "- **자가 회귀 언어 모델**은 이전 단어만 사용하여 시퀀스에서 다음 단어를 예측하도록 훈련됩니다. 예를 들어, \"My favorite color is __ (내가 가장 좋아하는 색은 __입니다)\"에서 다음에 올 단어를 예측합니다. 오늘날 자가 회귀 언어 모델은 텍스트 생성 작업에서 선호되는 모델로, 마스킹 언어 모델보다 훨씬 인기가 많습니다. 이 책에서는 별도로 언급하지 않는 한, 언어 모델은 자가 회귀 모델을 의미합니다.\n",
    "\n",
    "언어 모델의 출력은 개방형입니다. 즉, 언어 모델은 고정된 유한한 어휘를 사용하여 무한한 가능한 출력을 생성할 수 있습니다. 개방형 출력을 생성할 수 있는 모델을 **생성형(generative)** 이라고 하며, 여기에서 **생성형 AI(generative AI)** 라는 용어가 유래되었습니다.\n",
    "\n",
    "언어 모델을 **완성 기계(completion machine)** 로 생각할 수 있습니다. 주어진 텍스트(프롬프트)에 대해 해당 텍스트를 완성하려고 시도합니다. 예를 들어:\n",
    "\n",
    "```\n",
    "Prompt (from user): \"To be or not to be\"\n",
    "Completion (from language model): \", that is the question.\n",
    "```\n",
    "이처럼 간단하게 보이지만, 완성은 매우 강력한 기능입니다. 많은 작업이 완성 작업으로 구성될 수 있기 때문입니다. 예를 들어 번역, 요약, 코딩, 수학 문제 해결 등이 포함됩니다. 프롬프트로 \"How are you in French is... (프랑스어로 'How are you'는...)\"를 주었을 때, 언어 모델은 \"Comment ça va\"로 이를 완성하여 한 언어에서 다른 언어로 효과적으로 번역할 수 있습니다.\n",
    "\n",
    "다음과 같은 프롬프트를 주었을 때:\n",
    "\n",
    "```\n",
    "**질문**: \"이 이메일이 스팸일 가능성이 있나요? 다음은 이메일입니다: <이메일 내용>\"  \n",
    "**답변**:  \n",
    "```\n",
    "언어 모델은 \"Likely spam(스팸일 가능성 높음)\"으로 답변하여, 이를 스팸 분류기로 변환할 수 있습니다.\n",
    "\n",
    "완성이 강력한 기능이긴 하지만, 완성은 대화에 참여하는 것과는 다릅니다. 예를 들어, 사용자가 질문을 하면 모델이 사용자의 질문에 답하지 않고 다른 질문을 추가하여 완성할 수 있습니다. 다음 장의 \"Alignment(정렬)\" 섹션에서는 모델이 사용자 요청에 적절히 응답하도록 만드는 방법을 논의합니다.\n",
    "\n",
    "---\n",
    "\n",
    "**자기 지도 학습(Self-supervision)**\n",
    "\n",
    "언어 모델링은 기계 학습(Machine Learning) 알고리즘의 여러 유형 중 하나일 뿐입니다. 객체 탐지(object detection), 주제 모델링(topic modeling), 추천 시스템(recommender system), 날씨 예측(weather forecasting), 주가 예측(stock price prediction) 등을 위한 모델도 있습니다. 언어 모델이 **스케일링 접근법(scaling approach)** 의 중심이 되었고, ChatGPT의 순간적 인기를 이끈 특별한 점은 무엇일까요?\n",
    "\n",
    "답은 언어 모델은 자기 지도 학습(self-supervision)을 사용하여 훈련될 수 있는 반면, 많은 다른 모델들은 지도 학습(supervision)을 필요로 한다는 것입니다. 자기 지도 학습은 데이터 레이블링 병목현상을 극복하여 모델이 학습할 수 있는 더 큰 데이터셋을 생성하는 데 기여했으며, 결과적으로 모델의 확장이 가능하도록 했습니다. 방법은 다음과 같습니다.\n",
    "\n",
    "**지도 학습(Supervision)** 은 레이블이 지정된 데이터를 사용하여 기계 학습(ML) 알고리즘을 훈련시키는 과정을 의미합니다. 레이블링된 예제는 모델에게 무엇을 해야 하는지를 알려주며, 모델은 이러한 예제로부터 학습하도록 훈련됩니다. 모델이 훈련되고 나면, 새로운 데이터에 이를 적용할 수 있습니다. 예를 들어, 사기 탐지 모델을 훈련하려면 \"사기(fraud)\" 또는 \"비사기(not fraud)\"로 레이블이 지정된 거래 사례를 사용합니다.\n",
    "\n",
    "모델이 이러한 예제에서 학습한 후에는 해당 모델을 사용하여 거래가 사기인지 여부를 예측할 수 있습니다.\n",
    "\n",
    "2010년대 AI 모델의 성공은 지도 학습에 기반을 두고 있습니다. 딥러닝 혁명을 시작한 모델인 **AlexNet(Krizhevsky 외, 2012)** 은 지도 학습 방식으로 훈련되었습니다. 이 모델은 데이터셋 **ImageNet** 에 있는 100만 개 이상의 이미지를 분류하도록 학습되었으며, 각각의 이미지를 \"자동차(car)\", \"풍선(balloon)\", \"원숭이(monkey)\"와 같은 1,000개 카테고리 중 하나로 분류했습니다.\n",
    "\n",
    "지도 학습의 단점은 데이터 레이블링이 비용이 많이 들고 시간이 많이 소요된다는 점입니다. 예를 들어, 한 사람이 이미지를 하나 레이블링하는 데 5센트가 든다면, **ImageNet** 의 100만 개 이미지를 레이블링하는 데만 5만 달러가 필요합니다. 각 이미지를 두 명의 다른 사람이 레이블링하도록 한다면(레이블 품질을 교차 검토하기 위해), 비용이 두 배가 됩니다. 세상에는 1,000개 이상의 객체가 훨씬 많기 때문에, 모델이 더 많은 객체와 작업할 수 있도록 기능을 확장하려면 더 많은 카테고리에 대한 레이블을 추가해야 합니다. 이를 100만 개의 카테고리로 확장하려면 레이블링 비용만으로 5,000만 달러가 필요합니다.\n",
    "\n",
    "일상적인 객체를 레이블링하는 것은 대부분의 사람들이 사전 교육 없이도 할 수 있는 작업이므로 비교적 저렴하게 수행될 수 있습니다. 그러나 모든 레이블링 작업이 그렇게 간단한 것은 아닙니다. 예를 들어, 영어-라틴어 모델을 위한 라틴어 번역을 생성하는 작업은 더 많은 비용이 들며, CT 스캔이 암의 징후를 보이는지 여부를 레이블링하는 것은 천문학적인 비용이 필요합니다.\n",
    "\n",
    "**자기 지도 학습(Self-supervision)** 은 데이터 레이블링 병목현상을 극복하는 데 도움을 줍니다. 수동으로 생성된 레이블을 사용해 모델을 훈련시키는 대신, 자연적으로 발생하는 레이블을 사용하여 모델을 훈련시킵니다. 자기 지도 학습은 비지도 학습과 다릅니다. 비지도 학습에서는 아예 레이블이 필요하지 않습니다.\n",
    "\n",
    "언어 모델링은 자기 지도 학습 방식으로 작동합니다. 텍스트의 모든 시퀀스가 레이블 데이터로 사용될 수 있기 때문입니다. 예를 들어, \"I love street food.\"(나는 길거리 음식을 좋아합니다)라는 문장은 Table 1-1에 표시된 대로 6개의 훈련 샘플을 제공합니다. 여기에서, \\<BOS>와 \\<EOS>를 사용하여 시퀀스의 시작과 끝을 표시합니다. 이러한 마커는 언어 모델이 여러 시퀀스를 처리할 때 필요합니다. 특히 **시퀀스 종료 마커(end-of-sequence marker)** 는 언어 모델이 응답을 끝낼 시점을 파악하는 데 매우 중요합니다.\n",
    "\n",
    "<img src=\"images/tbl_01_01.png\" width=800>\n",
    "\n",
    "대규모 데이터를 활용하면 언어 모델을 확장하여 **대규모 언어 모델(LLM)** 로 만들 수 있습니다. 그러나 **LLM**은 과학적인 용어라고 보기는 어렵습니다. 언어 모델이 얼마나 커야 \"대규모\"라고 간주될 수 있을까요? 오늘날 \"대규모\"로 간주되는 것이 내일은 \"작다\"고 여겨질 수 있습니다.  \n",
    "모델의 크기를 측정하기 위해 일반적으로 **파라미터(parameter)** 의 수를 사용합니다. **모델 파라미터** 란 모델 훈련 과정에서 수정 가능한 값들의 집합을 말합니다. 일반적으로, 항상 그런 것은 아니지만, 모델에 파라미터가 많을수록 원하는 행동을 학습할 수 있는 유연성이 더 커집니다.\n",
    "\n",
    "OpenAI의 첫 번째 GPT 모델이 2018년 6월에 출시되었을 때, 이 모델은 1억 1,700만 개의 파라미터를 가지고 있었으며, 당시에는 \"대규모\"로 간주되었습니다. 하지만 2019년 2월, OpenAI가 15억 개의 파라미터를 가진 GPT-2를 소개했을 때, 1억 1,700만 개는 \"작은 규모\"로 강등되었습니다. 이 책을 집필하는 시점에서 1,000억 개의 파라미터를 가진 모델은 \"대규모\"로 간주됩니다. 그러나 언젠가 이 크기도 \"작다\"고 여겨질 날이 올지도 모릅니다.\n",
    "\n",
    "다음 섹션으로 넘어가기 전에, 일반적으로 당연하게 여겨지는 질문 하나를 다루고자 합니다: 왜 더 큰 모델이 더 많은 데이터를 필요로 할까요? 더 큰 모델은 학습할 수 있는 용량이 더 크기 때문에, 성능을 극대화하기 위해 더 많은 훈련 데이터가 필요합니다. 큰 모델을 작은 데이터셋에서 훈련시킬 수도 있지만, 이는 컴퓨팅 리소스의 낭비일 것입니다. 더 작은 모델을 사용했다면 동일하거나 더 나은 결과를 해당 데이터셋에서 얻을 수 있었을 것입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대규모 언어 모델에서 기본 모델로\n",
    "\n",
    "언어 모델은 놀라운 작업을 수행할 수 있지만, 텍스트에 국한됩니다. 인간은 언어뿐만 아니라 시각, 청각, 촉각 등을 통해 세상을 인식합니다. 텍스트를 넘어선 데이터를 처리할 수 있는 능력은 AI가 현실 세계에서 작동하는 데 필수적입니다.\n",
    "\n",
    "이러한 이유로 언어 모델은 더 많은 데이터 모달리티를 통합하도록 확장되고 있습니다. 예를 들어, **GPT-4V**는 이미지와 텍스트를 이해할 수 있고, **Gemini**는 비디오뿐만 아니라 이미지와 텍스트도 이해할 수 있습니다. 어떤 모델은 3D 자산, 단백질 구조 등도 이해합니다. 언어 모델에 더 많은 데이터 모드를 통합하면 모델은 더욱 강력해집니다. **OpenAI**는 2023년 **GPT-4V 시스템 카드**에서 \"이미지 입력과 같은 추가 모달리티를 LLM에 통합하는 것은 AI 연구와 개발에서 중요한 최전선으로 간주된다\"고 언급했습니다.\n",
    "\n",
    "많은 사람들이 여전히 **Gemini**와 **GPT-4V**를 LLM으로 부르지만, 이 모델들은 **기본 모델(foundation models)** 로 더 잘 특징지어집니다. **foundation(기본)** 이라는 단어는 이러한 모델이 AI 애플리케이션에서 가지는 중요성과 다양한 요구를 충족시키기 위해 구축될 수 있는 가능성을 모두 나타냅니다.\n",
    "\n",
    "기본 모델은 전통적인 AI 연구 구조에서 획기적인 발전을 의미합니다. 오랜 시간 동안 AI 연구는 데이터 모달리티별로 나뉘어 있었습니다. 자연어 처리(NLP)는 텍스트만 다루고, 컴퓨터 비전은 시각 정보만 다룹니다. 텍스트 전용 모델은 번역과 스팸 탐지 같은 작업에 사용할 수 있습니다. 이미지 전용 모델은 객체 탐지와 이미지 분류에 사용할 수 있습니다. 오디오 전용 모델은 음성 인식(음성-텍스트 변환, STT) 및 음성 합성(텍스트-음성 변환, TTS)을 처리할 수 있습니다.\n",
    "\n",
    "여러 데이터 모드를 처리할 수 있는 모델은 **멀티모달 모델(multimodal model)** 이라고도 합니다. 생성형 멀티모달 모델은 **대규모 멀티모달 모델(LMM)** 이라고도 불립니다. 텍스트 전용 토큰을 기반으로 다음 토큰을 생성하는 언어 모델과 달리, LMM은 텍스트와 이미지 토큰 모두를 기반으로 하거나 모델이 지원하는 모든 모달리티를 기반으로 다음 토큰을 생성합니다. 이는 **Figure 1-2** 에 나타나 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_02.png\" width=800>\n",
    "\n",
    "언어 모델과 마찬가지로, 멀티모달 모델도 확장을 위해 데이터가 필요합니다. 자기 지도 학습(self-supervision)은 멀티모달 모델에서도 작동합니다. 예를 들어, OpenAI는 **자연어 지도 학습(natural language supervision)** 이라는 자기 지도 학습 변형을 사용하여 언어-이미지 모델 **CLIP** (OpenAI, 2021)을 훈련시켰습니다. 각 이미지를 수동으로 레이블링하는 대신, 인터넷에서 함께 등장하는 (이미지, 텍스트) 쌍을 찾았습니다. 이를 통해 **4억 개의 (이미지, 텍스트) 쌍** 데이터셋을 생성할 수 있었는데, 이는 ImageNet보다 400배 큰 크기였으며 수동 레이블링 비용 없이 이루어졌습니다. 이 데이터셋 덕분에 CLIP은 재훈련 없이도 여러 이미지 분류 작업을 일반화할 수 있는 최초의 모델이 되었습니다.\n",
    "\n",
    ">**참고**\n",
    ">\n",
    ">이 책에서는 대규모 언어 모델과 대규모 멀티모달 모델을 모두 기본 모델이라는 용어로 지칭합니다.\n",
    "\n",
    "\n",
    "CLIP이 생성형 모델은 아니라는 점에 유의하세요. CLIP은 개방형 출력을 생성하도록 훈련된 것이 아닙니다. CLIP은 **임베딩 모델(embedding model)** 로, 텍스트와 이미지의 **공동 임베딩(joint embedding)** 을 생성하도록 훈련되었습니다. 임베딩이 낯설다면, 이를 원본 데이터의 의미를 포착하려는 벡터로 생각할 수 있습니다. 임베딩에 대한 자세한 내용은 3장에서 논의될 것입니다. CLIP과 같은 멀티모달 임베딩 모델은 Flamingo, LLaVA, Gemini와 같은 **생성형 멀티모달 모델** 의 핵심입니다. Flamingo는 멀티모달 입력의 임베딩을 생성하기 위해 CLIP을 사용하며, 이를 바탕으로 출력을 생성합니다.\n",
    "\n",
    "기본 모델은 작업 특정 모델(task-specific model)에서 범용 모델(general-purpose model)로의 전환을 나타냅니다. 특정 작업을 해결하기 위해 모델을 구축하면, 해당 작업에서 모델의 성능을 최적화하는 데 자원을 집중할 수 있습니다. 그러나 그 결과로, 그 모델은 다른 작업에는 전혀 작동하지 않을 수 있습니다. 기본 모델은 그 크기와 훈련 방식 덕분에 광범위한 작업을 수행할 수 있습니다. 기본 상태에서도 범용 모델은 많은 작업에서 비교적 잘 작동할 수 있지만, 특정 작업의 성능을 극대화하기 위해 자주 **\"조정(tweaked)\"** 이 필요합니다.\n",
    "\n",
    "예를 들어, 의류 소매업체로서 웹사이트에 매력적인 제품 설명을 생성하는 애플리케이션을 만들고 싶다고 가정해 봅시다. 기본 모델에서 생성된 설명은 정확할 수 있지만, 브랜드의 톤이나 메시지를 반영하지 못할 수 있습니다. 모델이 어떤 데이터로 훈련되었는지에 따라 설명이 마케팅 문구와 진부한 표현으로 가득 차 있을 수도 있습니다.\n",
    "\n",
    "이를 해결하기 위해, 원하는 제품 설명의 유형에 대해 모델에 상세한 지침을 제공할 수 있습니다. 이를 **프롬프트 엔지니어링(prompt engineering)** 이라고 합니다. 지침에는 훌륭한 설명의 예시를 포함시킬 수 있습니다. 이 기술은 **Few-shot 학습(few-shot learning)** 이라고 불립니다. 또한, 모델을 고객 리뷰 데이터베이스에 연결하여 이러한 리뷰를 활용해 더 나은 설명을 생성하도록 할 수 있습니다. 데이터베이스를 사용해 모델의 지침을 보완하는 방식을 **검색 증강 생성(retrieval augmented generation, RAG)** 이라고 합니다. 모델을 **미세 조정(finetune)** 하거나 추가적으로 훈련시킬 수도 있습니다. 이는 모델을 필요에 맞게 조정할 수 있는 AI 엔지니어링 기술 중 일부일 뿐이며, 이 책에서는 이러한 기술을 자세히 다룰 것입니다.\n",
    "\n",
    "**기본 모델**이 없다면, 특정 작업에 대해 처음부터 모델을 훈련해야 할 것입니다. 자체 모델을 사용하는 것은 범용 모델을 사용하는 것보다 더 많은 제어권을 제공합니다. 그러나 모델의 크기가 작다면 기존 대규모 모델만큼 성능이 뛰어나지 않을 수 있습니다. 모델이 크다면 처음부터 훈련시키는 데는 기존의 강력한 모델을 적응시키는 것보다 훨씬 더 많은 시간과 데이터가 필요합니다. 예를 들어, 처음부터 훈련하려면 **100만 개의 훈련 샘플과 6개월** 이 걸리는 반면, 기존 모델을 적응시키는 데는 **10개의 훈련 샘플과 주말** 만 필요할 수 있습니다. 자체 모델을 구축할지 아니면 기존 모델을 활용할지는 각 팀이 스스로 답해야 하는 고전적인 **구축 또는 구매(buy-or-build)** 질문입니다. 이 책 전반에서의 논의는 이 결정을 내리는 데 도움을 줄 것입니다. 그러나 일반적으로 **기본 모델** 은 AI 애플리케이션 개발 비용을 절감하고 시장 출시 시간을 단축시킵니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 모델에서 AI 엔지니어링으로\n",
    "\n",
    "**AI 엔지니어링(AI engineering)** 은 기본 모델을 기반으로 애플리케이션을 구축하는 과정을 의미합니다. 사람들은 10년 넘게 **ML 엔지니어링(ML engineering)** 또는 **MLOps(ML operations)** 라는 이름으로 AI 애플리케이션을 개발해 왔습니다. 그렇다면 왜 지금 AI 엔지니어링에 대해 이야기할까요?\n",
    "\n",
    "전통적인 ML 엔지니어링이 ML 모델 개발에서 시작된다면, AI 엔지니어링은 기존 ML 모델에서 시작됩니다. AI 엔지니어링의 촉매제는 강력한 **기본 모델**의 가용성과 접근성입니다. 이것은 AI 엔지니어링이 하나의 분야로서 빠르게 성장하기 위한 이상적인 조건을 만드는 세 가지 요소로 이어집니다.\n",
    "\n",
    "**요소 1: AI 기능의 발전**\n",
    "- 기본 모델은 단순히 기존 작업을 더 잘 수행할 수 있다는 이유로만 강력한 것이 아닙니다. 이들은 개방형 응답을 생성할 수 있기 때문에 더 많은 작업을 수행할 수 있습니다. 이전에는 불가능하다고 여겨졌던 애플리케이션이 이제 가능해졌고, 이전에 생각지도 못했던 애플리케이션들이 등장하고 있습니다. 이는 AI를 삶의 더 많은 측면에서 유용하게 만들며, 사용자 기반과 AI 애플리케이션 수요를 크게 증가시킵니다.\n",
    "- AI는 이제 인간과 동일한 수준으로, 때로는 더 나은 수준으로 글을 작성할 수 있습니다. AI는 커뮤니케이션이 필요한 모든 작업을 자동화하거나 부분적으로 자동화할 수 있으며, 사실상 거의 모든 것에 해당됩니다. AI는 이메일 작성, 고객 요청 응답, 복잡한 계약 요약 등에 사용됩니다. 오늘날 컴퓨터와 인터넷 연결만으로도 사용자는 맞춤화된 고품질 이미지와 비디오를 생성해 디자인을 돕거나, 마케팅 자료를 생성하거나, 전문가 프로필 사진을 제작하거나, 예술적 개념을 시각화하거나, 책을 삽화로 채우는 등의 작업을 즉시 수행할 수 있습니다. AI는 또한 훈련 데이터를 합성하고 코드를 작성하는 데도 사용될 수 있으며, 이는 미래에 더욱 강력한 모델을 훈련시키는 데 도움을 줄 것입니다.\n",
    "\n",
    "**요소 2: AI 투자 증가**\n",
    "- 두 번째 요소는 벤처 캐피탈과 기업 모두에서 AI에 대한 투자가 급증한 것입니다. AI 애플리케이션 개발 비용이 저렴해지고 시장 출시 속도가 빨라짐에 따라, AI에 대한 투자 수익률은 훨씬 더 매력적으로 변했습니다. **Scribd**의 응용 연구 선임 매니저인 **Matt Ross**는 2022년 4월부터 2023년 4월까지 그의 사용 사례에서 AI 비용이 두 단계 감소했다고 말했습니다.\n",
    "- **Goldman Sachs Research**는 AI에 대한 투자가 미국에서 1,000억 달러에, 전 세계적으로 2025년까지 2,000억 달러에 이를 것으로 추정했습니다. 기업들은 AI를 제품과 프로세스에 통합하기 위해 서둘렀습니다. AI는 종종 경쟁 우위로 언급됩니다. **FactSheet**에 따르면, 2023년 2분기에 S&P 500 기업의 4분의 1이 실적 발표에서 AI를 언급했으며, 이는 전년도 같은 기간보다 3배 증가한 수치입니다. **Figure 1-3**은 2018년부터 2023년까지 S&P 500 기업이 실적 발표에서 AI를 언급한 횟수를 보여줍니다.\n",
    "- **WallStreetZen**에 따르면, 실적 발표에서 AI를 언급한 기업들은 그렇지 않은 기업들보다 평균 주가 상승률이 높았습니다: **4.6%** 상승, 반면 AI를 언급하지 않은 기업은 **2.4%** 상승에 그쳤습니다. 이것이 AI로 인해 이러한 기업들이 더 성공적이 되었는지, 아니면 새로운 기술에 빠르게 적응하는 기업이 성공적인지에 대한 인과 관계인지, 단순 상관 관계인지는 불분명합니다.\n",
    "\n",
    "<img src=\"images/fig_01_03.png\" width=800>\n",
    "\n",
    "**요소 3: AI 애플리케이션 구축의 낮은 진입 장벽**\n",
    "- **OpenAI** 및 기타 모델 제공업체들이 대중화한 **서비스형 모델(model-as-a-service)** 접근 방식은 사람들이 AI를 애플리케이션에 더 쉽게 활용할 수 있도록 만듭니다. 이러한 API가 없다면, AI 모델을 사용하려면 이를 호스팅하고 최적화할 인프라가 필요합니다. 그러나 **모델 API**를 통해 단일 API 호출로 이러한 모델을 애플리케이션에 통합할 수 있습니다.\n",
    "- 또한, AI는 코드 작성 능력을 입증하며, 소프트웨어 엔지니어링 배경이 없는 사람들도 자신의 아이디어를 빠르게 코드로 전환하여 사용자에게 제공할 수 있도록 도와줍니다. 게다가, 이러한 모델은 프로그래밍 언어를 사용하는 대신 **프롬프트 엔지니어링(prompt engineering)** 을 통해 일반 영어로 작업할 수 있습니다. 이제 **누구나, 정말로 누구나** AI 애플리케이션을 개발할 수 있습니다.\n",
    "\n",
    "2022년 9월 한 인터뷰에서 OpenAI의 CEO **Sam Altman**은 강력하고 범용적인 기본 모델을 개발하는 팀은 소수에 불과할 것이라고 예측했습니다. 이러한 과정은 **Google, Meta, Microsoft, Baidu, Tencent** 와 같은 대기업, **일본, UAE** 와 같은 정부, 그리고 **OpenAI, Mistral, Adept** 와 같은 야심차고 자금이 잘 지원된 스타트업들만이 가능하다고 말했습니다. 대다수에게 가장 큰 기회는 이러한 모델을 특정 애플리케이션에 맞게 조정하는 데 있을 것이라고 덧붙였습니다. 인터뷰 두 달 후 **ChatGPT**가 출시되면서 그의 예측은 현실이 되었습니다.\n",
    "\n",
    "AI 엔지니어링은 아직 초기 단계이지만 빠르게 성장하는 분야로 입증되었습니다. AI 엔지니어링 도구들은 GitHub에서 기존의 어떤 소프트웨어 엔지니어링 도구들보다도 빠르게 성장하고 있으며, **React**와 **Vue**와 같은 가장 인기 있는 웹 개발 도구들보다도 더 빠르게 성장하고 있습니다. 출시된 지 1년도 안 되어 **AutoGPT**는 GitHub에서 **Bitcoin**보다 두 배 많은 별(Stars)을 획득했습니다(Figure 1-4 참조). 2023년 8월 **LinkedIn** 설문조사에 따르면, \"Generative AI,\" \"ChatGPT,\" \"Prompt Engineering,\" \"Prompt Crafting\"과 같은 용어를 프로필에 추가하는 전문가 수가 매달 평균 **75%** 증가했다고 합니다. **ComputerWorld**는 \"AI에게 행동 방식을 가르치는 것이 가장 빠르게 성장하는 경력 기술\"이라고 선언했습니다.\n",
    "\n",
    "<img src=\"images/fig_01_04.png\" width=800>\n",
    "\n",
    "Star History (스타 기록)\n",
    "GitHub 별 수를 기준으로 **AutoGPT**는 **Bitcoin**, **React**, **Vue**보다 훨씬 빠르게 성장하고 있습니다(Figure 1-4 참조).\n",
    "2023년, 전 세계 웹 개발자 수는 약 **1,900만 명**으로 추정되었습니다. AI 엔지니어링의 성장 속도를 고려할 때, AI 엔지니어 수가 곧 이를 능가할 가능성이 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "**왜 AI 엔지니어링이라는 용어를 선택했는가?**\n",
    "\n",
    "기본 모델을 기반으로 애플리케이션을 구축하는 과정을 설명하기 위해 사용되는 다른 용어들도 많습니다. 예를 들어, ML 엔지니어링(ML engineering), MLOps, AIOps, LLMOps 등이 있습니다.\n",
    "\n",
    "저는 **ML 엔지니어링** 이라는 용어를 선택하지 않았습니다. 이 장의 후반부에서 논의될 \"AI 엔지니어링 vs. ML 엔지니어링\" 섹션에서 다루듯이, 기본 모델을 다루는 데는 전통적인 ML 모델과는 다른 여러 측면이 있기 때문입니다.\n",
    "\n",
    "저는 \"Ops\"로 끝나는 모든 용어들 대신 **AI 엔지니어링** 을 선택했습니다. 그 이유는, 이 과정에는 많은 운영적 요소들이 포함되어 있지만, 초점은 기본 모델을 조정하고(엔지니어링) 원하는 대로 작동하도록 만드는 데 있기 때문입니다.\n",
    "\n",
    "마지막 이유로, 기본 모델을 기반으로 애플리케이션을 개발 중인 20명을 대상으로 어떤 용어를 사용해 자신들의 작업을 설명할지 설문 조사했는데, 응답자 대부분이 **AI 엔지니어링** 을 선호했습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **기반 모델의 사용 사례**\n",
    "\n",
    "AI 애플리케이션을 아직 개발하지 않고 있다면, 이전 섹션을 통해 지금이 이를 시작하기 좋은 시기라는 것을 확신했을 것입니다. AI 애플리케이션 계획이 이미 있다면, \"AI 애플리케이션 계획하기\"로 바로 이동할 수 있습니다. 영감을 얻고 싶다면, 이 섹션에서는 다양한 산업 분야의 유망한 사용 사례를 다룹니다.\n",
    "\n",
    "기반 모델로 구축할 수 있는 잠재적인 애플리케이션의 수는 끝이 없어 보입니다. 떠올릴 수 있는 모든 사용 사례가 있다면, 이를 위한 AI가 이미 있을 가능성이 큽니다. **AI의 모든 잠재적 사용 사례를 다루는 것은 불가능합니다.**\n",
    "\n",
    "이러한 사용 사례를 분류하려고 시도하는 것조차 어렵습니다. 다양한 서비스가 서로 다른 분류를 사용하기 때문입니다. 예를 들어, **Amazon Web Services(AWS)** 는 엔터프라이즈 생성형 AI 사용 사례를 세 가지 범주로 분류했습니다: 고객 경험, 직원 생산성, 그리고 프로세스 최적화입니다. 한편, 2024년 **O’Reilly** 설문조사에서는 이러한 사용 사례를 여덟 가지 범주로 분류했습니다: 프로그래밍, 데이터 분석, 고객 지원, 마케팅 카피, 기타 카피, 연구, 웹 디자인, 아트 등.\n",
    "\n",
    "일부 조직, 예를 들어 **Deloitte**,는 비용 절감, 프로세스 효율성, 성장, 혁신 가속화 등과 같은 가치를 포착하는 사용 사례로 이를 분류했습니다. **Gartner**는 **비즈니스 연속성**이라는 범주를 두고, 조직이 AI를 채택하지 않으면 사업을 지속할 수 없을 수도 있다고 지적했습니다. 2023년 Gartner 설문조사에 따르면, 응답자의 7%가 생성형 AI를 채택하는 동기를 비즈니스 연속성으로 언급했습니다.\n",
    "\n",
    "**Eloundou et al. (2023)** 는 다양한 직업이 AI에 노출되는 정도에 대해 탁월한 연구를 수행했습니다. 그들은 AI와 AI 기반 소프트웨어가 작업 시간의 최소 50%를 단축할 수 있다면, 해당 작업이 노출되었다고 정의했습니다. 80%의 노출도를 가진 직업은 해당 직업 작업의 80%가 노출되었음을 의미합니다. 연구에 따르면, **100% 또는 거의 100% 노출**을 가진 직업에는 **통역사 및 번역가, 세무사, 웹 디자이너, 작가** 등이 포함됩니다. Table 1-2는 이러한 예시를 보여줍니다. 놀랍게도, AI에 전혀 노출되지 않은 직업으로는 **요리사, 석공, 운동선수** 등이 포함됩니다. 이 연구는 AI가 적합한 사용 사례에 대해 좋은 통찰을 제공합니다.\n",
    "\n",
    "**Table 1-2. 인간이 주석을 단, AI에 가장 높은 노출을 가진 직업**\n",
    "α는 **AI 모델에 직접 노출**되는 경우를, β와 ζ는 **AI 기반 소프트웨어에 노출**되는 경우를 나타냅니다.  \n",
    "**출처: Eloundou et al. (2023)**  \n",
    "\n",
    "| 그룹        | 가장 높은 노출을 가진 직업                 | 노출 비율 (%)  |\n",
    "|-------------|-----------------------------------------|----------------|\n",
    "| **Human α** | 통역사 및 번역가                        | 76.5           |\n",
    "|             | 설문조사 연구원                         | 75.0           |\n",
    "|             | 시인, 작사가, 창작 작가                  | 68.8           |\n",
    "|             | 동물 과학자                             | 66.7           |\n",
    "|             | 공공 관계 전문가                        | 66.7           |\n",
    "| **Human β** | 설문조사 연구원                         | 84.4           |\n",
    "|             | 작가 및 저자                            | 82.5           |\n",
    "|             | 통역사 및 번역가                        | 82.4           |\n",
    "|             | 공공 관계 전문가                        | 80.6           |\n",
    "|             | 애니메이션 과학자                       | 77.8           |\n",
    "| **Human ζ** | 수학자                                 | 100.0          |\n",
    "|             | 세무사                                 | 100.0          |\n",
    "|             | 금융 정량 분석가                        | 100.0          |\n",
    "|             | 작가 및 저자                            | 100.0          |\n",
    "|             | 웹 및 디지털 인터페이스 디자이너         | 100.0          |\n",
    "\n",
    "*연구에 따르면 인간은 15개의 직업을 \"완전히 노출됨\"으로 분류했습니다.*\n",
    "\n",
    "사용 사례를 분석할 때, 저는 엔터프라이즈 애플리케이션과 소비자 애플리케이션 모두를 검토했습니다. 엔터프라이즈 사용 사례를 이해하기 위해, 저는 50개 기업의 AI 전략에 대해 인터뷰를 진행했으며, 100건 이상의 사례 연구를 검토했습니다. 소비자 애플리케이션을 이해하기 위해, 저는 GitHub에서 별 500개 이상을 받은 205개의 오픈 소스 AI 애플리케이션을 조사했습니다. 저는 이러한 애플리케이션을 Table 1-3에서 보이는 여덟 가지 그룹으로 분류했습니다. 여기 제공된 제한된 목록은 참고 자료로 가장 적합합니다. 2장에서 기반 모델을 구축하는 방법과 3장에서 이를 평가하는 방법을 배우면서, 기반 모델이 사용할 수 있는 사용 사례와 적합한 사용 사례에 대해 더 명확한 그림을 그릴 수 있을 것입니다.\n",
    "\n",
    "**Table 1-3. 소비자 및 엔터프라이즈 애플리케이션에서의 일반적인 생성형 AI 사용 사례**\n",
    "\n",
    "| **카테고리**               | **소비자 사용 사례 예시**                    | **엔터프라이즈 사용 사례 예시**              |\n",
    "|----------------------------|--------------------------------------------|-------------------------------------------|\n",
    "| **코딩(Coding)**           | 코딩                                       | 코딩                                      |\n",
    "| **이미지 및 비디오 제작**   | 사진 및 비디오 편집, 디자인                 | 프레젠테이션, 광고 생성                   |\n",
    "| **글쓰기(Writing)**         | 이메일, 소셜 미디어 및 블로그 게시물         | 카피라이팅, 검색 엔진 최적화(SEO), 보고서, 메모, 설계 문서 |\n",
    "| **교육(Education)**         | 과외, 에세이 채점                           | 직원 온보딩, 직원 재교육 및 기술 향상      |\n",
    "| **대화형 봇**               | 일반 채팅봇, AI 동반자                      | 고객 지원, 제품 보조 도구                 |\n",
    "| **정보 집계**               | 요약, 문서와 대화하기                       | 요약, 시장 조사                           |\n",
    "| **데이터 조직화**           | 이미지 검색, Memex                         | 지식 관리, 문서 처리                      |\n",
    "| **워크플로 자동화**         | 여행 계획, 이벤트 계획                      | 데이터 추출, 입력, 주석 작성, 리드 생성    |\n",
    "\n",
    "\n",
    "기본 모델은 범용적이기 때문에, 이를 기반으로 구축된 애플리케이션은 여러 용도로 사용될 수 있습니다. 이는 하나의 애플리케이션이 여러 카테고리에 속할 수 있음을 의미합니다. 예를 들어, 봇은 동반자 역할을 하면서 정보를 집계할 수 있습니다. 또 다른 애플리케이션은 PDF에서 구조화된 데이터를 추출하고 해당 PDF에 대한 질문에 답할 수 있습니다.\n",
    "\n",
    "**Figure 1-5**는 205개의 오픈 소스 애플리케이션에 대한 이러한 사용 사례 분포를 보여줍니다. 교육, 데이터 조직화, 글쓰기와 관련된 사용 사례의 비율이 낮다는 것은 이러한 사용 사례가 인기가 없다는 것을 의미하지는 않습니다. 이는 단지 이러한 애플리케이션들이 오픈 소스가 아니라는 것을 의미합니다. 이러한 애플리케이션의 개발자들은 이를 기업용 사용 사례에 더 적합하다고 생각할 수도 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_05.png\" width=800>\n",
    "\n",
    "기업 환경에서는 일반적으로 위험이 낮은 애플리케이션이 선호됩니다. 예를 들어, **2024년 a16z 보고서** 에 따르면, 기업은 외부 고객 지원 챗봇과 같은 외부 지향 애플리케이션보다 내부 지식 관리와 같은 내부 지향 애플리케이션을 더 빠르게 배포한다고 합니다(Figure 1-6 참조). 내부 지향 애플리케이션은 데이터 프라이버시, 규정 준수, 잠재적 재앙적 실패와 관련된 위험을 최소화하면서 기업이 AI 엔지니어링에 대한 전문성을 개발하도록 돕습니다. 마찬가지로, 기본 모델은 개방형이며 어떤 작업에도 사용할 수 있지만, 이를 기반으로 구축된 많은 애플리케이션은 여전히 **종료형(close-ended)** 입니다. 예를 들어 분류 작업은 평가하기가 더 쉬워서 위험을 추정하기가 더 쉽습니다.\n",
    "\n",
    "<img src=\"images/fig_01_06.png\" width=800>\n",
    "\n",
    "수백 개의 AI 애플리케이션을 본 후에도 매주 저를 놀라게 하는 새로운 애플리케이션을 발견하곤 합니다. 인터넷 초창기 시절, 인터넷에서 지배적인 사용 사례가 소셜 미디어가 될 것이라고 예측한 사람은 거의 없었습니다. AI를 최대한 활용하는 법을 배워나가면서, 결국 지배적인 사용 사례가 될 것이 무엇인지는 우리를 놀라게 할 수 있습니다. 다행히도, 그 놀라움은 긍정적인 것이 될 가능성이 큽니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **코딩(Coding)**\n",
    "\n",
    "다수의 생성형 AI 설문 조사에서 코딩은 단연코 가장 인기 있는 사용 사례로 꼽혔습니다. AI 코딩 도구는 AI가 코딩을 잘 수행할 수 있고, 초기 AI 엔지니어들이 주로 코딩에 노출된 사람들이라는 이유로 인기가 높습니다.\n",
    "\n",
    "생산 단계에서 기반 모델의 초기 성공 사례 중 하나는 코드 완성 도구인 **GitHub Copilot**입니다. 이 도구는 출시 후 2년 만에 **연간 반복 수익(Annual Recurring Revenue)이 1억 달러를 돌파**했습니다. 현재 시점에서, AI 기반 코딩 스타트업은 수억 달러를 조달했습니다. 예를 들어, **Magic**은 2024년 8월에 3억 2천만 달러를, **AnySphere**는 6천만 달러를 조달했습니다. 오픈 소스 코딩 도구인 **gpt-engineer**와 **screenshot-to-code**는 모두 GitHub에서 1년 이내에 50,000개의 별을 받았으며, 그 외에도 수많은 도구가 빠르게 등장하고 있습니다.\n",
    "\n",
    "일반적인 코딩을 지원하는 도구 외에도, 특정 코딩 작업을 전문으로 하는 많은 도구가 있습니다. 다음은 이러한 작업의 예시입니다:\n",
    "\n",
    "- **웹 페이지 및 PDF에서 구조화된 데이터를 추출** (예: AgentGPT)  \n",
    "- **영어를 코드로 변환** (예: DB-GPT, SQL Chat, PandasAI)  \n",
    "- **디자인이나 스크린샷을 기반으로 해당 이미지를 웹사이트로 변환하는 코드 생성** (예: screenshot-to-code, draw-a-ui)  \n",
    "- **프로그래밍 언어나 프레임워크 간 변환** (예: GPT-Migrate, AI Code Translator)  \n",
    "- **문서 작성** (예: Autodoc)  \n",
    "- **테스트 생성** (예: PentestGPT)  \n",
    "- **커밋 메시지 생성** (예: AI Commits)  \n",
    "\n",
    "AI가 소프트웨어 엔지니어링 작업을 많이 수행할 수 있다는 것은 분명합니다. 문제는 AI가 소프트웨어 엔지니어링을 완전히 자동화할 수 있는가입니다. 스펙트럼의 한쪽 끝에는 **엔비디아(NVIDIA)** 의 CEO **Jensen Huang**처럼 AI가 인간 소프트웨어 엔지니어를 완전히 대체할 것이며, \"아이들에게 코딩을 배워야 한다고 말하는 것을 그만둬야 한다\"고 주장하는 사람들이 있습니다. 반면, 다른 한쪽 끝에는 기술적, 감정적 이유로 자신들이 AI에 의해 대체되지 않을 것이라고 확신하는 많은 소프트웨어 엔지니어들이 있습니다(사람들은 자신이 대체될 수 있다는 사실을 인정하고 싶어하지 않기 때문입니다).\n",
    "\n",
    "소프트웨어 엔지니어링 작업에는 여러 유형이 있습니다. AI는 특정 작업에서 다른 작업보다 더 뛰어난 성능을 발휘합니다. **맥킨지(McKinsey)** 연구에 따르면, AI는 문서화 작업에서 개발자의 생산성을 두 배로 향상시킬 수 있으며, 코드 생성 및 코드 리팩토링 작업에서는 생산성을 25~50% 더 높일 수 있습니다. 반면, **Figure 1-7**에 나타나 있듯이, 매우 복잡한 작업에서는 최소한의 생산성 향상만 관찰되었습니다. AI 코딩 도구를 개발하는 개발자들과의 대화에서, 많은 이들이 AI가 백엔드 개발보다 프론트엔드 개발에서 훨씬 더 우수한 성능을 발휘한다는 것을 알게 되었다고 말했습니다.\n",
    "\n",
    "<img src=\"images/fig_01_07.png\" width=800>\n",
    " \n",
    "AI가 소프트웨어 엔지니어를 대체할지 여부와 관계없이, AI는 분명히 그들의 생산성을 향상시킬 수 있습니다. 이는 기업이 더 적은 수의 엔지니어로도 더 많은 일을 해낼 수 있다는 것을 의미합니다. AI는 또한 아웃소싱 산업을 교란시킬 수 있는데, 아웃소싱되는 작업들은 주로 기업의 핵심 비즈니스 외의 더 단순한 작업들이기 때문입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **이미지 및 비디오 제작**\n",
    "\n",
    "그 확률적 특성 덕분에, 2장에서 더 자세히 논의되겠지만, AI는 창의적인 작업에 매우 적합합니다. 가장 성공적인 AI 스타트업 중 일부는 창의적 애플리케이션으로, 이미지 생성용 **Midjourney**, 사진 편집용 **Adobe Firefly**, 비디오 생성용 **Runway**와 **Pika Labs** 등이 있습니다. 2023년 말 기준, 출시 1년 반 만에 **Midjourney**는 연간 반복 매출이 **2억 달러**를 넘겼습니다. 2023년 12월 기준, Apple App Store의 **그래픽 및 디자인** 무료 앱 상위 10개 중 절반이 이름에 \"AI\"를 포함하고 있었습니다. 앞으로는 그래픽 및 디자인 앱이 기본적으로 AI를 통합하게 되어, 이름에 \"AI\"라는 단어가 더 이상 필요하지 않을 것이라 예상됩니다.\n",
    "\n",
    "AI를 사용하여 **소셜 미디어용 프로필 사진**을 생성하는 것이 이제 흔한 일이 되었습니다. LinkedIn에서 TikTok까지 다양한 플랫폼에서 사용됩니다. 많은 구직자들은 AI로 생성된 프로필 사진이 자신을 더 잘 표현하고, **취업 가능성을 높이는 데** 도움이 된다고 믿고 있습니다. AI 생성 프로필 사진에 대한 인식도 크게 변했습니다. 2019년에는 Facebook이 **AI로 생성된 프로필 사진을 사용하는 계정을 안전상의 이유로 금지**했으나, 2023년에는 많은 소셜 미디어 앱이 사용자가 AI를 이용해 프로필 사진을 생성할 수 있는 도구를 제공하고 있습니다.\n",
    "\n",
    "기업의 경우, 광고 및 마케팅 분야에서 AI를 빠르게 도입하고 있습니다. AI는 프로모션 이미지와 비디오를 직접 생성하는 데 사용될 수 있습니다. 이를 통해 아이디어를 브레인스토밍하거나, 인간 전문가가 개선할 수 있도록 초안을 생성할 수 있습니다. 또한, 여러 광고를 생성하고 어떤 광고가 청중에게 가장 효과적인지 테스트할 수 있습니다. AI는 계절과 지역에 따라 광고의 다양한 변형을 생성할 수 있습니다. 예를 들어, 가을에는 잎 색상을 변경하거나, 겨울에는 땅에 눈을 추가하는 등의 작업이 가능합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **글쓰기 (Writing)**\n",
    "\n",
    "AI는 오랜 시간 동안 글쓰기를 지원하는 데 사용되었습니다. 스마트폰을 사용한다면 AI로 구동되는 자동 수정 및 자동 완성을 익히 알고 있을 것입니다. 글쓰기는 AI에 이상적인 애플리케이션입니다. 우리가 글을 자주 쓰고, 때로는 다소 지루하며, 실수에 대한 관용도가 높기 때문입니다. 모델이 마음에 들지 않는 제안을 하면 그냥 무시하면 됩니다.\n",
    "\n",
    "LLM(대규모 언어 모델)이 글쓰기에 능숙한 것은 이들이 텍스트 완성을 위해 훈련되었다는 점에서 놀랍지 않습니다. ChatGPT의 글쓰기에 대한 영향을 연구하기 위해 MIT 연구(Noy and Zhang, 2023)는 453명의 대학 교육을 받은 전문가들에게 직업별 글쓰기 과제를 할당하고 절반은 ChatGPT에 노출시켰습니다. 결과에 따르면 ChatGPT에 노출된 참가자들의 작업 시간은 평균 40% 단축되고 출력 품질은 18% 향상되었습니다. ChatGPT는 작업자 간 출력 품질 격차를 줄이는 데 도움이 되어 글쓰기에 대한 성향이 낮은 사람들에게 더 유용한 도구임을 보여줍니다. 실험 동안 ChatGPT를 사용한 작업자는 2주 후 실제 업무에서 ChatGPT를 사용하는 경우가 2배, 2개월 후에는 1.6배 더 많았습니다.\n",
    "\n",
    "소비자 입장에서, 사용 사례는 명확합니다. 많은 사람들이 AI를 사용해 더 나은 소통을 합니다. 화가 난 이메일을 AI에게 부탁해 부드럽게 바꿀 수 있습니다. 간단한 포인트를 주면 완전한 문단으로 돌려받을 수 있습니다. 몇몇 사람들은 중요한 이메일을 보내기 전에 AI에게 먼저 개선을 요청한다고 말합니다.\n",
    "\n",
    "학생들은 에세이를 작성하기 위해 AI를 사용합니다. 작가들은 책을 쓰기 위해 AI를 사용합니다. 이미 여러 스타트업이 AI를 이용해 아동용, 팬픽션, 로맨스, 판타지 책을 제작합니다. 전통적인 책과는 달리, AI로 생성된 책은 독자의 선호에 따라 플롯이 변경될 수 있어 상호작용이 가능합니다. 이는 독자가 읽는 이야기를 적극적으로 창작하는 데 참여할 수 있다는 의미입니다. 아동용 독서 앱은 아이가 어려움을 겪는 단어를 식별하고 이를 중심으로 한 이야기를 생성합니다.\n",
    "\n",
    "Google Docs, Notion, Gmail과 같은 필기 및 이메일 앱도 AI를 사용해 사용자의 글쓰기를 개선하도록 돕습니다. Grammarly와 같은 글쓰기 보조 앱은 사용자의 글을 더욱 유창하고 일관성 있으며 명확하게 만드는 모델을 미세 조정합니다.\n",
    "\n",
    "AI의 글쓰기 능력은 악용될 수도 있습니다. 2023년, 뉴욕타임스는 아마존이 저품질 AI로 생성된 여행 가이드북으로 넘쳐났다고 보도했습니다. 이들 가이드북에는 작가 소개, 웹사이트, 그리고 모두 AI로 생성된 극찬 리뷰가 포함되어 있었습니다.\n",
    "\n",
    "기업에서도 AI 글쓰기는 영업, 마케팅, 팀 커뮤니케이션에서 흔히 사용됩니다. 많은 관리자가 AI를 사용해 성과 보고서를 작성한다고 말합니다. AI는 효과적인 콜드 이메일, 광고 카피라이팅, 제품 설명 등을 제작하는 데 도움을 줍니다. HubSpot, Salesforce와 같은 CRM(고객 관계 관리) 앱도 기업 사용자를 위해 웹 콘텐츠와 아웃리치 이메일을 생성하는 도구를 제공합니다.\n",
    "\n",
    "AI는 특히 SEO(검색 엔진 최적화)에 뛰어난 것으로 보입니다. 이는 많은 AI 모델이 인터넷 데이터를 학습하는데, 인터넷에는 SEO에 최적화된 텍스트가 많기 때문입니다. AI는 SEO에 매우 능숙하여 새로운 콘텐츠 농장을 탄생시켰습니다. 이러한 농장은 AI로 생성된 콘텐츠로 채워진 저질 웹사이트를 설정해 Google 검색 순위를 높이고 트래픽을 유도합니다. 그런 다음 광고 거래소를 통해 광고 슬롯을 판매합니다. 2023년 6월, NewsGuard는 141개의 인기 브랜드로부터 거의 400개의 광고가 저질 AI로 생성된 웹사이트에 게재되었다고 확인했습니다. 이러한 저질 웹사이트 중 하나는 하루에 1,200개의 기사를 생성했습니다. 이를 제한하기 위한 조치가 없으면, 인터넷 콘텐츠의 미래는 AI가 생성한 것이 될 것이며, 이는 다소 암울할 것입니다.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **교육 (Education)**\n",
    "\n",
    "ChatGPT가 작동하지 않을 때마다, OpenAI의 Discord 서버는 숙제를 완수하지 못해 불평하는 학생들로 가득 찹니다. **뉴욕시 공립학교(New York City Public Schools)** 와 **로스앤젤레스 통합교육구(Los Angeles Unified School District)** 를 포함한 여러 교육위원회는 학생들이 AI를 부정행위에 사용할 것을 우려하여 ChatGPT를 빠르게 금지했습니다. 제 생각에는 AI를 금지하려는 시도는 인터넷을 금지하려는 시도와 같다고 봅니다. 이는 효과가 없을 것이라 생각합니다.\n",
    "\n",
    "AI를 금지하는 대신, 학교는 이를 통합하여 학생들이 더 빨리 학습할 수 있도록 도와야 합니다. AI는 교과서를 요약하고, 각 학생에게 맞춤화된 강의 계획을 생성할 수 있습니다. 광고는 모든 사람이 다르다는 것을 알고 맞춤화되지만, 교육은 그렇지 않다는 점이 이상하다고 느껴집니다. AI는 각 학생에게 가장 적합한 형식으로 자료를 조정하도록 도울 수 있습니다. 예를 들어, 청각 학습자는 AI를 사용해 자료를 소리 내어 읽을 수 있습니다. 동물을 좋아하는 학생들은 시각 자료에 더 많은 동물이 포함되도록 AI를 활용할 수 있습니다. 수학 방정식을 읽기보다 코드를 읽는 것이 더 쉬운 학생들은 AI에게 수학 방정식을 코드로 변환하도록 요청할 수 있습니다.\n",
    "\n",
    "AI는 특히 언어 학습에 매우 유용합니다. AI에게 다양한 연습 시나리오에서 역할극을 요청할 수 있기 때문입니다. **Duolingo**는 강의 생성의 네 가지 단계 중 **개인화된 수업(Lesson Personalization)** 이 AI로부터 가장 많은 이점을 얻을 수 있는 단계임을 발견했습니다(Figure 1-8 참조).\n",
    "\n",
    "<img src=\"images/fig_01_08.png\" width=800>\n",
    "\n",
    "**강의 생성의 4단계:**\n",
    "1. 교육과정 설계 (Curriculum Design)  \n",
    "2. 원시 콘텐츠 생성 (Raw Content Creation)  \n",
    "3. 연습 문제 생성 (Exercise Creation)  \n",
    "4. 수업 개인화 (Lesson Personalization)  \n",
    "\n",
    "**AI 작업량과 인간 작업량 비교 (Figure 1-8)**: AI는 Duolingo에서 강의 생성의 모든 단계에 사용될 수 있지만, 개인화 단계에서 가장 큰 도움을 줍니다.  \n",
    "이미지 출처: *\"At Duolingo, humans and AI work together to create a high-quality learning experience\"* (Pajak and Bicknell).\n",
    "\n",
    "AI는 객관식 및 주관식 퀴즈를 생성하고 답변을 평가할 수 있습니다. AI는 평균적인 인간보다 동일한 주제에 대해 다양한 관점을 제시하는 데 훨씬 뛰어나서 토론 파트너로 활용될 수 있습니다. 예를 들어, **Khan Academy**는 학생들을 위한 교수 보조자와 교사를 위한 강의 보조자로 AI를 제공합니다. 제가 본 혁신적인 교육 방법 중 하나는 교사들이 AI로 생성된 에세이를 학생들에게 배포해 오류를 찾고 수정하도록 하는 것입니다.\n",
    "\n",
    "AI가 많은 기술을 대체할 위험이 있다면, AI가 어떤 기술이든 학습할 수 있는 교사로 사용될 기회도 있습니다. AI는 방대한 데이터로 훈련되었기 때문에 대중의 집합적 지식을 반영합니다. 많은 기술에서 AI의 역량은 평균 수준입니다. 그러나 AI는 누군가가 빠르게 기본을 익히고, 이후 독립적으로 학습을 계속하여 AI보다 더 나은 수준에 도달하도록 도울 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **대화형 봇 (Conversational bots)**\n",
    "\n",
    "대화형 봇은 다재다능합니다. 정보를 찾거나 개념을 설명하고, 아이디어를 브레인스토밍하는 데 도움을 줄 수 있습니다. AI는 동반자이자 상담사가 될 수 있습니다. AI는 특정 인물의 디지털 복제본과 대화할 수 있도록 성격을 모방할 수 있습니다. 디지털 여자친구와 남자친구는 놀라울 정도로 짧은 시간 안에 인기를 얻었으며, 이미 많은 사람들이 인간보다 봇과 더 많은 시간을 보내고 있습니다(관련 논의는 [**여기**](https://www.reddit.com/r/CharacterAI/comments/11r4gwi/spent_more_time_on_charecter_ai_than_speaking_to/?rdt=59658) 및 [**여기**](https://www.myaiobsession.com/p/is-it-so-wrong-to-spend-two-hours)에서 확인할 수 있습니다). [일부](https://thehill.com/opinion/technology/4218666-ai-girlfriends-are-ruining-an-entire-generation-of-men/)는 AI가 데이트 문화를 망칠 것을 우려합니다.\n",
    "\n",
    "연구에서는 대화형 봇이 사회를 시뮬레이션하여 사회 역학에 대한 연구를 수행하는 데 사용될 수 있음을 발견했습니다.\n",
    "\n",
    "기업에서는 **고객 지원 봇**이 가장 인기가 있습니다. 이러한 봇은 고객 경험을 개선하면서도 비용을 절감할 수 있도록 돕습니다. 고객 지원 봇은 인간 상담원보다 더 빠르게 사용자에게 응답할 수 있습니다. 또한, AI는 보험 청구 제출, 세금 신고, 회사 정책 검색과 같은 어려운 작업을 안내하는 **제품 보조 파일럿(product copilots)** 역할을 할 수 있습니다.\n",
    "\n",
    "ChatGPT의 성공은 텍스트 기반 대화형 봇의 물결을 일으켰습니다. 그러나 텍스트는 대화형 에이전트를 위한 유일한 인터페이스가 아닙니다. **Google Assistant**, **Siri**, **Alexa**와 같은 음성 비서들은 오랜 기간 동안 존재해 왔으며, 3D 대화형 봇은 이미 게임에서 흔히 사용되고 있으며 소매 및 마케팅에서도 점차 확산되고 있습니다.\n",
    "\n",
    "AI 기반 3D 캐릭터의 한 가지 사용 사례는 **스마트 NPC(비플레이어 캐릭터)** 입니다. NPC는 많은 게임의 스토리라인을 진행하는 데 필수적입니다. AI가 없으면 NPC는 제한된 대화 범위로 단순한 작업만 수행하도록 스크립팅됩니다. AI는 이러한 NPC를 훨씬 더 똑똑하게 만들 수 있습니다. 지능형 봇은 **The Sims**, **Skyrim**과 같은 기존 게임의 역학을 변화시킬 수 있을 뿐만 아니라 이전에는 불가능했던 새로운 게임을 가능하게 할 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **정보 통합 (Information aggregation)**\n",
    "\n",
    "많은 사람들은 성공이 유용한 정보를 필터링하고 소화하는 능력에 달려 있다고 믿습니다. 그러나 이메일, **Slack 메시지**, 뉴스 등을 관리하는 것은 때로는 벅찰 수 있습니다. 다행히 AI가 이 문제를 해결했습니다. AI는 정보를 통합하고 요약하는 데 뛰어난 역량을 입증했습니다.\n",
    "\n",
    "소비자 관점에서, 많은 애플리케이션이 계약서, 공시자료, 논문 등의 문서를 처리하고 대화형 방식으로 정보를 검색할 수 있도록 도와줍니다. 이 사용 사례는 **talk-to-your-docs**라고도 불립니다. AI는 웹사이트, 연구를 요약하고 사용자가 선택한 주제에 대한 보고서를 작성할 수 있습니다. **Salesforce의 Generative AI Snapshot Research**에 따르면, 생성형 AI 사용자 중 **74%** 가 복잡한 아이디어를 간소화하고 정보를 요약하기 위해 AI를 사용합니다.\n",
    "\n",
    "정보 통합 및 요약은 기업 운영에 필수적입니다. 보다 효율적인 정보 통합은 중간 관리자의 필요성을 줄임으로써 조직이 더 간소화될 수 있도록 돕습니다. AI는 잠재 고객에 대한 중요한 정보를 제공하고 경쟁사에 대한 분석을 실행할 수 있도록 돕습니다. **Instacart**가 내부 프롬프트 마켓플레이스를 출시했을 때, 가장 인기 있는 프롬프트 템플릿 중 하나가 **\"Fast Breakdown\"** 임을 발견했습니다. 이 템플릿은 AI에게 사실, 열린 질문, 행동 항목으로 대화를 요약하도록 요청합니다. 이는 회의 노트, 이메일, 특히 **Slack 대화** 에 적용될 수 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **데이터 조직화**\n",
    "\n",
    "미래에 확실한 한 가지는 우리가 점점 더 많은 데이터를 생산하게 될 것이라는 점입니다. 스마트폰 사용자들은 계속해서 사진과 동영상을 찍을 것이고, 기업들은 제품, 직원, 고객에 관한 모든 것을 계속 기록할 것입니다.\n",
    "\n",
    "매년 수십억 건의 계약서가 생성되고 있습니다. 사진, 동영상, 로그, PDF 파일 등은 모두 비정형 또는 반정형 데이터입니다. 이러한 모든 데이터를 필요한 정보를 나중에 검색할 수 있는 방식으로 조직화하는 것이 중요합니다.\n",
    "\n",
    "AI는 바로 이 작업을 도울 수 있습니다. AI는 이미지와 동영상에 대한 텍스트 설명을 자동으로 생성하거나, 텍스트 쿼리와 시각적으로 일치하는 항목을 연결하는 데 도움을 줄 수 있습니다. Google Photos와 같은 서비스는 이미 AI를 사용하여 검색 쿼리와 일치하는 이미지를 표시하고 있습니다. Google 이미지 검색은 한 걸음 더 나아가, 사용자의 요구에 맞는 기존 이미지가 없을 경우 이미지를 생성할 수 있습니다.\n",
    "\n",
    "기업의 경우, AI는 비정형 데이터를 정형 데이터로 추출하여 데이터를 정리하고 검색을 돕는 데 활용될 수 있습니다. 간단한 사용 사례로는 신용카드, 운전면허증, 영수증, 티켓, 이메일 푸터에서 연락처 정보를 자동으로 추출하는 것이 있습니다. 더 복잡한 사용 사례로는 계약서, 보고서, 차트 등의 데이터에서 정보를 추출하는 작업이 포함됩니다. IDP(Intelligent Data Processing, 지능형 데이터 처리) 산업은 2030년까지 128억 1천만 달러에 이를 것으로 추산되며, 매년 32.9%씩 성장하고 있습니다. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **워크플로 자동화**\n",
    "\n",
    "궁극적으로, AI는 가능한 한 많은 작업을 자동화해야 합니다. 최종 사용자에게 자동화는 식당 예약, 환불 요청, 여행 계획, 양식 작성과 같은 지루한 일상 업무를 돕는 데 유용합니다.\n",
    "\n",
    "기업의 경우, AI는 리드 관리, 송장 처리, 상환, 고객 요청 관리, 데이터 입력 등 반복적인 작업을 자동화할 수 있습니다. 특히 흥미로운 사용 사례 중 하나는 AI 모델을 사용하여 데이터를 합성하는 것으로, 이를 통해 모델 자체를 개선할 수 있습니다. 원하는 데이터의 몇 가지 예를 모델에 제공한 뒤, 모델이 이를 기반으로 더 많은 유사한 예를 생성하도록 요청할 수 있습니다. 데이터를 라벨링하는 데 AI를 활용할 수 있으며, 라벨의 품질을 높이기 위해 사람을 개입시킬 수도 있습니다.\n",
    "\n",
    "많은 작업을 수행하려면 외부 도구에 대한 접근이 필요합니다. 예를 들어, 식당을 예약하려면 애플리케이션이 검색 엔진을 열어 식당의 번호를 조회하거나, 전화를 걸고, 일정을 캘린더에 추가하는 등의 작업을 수행할 수 있어야 합니다. 도구를 계획하고 사용하는 AI는 **에이전트(agents)** 라고 불립니다. 에이전트에 대한 관심은 거의 집착 수준에 가깝지만, 이는 완전히 근거 없는 것이 아닙니다. AI 에이전트는 모든 사람을 훨씬 더 생산적이고 경제적 가치를 창출하는 데 기여할 잠재력을 가지고 있습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 애플리케이션 기획\n",
    "\n",
    "AI의 무한한 가능성을 보면 애플리케이션 구축에 바로 뛰어들고 싶을 것입니다. 만약 배우고 재미를 느끼고 싶다면, 바로 시작하십시오. 애플리케이션을 구축하는 것은 배우는 최고의 방법 중 하나입니다. 기초 모델의 초창기에는 여러 AI 책임자들이 팀원들에게 AI 애플리케이션을 실험하며 스스로 기술을 향상시키도록 독려했다고 합니다.\n",
    "\n",
    "그러나, 만약 생업으로 이를 수행하는 것이라면, 한 걸음 물러나서 왜 이 작업을 하고 있는지, 어떻게 접근해야 하는지 신중히 생각해보는 것이 좋습니다. 기초 모델로 멋진 데모를 만드는 것은 쉬울 수 있지만, 수익성 있는 제품을 만드는 것은 어렵습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 사용 사례 평가\n",
    "\n",
    "애플리케이션을 구축하려는 첫 번째 이유는 무엇인지 물어봐야 합니다. 많은 비즈니스 결정과 마찬가지로, AI 애플리케이션 구축은 종종 위험과 기회에 대한 반응입니다. 아래는 위험의 수준에 따라 정리된 몇 가지 예입니다.\n",
    "\n",
    "1. **이 작업을 하지 않으면 AI를 사용하는 경쟁자가 당신을 도태시킬 수 있습니다.** AI가 귀하의 비즈니스에 중대한 생존 위협을 가하는 경우, AI 통합은 최우선 과제가 되어야 합니다. 2023년 Gartner 연구에서는 7%가 AI 도입 이유로 비즈니스 연속성을 언급했습니다. 이는 재무 분석, 보험, 데이터 처리와 같은 문서 처리 및 정보 집계를 포함하는 비즈니스에 더 흔합니다. 광고, 웹 디자인, 이미지 제작과 같은 창의적 작업에서도 일반적입니다. 2023년 OpenAI 연구인 “GPTs are GPTs”(Eloundou et al., 2023)를 참조하면 업계별 AI 노출 순위를 확인할 수 있습니다.\n",
    "\n",
    "2. **이 작업을 하지 않으면 수익과 생산성을 높일 기회를 놓치게 됩니다.** 대부분의 회사는 AI가 제공하는 기회를 활용합니다. AI는 더 효과적인 카피 작성, 제품 설명, 홍보용 시각 콘텐츠 제작을 통해 사용자 확보 비용을 절감할 수 있습니다. AI는 고객 지원 개선 및 사용자 경험 맞춤화를 통해 사용자 유지율을 증가시킬 수 있습니다. 또한 AI는 영업 기회 창출, 내부 커뮤니케이션, 시장 조사, 경쟁자 추적에도 도움을 줄 수 있습니다.\n",
    "\n",
    "3. **AI가 비즈니스에 어떻게 적합할지 아직 확신하지 못하지만 뒤처지고 싶지 않습니다.** 모든 유행을 쫓아서는 안 되지만, Kodak, Blockbuster, BlackBerry처럼 너무 오래 기다리다 실패한 사례가 많습니다. 새로운 혁신 기술이 비즈니스에 미치는 영향을 이해하는 데 자원을 투자하는 것은 나쁜 선택이 아닙니다. 특히 여유가 있다면 더 큰 기업에서는 이를 R&D 부서의 일부로 활용할 수 있습니다.\n",
    "\n",
    "사용 사례를 개발할 좋은 이유를 찾은 후에는 이를 직접 구축해야 할지 고민해볼 수 있습니다. AI가 비즈니스에 실존적 위협을 가하는 경우, 경쟁업체에 외주를 주는 대신 내부적으로 AI를 개발하는 것이 좋습니다. 하지만 수익과 생산성을 높이기 위해 AI를 사용하는 경우, 시간과 비용을 절약하면서 더 나은 성과를 제공하는 다양한 구매 옵션이 있을 수 있습니다.\n",
    "\n",
    "**애플리케이션에서 AI와 인간의 역할**\n",
    "\n",
    "AI가 제품에서 어떤 역할을 하는지에 따라 애플리케이션의 개발 및 요구 사항에 영향을 미칩니다. Apple은 AI가 제품에 사용되는 다양한 방법을 설명하는 훌륭한 문서를 보유하고 있습니다. 다음은 현재 논의와 관련된 세 가지 주요 사항입니다.\n",
    "\n",
    "**중요하거나 보완적 역할**\n",
    "- 애플리케이션이 AI 없이도 작동할 수 있다면, AI는 해당 애플리케이션의 보완적 역할을 합니다. 예를 들어, Face ID는 AI 기반 얼굴 인식 없이는 작동하지 않지만 Gmail은 Smart Compose 없이도 작동합니다.\n",
    "- AI가 애플리케이션에서 더 중요한 역할을 할수록, AI 부분이 더 정확하고 신뢰할 수 있어야 합니다. AI가 애플리케이션의 핵심이 아닐 경우, 사용자는 AI의 실수를 더 잘 받아들입니다.\n",
    "\n",
    "**반응형 또는 능동형**\n",
    "- 반응형 기능은 사용자의 요청이나 특정 작업에 반응하여 응답을 보여주는 반면, 능동형 기능은 기회가 있을 때 응답을 보여줍니다. 예를 들어, 챗봇은 반응형이고, Google Maps의 교통 경고는 능동형입니다.\n",
    "- 반응형 기능은 이벤트에 반응하여 생성되므로, 일반적으로(항상 그런 것은 아니지만) 빠르게 작동해야 합니다. 반면, 능동형 기능은 사전 계산되어 적절한 시기에 표시될 수 있으므로 지연 시간이 덜 중요합니다.\n",
    "- 사용자가 능동형 기능을 요청하지 않는 경우, 품질이 낮을 경우 이를 성가시거나 불쾌하게 여길 수 있습니다. 따라서 능동형 예측 및 생성은 일반적으로 더 높은 품질 기준을 갖습니다.\n",
    "\n",
    "**동적 또는 정적**\n",
    "- 동적 기능은 사용자 피드백과 함께 지속적으로 업데이트되며, 정적 기능은 주기적으로 업데이트됩니다. 예를 들어, Face ID는 사람들의 얼굴이 시간이 지남에 따라 변하기 때문에 업데이트가 필요합니다. 하지만 Google Photos의 객체 감지는 Google Photos가 업그레이드될 때만 업데이트될 가능성이 높습니다.\n",
    "- AI의 경우, 동적 기능은 각 사용자가 자신의 데이터를 기반으로 지속적으로 미세 조정된 자신만의 모델을 가지거나, ChatGPT의 메모리 기능과 같은 개인화 메커니즘을 사용할 수 있다는 것을 의미할 수 있습니다. 이는 ChatGPT가 각 사용자의 선호도를 기억할 수 있게 해줍니다. 반면, 정적 기능은 사용자 그룹을 위한 하나의 모델을 가질 수 있습니다. 이 경우, 이러한 기능은 공유 모델이 업데이트될 때만 갱신됩니다.\n",
    "\n",
    "AI가 인간에게 백그라운드 지원을 제공할 것인지, 직접 결정을 내릴 것인지, 아니면 둘 다 할 것인지 명확히 하는 것도 중요합니다. 예를 들어, 고객 지원 챗봇의 경우, AI 응답은 다양한 방식으로 사용될 수 있습니다:\n",
    "\n",
    "- AI가 여러 응답을 표시하여 인간 상담원이 더 빠르게 응답을 작성할 수 있도록 참조할 수 있습니다.\n",
    "- AI는 간단한 요청에만 응답하고 더 복잡한 요청은 인간에게 전달합니다.\n",
    "- AI는 인간의 개입 없이 모든 요청에 직접 응답합니다.\n",
    "\n",
    "AI의 의사결정 과정에 인간을 포함시키는 것을 \"Human-in-the-loop\"라고 합니다.\n",
    "\n",
    "Microsoft(2023)는 제품에서 AI 자동화를 점진적으로 증가시키는 프레임워크를 \"Crawl-Walk-Run\"이라고 부릅니다:\n",
    "1. **Crawl**: 인간의 개입이 필수적입니다.\n",
    "2. **Walk**: AI가 내부 직원과 직접 상호작용할 수 있습니다.\n",
    "3. **Run**: 자동화가 증가하며, 외부 사용자와의 직접적인 AI 상호작용이 포함될 수 있습니다.\n",
    "\n",
    "AI 시스템의 품질이 향상됨에 따라 인간의 역할은 시간이 지남에 따라 변화할 수 있습니다. 초기에는 AI 기능을 평가하는 과정에서 인간 상담원을 위한 제안을 생성하는 데 사용할 수 있습니다. 예를 들어, 간단한 요청에 대한 AI 제안 응답의 95%가 인간 상담원에 의해 그대로 사용된다면, 고객이 간단한 요청에 대해 AI와 직접 상호작용할 수 있도록 허용할 수 있습니다.\n",
    "\n",
    "**AI 제품의 방어 가능성**\n",
    "\n",
    "독립형 제품으로 AI 애플리케이션을 판매하는 경우, 제품의 방어 가능성을 고려하는 것이 중요합니다. 낮은 진입 장벽은 축복이자 저주일 수 있습니다. 어떤 것이 구축하기 쉽다면, 경쟁자에게도 쉽습니다. 제품을 방어하기 위해 어떤 방책을 마련할 수 있습니까?\n",
    "\n",
    "기반 모델 위에 애플리케이션을 구축한다는 것은 이 모델 위에 레이어를 제공한다는 것을 의미합니다. 하지만 기반 모델이 기능을 확장하면 제공한 레이어가 이 모델에 포함될 수 있으며, 애플리케이션이 쓸모없게 될 수 있습니다. 예를 들어, ChatGPT 위에 PDF를 잘 처리하지 못한다고 가정하여 PDF 처리 애플리케이션을 구축했다고 상상해보세요. 이 가정이 더 이상 맞지 않다면 경쟁력이 약화될 것입니다. 그러나 이 경우에도 PDF 처리 애플리케이션은 오픈 소스 모델 위에 구축되어 자체적으로 모델을 호스팅하려는 사용자들에게 유용할 수 있습니다.\n",
    "\n",
    "한 주요 벤처캐피털 회사의 일반 파트너는 Google Docs나 Microsoft Office의 기능이 될 수 있는 제품을 가진 많은 스타트업을 보았다고 말했습니다. 이들의 제품이 성공한다면, Google이나 Microsoft가 엔지니어 세 명을 할당하여 2주 만에 이러한 제품을 복제하는 것을 막을 방법은 무엇일까요?\n",
    "\n",
    "AI에서는 일반적으로 기술, 데이터, 유통이라는 세 가지 경쟁 우위를 찾을 수 있습니다. 이는 제품을 사용자 앞에 가져다 놓는 능력을 의미합니다. 기반 모델을 활용하면 대부분의 회사의 핵심 기술은 유사할 것입니다. 유통의 장점은 대기업에 속하는 경향이 있습니다.\n",
    "\n",
    "데이터의 장점은 더 세밀합니다. 대기업은 기존 데이터를 더 많이 보유하고 있을 가능성이 높습니다. 그러나 스타트업이 시장에 먼저 진입하고 충분한 사용자 데이터를 모아 제품을 지속적으로 개선할 수 있다면 데이터는 큰 방어막이 될 것입니다. 심지어 사용자의 데이터가 모델을 직접 훈련하는 데 사용될 수 없는 시나리오에서도, 사용 정보는 사용자 행동과 제품 약점을 이해하는 데 귀중한 통찰력을 제공할 수 있습니다.\n",
    "\n",
    "원래의 제품이 더 큰 제품의 기능에 불과할 수도 있었던 성공적인 회사들이 많이 있었습니다. Calendly는 Google Calendar의 기능이 될 수도 있었고, Mailchimp는 Gmail의 기능이 될 수도 있었으며, Photoroom은 Google Photo의 기능이 될 수도 있었습니다.\n",
    "\n",
    "많은 스타트업은 더 큰 경쟁업체를 따라잡고 결국에는 능가하게 되는데, 이는 주로 큰 경쟁업체들이 간과한 기능을 먼저 개발하는 것으로 시작됩니다. 어쩌면 당신의 스타트업이 그다음 주인공이 될지도 모릅니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 기대 설정\n",
    "\n",
    "이 놀라운 AI 애플리케이션을 직접 구축하기로 결정한 후에는 다음 단계로 성공의 기준을 설정해야 합니다. 성공은 어떻게 측정할 수 있을까요? 가장 중요한 지표는 이 애플리케이션이 귀사의 비즈니스에 어떤 영향을 미칠 것인지입니다. 예를 들어, 고객 지원 챗봇의 경우 비즈니스 메트릭은 다음을 포함할 수 있습니다:\n",
    "\n",
    "- 고객 메시지 중 몇 퍼센트를 챗봇이 자동화하도록 할 것인가?\n",
    "- 챗봇이 처리할 수 있는 메시지 수를 얼마나 늘릴 것인가?\n",
    "- 챗봇을 사용하여 응답 속도를 얼마나 개선할 수 있는가?\n",
    "- 챗봇이 절약할 수 있는 인간 노동 시간은 얼마인가?\n",
    "\n",
    "챗봇은 더 많은 메시지를 처리할 수 있지만, 이것이 사용자를 만족시킨다는 것을 의미하지는 않습니다. 따라서 고객 만족도와 전반적인 고객 피드백을 추적하는 것이 중요합니다. “User Feedback”에서는 피드백 시스템을 설계하는 방법을 다룹니다.\n",
    "\n",
    "제품이 고객에게 제공되기 전에 준비되지 않은 상태에서 출시되지 않도록 하기 위해, 제품의 유용성 임계값에 대한 명확한 기대치를 설정해야 합니다. 즉, 유용하기 위해 얼마나 좋아야 하는지에 대한 기준입니다. 유용성 임계값에는 다음과 같은 메트릭 그룹이 포함될 수 있습니다:\n",
    "\n",
    "- **품질 메트릭**: 챗봇 응답의 품질을 측정합니다.\n",
    "- **지연 시간 메트릭**: TTFT(첫 번째 토큰까지 걸리는 시간), TPOT(출력 토큰당 시간), 전체 지연 시간 등이 포함됩니다. 수용 가능한 지연 시간은 사용 사례에 따라 다릅니다. 모든 고객 요청이 현재 인간에 의해 처리되고 있으며, 평균 응답 시간이 1시간인 경우 이보다 빠르다면 충분할 수 있습니다.\n",
    "- **비용 메트릭**: 추론 요청당 비용을 측정합니다.\n",
    "- **기타 메트릭**: 해석 가능성 및 공정성 등이 포함됩니다.\n",
    "\n",
    "아직 사용할 메트릭을 결정하지 못했다면 걱정하지 마세요. 이 책의 나머지 부분에서 많은 메트릭을 다룰 것입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목표 계획\n",
    "\n",
    "측정 가능한 목표를 설정한 후에는 이 목표를 달성하기 위한 계획이 필요합니다. 목표 달성 방법은 시작 위치에 따라 달라집니다. 기존 모델을 평가하여 그 기능을 이해하세요. 사전 구축된 모델이 강력할수록 해야 할 일이 줄어듭니다. 예를 들어, 고객 지원 티켓의 60%를 자동화하는 것이 목표이고 사용하려는 사전 모델이 이미 30%를 자동화할 수 있다면, 전혀 자동화할 수 없는 모델을 사용하는 경우보다 투입해야 할 노력이 적을 수 있습니다.\n",
    "\n",
    "평가 후에는 목표가 변경될 가능성이 있습니다. 예를 들어, 평가 후 애플리케이션을 유용성 임계값까지 도달시키는 데 필요한 리소스가 잠재적 수익보다 더 많다는 것을 깨닫고 이를 더 이상 추구하지 않을 수도 있습니다.\n",
    "\n",
    "AI 제품 계획은 마지막 단계의 도전을 고려해야 합니다. 기반 모델에서 초기 성공은 오해를 불러일으킬 수 있습니다. 기반 모델의 기본 기능은 이미 매우 인상적이기 때문에 재미있는 데모를 만드는 데는 시간이 많이 걸리지 않을 수 있습니다. 하지만 초기 데모가 좋은 최종 제품을 보장하지는 않습니다. 데모를 만드는 데는 주말이 걸릴 수 있지만, 제품을 만드는 데는 몇 달, 심지어 몇 년이 걸릴 수 있습니다.\n",
    "\n",
    "UltraChat 연구에서 Ding 외(2023)는 “0에서 60까지의 여정은 쉽지만, 60에서 100으로의 진행은 매우 어려워진다”고 밝혔습니다. LinkedIn(2024)도 동일한 의견을 공유했습니다. 원하는 경험의 80%를 달성하는 데 한 달이 걸렸지만, 초기 성공이 얼마나 많은 시간을 더 필요로 할지를 심각하게 과소평가하게 만들었습니다. 최종적으로 95%를 초과하는 데 추가로 4개월이 걸렸으며, 이 과정에서 제품 문제와 헛된 결과(hallucinations) 문제를 해결하는 데 많은 시간이 소요되었습니다. 후속 1%의 개선을 달성하는 데 걸리는 느린 속도는 실망스러웠습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유지보수\n",
    "\n",
    "제품 계획은 목표를 달성하는 것으로 끝나지 않습니다. 시간이 지남에 따라 이 제품이 어떻게 변화할지, 그리고 이를 어떻게 유지 관리할지를 고민해야 합니다. AI 제품의 유지보수는 AI의 빠른 변화 속도라는 추가적인 도전을 수반합니다. 지난 10년 동안 AI 분야는 놀라울 정도로 빠르게 발전해 왔으며, 향후 10년 동안도 이러한 빠른 변화는 계속될 가능성이 높습니다. 오늘날 기반 모델 위에 구축하는 것은 이 고속열차를 타겠다는 약속과도 같습니다.\n",
    "\n",
    "많은 변화는 긍정적입니다. 예를 들어, 많은 모델의 한계가 점차 해결되고 있습니다. 문맥 길이가 점점 더 길어지고 있으며, 모델 출력은 더 나아지고 있습니다. 입력을 받아 출력 결과를 계산하는 모델 추론 속도는 더 빠르고 저렴해지고 있습니다. **그림 1-11**은 2022년에서 2024년 사이 대규모 멀티태스크 언어 이해(MMLU)(Hendrycks et al., 2020)라는 인기 있는 기반 모델 벤치마크에서 추론 비용과 모델 성능의 진화를 보여줍니다.\n",
    "\n",
    "<img src=\"images/fig_01_11_2.png\" width=800>\n",
    "\n",
    "그러나 이러한 긍정적인 변화조차도 작업 흐름에 마찰을 일으킬 수 있습니다. 기술 투자마다 비용-편익 분석을 끊임없이 실행하며 주의를 기울여야 합니다. 오늘의 최선의 선택이 내일의 최악의 선택으로 바뀔 수 있습니다. 예를 들어, 모델 제공업체에 비용을 지불하는 것보다 직접 모델을 구축하는 것이 더 저렴하다고 판단하여 내부적으로 모델을 구축했지만, 3개월 후 모델 제공업체들이 가격을 절반으로 낮춰 내부 구축이 더 비싼 선택이 되는 경우가 있을 수 있습니다. 또는 외부 제공업체의 솔루션에 투자하고 이를 기반으로 인프라를 맞춤화했는데, 그 제공업체가 자금을 확보하지 못해 사업을 접는 상황이 발생할 수도 있습니다.\n",
    "\n",
    "일부 변화는 적응하기 쉬울 수 있습니다. 예를 들어, 모델 제공업체들이 동일한 API로 수렴하면서 한 모델 API를 다른 것으로 교체하는 것이 점점 더 쉬워지고 있습니다. 그러나 각 모델은 고유한 특징, 강점, 약점을 가지고 있기 때문에, 새로운 모델과 작업하는 개발자는 워크플로우, 프롬프트, 데이터를 새로운 모델에 맞게 조정해야 합니다. 버전 관리와 평가를 위한 적절한 인프라가 없으면 이 과정은 많은 골칫거리를 유발할 수 있습니다.\n",
    "\n",
    "일부 변화는 적응하기 더 어렵습니다. 특히 규제와 관련된 변화가 그렇습니다. AI 관련 기술은 많은 국가에서 국가 안보 문제로 간주되며, 컴퓨팅 자원, 인재, 데이터 등 AI와 관련된 자원이 강하게 규제됩니다. 예를 들어, 유럽의 일반 데이터 보호 규정(GDPR)의 도입은 기업들이 규정을 준수하는 데 약 90억 달러의 비용이 들 것으로 추산되었습니다. 새로운 법률이 컴퓨팅 자원의 구매 및 판매에 대한 제한을 강화함에 따라 컴퓨팅 자원의 가용성이 하룻밤 사이에 변할 수 있습니다(2023년 10월 미국 행정명령 참조). 만약 GPU 공급업체가 귀하의 국가에 GPU 판매를 갑자기 금지당한다면, 심각한 문제가 발생할 수 있습니다.\n",
    "\n",
    "일부 변화는 치명적일 수도 있습니다. 예를 들어, 지적 재산(IP)과 AI 사용과 관련된 규제는 여전히 발전하고 있습니다. 다른 사람들의 데이터를 사용해 훈련된 모델 위에 제품을 구축한다면, 해당 제품의 IP가 항상 귀하에게 속할 것이라고 확신할 수 있습니까? 제가 이야기한 많은 IP 중심의 회사들, 예를 들어 게임 스튜디오 등은 나중에 IP를 잃을지도 모른다는 두려움 때문에 AI 사용을 주저하고 있습니다.  \n",
    "\n",
    "AI 제품을 구축하기로 결정했다면, 이제 이러한 애플리케이션을 구축하는 데 필요한 엔지니어링 스택을 살펴보겠습니다.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AI 엔지니어링 스택(The AI Engineering Stack)**\n",
    "\n",
    "AI 엔지니어링의 빠른 성장은 엄청난 기대와 함께 FOMO(Fear Of Missing Out, 놓치고 싶지 않다는 두려움)를 유발했습니다. 매일 새로운 도구, 기술, 모델, 애플리케이션이 도입되면서 압도감을 느낄 수 있습니다. 계속 변하는 환경을 따라잡으려 하기보다는, AI 엔지니어링의 기본 구성 요소에 대해 살펴보겠습니다.\n",
    "\n",
    "AI 엔지니어링을 이해하기 위해서는 AI 엔지니어링이 ML(Machine Learning) 엔지니어링에서 발전해왔다는 점을 인식하는 것이 중요합니다. 회사가 기본 모델(foundation models)을 실험하기 시작할 때, 기존 ML 팀이 노력을 주도하는 것이 자연스럽습니다. 어떤 회사들은 AI 엔지니어링을 ML 엔지니어링과 동일하게 간주하며, 이는 **Figure 1-9**에서 볼 수 있습니다. 또 다른 회사들은 AI 엔지니어링을 위한 별도의 직무 설명서를 가지고 있으며, 이는 **Figure 1-10**에서 볼 수 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_09.png\" width=800>\n",
    "\n",
    "조직이 AI 엔지니어와 ML 엔지니어를 어디에 배치하든, 두 직무는 상당한 공통점을 가지고 있습니다. 기존 ML 엔지니어들은 AI 엔지니어링을 기술 목록에 추가하여 직업 기회를 확장할 수 있습니다. 하지만 이전 ML 경험 없이 AI 엔지니어로 일하는 경우도 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_10.png\" width=800>\n",
    "\n",
    "AI 엔지니어링을 최선으로 이해하고 전통적인 ML 엔지니어링과 어떻게 다른지 파악하려면, 다음 섹션에서는 AI 애플리케이션 구축 과정의 다양한 계층을 분석하고, 각 계층이 AI 엔지니어링과 ML 엔지니어링에서 수행하는 역할을 살펴보겠습니다.\n",
    "\n",
    "### **AI 스택의 세 가지 계층**\n",
    "\n",
    "AI 애플리케이션 스택은 인프라스트럭처, 모델 개발, 애플리케이션 개발이라는 세 가지 계층으로 구성됩니다.\n",
    "\n",
    "1. **인프라스트럭처(Infrastructure)**: 스택의 가장 하단에 있는 계층으로, 모델 제공, 모니터링, 데이터와 컴퓨팅 관리 등을 위한 도구를 포함합니다.\n",
    "\n",
    "2. **모델 개발(Model Development)**: 이 계층은 모델 개발을 위한 도구를 제공합니다. 여기에는 모델링, 훈련, 파인튜닝, 추론 최적화, 데이터셋 엔지니어링을 위한 프레임워크가 포함됩니다.\n",
    "\n",
    "3. **애플리케이션 개발(Application Development)**: 모델이 이미 사용 가능한 상태에서는 누구나 이를 이용해 애플리케이션을 개발할 수 있습니다. 이 계층은 지난 2년 동안 가장 많은 변화가 있었으며 여전히 빠르게 진화하고 있습니다. 애플리케이션 개발은 평가, 프롬프트 엔지니어링, AI 애플리케이션 인터페이스 제공을 포함합니다.\n",
    "\n",
    "이 세 가지 계층과 각 계층에 해당하는 책임의 예시는 **Figure 1-11**에서 확인할 수 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_11.png\" width=800>\n",
    "\n",
    "기본 모델(foundation models)과 함께 생태계가 어떻게 진화했는지 이해하기 위해, 2024년 3월에 GitHub에서 최소 500개의 별(star)을 받은 모든 AI 관련 저장소를 검색했습니다. GitHub의 보편적인 사용을 고려할 때, 이 데이터는 생태계를 이해하는 좋은 지표라고 생각합니다. 제 분석에는 애플리케이션 개발과 모델 개발 계층의 산출물인 애플리케이션과 모델에 해당하는 저장소도 포함되었습니다. 총 920개의 저장소를 발견했으며, **Figure 1-12**는 각 카테고리의 월별 누적 저장소 수를 보여줍니다.\n",
    " \n",
    "<img src=\"images/fig_01_12.png\" width=800>\n",
    "\n",
    "2023년 Stable Diffusion과 ChatGPT 도입 이후, AI 도구의 수가 크게 증가했음을 보여줍니다. 2023년에 가장 큰 증가를 보인 범주는 애플리케이션과 애플리케이션 개발이었습니다. 인프라스트럭처 계층도 약간의 성장을 보였지만, 다른 계층에서의 성장에 비하면 훨씬 적었습니다. 이는 예상된 결과로, 모델과 애플리케이션이 변화했더라도 리소스 관리, 제공, 모니터링 등과 같은 인프라스트럭처의 요구 사항은 여전히 동일하기 때문입니다.\n",
    "\n",
    "이제 다음 요점으로 넘어가겠습니다. 기본 모델(foundation models)에 대한 흥분감은 새로운 것이지만, AI 애플리케이션 구축의 원칙은 여전히 동일합니다. 기업의 사용 사례에서는 여전히 AI 애플리케이션이 비즈니스 문제를 해결해야 하며, 따라서 비즈니스 지표를 ML 지표와 연결하거나 그 반대로 연결하는 것이 중요합니다. 여전히 체계적인 실험이 필요합니다. 전통적인 ML 엔지니어링에서는 다양한 하이퍼파라미터로 실험을 진행합니다. 반면 기본 모델에서는 다양한 프롬프트와 샘플링 변수로 실험을 진행합니다. (샘플링 변수에 대한 내용은 2장에서 논의됩니다.) 우리는 여전히 모델을 더 빠르고 저렴하게 실행하고자 합니다. 피드백 루프를 설정하여 프로덕션 데이터를 기반으로 애플리케이션을 반복적으로 개선하는 것이 여전히 중요합니다.\n",
    "\n",
    "이는 지난 10년 동안 ML 엔지니어들이 배우고 공유해온 많은 것이 여전히 적용 가능함을 의미합니다. 이러한 공유된 학습은 모두가 AI 애플리케이션 구축을 시작하는 데 더 쉽게 접근할 수 있도록 만듭니다.\n",
    "\n",
    "### **AI 엔지니어링 vs. ML 엔지니어링**\n",
    "\n",
    "AI 애플리케이션을 배포하는 변치 않는 원칙은 좋은 소식입니다. 그러나 이제는 상황이 어떻게 변했는지를 살펴보는 것이 더 중요합니다. 팀은 새로운 AI 사용 사례에 맞게 기존 플랫폼을 적응시키고자 합니다. 개발자들은 새로운 시장에서 경쟁력을 유지하기 위해 어떤 기술을 배워야 하는지에 관심이 있습니다.\n",
    "\n",
    "높은 수준에서 보면, 오늘날 기본 모델을 사용하여 애플리케이션을 구축하는 것은 기존의 ML 엔지니어링과 다음 세 가지 주요 방식에서 다릅니다.\n",
    "\n",
    "1. **기본 모델이 없을 경우**, 애플리케이션을 위해 자체 모델을 훈련해야 합니다. AI 엔지니어링에서는 다른 사람이 이미 훈련한 모델을 사용합니다. 즉, AI 엔지니어링은 모델링과 훈련보다는 프롬프트 엔지니어링과 파인튜닝과 같은 모델 적응 기술에 더 집중합니다.\n",
    "\n",
    "2. **AI 엔지니어링은 기존 ML 엔지니어링보다 더 큰 모델을 다룹니다.** 더 큰 모델은 다루기 더 어렵고, 더 많은 컴퓨팅 리소스를 사용하며, 더 큰 지연 시간을 유발합니다. 이는 더 효율적인 훈련과 추론 최적화에 대한 압박이 커진다는 것을 의미합니다. 계산 집약적인 모델의 결과로, 많은 기업들이 이제 더 많은 GPU를 필요로 하고 이전보다 더 큰 컴퓨팅 클러스터를 사용하게 되었습니다. 이는 GPU와 대형 클러스터를 다룰 줄 아는 엔지니어의 필요성이 증가했음을 의미합니다.\n",
    "\n",
    "3. **AI 엔지니어링은 개방형 출력을 생성할 수 있는 모델을 다룹니다.** 개방형 출력은 모델이 더 많은 작업에 사용될 수 있도록 유연성을 제공하지만, 평가하기가 더 어렵습니다. 이로 인해 평가가 AI 엔지니어링에서 훨씬 더 큰 문제가 됩니다.\n",
    "\n",
    "간단히 말해, AI 엔지니어링은 ML 엔지니어링과 다릅니다. AI 엔지니어링은 모델 개발보다는 모델을 적응시키고 평가하는 데 더 중점을 둡니다. 이 장에서 모델 적응에 대해 여러 번 언급했으므로, 계속하기 전에 모델 적응이 무엇을 의미하는지 같은 이해를 공유하고 싶습니다. 일반적으로, 모델 적응 기술은 모델 가중치를 업데이트해야 하는지 여부에 따라 두 가지 범주로 나눌 수 있습니다.\n",
    "\n",
    "**프롬프트 엔지니어링(prompt engineering)** 은 모델 가중치를 업데이트할 필요가 없는 적응 기술입니다. 모델 자체를 변경하지 않고, 컨텍스트 입력에 지침과 예제를 제공하여 모델을 적응시킵니다. RAG(정보 증강 검색, Retrieval Augmented Generation)는 프롬프트 엔지니어링의 한 부분입니다. RAG에서는 외부 데이터베이스에서 검색된 정보를 사용해 프롬프트를 확장합니다. 프롬프트 엔지니어링은 시작하기 쉽고 더 적은 데이터가 필요합니다. 이를 통해 상당한 거리를 나아갈 수 있으며, 많은 성공적인 애플리케이션이 프롬프트 엔지니어링만으로 구축되었습니다. 이러한 사용의 용이성 덕분에 더 많은 모델을 실험할 수 있어, 애플리케이션에 예상외로 적합한 모델을 찾을 가능성이 높아집니다. 그러나 프롬프트 엔지니어링은 복잡한 애플리케이션이나 엄격한 성능 요구 사항을 가진 애플리케이션에는 충분하지 않을 수 있습니다.\n",
    "\n",
    "**파인튜닝(finetuning)** 과 **추론 최적화(inference optimization)** 는 모델 가중치를 업데이트해야 하는 기술입니다. 모델에 변경을 가해 모델을 적응시키는 과정입니다. 고수준에서 이러한 기술은 더 복잡하고 더 많은 데이터를 필요로 하지만, 품질과 속도 측면에서 모델의 품질을 크게 향상시킬 수 있습니다. 모델 가중치를 변경하지 않고는 불가능한 작업이 많습니다. 예를 들어, 모델의 크기를 줄여 더 빠르고 작게 만들거나, 훈련 중 노출되지 않았던 새로운 작업에 모델을 적응시키는 경우가 이에 해당합니다.\n",
    "\n",
    "이제 애플리케이션 개발 계층과 모델 개발 계층으로 시선을 돌려, AI 엔지니어링과 함께 각 계층이 어떻게 변화했는지 살펴보겠습니다.\n",
    "\n",
    "**모델 개발(Model development)**\n",
    "\n",
    "모델 개발은 전통적인 ML 엔지니어링과 가장 많이 연관된 계층입니다. 세 가지 주요 책임이 있습니다: **모델링 및 훈련**, **데이터셋 엔지니어링**, **추론 최적화**입니다.\n",
    "\n",
    "**모델링 및 훈련(Modeling and training)**\n",
    "\n",
    "모델링 및 훈련은 모델 아키텍처를 설계하고 이를 훈련하며 파인튜닝하는 과정을 의미합니다. 이 범주에 포함되는 도구의 예로는 Google의 **TensorFlow**, HuggingFace의 **Transformers**, Meta의 **PyTorch**가 있습니다.\n",
    "\n",
    "ML 모델을 개발하는 데는 전문적인 ML 지식이 필요합니다. 이는 클러스터링, 로지스틱 회귀, 의사 결정 트리, 협업 필터링과 같은 다양한 ML 알고리즘뿐만 아니라, 피드포워드, 순환(Recurrent), 컨볼루션(Convolutional), 트랜스포머(Transformer)와 같은 신경망 아키텍처를 이해하는 것을 요구합니다. 또한, 훈련 과정에 관련된 개념, 예를 들어 경사 하강법, 목적 함수, 손실 함수, 정규화 등도 이해해야 합니다.\n",
    "\n",
    "기본 모델의 가용성 덕분에, ML 지식은 더 이상 AI 애플리케이션을 구축하는 데 필수 조건이 아닙니다. 저는 경사 하강법에 대해 배우는 데 전혀 관심이 없으면서도 멋지고 성공적인 AI 애플리케이션을 구축한 많은 개발자를 만났습니다. 그럼에도 불구하고 ML 지식은 여전히 가치가 있습니다. 이는 기본 모델을 사용자 요구에 맞게 더 잘 적응시키기 위해 사용할 수 있는 도구의 범위를 확장시켜줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**훈련, 사전 훈련, 파인튜닝의 차이점에 대하여**\n",
    "\n",
    "**훈련(training)** 이라는 용어는 종종 **사전 훈련(pre-training)** 과 **파인튜닝(finetuning)** 모두를 대신해서 사용될 수 있습니다. 훈련은 항상 모델의 가중치를 변경하는 작업을 포함하지만, 모델 가중치를 변경하는 모든 작업이 훈련으로 간주되지는 않습니다. 예를 들어, 양자화(quantization)는 모델 가중치의 정밀도를 낮추는 과정인데, 기술적으로 모델 가중치를 변경하지만 훈련으로는 간주되지 않습니다.\n",
    "\n",
    "사전 훈련과 파인튜닝은 서로 다른 훈련 단계에 해당합니다:\n",
    "\n",
    "- **사전 훈련(Pre-training)**: 처음부터 모델을 훈련하는 것으로, 모델의 가중치는 무작위로 초기화됩니다.\n",
    "\n",
    "- **파인튜닝(Finetuning)**: 이전에 훈련된 모델을 계속해서 훈련하는 과정입니다. 모델의 가중치는 이전 훈련 과정에서 얻어진 것입니다. 이미 모델이 훈련되었기 때문에 파인튜닝에 필요한 자원(데이터 및 컴퓨팅 등)은 사전 훈련에 비해 일반적으로 적게 소모됩니다.\n",
    "\n",
    "사전 훈련과 파인튜닝은 하나의 연속된 스펙트럼을 구성합니다. 파인튜닝은 사전 훈련과 별개로 진행될 수 있습니다. 예를 들어, 한 회사가 모델을 사전 훈련시키고, 다른 회사가 이를 파인튜닝할 수도 있습니다. 두 과정의 절차와 도구는 매우 유사하지만, 주요 차이점은 필요한 자원의 양입니다.\n",
    "\n",
    "일부 사람들은 훈련이라는 용어를 **프롬프트 엔지니어링(prompt engineering)** 에 사용하기도 하는데, 이는 정확하지 않습니다. 저는 한 **비즈니스 인사이더(Business Insider)** 기사에서 저자가 **ChatGPT를 훈련시켜 자신의 어린 시절을 모방하게 했다** 고 말하는 내용을 읽었습니다. 그녀는 자신의 어린 시절 일기를 ChatGPT에 입력하여 이를 수행했다고 설명했습니다.\n",
    "\n",
    "구어체에서 저자가 **training(훈련)** 이라는 단어를 사용하는 것은 맞습니다. 그녀는 모델에게 어떤 작업을 가르치고 있기 때문입니다. 하지만 기술적으로는 모델에 컨텍스트 입력을 통해 무엇을 해야 할지 가르치는 경우, 이는 **프롬프트 엔지니어링(prompt engineering)** 입니다. 마찬가지로 **finetuning(파인튜닝)** 이라는 용어를 사용하는 사람들도 있지만 실제로는 프롬프트 엔지니어링을 하는 경우가 많습니다.\n",
    "\n",
    "---\n",
    "\n",
    "**데이터셋 엔지니어링(Dataset engineering)**\n",
    "\n",
    "**데이터셋 엔지니어링**은 AI 모델 훈련 및 적응에 필요한 데이터를 생성, 선별, 라벨링하는 작업과 특징 엔지니어링을 의미합니다. 데이터셋 엔지니어링의 중요도는 필요한 데이터의 양에 따라 달라집니다. 모델을 처음부터 훈련하는 것은 일반적으로 파인튜닝보다 더 많은 데이터를 요구하며, 파인튜닝은 다시 프롬프트 엔지니어링보다 더 많은 데이터를 필요로 합니다.\n",
    "\n",
    "전통적인 ML 엔지니어링, 특히 테이블형 데이터를 다룰 때는 데이터 조작이 주로 특징 엔지니어링을 중심으로 이루어졌습니다. 하지만 기본 모델의 경우, 데이터 조작은 특징 엔지니어링보다는 중복 제거, 토큰화, 품질 관리에 더 중점을 둡니다. 여기에는 민감한 정보나 유해 데이터를 제거하는 작업도 포함됩니다. 데이터셋 엔지니어링은 **5장**에서 중점적으로 다루게 됩니다.\n",
    "\n",
    "모델 적응에 필요한 데이터 양과 상관없이, 데이터 전문 지식은 매우 유용합니다. 이는 기본 모델에 사용된 훈련 데이터를 이해하는 데 도움을 주며, 모델 성능에 대한 힌트를 제공하고 모델을 가장 효과적으로 사용하는 방법을 파악하는 데 도움이 됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "**추론 최적화(Inference optimization)**\n",
    "\n",
    "**추론 최적화**는 모델을 더 작고, 빠르고, 더 저렴하게 만드는 것을 의미합니다. 추론 최적화 기법의 예로는 양자화(quantization), 증류(distillation), 분해(factorization), 그리고 더 빠른 디코딩을 위한 모델 변경 등이 있습니다.\n",
    "\n",
    "추론 최적화는 항상 ML 엔지니어링에서 중요했습니다. 사용자들은 더 빠른 모델을 항상 선호하며, 기업은 더 저렴한 추론에서 혜택을 얻을 수 있습니다. 그러나 기본 모델이 등장하면서 추론 최적화의 중요성은 더욱 커졌습니다.\n",
    "\n",
    "기본 모델과 관련된 한 가지 도전 과제는 그것들이 종종 **자가회귀(autoregressive)** 라는 점입니다. 즉, 출력을 순차적으로 토큰으로 생성합니다. 예를 들어, 모델이 토큰 하나를 생성하는 데 10밀리초가 걸린다면, 100개의 토큰 출력을 생성하는 데 1초가 걸리며 더 긴 출력은 더 많은 시간이 소요됩니다. 사용자는 점점 더 인내심이 부족해지고 있어, AI 애플리케이션의 지연 시간을 일반적인 인터넷 애플리케이션에서 기대되는 **100밀리초** 수준으로 낮추는 것은 큰 도전 과제입니다. 추론 최적화는 산업과 학계 모두에서 활발한 연구 분야가 되었습니다. 추론 최적화 접근법은 **7장**에서 중점적으로 다룰 것입니다.\n",
    "\n",
    "다음은 AI 엔지니어링과 함께 모델 개발의 다양한 범주의 중요성이 어떻게 변화했는지를 보여주는 요약입니다.\n",
    "\n",
    "**Table 1-4. 기본 모델과 함께 모델 개발의 책임이 어떻게 변화했는가**\n",
    "\n",
    "| **범주**                | **전통적인 ML에서의 구축**                              | **기본 모델에서의 구축**                               |\n",
    "|----------------------|--------------------------------------------------|--------------------------------------------------|\n",
    "| **모델링 및 훈련**       | 처음부터 모델을 훈련하려면 ML 지식이 필요합니다.              | ML 지식은 있으면 좋지만 필수는 아닙니다.                    |\n",
    "| **데이터셋 엔지니어링**   | 특징 엔지니어링에 중점을 둡니다, 특히 테이블형 데이터의 경우.     | 특징 엔지니어링보다 데이터 중복 제거, 토큰화, 품질 관리에 더 중점을 둡니다. |\n",
    "| **추론 최적화**          | 중요함                                                | 더 중요함                                               |\n",
    "\n",
    "---\n",
    "\n",
    "**애플리케이션 개발(Application development)**\n",
    "\n",
    "전통적인 ML 엔지니어링에서는 팀이 독자적인 모델을 사용해 애플리케이션을 구축하며, 모델의 품질이 차별화 요소가 됩니다. 반면, 기본 모델을 사용하는 경우 여러 팀이 동일한 모델을 사용하므로, 차별화는 애플리케이션 개발 과정을 통해 이루어져야 합니다.\n",
    "\n",
    "애플리케이션 개발 계층은 다음과 같은 책임으로 구성됩니다: **평가(evaluation)**, **프롬프트 엔지니어링(prompt engineering)**, **AI 인터페이스(AI interface)**.\n",
    "\n",
    "---\n",
    "\n",
    "**평가(Evaluation)**\n",
    "\n",
    "**평가(Evaluation)** 는 두 가지 목표를 가집니다: **기본 모델을 평가하여 작업에 가장 적합한 모델을 선택하는 것**, 그리고 **선택한 모델을 적응시키는 과정에서의 진행 상황을 평가하는 것** 입니다.\n",
    "\n",
    "평가는 ML 엔지니어링에서 항상 중요했지만, 기본 모델에서는 그 중요성이 더욱 커집니다. 그 이유는 두 가지입니다. 첫째, **기본 모델의 출력이 개방형**이기 때문입니다. 전통적인 ML 작업(예: **사기 탐지, 추천 시스템, 수익 예측**)에서는 비교할 수 있는 예상 결과(ground truths)가 명확히 존재합니다. 모델의 출력이 예상 결과와 다르면 모델이 잘못된 것입니다. 하지만 **챗봇이나 이미지 생성**과 같은 작업에서는 프롬프트에 대한 가능한 응답이 너무 많기 때문에 모델의 출력을 비교할 완벽한 결과 목록을 만드는 것이 불가능합니다.\n",
    "\n",
    "둘째 이유는 모델의 용량과 AI 엔지니어링 기술이 계속 발전하고 있기 때문입니다. 새로운 사용 사례가 매일 발견되면서 평가 벤치마크도 뒤처지지 않기 위해 노력하고 있습니다. 벤치마크에서 모델 A가 모델 B보다 더 나은 성능을 보였다고 해서, 실제 프로덕션에서도 항상 모델 A가 더 나은 성능을 보인다는 보장은 없습니다.\n",
    "\n",
    "수많은 평가 기술이 존재하며, 그중 많은 것이 맞춤형(custom)이라는 점도 평가를 더 어렵게 만듭니다. **2023년 12월**, Google은 ChatGPT에 대응하기 위해 **Gemini**를 출시했습니다. 기술 보고서에서 Google은 Gemini가 **MMLU**라는 벤치마크에서 ChatGPT보다 우수하다고 주장했습니다. Google은 자체적으로 개발한 프롬프트 엔지니어링 기법인 **CoT@32**를 사용하여 Gemini를 평가했습니다. 반면, **5-shot 학습**이라는 다른 프롬프트 엔지니어링 기법을 사용할 경우, **ChatGPT**가 더 좋은 성능을 보이는 것으로 나타났습니다. 이는 **표 1-5**에 나와 있습니다.\n",
    "\n",
    "**표 1-5. 서로 다른 프롬프트가 모델의 성능에 매우 다른 영향을 미칠 수 있음을 보여주는 Gemini 기술 보고서 (2023년 12월).**\n",
    "\n",
    "| 모델          | MMLU 성능       | 프롬프트 조건         |\n",
    "|---------------|-----------------|-----------------------|\n",
    "| Gemini Ultra  | 90.04%          | CoT@32               |\n",
    "| Gemini Pro    | 79.13%          | CoT@8                |\n",
    "| GPT-4         | 87.29%          | CoT@32 (API를 통해)  |\n",
    "| GPT-3.5       | 70%             | 5-shot               |\n",
    "| PaLM 2-L      | 78.4%           | 5-shot               |\n",
    "| Claude 2      | 78.5%           | 5-shot CoT           |\n",
    "| Inflection-2  | 79.6%           | 5-shot               |\n",
    "| Grok 1        | 73.0%           | 5-shot               |\n",
    "| Llama-2       | 68.0%           | 5-shot               |\n",
    "\n",
    "추가 성능 데이터:\n",
    "- Gemini Ultra: 5-shot에서 83.7%\n",
    "- Gemini Pro: 5-shot에서 71.8%\n",
    "- GPT-4: 5-shot에서 86.4% (보고됨)\n",
    "\n",
    "\n",
    "**프롬프트 엔지니어링과 문맥 구성**\n",
    "\n",
    "**프롬프트 엔지니어링**은 모델 가중치를 변경하지 않고 입력만으로 AI 모델이 원하는 동작을 표현하도록 하는 것입니다. Gemini 평가 사례는 프롬프트 엔지니어링이 모델 성능에 미치는 영향을 강조합니다. 다른 프롬프트 엔지니어링 기술을 사용하여 Gemini Ultra의 MMLU 성능이 83.7%에서 90.04%로 향상되었습니다.\n",
    "\n",
    "모델은 단순히 프롬프트만으로도 놀라운 작업을 수행할 수 있습니다. 적절한 지시를 통해 모델이 원하는 작업을 사용자가 선택한 형식으로 수행할 수 있습니다. 프롬프트 엔지니어링은 단순히 모델에게 무엇을 해야 할지 지시하는 것뿐만 아니라, 주어진 작업을 수행하기 위해 필요한 문맥과 도구를 제공하는 것도 포함합니다. 긴 문맥이 요구되는 복잡한 작업의 경우, 모델이 과거 기록을 추적할 수 있도록 메모리 관리 시스템을 제공해야 할 수도 있습니다.  \n",
    "\n",
    "**5장**에서는 프롬프트 엔지니어링에 대해 다루고, **6장**에서는 문맥 구성에 대해 논의합니다.\n",
    "\n",
    "**AI 인터페이스(AI interface)**\n",
    "\n",
    "**AI 인터페이스**는 최종 사용자가 AI 애플리케이션과 상호작용할 수 있도록 인터페이스를 만드는 것을 의미합니다. 기본 모델 이전에는 AI 모델을 개발할 수 있는 충분한 자원을 가진 조직만이 AI 애플리케이션을 개발할 수 있었습니다. 이러한 애플리케이션은 종종 조직의 기존 제품에 통합되었습니다. 예를 들어, **사기 탐지**는 Stripe, Venmo, Paypal에 통합되었고, **추천 시스템**은 Netflix, TikTok, Spotify와 같은 소셜 네트워크 및 미디어 애플리케이션의 일부가 되었습니다.\n",
    "\n",
    "**기본 모델**이 등장하면서 누구나 AI 애플리케이션을 구축할 수 있게 되었습니다. AI 애플리케이션은 독립형 제품일 수도 있고 다른 제품에 통합될 수도 있습니다. 이제 사용자가 이러한 새로운 AI 애플리케이션과 상호작용할 수 있는 새로운 **인터페이스**가 필요하고, 개발자가 AI 애플리케이션을 다른 제품에 통합할 수 있는 새로운 도구 세트가 필요합니다. 다음은 AI 애플리케이션에서 점점 인기를 얻고 있는 인터페이스의 몇 가지 예시입니다:\n",
    "\n",
    "- **웹 및 데스크톱 애플리케이션**  \n",
    "- **브라우저 확장 프로그램** (사용자가 웹 탐색 중 AI 모델에 빠르게 쿼리할 수 있도록 지원)  \n",
    "- **봇** (Slack, Discord, WeChat, WhatsApp 등과 같은 채팅 애플리케이션에서 작동)  \n",
    "- **플러그인** (개발자가 VSCode, Shopify, Microsoft Office와 같은 애플리케이션에 AI를 통합하도록 지원). 플러그인 접근 방식은 **도구를 사용해 복잡한 작업을 수행하는 에이전트(agent)** 와 같은 AI 애플리케이션에서 일반적으로 사용됩니다.\n",
    "\n",
    "다음은 **AI 엔지니어링**과 **ML 엔지니어링**에서 애플리케이션 개발의 다양한 범주의 중요도가 어떻게 변화했는지를 보여주는 요약입니다.\n",
    "\n",
    "**Table 1-6. AI 엔지니어링과 ML 엔지니어링에서 애플리케이션 개발 범주의 중요성**\n",
    "\n",
    "| **범주**            | **전통적 ML 구축**       | **기본 모델을 활용한 구축**      |\n",
    "|-------------------|----------------------|---------------------------|\n",
    "| **AI 인터페이스**     | 덜 중요                  | 중요                          |\n",
    "| **프롬프트 엔지니어링** | 적용되지 않음               | 중요                          |\n",
    "| **오케스트레이션**     | 중요                     | 중요                          |\n",
    "| **평가**             | 중요                     | 더 중요                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AI 엔지니어링 대 풀스택 엔지니어링**\n",
    "\n",
    "애플리케이션 개발, 특히 인터페이스에 대한 강조가 증가하면서 AI 엔지니어링은 풀스택 개발에 더욱 가까워지고 있습니다. 인터페이스의 중요성이 증가함에 따라 더 많은 프론트엔드 엔지니어를 유치하기 위해 AI 도구 설계 방식이 변화하고 있습니다. 전통적으로, 머신러닝(ML) 엔지니어링은 Python 중심이었습니다. 기반 모델 이전에는 가장 인기 있는 ML 프레임워크들이 대부분 Python API를 지원했습니다. 오늘날에도 Python은 여전히 인기가 많지만, LangChain.js, Transformers.js, OpenAI의 Node 라이브러리, Vercel의 AI SDK와 함께 JavaScript API에 대한 지원도 증가하고 있습니다.\n",
    "\n",
    "많은 AI 엔지니어가 전통적인 ML 배경을 가지고 있지만, 점점 더 많은 엔지니어가 웹 개발 또는 풀스택 배경에서 오고 있습니다. 풀스택 엔지니어가 전통적인 ML 엔지니어보다 가지는 이점은 아이디어를 빠르게 데모로 변환하고, 피드백을 얻고, 반복할 수 있다는 점입니다.\n",
    "\n",
    "전통적인 ML 엔지니어링에서는 보통 데이터를 수집하고 모델을 훈련하는 것으로 시작하며, 제품 개발은 마지막 단계에서 이루어집니다. 그러나 오늘날에는 이미 사용할 수 있는 AI 모델들이 많아, 제품을 먼저 개발한 후에 데이터와 모델에 투자하는 것이 가능합니다. 이는 제품이 가능성을 보인 후에만 이루어질 수 있으며, **그림 1-14**에 시각화되어 있습니다.\n",
    "\n",
    "<img src=\"./images/fig_01_14.png\" alt=\"Figure 1-14\" width=\"800\">\n",
    "\n",
    "전통적인 머신러닝(ML) 엔지니어링에서는 모델 개발과 제품 개발이 종종 분리된 프로세스로 이루어지며, 많은 조직에서 ML 엔지니어는 제품 결정에 거의 관여하지 않습니다. 그러나 기반 모델이 등장하면서 AI 엔지니어는 제품 구축에 훨씬 더 많이 관여하게 되었습니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "전통적인 머신러닝(ML) 엔지니어링에서는 모델 개발과 제품 개발이 종종 분리된 프로세스였으며, 많은 조직에서 ML 엔지니어는 제품 결정에 거의 관여하지 않았습니다. 그러나 기반 모델이 등장하면서 AI 엔지니어는 제품 구축에 훨씬 더 많이 관여하게 되었습니다.\n",
    "\n",
    "이 장은 두 가지 목적을 가지고 작성되었습니다. 첫 번째는 기반 모델의 가용성 덕분에 하나의 학문으로서 AI 엔지니어링의 등장을 설명하는 것입니다. 두 번째는 이러한 모델 위에서 애플리케이션을 구축하는 데 필요한 프로세스를 개괄적으로 설명하는 것입니다. 이 장이 이 목표를 달성했기를 바랍니다. 개괄적인 장으로서, 여러 개념을 가볍게 다뤘으며, 이 개념들은 책의 나머지 부분에서 더 자세히 탐구될 것입니다.\n",
    "\n",
    "이 장은 최근 몇 년간 AI의 급격한 진화를 논의했습니다. 언어 모델에서 대규모 언어 모델로의 전환을 시작으로, **자기지도학습(self-supervision)**이라는 훈련 접근 방식을 통해 이루어진 가장 주목할 만한 변화를 다뤘습니다. 이어서 언어 모델이 다른 데이터 양식을 어떻게 통합하여 기반 모델이 되었는지, 그리고 기반 모델이 AI 엔지니어링의 부상을 어떻게 이끌었는지 추적했습니다.\n",
    "\n",
    "AI 엔지니어링의 급속한 성장은 기반 모델의 새로운 기능으로 가능해진 다양한 애플리케이션들에 의해 촉진되고 있습니다. 이 장에서는 소비자와 기업 모두를 위한 가장 성공적인 애플리케이션 패턴을 논의했습니다. 이미 많은 AI 애플리케이션이 생산에 투입되고 있음에도 불구하고, 우리는 여전히 AI 엔지니어링의 초기 단계에 있으며, 앞으로도 무수히 많은 혁신이 만들어질 것입니다.\n",
    "\n",
    "애플리케이션을 구축하기 전에 종종 간과되지만 중요한 질문은 '이것을 구축해야 하는가?'입니다. 이 장에서는 이 질문과 AI 애플리케이션을 구축할 때 고려해야 할 주요 사항들을 함께 논의했습니다.\n",
    "\n",
    "---\n",
    "\n",
    "1. 이 책에서는 **전통적인 ML**이란 기반 모델 이전의 모든 ML을 지칭합니다.\n",
    "\n",
    "2. 비영어권 언어에서는 단일 유니코드 문자도 여러 개의 토큰으로 표현될 수 있습니다.\n",
    "\n",
    "3. **오토리그레시브(autoregressive) 언어 모델**은 **인과적(causal) 언어 모델**로도 언급됩니다.\n",
    "\n",
    "4. 기술적으로, BERT와 같은 **마스크 언어 모델**도 텍스트 생성에 사용할 수 있습니다. 다만, 상당한 노력이 필요합니다.\n",
    "\n",
    "5. 실제 데이터 라벨링 비용은 작업의 복잡성, 데이터셋 크기(대규모 데이터셋은 보통 단위당 비용이 더 낮음), 라벨링 서비스 제공업체에 따라 달라집니다. 예를 들어, 2024년 9월 기준, **Amazon SageMaker Ground Truth**는 50,000개 미만의 이미지 라벨링에 대해 이미지당 8센트를 청구하지만, 100만 개 이상의 이미지 라벨링에 대해서는 이미지당 2센트만 청구합니다.\n",
    "\n",
    "6. 이는 인간이 대화를 언제 멈춰야 하는지를 아는 것이 중요한 것과 유사합니다.\n",
    "\n",
    "7. 학교에서는 모델 매개변수(parameters)가 모델 가중치(weights)와 모델 편향(biases)을 모두 포함한다고 배웠습니다. 하지만 오늘날에는 일반적으로 **모델 가중치**를 모든 매개변수의 통칭으로 사용합니다.\n",
    "\n",
    "8. 더 큰 모델이 더 많은 훈련 데이터를 필요로 한다는 것은 직관에 반하는 것처럼 보입니다. 모델이 더 강력하다면 더 적은 예제로 학습할 수 있어야 하지 않을까요? 그러나 우리는 동일한 데이터를 사용하여 소형 모델의 성능에 맞추려는 것이 아니라, 모델 성능을 극대화하려는 것입니다.\n",
    "\n",
    "9. 참고로, 미국의 공립 초등학교 및 중등학교 교육에 대한 전체 지출은 약 9,000억 달러이며, 이는 미국 내 AI 투자액의 9배에 해당합니다.\n",
    "\n",
    "10. 재미있는 사실: 2024년 9월 16일 기준, **theresanaiforthat.com** 웹사이트는 16,814개의 AI를 14,688개의 작업과 4,803개의 직업에 연결하고 있습니다.\n",
    "\n",
    "11. 다양한 AI 애플리케이션을 탐구하는 것은 제가 이 책을 쓰면서 가장 좋아하는 부분 중 하나입니다. 사람들이 무엇을 만드는지 보는 것은 정말 재미있습니다. 제가 추적하는 **오픈 소스 AI 애플리케이션 목록**은 매 12시간마다 업데이트됩니다.\n",
    "\n",
    "12. 기업들은 보통 광고와 마케팅에 많은 비용을 지출하기 때문에, 이러한 영역에서의 자동화는 큰 절감 효과를 낼 수 있습니다. 평균적으로 기업 예산의 11%가 마케팅에 사용됩니다. **\"산업별 마케팅 예산\"(Christine Moorman, WSJ, 2017)**을 참조하세요.\n",
    "\n",
    "13. 이 책을 쓰는 과정에서 AI는 매우 유용했습니다. 저는 AI가 글쓰기 과정의 많은 부분을 자동화할 수 있을 것이라고 봅니다. 소설을 쓸 때, 종종 AI에게 다음에 어떤 일이 일어날지 또는 특정 상황에서 캐릭터가 어떻게 반응할지에 대한 아이디어를 제안받습니다. 어떤 유형의 글쓰기가 자동화될 수 있고, 어떤 것이 불가능한지를 아직 평가 중입니다.\n",
    "\n",
    "14. 제 가설은 우리가 인터넷에서의 콘텐츠를 너무 불신하게 되어 신뢰하는 사람이나 브랜드가 생성한 콘텐츠만 읽게 될 것이라는 것입니다.\n",
    "\n",
    "15. Apple과 Amazon이 Siri와 Alexa에 생성 AI 발전을 통합하는 데 왜 이렇게 오래 걸리는지 놀랍습니다. 한 친구는 이러한 회사들이 품질과 규정 준수에 대해 더 높은 기준을 가지고 있으며, 음성 인터페이스 개발이 챗 인터페이스 개발보다 더 오래 걸리기 때문이라고 생각합니다.\n",
    "\n",
    "16. 참고: 저는 Convai의 자문 위원입니다.\n",
    "\n",
    "17. 현재 Google Photos에 40,000장이 넘는 사진과 동영상이 있습니다. AI가 없었다면 제가 원하는 시점에 원하는 사진을 검색하는 것은 거의 불가능했을 것입니다.\n",
    "\n",
    "18. 개인적으로도 AI가 데이터와 그래프를 설명하는 데 매우 유용하다는 것을 발견했습니다. 정보가 너무 많아 혼란스러운 그래프를 보면, ChatGPT에게 이를 요약해달라고 요청합니다.\n",
    "\n",
    "19. 작은 스타트업은 제품 초점을 우선시해야 하며, 한 사람이라도 \"둘러보기\"에 할애할 여유가 없습니다.\n",
    "\n",
    "20. 생성 AI 초창기에는 AI 스타트업이 OpenAI 또는 Claude 래퍼라는 농담이 돌았습니다.\n",
    "\n",
    "21. 이 책을 쓰는 동안, \"데이터 플라이휠(data flywheel)\"이라는 말을 듣지 않고 AI 스타트업과 대화하는 것이 거의 불가능했습니다.\n",
    "\n",
    "22. 참고: 저는 Photoroom의 투자자입니다.\n",
    "\n",
    "23. 한 포춘 500 기업의 AI 책임자는 \"10개의 GPU로 작업하는 방법은 알고 있지만, 1,000개의 GPU로 작업하는 방법은 모른다\"고 말했습니다.\n",
    "\n",
    "24. 이들에게는 **엄청난 보상 패키지**가 제공됩니다.\n",
    "\n",
    "25. \"사전 훈련(pre-training)\"과 \"사후 훈련(post-training)\"이라는 용어에 상상력이 부족하다고 느낀다면, 혼자가 아닙니다. AI 연구 커뮤니티는 많은 것을 잘하지만, 이름 짓는 것은 그렇지 못합니다. 예를 들어 \"대규모 언어 모델\"이라는 용어는 \"대규모(large)\"라는 단어의 모호성 때문에 과학적 용어라고 보기 어렵습니다. 그리고 \"X가 전부다(X is all you need)\"라는 제목의 논문이 더 이상 나오지 않기를 바랍니다.\n",
    "\n",
    "26. **Streamlit, Gradio, Plotly Dash**는 AI 웹 애플리케이션을 구축하는 데 일반적으로 사용되는 도구입니다.\n",
    "\n",
    "27. **Anton Bacaj**는 \"AI 엔지니어링은 소프트웨어 엔지니어링에 AI 모델을 스택에 추가한 것일 뿐이다\"고 말했습니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
