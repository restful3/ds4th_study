{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장: 기본 모델을 활용한 AI 애플리케이션 구축 개론\n",
    "\n",
    "만약 제가 AI의 2020년 이후를 한 단어로 표현해야 한다면, 그것은 ‘**규모**(scale)’일 것입니다. ChatGPT, Google의 Gemini, Midjourney와 같은 애플리케이션 뒤에 있는 AI 모델들은 전 세계 전력의 적지 않은 부분을 소비할 정도로 엄청난 규모에 도달했으며, 공용 인터넷 데이터를 훈련에 사용하는 데 있어 고갈될 위험에 직면해 있습니다.\n",
    "\n",
    "AI 모델의 규모 확장은 두 가지 주요 결과를 초래합니다.  \n",
    "첫째, AI 모델은 더 강력해지고 더 많은 작업을 처리할 수 있게 되면서 더 많은 애플리케이션을 가능하게 만들었습니다. 더 많은 개인과 팀이 AI를 활용하여 생산성을 높이고 경제적 가치를 창출하며 삶의 질을 향상시키고 있습니다.\n",
    "\n",
    "둘째, 대규모 언어 모델(LLM)을 훈련하려면 데이터, 계산 자원, 그리고 전문 인력이 필요하며, 이는 소수의 조직만이 감당할 수 있습니다. 이러한 이유로 **서비스형 모델(Model-as-a-Service)**이 등장했으며, 이를 통해 AI를 활용하여 애플리케이션을 구축하고자 하는 사람은 이제 최소한의 초기 투자로도 이를 실현할 수 있습니다.\n",
    "\n",
    "간단히 말해, AI 애플리케이션에 대한 수요는 증가한 반면, 이를 구축하기 위한 진입 장벽은 낮아졌습니다. 이로 인해 손쉽게 활용할 수 있는 모델을 기반으로 애플리케이션을 구축하는 프로세스인 **AI 엔지니어링**은 가장 빠르게 성장하는 엔지니어링 분야 중 하나로 자리 잡았습니다.\n",
    "\n",
    "---\n",
    "\n",
    "기계 학습(ML) 모델을 기반으로 애플리케이션을 구축하는 것은 새로운 일이 아닙니다. 생성형 AI가 등장하기 훨씬 전부터 AI는 제품 추천, 사기 탐지, 고객 이탈 예측 등 다양한 애플리케이션을 이미 지원하고 있었습니다. AI 애플리케이션을 프로덕션화하는 원칙은 변하지 않았지만, 대규모로 손쉽게 사용할 수 있는 새로운 모델 세대는 새로운 가능성과 도전 과제를 제공합니다. 이러한 점이 이 책에서 다루는 주요 초점입니다.\n",
    "\n",
    "---\n",
    "\n",
    "이 장은 **AI 엔지니어링의 폭발적 성장을 촉진한 기본 모델의 부상**으로 시작합니다. 이후, 무엇을 구축할지 영감을 얻고자 하는 사람들을 위해 다양한 애플리케이션 패턴과 실행 전 염두에 두어야 할 주요 고려사항을 설명합니다.\n",
    "\n",
    "마지막으로, 기본 모델로 인해 변화된 **새로운 AI 스택**, 변하지 않은 요소, 그리고 오늘날 AI 엔지니어의 역할이 전통적인 ML 엔지니어와 어떻게 다른지에 대한 개요로 이 장을 마무리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 엔지니어링의 부상\n",
    "\n",
    "기본 모델은 대규모 언어 모델에서 시작되었으며, 이는 다시 언어 모델에서 기원했습니다. ChatGPT와 GitHub의 Copilot과 같은 애플리케이션은 최근의 현상이지만, 언어 모델 자체는 70년이 넘는 역사를 가지고 있습니다. 이 섹션에서는 언어 모델에서 AI 엔지니어링으로의 발전을 가능하게 한 주요 혁신을 추적합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 언어 모델에서 대규모 언어 모델로\n",
    "\n",
    "언어 모델을 확장할 수 있게 한 핵심 기술은 **자기 지도 학습(self-supervision)**입니다. 이 섹션에서는 언어 모델과 자기 지도 학습이 무엇을 의미하는지 간략히 설명합니다. 이미 이 주제에 익숙하다면 이 섹션을 건너뛰어도 좋습니다.\n",
    "\n",
    "---\n",
    "\n",
    "#### 언어 모델\n",
    "\n",
    "언어 모델은 하나 이상의 언어에 대한 통계적 정보를 인코딩합니다. 직관적으로, 이러한 정보는 특정 맥락에서 단어가 나타날 확률을 알려줍니다. 예를 들어, \"내가 가장 좋아하는 색은 __입니다(My favorite color is __)\"라는 맥락에서, 영어를 인코딩한 언어 모델은 \"blue(파란색)\"를 \"car(자동차)\"보다 더 자주 예측해야 합니다.\n",
    "\n",
    "언어의 통계적 특성은 수 세기 전에 발견되었습니다. 1905년에 발표된 이야기 **\"춤추는 남자들(The Adventure of the Dancing Men)\"**에서, 셜록 홈즈는 영어의 간단한 통계 정보를 활용해 신비한 막대 그림 시퀀스를 해독했습니다. 영어에서 가장 많이 사용되는 글자가 'E'라는 점을 바탕으로, 홈즈는 가장 흔한 막대 그림이 'E'를 나타내야 한다고 추론했습니다.\n",
    "\n",
    "그 후, 클로드 섀넌(Claude Shannon)은 더 정교한 통계 기법을 사용해 제2차 세계대전 동안 적의 메시지를 해독했습니다. 그는 영어 모델링 방법에 대한 연구를 1951년 그의 기념비적인 논문 **\"인쇄된 영어의 예측과 엔트로피(Prediction and Entropy of Printed English)\"**에 발표했습니다. 이 논문에서 소개된 개념(예: 엔트로피)은 오늘날 언어 모델링에서도 여전히 사용되고 있습니다.\n",
    "\n",
    "초기에는 언어 모델이 하나의 언어만 처리했습니다. 그러나 오늘날에는 많은 언어 모델이 여러 언어를 다룰 수 있습니다.\n",
    "\n",
    "언어 모델의 기본 단위는 **토큰(token)**입니다. 토큰은 문자, 단어, 또는 단어의 일부(예: \"-tion\")일 수 있으며, 이는 모델에 따라 달라집니다. 예를 들어, ChatGPT의 기반이 되는 GPT-4 모델은 \"I can't wait to build AI applications(나는 AI 애플리케이션을 구축하기를 기다릴 수 없다)\"라는 구문을 9개의 토큰으로 분리합니다. **\"can't\"**라는 단어는 두 개의 토큰(**can**과 **'t**)으로 나뉩니다. OpenAI의 다양한 모델이 텍스트를 어떻게 토큰화하는지 확인하려면 [OpenAI Tokenizer](https://platform.openai.com/tokenizer)를 방문하세요.\n",
    "\n",
    "<img src=\"images/fig_01_01.png\" width=800>\n",
    "\n",
    "텍스트를 토큰으로 나누는 과정을 **토크나이제이션(tokenization)**이라고 합니다. GPT-4의 경우, 평균 토큰은 단어 길이의 약 ¾ 정도입니다. 따라서 100개의 토큰은 대략 75개의 단어에 해당합니다.  \n",
    "\n",
    "모델이 사용할 수 있는 모든 토큰의 집합을 **모델의 어휘(vocabulary)**라고 합니다. 소수의 토큰으로 많은 고유 단어를 구성할 수 있는데, 이는 알파벳의 몇 개의 글자로 많은 단어를 만들 수 있는 방식과 유사합니다. Mixtral 8x7B 모델의 어휘 크기는 32,000입니다. OpenAI의 토크나이제이션 라이브러리인 **tiktoken**에 따르면, GPT-4의 어휘 크기는 100,256입니다.  \n",
    "토크나이제이션 방식과 어휘 크기는 모델 개발자가 결정하며, 이 결정에 대한 내용은 6장에서 더 자세히 논의됩니다.\n",
    "\n",
    "언어 모델에는 두 가지 주요 유형이 있습니다: **마스킹 언어 모델(masked language model)**과 **자가 회귀 언어 모델(autoregressive language model)**입니다.\n",
    "\n",
    "**마스킹 언어 모델**은 문장에서 누락된 단어를 예측하도록 훈련됩니다. 예를 들어, \"My favorite __ is blue(내가 가장 좋아하는 __은 파란색입니다)\"에서 빈칸 앞뒤의 문맥을 사용해 빈칸에 들어갈 단어를 예측할 수 있습니다. 마스킹 언어 모델의 예로는 BERT(Devlin 외, 2018)가 있습니다. 현재 작성 시점에서 마스킹 언어 모델은 주로 감정 분석이나 텍스트 분류와 같은 작업에 사용됩니다.\n",
    "\n",
    "**자가 회귀 언어 모델**은 이전 단어만 사용하여 시퀀스에서 다음 단어를 예측하도록 훈련됩니다. 예를 들어, \"My favorite color is __ (내가 가장 좋아하는 색은 __입니다)\"에서 다음에 올 단어를 예측합니다. 오늘날 자가 회귀 언어 모델은 텍스트 생성 작업에서 선호되는 모델로, 마스킹 언어 모델보다 훨씬 인기가 많습니다. 이 책에서는 별도로 언급하지 않는 한, 언어 모델은 자가 회귀 모델을 의미합니다.\n",
    "\n",
    "언어 모델의 출력은 개방형입니다. 즉, 언어 모델은 고정된 유한한 어휘를 사용하여 무한한 가능한 출력을 생성할 수 있습니다. 개방형 출력을 생성할 수 있는 모델을 **생성형(generative)**이라고 하며, 여기에서 **생성형 AI(generative AI)**라는 용어가 유래되었습니다.\n",
    "\n",
    "언어 모델을 **완성 기계(completion machine)**로 생각할 수 있습니다. 주어진 텍스트(프롬프트)에 대해 해당 텍스트를 완성하려고 시도합니다. 예를 들어:\n",
    "\n",
    "**사용자로부터의 프롬프트**: \"I tried so hard, and got so far (난 정말 열심히 노력했고, 여기까지 왔어)\"  \n",
    "**언어 모델의 완성**: \"But in the end, it doesn’t even matter. (하지만 결국에는, 아무 의미도 없게 되었어.)\"\n",
    "\n",
    "이처럼 간단하게 보이지만, 완성은 매우 강력한 기능입니다. 많은 작업이 완성 작업으로 구성될 수 있기 때문입니다. 예를 들어 번역, 요약, 코딩, 수학 문제 해결 등이 포함됩니다. 프롬프트로 \"How are you in French is... (프랑스어로 'How are you'는...)\"를 주었을 때, 언어 모델은 \"Comment ça va\"로 이를 완성하여 한 언어에서 다른 언어로 효과적으로 번역할 수 있습니다.\n",
    "\n",
    "다음과 같은 프롬프트를 주었을 때:\n",
    "\n",
    "**질문**: \"이 이메일이 스팸일 가능성이 있나요? 다음은 이메일입니다: <이메일 내용>\"  \n",
    "**답변**:  \n",
    "언어 모델은 \"Likely spam(스팸일 가능성 높음)\"으로 답변하여, 이를 스팸 분류기로 변환할 수 있습니다.\n",
    "\n",
    "완성이 강력한 기능이긴 하지만, 완성은 대화에 참여하는 것과는 다릅니다. 예를 들어, 사용자가 질문을 하면 모델이 사용자의 질문에 답하지 않고 다른 질문을 추가하여 완성할 수 있습니다. 다음 장의 \"Alignment(정렬)\" 섹션에서는 모델이 사용자 요청에 적절히 응답하도록 만드는 방법을 논의합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 자기 지도 학습(Self-supervision)\n",
    "\n",
    "언어 모델링은 기계 학습(Machine Learning) 알고리즘의 여러 유형 중 하나일 뿐입니다. 객체 탐지(object detection), 주제 모델링(topic modeling), 추천 시스템(recommender system), 날씨 예측(weather forecasting), 주가 예측(stock price prediction) 등을 위한 모델도 있습니다. 언어 모델이 **스케일링 접근법(scaling approach)**의 중심이 되었고, ChatGPT의 순간적 인기를 이끈 특별한 점은 무엇일까요?\n",
    "\n",
    "답은 언어 모델은 자기 지도 학습(self-supervision)을 사용하여 훈련될 수 있는 반면, 많은 다른 모델들은 지도 학습(supervision)을 필요로 한다는 것입니다. 자기 지도 학습은 데이터 레이블링 병목현상을 극복하여 모델이 학습할 수 있는 더 큰 데이터셋을 생성하는 데 기여했으며, 결과적으로 모델의 확장이 가능하도록 했습니다. 방법은 다음과 같습니다.\n",
    "\n",
    "**지도 학습(Supervision)**은 레이블이 지정된 데이터를 사용하여 기계 학습(ML) 알고리즘을 훈련시키는 과정을 의미합니다. 레이블링된 예제는 모델에게 무엇을 해야 하는지를 알려주며, 모델은 이러한 예제로부터 학습하도록 훈련됩니다. 모델이 훈련되고 나면, 새로운 데이터에 이를 적용할 수 있습니다. 예를 들어, 사기 탐지 모델을 훈련하려면 \"사기(fraud)\" 또는 \"비사기(not fraud)\"로 레이블이 지정된 거래 사례를 사용합니다.\n",
    "\n",
    "모델이 이러한 예제에서 학습한 후에는 해당 모델을 사용하여 거래가 사기인지 여부를 예측할 수 있습니다.\n",
    "\n",
    "2010년대 AI 모델의 성공은 지도 학습에 기반을 두고 있습니다. 딥러닝 혁명을 시작한 모델인 **AlexNet(Krizhevsky 외, 2012)**은 지도 학습 방식으로 훈련되었습니다. 이 모델은 데이터셋 **ImageNet**에 있는 100만 개 이상의 이미지를 분류하도록 학습되었으며, 각각의 이미지를 \"자동차(car)\", \"풍선(balloon)\", \"원숭이(monkey)\"와 같은 1,000개 카테고리 중 하나로 분류했습니다.\n",
    "\n",
    "지도 학습의 단점은 데이터 레이블링이 비용이 많이 들고 시간이 많이 소요된다는 점입니다. 예를 들어, 한 사람이 이미지를 하나 레이블링하는 데 5센트가 든다면, **ImageNet**의 100만 개 이미지를 레이블링하는 데만 5만 달러가 필요합니다. 각 이미지를 두 명의 다른 사람이 레이블링하도록 한다면(레이블 품질을 교차 검토하기 위해), 비용이 두 배가 됩니다. 세상에는 1,000개 이상의 객체가 훨씬 많기 때문에, 모델이 더 많은 객체와 작업할 수 있도록 기능을 확장하려면 더 많은 카테고리에 대한 레이블을 추가해야 합니다. 이를 100만 개의 카테고리로 확장하려면 레이블링 비용만으로 5,000만 달러가 필요합니다.\n",
    "\n",
    "일상적인 객체를 레이블링하는 것은 대부분의 사람들이 사전 교육 없이도 할 수 있는 작업이므로 비교적 저렴하게 수행될 수 있습니다. 그러나 모든 레이블링 작업이 그렇게 간단한 것은 아닙니다. 예를 들어, 영어-라틴어 모델을 위한 라틴어 번역을 생성하는 작업은 더 많은 비용이 들며, CT 스캔이 암의 징후를 보이는지 여부를 레이블링하는 것은 천문학적인 비용이 필요합니다.\n",
    "\n",
    "**자기 지도 학습(Self-supervision)**은 데이터 레이블링 병목현상을 극복하는 데 도움을 줍니다. 수동으로 생성된 레이블을 사용해 모델을 훈련시키는 대신, 자연적으로 발생하는 레이블을 사용하여 모델을 훈련시킵니다. 자기 지도 학습은 비지도 학습과 다릅니다. 비지도 학습에서는 아예 레이블이 필요하지 않습니다.\n",
    "\n",
    "언어 모델링은 자기 지도 학습 방식으로 작동합니다. 텍스트의 모든 시퀀스가 레이블 데이터로 사용될 수 있기 때문입니다. 예를 들어, \"I love street food.\"(나는 길거리 음식을 좋아합니다)라는 문장은 Table 1-1에 표시된 대로 6개의 훈련 샘플을 제공합니다. 여기에서, **<BOS>**와 **<EOS>**를 사용하여 시퀀스의 시작과 끝을 표시합니다. 이러한 마커는 언어 모델이 여러 시퀀스를 처리할 때 필요합니다. 특히 **시퀀스 종료 마커(end-of-sequence marker)**는 언어 모델이 응답을 끝낼 시점을 파악하는 데 매우 중요합니다.\n",
    "\n",
    "<img src=\"images/tbl_01_01.png\" width=800>\n",
    "\n",
    "대규모 데이터를 활용하면 언어 모델을 확장하여 **대규모 언어 모델(LLM)**로 만들 수 있습니다. 그러나 **LLM**은 과학적인 용어라고 보기는 어렵습니다. 언어 모델이 얼마나 커야 \"대규모\"라고 간주될 수 있을까요? 오늘날 \"대규모\"로 간주되는 것이 내일은 \"작다\"고 여겨질 수 있습니다.  \n",
    "모델의 크기를 측정하기 위해 일반적으로 **파라미터(parameter)**의 수를 사용합니다. **모델 파라미터**란 모델 훈련 과정에서 수정 가능한 값들의 집합을 말합니다. 일반적으로, 항상 그런 것은 아니지만, 모델에 파라미터가 많을수록 원하는 행동을 학습할 수 있는 유연성이 더 커집니다.\n",
    "\n",
    "OpenAI의 첫 번째 GPT 모델이 2018년 6월에 출시되었을 때, 이 모델은 1억 1,700만 개의 파라미터를 가지고 있었으며, 당시에는 \"대규모\"로 간주되었습니다. 하지만 2019년 2월, OpenAI가 15억 개의 파라미터를 가진 GPT-2를 소개했을 때, 1억 1,700만 개는 \"작은 규모\"로 강등되었습니다. 이 책을 집필하는 시점에서 1,000억 개의 파라미터를 가진 모델은 \"대규모\"로 간주됩니다. 그러나 언젠가 이 크기도 \"작다\"고 여겨질 날이 올지도 모릅니다.\n",
    "\n",
    "다음 섹션으로 넘어가기 전에, 일반적으로 당연하게 여겨지는 질문 하나를 다루고자 합니다: 왜 더 큰 모델이 더 많은 데이터를 필요로 할까요?  \n",
    "더 큰 모델은 학습할 수 있는 용량이 더 크기 때문에, 성능을 극대화하기 위해 더 많은 훈련 데이터가 필요합니다.  \n",
    "큰 모델을 작은 데이터셋에서 훈련시킬 수도 있지만, 이는 컴퓨팅 리소스의 낭비일 것입니다. 더 작은 모델을 사용했다면 동일하거나 더 나은 결과를 해당 데이터셋에서 얻을 수 있었을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대규모 언어 모델에서 기본 모델로\n",
    "\n",
    "언어 모델은 놀라운 작업을 수행할 수 있지만, 텍스트에 국한됩니다. 인간은 언어뿐만 아니라 시각, 청각, 촉각 등을 통해 세상을 인식합니다. 텍스트를 넘어선 데이터를 처리할 수 있는 능력은 AI가 현실 세계에서 작동하는 데 필수적입니다.\n",
    "\n",
    "이러한 이유로 언어 모델은 더 많은 데이터 모달리티를 통합하도록 확장되고 있습니다. 예를 들어, **GPT-4V**는 이미지와 텍스트를 이해할 수 있고, **Gemini**는 비디오뿐만 아니라 이미지와 텍스트도 이해할 수 있습니다. 어떤 모델은 3D 자산, 단백질 구조 등도 이해합니다. 언어 모델에 더 많은 데이터 모드를 통합하면 모델은 더욱 강력해집니다. **OpenAI**는 2023년 **GPT-4V 시스템 카드**에서 \"이미지 입력과 같은 추가 모달리티를 LLM에 통합하는 것은 AI 연구와 개발에서 중요한 최전선으로 간주된다\"고 언급했습니다.\n",
    "\n",
    "많은 사람들이 여전히 **Gemini**와 **GPT-4V**를 LLM으로 부르지만, 이 모델들은 **기본 모델(foundation models)**로 더 잘 특징지어집니다. **foundation(기본)**이라는 단어는 이러한 모델이 AI 애플리케이션에서 가지는 중요성과 다양한 요구를 충족시키기 위해 구축될 수 있는 가능성을 모두 나타냅니다.\n",
    "\n",
    "기본 모델은 전통적인 AI 연구 구조에서 획기적인 발전을 의미합니다. 오랜 시간 동안 AI 연구는 데이터 모달리티별로 나뉘어 있었습니다. 자연어 처리(NLP)는 텍스트만 다루고, 컴퓨터 비전은 시각 정보만 다룹니다. 텍스트 전용 모델은 번역과 스팸 탐지 같은 작업에 사용할 수 있습니다. 이미지 전용 모델은 객체 탐지와 이미지 분류에 사용할 수 있습니다. 오디오 전용 모델은 음성 인식(음성-텍스트 변환, STT) 및 음성 합성(텍스트-음성 변환, TTS)을 처리할 수 있습니다.\n",
    "\n",
    "여러 데이터 모드를 처리할 수 있는 모델은 **멀티모달 모델(multimodal model)**이라고도 합니다. 생성형 멀티모달 모델은 **대규모 멀티모달 모델(LMM)**이라고도 불립니다. 텍스트 전용 토큰을 기반으로 다음 토큰을 생성하는 언어 모델과 달리, LMM은 텍스트와 이미지 토큰 모두를 기반으로 하거나 모델이 지원하는 모든 모달리티를 기반으로 다음 토큰을 생성합니다. 이는 **Figure 1-2**에 나타나 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_02.png\" width=800>\n",
    "\n",
    "언어 모델과 마찬가지로, 멀티모달 모델도 확장을 위해 데이터가 필요합니다. 자기 지도 학습(self-supervision)은 멀티모달 모델에서도 작동합니다. 예를 들어, OpenAI는 **자연어 지도 학습(natural language supervision)**이라는 자기 지도 학습 변형을 사용하여 언어-이미지 모델 **CLIP**(OpenAI, 2021)을 훈련시켰습니다. 각 이미지를 수동으로 레이블링하는 대신, 인터넷에서 함께 등장하는 (이미지, 텍스트) 쌍을 찾았습니다. 이를 통해 **4억 개의 (이미지, 텍스트) 쌍** 데이터셋을 생성할 수 있었는데, 이는 ImageNet보다 400배 큰 크기였으며 수동 레이블링 비용 없이 이루어졌습니다. 이 데이터셋 덕분에 CLIP은 재훈련 없이도 여러 이미지 분류 작업을 일반화할 수 있는 최초의 모델이 되었습니다.\n",
    "\n",
    "CLIP이 생성형 모델은 아니라는 점에 유의하세요. CLIP은 개방형 출력을 생성하도록 훈련된 것이 아닙니다. CLIP은 **임베딩 모델(embedding model)**로, 텍스트와 이미지의 **공동 임베딩(joint embedding)**을 생성하도록 훈련되었습니다. 임베딩이 낯설다면, 이를 원본 데이터의 의미를 포착하려는 벡터로 생각할 수 있습니다. 임베딩에 대한 자세한 내용은 3장에서 논의될 것입니다. CLIP과 같은 멀티모달 임베딩 모델은 Flamingo, LLaVA, Gemini와 같은 **생성형 멀티모달 모델**의 핵심입니다. Flamingo는 멀티모달 입력의 임베딩을 생성하기 위해 CLIP을 사용하며, 이를 바탕으로 출력을 생성합니다.\n",
    "\n",
    "기본 모델은 작업 특정 모델(task-specific model)에서 범용 모델(general-purpose model)로의 전환을 나타냅니다. 특정 작업을 해결하기 위해 모델을 구축하면, 해당 작업에서 모델의 성능을 최적화하는 데 자원을 집중할 수 있습니다. 그러나 그 결과로, 그 모델은 다른 작업에는 전혀 작동하지 않을 수 있습니다. 기본 모델은 그 크기와 훈련 방식 덕분에 광범위한 작업을 수행할 수 있습니다. 기본 상태에서도 범용 모델은 많은 작업에서 비교적 잘 작동할 수 있지만, 특정 작업의 성능을 극대화하기 위해 자주 **\"조정(tweaked)\"**이 필요합니다.\n",
    "\n",
    "예를 들어, 의류 소매업체로서 웹사이트에 매력적인 제품 설명을 생성하는 애플리케이션을 만들고 싶다고 가정해 봅시다. 기본 모델에서 생성된 설명은 정확할 수 있지만, 브랜드의 톤이나 메시지를 반영하지 못할 수 있습니다. 모델이 어떤 데이터로 훈련되었는지에 따라 설명이 마케팅 문구와 진부한 표현으로 가득 차 있을 수도 있습니다.\n",
    "\n",
    "이를 해결하기 위해, 원하는 제품 설명의 유형에 대해 모델에 상세한 지침을 제공할 수 있습니다. 이를 **프롬프트 엔지니어링(prompt engineering)**이라고 합니다. 지침에는 훌륭한 설명의 예시를 포함시킬 수 있습니다. 이 기술은 **Few-shot 학습(few-shot learning)**이라고 불립니다.  \n",
    "또한, 모델을 고객 리뷰 데이터베이스에 연결하여 이러한 리뷰를 활용해 더 나은 설명을 생성하도록 할 수 있습니다. 데이터베이스를 사용해 모델의 지침을 보완하는 방식을 **검색 증강 생성(retrieval augmented generation, RAG)**이라고 합니다.  \n",
    "모델을 **미세 조정(finetune)**하거나 추가적으로 훈련시킬 수도 있습니다. 이는 모델을 필요에 맞게 조정할 수 있는 AI 엔지니어링 기술 중 일부일 뿐이며, 이 책에서는 이러한 기술을 자세히 다룰 것입니다.\n",
    "\n",
    "**기본 모델**이 없다면, 특정 작업에 대해 처음부터 모델을 훈련해야 할 것입니다. 자체 모델을 사용하는 것은 범용 모델을 사용하는 것보다 더 많은 제어권을 제공합니다. 그러나 모델의 크기가 작다면 기존 대규모 모델만큼 성능이 뛰어나지 않을 수 있습니다.  \n",
    "모델이 크다면 처음부터 훈련시키는 데는 기존의 강력한 모델을 적응시키는 것보다 훨씬 더 많은 시간과 데이터가 필요합니다. 예를 들어, 처음부터 훈련하려면 **100만 개의 훈련 샘플과 6개월**이 걸리는 반면, 기존 모델을 적응시키는 데는 **10개의 훈련 샘플과 주말**만 필요할 수 있습니다.  \n",
    "자체 모델을 구축할지 아니면 기존 모델을 활용할지는 각 팀이 스스로 답해야 하는 고전적인 **구축 또는 구매(buy-or-build)** 질문입니다. 이 책 전반에서의 논의는 이 결정을 내리는 데 도움을 줄 것입니다. 그러나 일반적으로 **기본 모델**은 AI 애플리케이션 개발 비용을 절감하고 시장 출시 시간을 단축시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 모델에서 AI 엔지니어링으로\n",
    "\n",
    "**AI 엔지니어링(AI engineering)**은 기본 모델을 기반으로 애플리케이션을 구축하는 과정을 의미합니다. 사람들은 10년 넘게 **ML 엔지니어링(ML engineering)** 또는 **MLOps(ML operations)**라는 이름으로 AI 애플리케이션을 개발해 왔습니다. 그렇다면 왜 지금 AI 엔지니어링에 대해 이야기할까요?\n",
    "\n",
    "전통적인 ML 엔지니어링이 ML 모델 개발에서 시작된다면, AI 엔지니어링은 기존 ML 모델에서 시작됩니다. AI 엔지니어링의 촉매제는 강력한 **기본 모델**의 가용성과 접근성입니다. 이것은 AI 엔지니어링이 하나의 분야로서 빠르게 성장하기 위한 이상적인 조건을 만드는 세 가지 요소로 이어집니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 요소 1: AI 기능의 발전\n",
    "\n",
    "기본 모델은 단순히 기존 작업을 더 잘 수행할 수 있다는 이유로만 강력한 것이 아닙니다. 이들은 개방형 응답을 생성할 수 있기 때문에 더 많은 작업을 수행할 수 있습니다. 이전에는 불가능하다고 여겨졌던 애플리케이션이 이제 가능해졌고, 이전에 생각지도 못했던 애플리케이션들이 등장하고 있습니다. 이는 AI를 삶의 더 많은 측면에서 유용하게 만들며, 사용자 기반과 AI 애플리케이션 수요를 크게 증가시킵니다.\n",
    "\n",
    "AI는 이제 인간과 동일한 수준으로, 때로는 더 나은 수준으로 글을 작성할 수 있습니다. AI는 커뮤니케이션이 필요한 모든 작업을 자동화하거나 부분적으로 자동화할 수 있으며, 사실상 거의 모든 것에 해당됩니다. AI는 이메일 작성, 고객 요청 응답, 복잡한 계약 요약 등에 사용됩니다. 오늘날 컴퓨터와 인터넷 연결만으로도 사용자는 맞춤화된 고품질 이미지와 비디오를 생성해 디자인을 돕거나, 마케팅 자료를 생성하거나, 전문가 프로필 사진을 제작하거나, 예술적 개념을 시각화하거나, 책을 삽화로 채우는 등의 작업을 즉시 수행할 수 있습니다. AI는 또한 훈련 데이터를 합성하고 코드를 작성하는 데도 사용될 수 있으며, 이는 미래에 더욱 강력한 모델을 훈련시키는 데 도움을 줄 것입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 요소 2: AI 투자 증가\n",
    "\n",
    "두 번째 요소는 벤처 캐피탈과 기업 모두에서 AI에 대한 투자가 급증한 것입니다. AI 애플리케이션 개발 비용이 저렴해지고 시장 출시 속도가 빨라짐에 따라, AI에 대한 투자 수익률은 훨씬 더 매력적으로 변했습니다. **Scribd**의 응용 연구 선임 매니저인 **Matt Ross**는 2022년 4월부터 2023년 4월까지 그의 사용 사례에서 AI 비용이 두 단계 감소했다고 말했습니다.\n",
    "\n",
    "**Goldman Sachs Research**는 AI에 대한 투자가 미국에서 1,000억 달러에, 전 세계적으로 2025년까지 2,000억 달러에 이를 것으로 추정했습니다. 기업들은 AI를 제품과 프로세스에 통합하기 위해 서둘렀습니다. AI는 종종 경쟁 우위로 언급됩니다. **FactSheet**에 따르면, 2023년 2분기에 S&P 500 기업의 4분의 1이 실적 발표에서 AI를 언급했으며, 이는 전년도 같은 기간보다 3배 증가한 수치입니다. **Figure 1-3**은 2018년부터 2023년까지 S&P 500 기업이 실적 발표에서 AI를 언급한 횟수를 보여줍니다.\n",
    "\n",
    "<img src=\"images/fig_01_03.png\" width=800>\n",
    "\n",
    "S&P 500 기업들이 실적 발표에서 \"AI\"를 언급한 수 (5년 데이터)  (출처: FactSet)\n",
    "- 2023년 데이터는 AI를 언급한 기업 수가 사상 최고치인 177개를 기록했음을 보여줍니다.\n",
    "\n",
    "**WallStreetZen**에 따르면, 실적 발표에서 AI를 언급한 기업들은 그렇지 않은 기업들보다 평균 주가 상승률이 높았습니다: **4.6%** 상승, 반면 AI를 언급하지 않은 기업은 **2.4%** 상승에 그쳤습니다. 이것이 AI로 인해 이러한 기업들이 더 성공적이 되었는지, 아니면 새로운 기술에 빠르게 적응하는 기업이 성공적인지에 대한 인과 관계인지, 단순 상관 관계인지는 불분명합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 요소 3: AI 애플리케이션 구축의 낮은 진입 장벽\n",
    "\n",
    "**OpenAI** 및 기타 모델 제공업체들이 대중화한 **서비스형 모델(model-as-a-service)** 접근 방식은 사람들이 AI를 애플리케이션에 더 쉽게 활용할 수 있도록 만듭니다. 이러한 API가 없다면, AI 모델을 사용하려면 이를 호스팅하고 최적화할 인프라가 필요합니다. 그러나 **모델 API**를 통해 단일 API 호출로 이러한 모델을 애플리케이션에 통합할 수 있습니다.\n",
    "\n",
    "또한, AI는 코드 작성 능력을 입증하며, 소프트웨어 엔지니어링 배경이 없는 사람들도 자신의 아이디어를 빠르게 코드로 전환하여 사용자에게 제공할 수 있도록 도와줍니다. 게다가, 이러한 모델은 프로그래밍 언어를 사용하는 대신 **프롬프트 엔지니어링(prompt engineering)**을 통해 일반 영어로 작업할 수 있습니다. 이제 **누구나, 정말로 누구나** AI 애플리케이션을 개발할 수 있습니다.\n",
    "\n",
    "2022년 9월 한 인터뷰에서 OpenAI의 CEO **Sam Altman**은 강력하고 범용적인 기본 모델을 개발하는 팀은 소수에 불과할 것이라고 예측했습니다. 이러한 과정은 **Google, Meta, Microsoft, Baidu, Tencent**와 같은 대기업, **일본, UAE**와 같은 정부, 그리고 **OpenAI, Mistral, Adept**와 같은 야심차고 자금이 잘 지원된 스타트업들만이 가능하다고 말했습니다. 대다수에게 가장 큰 기회는 이러한 모델을 특정 애플리케이션에 맞게 조정하는 데 있을 것이라고 덧붙였습니다. 인터뷰 두 달 후 **ChatGPT**가 출시되면서 그의 예측은 현실이 되었습니다.\n",
    "\n",
    "AI 엔지니어링은 아직 초기 단계이지만 빠르게 성장하는 분야로 입증되었습니다. AI 엔지니어링 도구들은 GitHub에서 기존의 어떤 소프트웨어 엔지니어링 도구들보다도 빠르게 성장하고 있으며, **React**와 **Vue**와 같은 가장 인기 있는 웹 개발 도구들보다도 더 빠르게 성장하고 있습니다. 출시된 지 1년도 안 되어 **AutoGPT**는 GitHub에서 **Bitcoin**보다 두 배 많은 별(Stars)을 획득했습니다(Figure 1-4 참조).  \n",
    "2023년 8월 **LinkedIn** 설문조사에 따르면, \"Generative AI,\" \"ChatGPT,\" \"Prompt Engineering,\" \"Prompt Crafting\"과 같은 용어를 프로필에 추가하는 전문가 수가 매달 평균 **75%** 증가했다고 합니다. **ComputerWorld**는 \"AI에게 행동 방식을 가르치는 것이 가장 빠르게 성장하는 경력 기술\"이라고 선언했습니다.\n",
    "\n",
    "\n",
    "<img src=\"images/fig_01_04.png\" width=800>\n",
    "\n",
    "Star History (스타 기록)\n",
    "GitHub 별 수를 기준으로 **AutoGPT**는 **Bitcoin**, **React**, **Vue**보다 훨씬 빠르게 성장하고 있습니다(Figure 1-4 참조).\n",
    "\n",
    "\n",
    "2023년, 전 세계 웹 개발자 수는 약 **1,900만 명**으로 추정되었습니다. AI 엔지니어링의 성장 속도를 고려할 때, AI 엔지니어 수가 곧 이를 능가할 가능성이 있습니다.\n",
    "\n",
    "이미지에서 텍스트를 추출한 후 그대로 한국어로 번역하겠습니다. 잠시만 기다려 주세요.\n",
    "\n",
    "다음은 텍스트를 한국어로 번역한 내용입니다:\n",
    "\n",
    "---\n",
    "\n",
    "**왜 AI 엔지니어링이라는 용어를 선택했는가?**\n",
    "\n",
    "기본 모델을 기반으로 애플리케이션을 구축하는 과정을 설명하기 위해 사용되는 다른 용어들도 많습니다. 예를 들어, ML 엔지니어링(ML engineering), MLOps, AIOps, LLMOps 등이 있습니다.\n",
    "\n",
    "저는 **ML 엔지니어링**이라는 용어를 선택하지 않았습니다. 이 장의 후반부에서 논의될 \"AI 엔지니어링 vs. ML 엔지니어링\" 섹션에서 다루듯이, 기본 모델을 다루는 데는 전통적인 ML 모델과는 다른 여러 측면이 있기 때문입니다.\n",
    "\n",
    "저는 \"Ops\"로 끝나는 모든 용어들 대신 **AI 엔지니어링**을 선택했습니다. 그 이유는, 이 과정에는 많은 운영적 요소들이 포함되어 있지만, 초점은 기본 모델을 조정하고(엔지니어링) 원하는 대로 작동하도록 만드는 데 있기 때문입니다.\n",
    "\n",
    "마지막 이유로, 기본 모델을 기반으로 애플리케이션을 개발 중인 20명을 대상으로 어떤 용어를 사용해 자신들의 작업을 설명할지 설문 조사했는데, 응답자 대부분이 **AI 엔지니어링**을 선호했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **기본 모델을 활용한 AI 애플리케이션**\n",
    "\n",
    "아직 AI 애플리케이션을 개발하지 않고 있다면, 이전 섹션이 지금이 바로 이를 시작하기에 흥미로운 시점임을 설득했기를 바랍니다. 이미 머릿속에 구상 중인 애플리케이션이 있다면, “AI 애플리케이션 구축 시 고려사항” 섹션으로 바로 넘어가보세요. 영감을 찾고 있다면, 이 섹션은 산업적으로 입증되고 유망한 다양한 사례를 다룹니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **사용 사례 (Use Cases)**\n",
    "\n",
    "기본 모델을 활용하여 구축할 수 있는 잠재적인 애플리케이션의 수는 끝이 없어 보입니다. 어떤 사용 사례를 생각하든, 그에 맞는 AI가 있을 가능성이 높습니다. **AI의 모든 잠재적인 사용 사례를 나열하는 것은 불가능**합니다.\n",
    "\n",
    "이러한 사용 사례를 분류하는 것조차도 도전 과제입니다. 서로 다른 설문 조사에서는 사용 사례를 다르게 분류합니다. 예를 들어, **AWS**는 기업의 생성형 AI 사용 사례를 다음 세 가지 범주로 분류했습니다: 고객 경험, 직원 생산성, 프로세스 최적화.  \n",
    "2024년 **O’Reilly** 설문 조사에서는 사용 사례를 다음의 여덟 가지 카테고리로 분류했습니다: 프로그래밍, 데이터 분석, 고객 지원, 마케팅 카피, 기타 카피, 연구, 웹 디자인, 예술.\n",
    "\n",
    "**Deloitte**와 같은 일부 조직은 사용 사례를 **가치 창출(value capture)**로 분류했으며, 여기에는 비용 절감, 프로세스 효율성, 성장, 혁신 가속화 등이 포함됩니다. **Gartner**는 가치 창출의 일부로 **비즈니스 연속성**이라는 범주를 정의했는데, 이는 생성형 AI를 도입하지 않으면 파산할 가능성이 있는 기업을 의미합니다. 2023년 **Gartner**가 조사한 2,500명의 임원 중 7%가 **생성형 AI 도입의 동기**로 비즈니스 연속성을 언급했습니다.\n",
    "\n",
    "사용 사례를 분석할 때 저는 기업 애플리케이션과 소비자 애플리케이션 모두를 살펴봅니다. 기업 애플리케이션을 이해하기 위해, 저는 **50개 기업**의 AI 전략에 대해 인터뷰를 했고 **100건 이상의 사례 연구**를 읽었습니다. 소비자 애플리케이션을 이해하기 위해, 저는 GitHub에서 **별 500개 이상을 받은 205개의 오픈 소스 AI 애플리케이션**을 분석했습니다. 저는 애플리케이션을 여덟 그룹으로 분류했으며, 이는 **Table 1-2**에 나와 있습니다.\n",
    "\n",
    "이 제한된 목록은 참조용으로 가장 적합합니다. 2장에서 기본 모델 구축 방법에 대해 더 배우고, 3장에서 이를 평가하는 방법을 배우면서, 기본 모델이 활용될 수 있는 적절한 사용 사례에 대해 더 명확한 그림을 그릴 수 있을 것입니다.\n",
    "\n",
    "<img src=\"images/tbl_01_02.png\" width=800>\n",
    "\n",
    "기본 모델은 범용적이기 때문에, 이를 기반으로 구축된 애플리케이션은 여러 용도로 사용될 수 있습니다. 이는 하나의 애플리케이션이 여러 카테고리에 속할 수 있음을 의미합니다. 예를 들어, 봇은 동반자 역할을 하면서 정보를 집계할 수 있습니다. 또 다른 애플리케이션은 PDF에서 구조화된 데이터를 추출하고 해당 PDF에 대한 질문에 답할 수 있습니다.\n",
    "\n",
    "**Figure 1-5**는 205개의 오픈 소스 애플리케이션에 대한 이러한 사용 사례 분포를 보여줍니다. 교육, 데이터 조직화, 글쓰기와 관련된 사용 사례의 비율이 낮다는 것은 이러한 사용 사례가 인기가 없다는 것을 의미하지는 않습니다. 이는 단지 이러한 애플리케이션들이 오픈 소스가 아니라는 것을 의미합니다. 이러한 애플리케이션의 개발자들은 이를 기업용 사용 사례에 더 적합하다고 생각할 수도 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_05.png\" width=800>\n",
    "\n",
    "기업 환경에서는 일반적으로 위험이 낮은 애플리케이션이 선호됩니다. 예를 들어, **2024년 a16z 보고서**에 따르면, 기업은 외부 고객 지원 챗봇과 같은 외부 지향 애플리케이션보다 내부 지식 관리와 같은 내부 지향 애플리케이션을 더 빠르게 배포한다고 합니다(Figure 1-6 참조). 내부 지향 애플리케이션은 데이터 프라이버시, 규정 준수, 잠재적 재앙적 실패와 관련된 위험을 최소화하면서 기업이 AI 엔지니어링에 대한 전문성을 개발하도록 돕습니다.  \n",
    "\n",
    "마찬가지로, 기본 모델은 개방형이며 어떤 작업에도 사용할 수 있지만, 이를 기반으로 구축된 많은 애플리케이션은 여전히 **종료형(close-ended)**입니다. 예를 들어 분류 작업은 평가하기가 더 쉬워서 위험을 추정하기가 더 쉽습니다.\n",
    "\n",
    "<img src=\"images/fig_01_06.png\" width=800>\n",
    "\n",
    "수백 개의 AI 애플리케이션을 본 후에도 매주 저를 놀라게 하는 새로운 애플리케이션을 발견하곤 합니다. 인터넷 초창기 시절, 인터넷에서 지배적인 사용 사례가 소셜 미디어가 될 것이라고 예측한 사람은 거의 없었습니다. AI를 최대한 활용하는 법을 배워나가면서, 결국 지배적인 사용 사례가 될 것이 무엇인지는 우리를 놀라게 할 수 있습니다. 다행히도, 그 놀라움은 긍정적인 것이 될 가능성이 큽니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 코딩\n",
    "\n",
    "여러 생성형 AI 설문조사에서, **코딩**은 단연 가장 인기 있는 카테고리입니다. AI 코딩 도구가 인기 있는 이유는 AI가 코딩에 능숙하기도 하고, AI 애플리케이션의 초기 개발자들이 주로 코딩 문제에 더 많이 노출된 개발자들이기 때문입니다.\n",
    "\n",
    "기본 모델이 실무에 적용된 초기 성공 사례 중 하나는 코드 완성 도구 **GitHub Copilot**입니다. 이 도구는 출시 2년 만에 연간 반복 매출이 **1억 달러**를 돌파했습니다. 현재 인기 있는 AI 코딩 도구로는 **Devin**(출시 일주일 만에 트위터 데모가 3천만 회 조회됨), **gpt-engineer**, **screenshot-to-code**가 있으며, 이들 모두 출시 1년 이내에 GitHub에서 **50,000개의 별(Stars)**을 획득했습니다. 그 외에도 많은 새로운 도구들이 빠르게 도입되고 있습니다.\n",
    "\n",
    "AI가 소프트웨어 엔지니어링 작업을 많이 수행할 수 있다는 것은 분명합니다. 문제는 AI가 소프트웨어 엔지니어링을 완전히 자동화할 수 있는가입니다. 스펙트럼의 한쪽 끝에는 **엔비디아(NVIDIA)**의 CEO **Jensen Huang**처럼 AI가 인간 소프트웨어 엔지니어를 완전히 대체할 것이며, \"아이들에게 코딩을 배워야 한다고 말하는 것을 그만둬야 한다\"고 주장하는 사람들이 있습니다. 반면, 다른 한쪽 끝에는 기술적, 감정적 이유로 자신들이 AI에 의해 대체되지 않을 것이라고 확신하는 많은 소프트웨어 엔지니어들이 있습니다(사람들은 자신이 대체될 수 있다는 사실을 인정하고 싶어하지 않기 때문입니다).\n",
    "\n",
    "소프트웨어 엔지니어링 작업에는 여러 유형이 있습니다. AI는 특정 작업에서 다른 작업보다 더 뛰어난 성능을 발휘합니다. **맥킨지(McKinsey)** 연구에 따르면, AI는 문서화 작업에서 개발자의 생산성을 두 배로 향상시킬 수 있으며, 코드 생성 및 코드 리팩토링 작업에서는 생산성을 25~50% 더 높일 수 있습니다. 반면, **Figure 1-7**에 나타나 있듯이, 매우 복잡한 작업에서는 최소한의 생산성 향상만 관찰되었습니다. AI 코딩 도구를 개발하는 개발자들과의 대화에서, 많은 이들이 AI가 백엔드 개발보다 프론트엔드 개발에서 훨씬 더 우수한 성능을 발휘한다는 것을 알게 되었다고 말했습니다.\n",
    "\n",
    "<img src=\"images/fig_01_07.png\" width=800>\n",
    "\n",
    "일반적인 코딩을 돕는 도구 외에도, 특정 코딩 작업에 특화된 많은 도구들이 있습니다. 아래는 이러한 작업의 일부입니다:\n",
    "\n",
    "- 웹페이지와 PDF에서 구조화된 데이터를 추출하는 코드를 생성 (AgentGPT)\n",
    "- 영어를 코드로 변환 (DB-GPT, sqlchat, PandasAI)\n",
    "- 디자인 또는 스크린샷을 기반으로 주어진 이미지를 렌더링하는 웹사이트 코드를 생성 (screenshot-to-code, draw-a-ui)\n",
    "- 하나의 프로그래밍 언어나 프레임워크를 다른 것으로 변환 (gpt-migrate, ai-code-translator)\n",
    "- 문서 작성 (autodoc)\n",
    "- 테스트 생성 (PentestGPT)\n",
    "- 커밋 메시지 생성 (aicommits)\n",
    "\n",
    "AI가 소프트웨어 엔지니어를 대체할 것인지 여부와 상관없이, AI는 확실히 엔지니어들의 생산성을 높일 수 있습니다. 이는 기업이 더 적은 엔지니어로 더 많은 작업을 완료할 수 있음을 의미합니다. 또한, AI는 아웃소싱 산업에 변화를 줄 수 있는데, 이는 아웃소싱된 작업이 대개 기업의 핵심 업무 외부에 있는 단순한 작업들인 경우가 많기 때문입니다.\n",
    "\n",
    "\n",
    "### 이미지 및 비디오 제작\n",
    "\n",
    "그 확률적 특성 덕분에, 2장에서 더 자세히 논의되겠지만, AI는 창의적인 작업에 매우 적합합니다. 가장 성공적인 AI 스타트업 중 일부는 창의적 애플리케이션으로, 이미지 생성용 **Midjourney**, 사진 편집용 **Adobe Firefly**, 비디오 생성용 **Runway**와 **Pika Labs** 등이 있습니다.  \n",
    "2023년 말 기준, 출시 1년 반 만에 **Midjourney**는 연간 반복 매출이 **2억 달러**를 넘겼습니다. 2023년 12월 기준, Apple App Store의 **그래픽 및 디자인** 무료 앱 상위 10개 중 절반이 이름에 \"AI\"를 포함하고 있었습니다. 앞으로는 그래픽 및 디자인 앱이 기본적으로 AI를 통합하게 되어, 이름에 \"AI\"라는 단어가 더 이상 필요하지 않을 것이라 예상됩니다.\n",
    "\n",
    "AI를 사용하여 **소셜 미디어용 프로필 사진**을 생성하는 것이 이제 흔한 일이 되었습니다. LinkedIn에서 TikTok까지 다양한 플랫폼에서 사용됩니다. 많은 구직자들은 AI로 생성된 프로필 사진이 자신을 더 잘 표현하고, **취업 가능성을 높이는 데** 도움이 된다고 믿고 있습니다. AI 생성 프로필 사진에 대한 인식도 크게 변했습니다. 2019년에는 Facebook이 **AI로 생성된 프로필 사진을 사용하는 계정을 안전상의 이유로 금지**했으나, 2023년에는 많은 소셜 미디어 앱이 사용자가 AI를 이용해 프로필 사진을 생성할 수 있는 도구를 제공하고 있습니다.\n",
    "\n",
    "기업의 경우, 광고 및 마케팅 분야에서 AI를 빠르게 도입하고 있습니다. AI는 프로모션 이미지와 비디오를 직접 생성하는 데 사용될 수 있습니다. 이를 통해 아이디어를 브레인스토밍하거나, 인간 전문가가 개선할 수 있도록 초안을 생성할 수 있습니다. 또한, 여러 광고를 생성하고 어떤 광고가 청중에게 가장 효과적인지 테스트할 수 있습니다. AI는 계절과 지역에 따라 광고의 다양한 변형을 생성할 수 있습니다. 예를 들어, 가을에는 잎 색상을 변경하거나, 겨울에는 땅에 눈을 추가하는 등의 작업이 가능합니다.\n",
    "\n",
    "### 글쓰기 (Writing)\n",
    "\n",
    "AI는 오랫동안 글쓰기를 돕는 데 사용되어 왔습니다. 스마트폰을 사용한다면, 아마도 AI가 지원하는 자동 완성 및 자동 수정 기능에 익숙할 것입니다. 글쓰기는 우리가 자주 수행하는 작업이며, 때로는 상당히 번거로울 수 있어 AI에 이상적인 애플리케이션입니다. 또한, 실수에 대한 관용도가 높은 작업입니다. 모델이 마음에 들지 않는 제안을 한다면 무시하면 됩니다. 글쓰기는 대규모 언어 모델(LLM)이 글쓰기를 위해 훈련되었기 때문에 일반적인 사용 사례로도 적합합니다.\n",
    "\n",
    "소비자 관점에서, 사용 사례는 명확합니다. 많은 사람들이 AI를 사용해 더 나은 의사소통을 돕고 있습니다. 예를 들어, 이메일에서 화가 난 상태로 AI에게 내용을 더 유쾌하게 만들어 달라고 요청할 수 있습니다. 간단한 요점만 주면 완전한 문단을 되돌려받을 수도 있습니다. 학생들은 AI를 사용해 에세이를 작성하고, 작가들은 책을 쓰는 데 AI를 활용하고 있습니다. 이미 많은 스타트업이 AI를 이용해 어린이책, 팬 픽션, 로맨스, 판타지 책을 생성하고 있습니다. 전통적인 책과 달리, AI가 생성한 책은 독자의 선호에 따라 책의 줄거리가 바뀔 수 있는 **인터랙티브**한 성격을 가질 수 있습니다. 이는 독자들이 읽고 있는 이야기의 창작에 적극적으로 참여할 수 있음을 의미합니다.\n",
    "\n",
    "기업에서는 판매, 마케팅, 일반 팀 커뮤니케이션에서 AI 글쓰기가 흔히 사용됩니다. AI는 효과적인 콜드 아웃리치 이메일, 광고 카피 작성, 제품 설명 제작을 도울 수 있습니다.\n",
    "\n",
    "AI는 특히 검색 엔진 최적화(SEO)에서 뛰어난 성능을 보입니다. 이는 많은 AI 모델이 인터넷 데이터, 특히 SEO에 최적화된 텍스트로 훈련되었기 때문일 수 있습니다. AI는 SEO 작업에서 매우 뛰어나서 새로운 형태의 콘텐츠 팜(content farm)을 가능하게 했습니다. 이 콘텐츠 팜은 쓰레기 같은 웹사이트를 만들고 AI가 생성한 콘텐츠로 채워 Google 검색 순위를 높이고 트래픽을 유도합니다. 그런 다음 광고 교환 플랫폼을 통해 광고 공간을 판매합니다. 2023년 6월, **NewsGuard**는 AI가 생성한 쓰레기 웹사이트에서 **141개의 주요 브랜드의 광고 400개**를 확인했습니다. 이 쓰레기 웹사이트 중 하나는 하루에 1200개의 기사를 생성했습니다. 이를 제한하기 위한 조치가 취해지지 않으면, 인터넷 콘텐츠의 미래는 AI가 생성한 콘텐츠로 채워지게 될 것이며, 이는 매우 암울할 것입니다.\n",
    "\n",
    "Google Docs, Notion, Gmail과 같은 노트 작성 및 이메일 앱은 모두 AI를 사용하여 사용자가 글쓰기를 개선할 수 있도록 돕습니다. 글쓰기 보조 앱인 Grammarly는 사용자의 글을 더 유창하고, 일관성 있으며, 명확하게 만들기 위해 모델을 미세 조정(finetune)합니다. HubSpot과 Salesforce와 같은 CRM 앱도 기업 사용자들을 위해 웹 콘텐츠와 아웃리치 이메일을 생성하는 도구를 제공합니다.\n",
    "\n",
    "이미지에서 텍스트를 추출한 후, 그대로 한국어로 번역하겠습니다. 잠시만 기다려 주세요.\n",
    "\n",
    "다음은 텍스트를 한국어로 번역한 내용입니다:\n",
    "\n",
    "\n",
    "### 교육 (Education)\n",
    "\n",
    "ChatGPT가 작동하지 않을 때마다, OpenAI의 Discord 서버는 숙제를 완수하지 못해 불평하는 학생들로 가득 찹니다. **뉴욕시 공립학교(New York City Public Schools)**와 **로스앤젤레스 통합교육구(Los Angeles Unified School District)**를 포함한 여러 교육위원회는 학생들이 AI를 부정행위에 사용할 것을 우려하여 ChatGPT를 빠르게 금지했습니다. 제 생각에는 AI를 금지하려는 시도는 인터넷을 금지하려는 시도와 같다고 봅니다. 이는 효과가 없을 것이라 생각합니다.\n",
    "\n",
    "AI를 금지하는 대신, 학교는 이를 통합하여 학생들이 더 빨리 학습할 수 있도록 도와야 합니다. AI는 교과서를 요약하고, 각 학생에게 맞춤화된 강의 계획을 생성할 수 있습니다. 광고는 모든 사람이 다르다는 것을 알고 맞춤화되지만, 교육은 그렇지 않다는 점이 이상하다고 느껴집니다. AI는 각 학생에게 가장 적합한 형식으로 자료를 조정하도록 도울 수 있습니다. 예를 들어, 청각 학습자는 AI를 사용해 자료를 소리 내어 읽을 수 있습니다. 동물을 좋아하는 학생들은 시각 자료에 더 많은 동물이 포함되도록 AI를 활용할 수 있습니다. 수학 방정식을 읽기보다 코드를 읽는 것이 더 쉬운 학생들은 AI에게 수학 방정식을 코드로 변환하도록 요청할 수 있습니다.\n",
    "\n",
    "AI는 특히 언어 학습에 매우 유용합니다. AI에게 다양한 연습 시나리오에서 역할극을 요청할 수 있기 때문입니다. **Duolingo**는 강의 생성의 네 가지 단계 중 **개인화된 수업(Lesson Personalization)**이 AI로부터 가장 많은 이점을 얻을 수 있는 단계임을 발견했습니다(Figure 1-8 참조).\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/fig_01_08.png\" width=800>\n",
    "\n",
    "**강의 생성의 4단계:**\n",
    "1. 교육과정 설계 (Curriculum Design)  \n",
    "2. 원시 콘텐츠 생성 (Raw Content Creation)  \n",
    "3. 연습 문제 생성 (Exercise Creation)  \n",
    "4. 수업 개인화 (Lesson Personalization)  \n",
    "\n",
    "**AI 작업량과 인간 작업량 비교 (Figure 1-8)**: AI는 Duolingo에서 강의 생성의 모든 단계에 사용될 수 있지만, 개인화 단계에서 가장 큰 도움을 줍니다.  \n",
    "이미지 출처: *\"At Duolingo, humans and AI work together to create a high-quality learning experience\"* (Pajak and Bicknell).\n",
    "\n",
    "---\n",
    "\n",
    "AI는 객관식 및 주관식 퀴즈를 생성하고 답변을 평가할 수 있습니다. AI는 평균적인 인간보다 동일한 주제에 대해 다양한 관점을 제시하는 데 훨씬 뛰어나서 토론 파트너로 활용될 수 있습니다. 예를 들어, **Khan Academy**는 학생들을 위한 교수 보조자와 교사를 위한 강의 보조자로 AI를 제공합니다. 제가 본 혁신적인 교육 방법 중 하나는 교사들이 AI로 생성된 에세이를 학생들에게 배포해 오류를 찾고 수정하도록 하는 것입니다.\n",
    "\n",
    "AI가 많은 기술을 대체할 위험이 있다면, AI가 어떤 기술이든 학습할 수 있는 교사로 사용될 기회도 있습니다. AI는 방대한 데이터로 훈련되었기 때문에 대중의 집합적 지식을 반영합니다. 많은 기술에서 AI의 역량은 평균 수준입니다. 그러나 AI는 누군가가 빠르게 기본을 익히고, 이후 독립적으로 학습을 계속하여 AI보다 더 나은 수준에 도달하도록 도울 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 대화형 봇 (Conversational bots)\n",
    "\n",
    "대화형 봇은 다재다능합니다. 정보를 찾거나 개념을 설명하고, 아이디어를 브레인스토밍하는 데 도움을 줄 수 있습니다. AI는 동반자이자 상담사가 될 수 있습니다. AI는 특정 인물의 디지털 복제본과 대화할 수 있도록 성격을 모방할 수 있습니다. 디지털 여자친구와 남자친구는 놀라울 정도로 짧은 시간 안에 인기를 얻었으며, 이미 많은 사람들이 인간보다 봇과 더 많은 시간을 보내고 있습니다(관련 논의는 **여기** 및 **여기**에서 확인할 수 있습니다). 일부는 AI가 데이트 문화를 망칠 것을 우려합니다.\n",
    "\n",
    "연구에서는 대화형 봇이 사회를 시뮬레이션하여 사회 역학에 대한 연구를 수행하는 데 사용될 수 있음을 발견했습니다.\n",
    "\n",
    "기업에서는 **고객 지원 봇**이 가장 인기가 있습니다. 이러한 봇은 고객 경험을 개선하면서도 비용을 절감할 수 있도록 돕습니다. 고객 지원 봇은 인간 상담원보다 더 빠르게 사용자에게 응답할 수 있습니다. 또한, AI는 보험 청구 제출, 세금 신고, 회사 정책 검색과 같은 어려운 작업을 안내하는 **제품 보조 파일럿(product copilots)** 역할을 할 수 있습니다.\n",
    "\n",
    "ChatGPT의 성공은 텍스트 기반 대화형 봇의 물결을 일으켰습니다. 그러나 텍스트는 대화형 에이전트를 위한 유일한 인터페이스가 아닙니다. **Google Assistant**, **Siri**, **Alexa**와 같은 음성 비서들은 오랜 기간 동안 존재해 왔으며, 3D 대화형 봇은 이미 게임에서 흔히 사용되고 있으며 소매 및 마케팅에서도 점차 확산되고 있습니다.\n",
    "\n",
    "AI 기반 3D 캐릭터의 한 가지 사용 사례는 **스마트 NPC(비플레이어 캐릭터)**입니다. NPC는 많은 게임의 스토리라인을 진행하는 데 필수적입니다. AI가 없으면 NPC는 제한된 대화 범위로 단순한 작업만 수행하도록 스크립팅됩니다. AI는 이러한 NPC를 훨씬 더 똑똑하게 만들 수 있습니다. 지능형 봇은 **The Sims**, **Skyrim**과 같은 기존 게임의 역학을 변화시킬 수 있을 뿐만 아니라 이전에는 불가능했던 새로운 게임을 가능하게 할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 정보 통합 (Information aggregation)\n",
    "\n",
    "많은 사람들은 성공이 유용한 정보를 필터링하고 소화하는 능력에 달려 있다고 믿습니다. 그러나 이메일, **Slack 메시지**, 뉴스 등을 관리하는 것은 때로는 벅찰 수 있습니다. 다행히 AI가 이 문제를 해결했습니다. AI는 정보를 통합하고 요약하는 데 뛰어난 역량을 입증했습니다.\n",
    "\n",
    "소비자 관점에서, 많은 애플리케이션이 계약서, 공시자료, 논문 등의 문서를 처리하고 대화형 방식으로 정보를 검색할 수 있도록 도와줍니다. 이 사용 사례는 **talk-to-your-docs**라고도 불립니다. AI는 웹사이트, 연구를 요약하고 사용자가 선택한 주제에 대한 보고서를 작성할 수 있습니다. **Salesforce의 Generative AI Snapshot Research**에 따르면, 생성형 AI 사용자 중 **74%**가 복잡한 아이디어를 간소화하고 정보를 요약하기 위해 AI를 사용합니다.\n",
    "\n",
    "정보 통합 및 요약은 기업 운영에 필수적입니다. 보다 효율적인 정보 통합은 중간 관리자의 필요성을 줄임으로써 조직이 더 간소화될 수 있도록 돕습니다. AI는 잠재 고객에 대한 중요한 정보를 제공하고 경쟁사에 대한 분석을 실행할 수 있도록 돕습니다. **Instacart**가 내부 프롬프트 마켓플레이스를 출시했을 때, 가장 인기 있는 프롬프트 템플릿 중 하나가 **\"Fast Breakdown\"**임을 발견했습니다. 이 템플릿은 AI에게 사실, 열린 질문, 행동 항목으로 대화를 요약하도록 요청합니다. 이는 회의 노트, 이메일, 특히 **Slack 대화**에 적용될 수 있습니다.\n",
    "\n",
    "## 데이터 조직화\n",
    "\n",
    "미래에 확실한 한 가지는 우리가 점점 더 많은 데이터를 생산하게 될 것이라는 점입니다. 스마트폰 사용자들은 계속해서 사진과 동영상을 찍을 것이고, 기업들은 제품, 직원, 고객에 관한 모든 것을 계속 기록할 것입니다.\n",
    "\n",
    "매년 수십억 건의 계약서가 생성되고 있습니다. 사진, 동영상, 로그, PDF 파일 등은 모두 비정형 또는 반정형 데이터입니다. 이러한 모든 데이터를 필요한 정보를 나중에 검색할 수 있는 방식으로 조직화하는 것이 중요합니다.\n",
    "\n",
    "AI는 바로 이 작업을 도울 수 있습니다. AI는 이미지와 동영상에 대한 텍스트 설명을 자동으로 생성하거나, 텍스트 쿼리와 시각적으로 일치하는 항목을 연결하는 데 도움을 줄 수 있습니다. Google Photos와 같은 서비스는 이미 AI를 사용하여 검색 쿼리와 일치하는 이미지를 표시하고 있습니다. Google 이미지 검색은 한 걸음 더 나아가, 사용자의 요구에 맞는 기존 이미지가 없을 경우 이미지를 생성할 수 있습니다.\n",
    "\n",
    "기업의 경우, AI는 비정형 데이터를 정형 데이터로 추출하여 데이터를 정리하고 검색을 돕는 데 활용될 수 있습니다. 간단한 사용 사례로는 신용카드, 운전면허증, 영수증, 티켓, 이메일 푸터에서 연락처 정보를 자동으로 추출하는 것이 있습니다. 더 복잡한 사용 사례로는 계약서, 보고서, 차트 등의 데이터에서 정보를 추출하는 작업이 포함됩니다. IDP(Intelligent Data Processing, 지능형 데이터 처리) 산업은 2030년까지 128억 1천만 달러에 이를 것으로 추산되며, 매년 32.9%씩 성장하고 있습니다. \n",
    "\n",
    "### 워크플로 자동화\n",
    "\n",
    "궁극적으로, AI는 가능한 한 많은 작업을 자동화해야 합니다. 최종 사용자에게 자동화는 식당 예약, 환불 요청, 여행 계획, 양식 작성과 같은 지루한 일상 업무를 돕는 데 유용합니다.\n",
    "\n",
    "기업의 경우, AI는 리드 관리, 송장 처리, 상환, 고객 요청 관리, 데이터 입력 등 반복적인 작업을 자동화할 수 있습니다. 특히 흥미로운 사용 사례 중 하나는 AI 모델을 사용하여 데이터를 합성하는 것으로, 이를 통해 모델 자체를 개선할 수 있습니다. 원하는 데이터의 몇 가지 예를 모델에 제공한 뒤, 모델이 이를 기반으로 더 많은 유사한 예를 생성하도록 요청할 수 있습니다. 데이터를 라벨링하는 데 AI를 활용할 수 있으며, 라벨의 품질을 높이기 위해 사람을 개입시킬 수도 있습니다.\n",
    "\n",
    "많은 작업을 수행하려면 외부 도구에 대한 접근이 필요합니다. 예를 들어, 식당을 예약하려면 애플리케이션이 검색 엔진을 열어 식당의 번호를 조회하거나, 전화를 걸고, 일정을 캘린더에 추가하는 등의 작업을 수행할 수 있어야 합니다. 도구를 계획하고 사용하는 AI는 **에이전트(agents)**라고 불립니다. 에이전트에 대한 관심은 거의 집착 수준에 가깝지만, 이는 완전히 근거 없는 것이 아닙니다. AI 에이전트는 모든 사람을 훨씬 더 생산적이고 경제적 가치를 창출하는 데 기여할 잠재력을 가지고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AI 애플리케이션을 구축할 때 고려사항**\n",
    "\n",
    "AI의 거의 무한한 가능성 때문에 애플리케이션을 구축하고 싶은 유혹을 느끼기 쉽습니다. 단순히 배우고 재미를 느끼고 싶다면, 그것이 아마도 해야 할 일일 것입니다. 그러나 이를 직업으로 삼는다면, 잠시 멈추고 무엇을 구축해야 할지 신중히 고려하는 것이 가치 있을 수 있습니다. 기본 모델로 멋진 데모를 만드는 것은 쉽지만, 수익성 있는 제품을 만드는 것은 어렵습니다.\n",
    "\n",
    "### **빠른 변화의 속도**\n",
    "\n",
    "지난 10년 동안 AI 분야는 놀라울 정도로 빠르게 발전해 왔습니다. 앞으로 10년 동안도 이러한 빠른 변화는 계속될 가능성이 높습니다. 오늘날 기본 모델을 기반으로 구축한다는 것은 이 초고속 열차를 타는 것과 같은 헌신을 의미합니다.\n",
    "\n",
    "많은 변화는 긍정적입니다. 예를 들어, 많은 모델의 한계가 개선되고 있습니다. 컨텍스트 길이는 점점 길어지고, 모델 출력은 더 나아지고 있습니다. 모델 추론은 점점 더 빠르고 저렴해지고 있습니다. 그러나 이러한 긍정적인 변화조차도 워크플로에 마찰을 초래할 수 있습니다. 끊임없이 경계하며 비용-편익 분석을 수행하여 어떤 기술에 투자할지 결정해야 합니다. 오늘 최고의 선택이 내일 최악의 선택이 될 수도 있습니다. 모델 제공업체에게 비용을 지불하는 것보다 자체적으로 모델을 구축하는 것이 더 저렴하다고 생각할 수 있지만, 3개월 후 모델 제공업체가 가격을 절반으로 낮춰 내부 구축이 더 비싼 옵션이 되는 상황을 맞닥뜨릴 수 있습니다.\n",
    "\n",
    "어떤 변화들은 적응하기 더 쉽습니다. 예를 들어, 모델 제공업체들이 동일한 API로 수렴함에 따라, 하나의 모델 API를 다른 것으로 교체하는 것이 점점 더 쉬워지고 있습니다. 하지만 각 모델은 고유한 특성, 강점, 약점을 가지고 있어, 새로운 모델로 작업하는 개발자들은 워크플로, 프롬프트, 데이터를 이 새로운 모델에 맞게 조정해야 합니다. 버전 관리와 평가를 위한 적절한 인프라 없이 이러한 과정을 진행하면 많은 골칫거리가 발생할 수 있습니다.\n",
    "\n",
    "어떤 변화들은 적응하기 더 어려운데, 특히 규제와 관련된 변화들이 그렇습니다. AI와 관련된 기술들은 많은 국가에서 국가 안보 문제로 간주되며, 이는 컴퓨팅, 인재, 데이터 등 AI 자원이 엄격히 규제됨을 의미합니다. 예를 들어, 유럽의 일반 데이터 보호 규정(GDPR)의 도입은 기업들이 규정을 준수하기 위해 약 **90억 달러**의 비용을 지출해야 할 것으로 추정되었습니다. 컴퓨팅 자원의 가용성은 새로운 법률이 컴퓨팅 자원의 구매 및 판매에 대한 제한을 강화함에 따라 하룻밤 사이에 변할 수 있습니다(2023년 10월의 [행정명령](https://www.whitehouse.gov/) 참조). 만약 GPU 공급업체가 귀하의 국가에 GPU 판매를 금지당한다면, 심각한 문제가 생길 수 있습니다.\n",
    "\n",
    "어떤 변화들은 치명적일 수도 있습니다. 예를 들어, 지적 재산권(IP)과 AI 사용에 관한 규정은 여전히 발전 중입니다. 만약 다른 사람들의 데이터를 사용해 훈련된 모델을 기반으로 제품을 구축한다면, 해당 제품의 IP가 항상 귀하의 소유로 남을 것이라고 확신할 수 있을까요? 제가 이야기해본 많은 IP 중심 기업들, 예를 들어 게임 스튜디오들은, 나중에 IP를 잃을 우려 때문에 AI 사용을 주저하고 있습니다.\n",
    "\n",
    "### **제품 방어력(Product Defensibility)**\n",
    "\n",
    "낮은 진입 장벽은 축복이자 저주입니다. 어떤 것을 만들기가 쉽다면, 경쟁자들에게도 그것을 만들기가 쉬워집니다. 그렇다면, 당신의 제품을 방어하기 위해 어떤 '해자'를 가지고 있습니까?\n",
    "\n",
    "OpenAI가 새로운 기능을 출시할 때마다 많은 스타트업이 문을 닫는다는 농담이 있습니다. OpenAI가 PDF 파싱 기능을 도입했을 때, 인터넷은 여러 PDF 파싱 스타트업들과 작별을 고했습니다. OpenAI가 사용자들이 자신의 데이터를 사용해 GPT를 구축할 수 있도록 허용했을 때, RAG 스타트업들은 충격을 받았습니다. (RAG가 무엇인지 아직 모르신다면, 4장에서 다루니 걱정하지 마세요.)\n",
    "\n",
    "한 주요 벤처 캐피탈(VC) 회사의 파트너는 전체 제품이 Google Docs나 Microsoft Office의 기능 하나로 대체될 수 있는 많은 스타트업을 보았다고 말했습니다. 이들의 제품이 성공하면, Google이나 Microsoft가 엔지니어 세 명만 배정하여 이 제품을 2주 만에 복제하지 않을 이유가 있을까요?\n",
    "\n",
    "AI 분야에서는 일반적으로 기술, 데이터, 그리고 배포라는 세 가지 경쟁 우위가 있습니다. 이는 사용자를 대상으로 제품을 선보일 수 있는 능력과 관련됩니다. 기본 모델(foundation models)을 사용하면 대부분의 회사가 사용하는 핵심 기술은 비슷할 것입니다. 배포 우위는 대기업이 가지게 될 가능성이 큽니다.\n",
    "\n",
    "데이터 우위는 조금 더 복잡합니다. 대기업은 더 많은 기존 데이터를 보유하고 있을 가능성이 높습니다. 하지만 스타트업이 시장에 먼저 진출해 충분한 사용 데이터를 모을 수 있다면, 데이터를 통해 지속적으로 제품을 개선할 수 있으며, 데이터가 이들의 방어 수단이 될 것입니다.\n",
    "\n",
    "대형 제품의 일부 기능으로 시작될 수도 있었던 원래의 제품이 성공한 많은 회사들이 있습니다. 예를 들어, Calendly는 Google Calendar의 기능이 될 수도 있었습니다. MailChimp는 Gmail의 기능이 될 수도 있었습니다. PhotoRoom은 Google Photos의 기능이 될 수도 있었습니다. 많은 스타트업은 이러한 대형 경쟁자들이 간과한 기능을 구축하면서 시작해 결국 더 큰 경쟁자를 추월합니다. 어쩌면 당신의 회사가 다음 차례일 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **AI 엔지니어링 스택(The AI Engineering Stack)**\n",
    "\n",
    "AI 엔지니어링의 빠른 성장은 엄청난 기대와 함께 FOMO(놓치고 싶지 않다는 두려움)를 유발했습니다. 매일 새로운 도구, 기술, 모델, 애플리케이션이 도입되면서 압도감을 느낄 수 있습니다. 계속 변하는 환경을 따라잡으려 하기보다는, AI 엔지니어링의 기본 구성 요소에 대해 살펴보겠습니다.\n",
    "\n",
    "AI 엔지니어링을 이해하기 위해서는 AI 엔지니어링이 ML(Machine Learning) 엔지니어링에서 발전해왔다는 점을 인식하는 것이 중요합니다. 회사가 기본 모델(foundation models)을 실험하기 시작할 때, 기존 ML 팀이 노력을 주도하는 것이 자연스럽습니다. 어떤 회사들은 AI 엔지니어링을 ML 엔지니어링과 동일하게 간주하며, 이는 **Figure 1-9**에서 볼 수 있습니다. 또 다른 회사들은 AI 엔지니어링을 위한 별도의 직무 설명서를 가지고 있으며, 이는 **Figure 1-10**에서 볼 수 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_09.png\" width=800>\n",
    "\n",
    "조직이 AI 엔지니어와 ML 엔지니어를 어디에 배치하든, 두 직무는 상당한 공통점을 가지고 있습니다. 기존 ML 엔지니어들은 AI 엔지니어링을 기술 목록에 추가하여 직업 기회를 확장할 수 있습니다. 하지만 이전 ML 경험 없이 AI 엔지니어로 일하는 경우도 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_10.png\" width=800>\n",
    "\n",
    "AI 엔지니어링을 최선으로 이해하고 전통적인 ML 엔지니어링과 어떻게 다른지 파악하려면, 다음 섹션에서는 AI 애플리케이션 구축 과정의 다양한 계층을 분석하고, 각 계층이 AI 엔지니어링과 ML 엔지니어링에서 수행하는 역할을 살펴보겠습니다.\n",
    "\n",
    "### **AI 스택의 세 가지 계층**\n",
    "\n",
    "AI 애플리케이션 스택은 인프라스트럭처, 모델 개발, 애플리케이션 개발이라는 세 가지 계층으로 구성됩니다.\n",
    "\n",
    "1. **인프라스트럭처(Infrastructure)**: 스택의 가장 하단에 있는 계층으로, 모델 제공, 모니터링, 데이터와 컴퓨팅 관리 등을 위한 도구를 포함합니다.\n",
    "\n",
    "2. **모델 개발(Model Development)**: 이 계층은 모델 개발을 위한 도구를 제공합니다. 여기에는 모델링, 훈련, 파인튜닝, 추론 최적화, 데이터셋 엔지니어링을 위한 프레임워크가 포함됩니다.\n",
    "\n",
    "3. **애플리케이션 개발(Application Development)**: 모델이 이미 사용 가능한 상태에서는 누구나 이를 이용해 애플리케이션을 개발할 수 있습니다. 이 계층은 지난 2년 동안 가장 많은 변화가 있었으며 여전히 빠르게 진화하고 있습니다. 애플리케이션 개발은 평가, 프롬프트 엔지니어링, AI 애플리케이션 인터페이스 제공을 포함합니다.\n",
    "\n",
    "이 세 가지 계층과 각 계층에 해당하는 책임의 예시는 **Figure 1-11**에서 확인할 수 있습니다.\n",
    "\n",
    "<img src=\"images/fig_01_11.png\" width=800>\n",
    "\n",
    "기본 모델(foundation models)과 함께 생태계가 어떻게 진화했는지 이해하기 위해, 2024년 3월에 GitHub에서 최소 500개의 별(star)을 받은 모든 AI 관련 저장소를 검색했습니다. GitHub의 보편적인 사용을 고려할 때, 이 데이터는 생태계를 이해하는 좋은 지표라고 생각합니다. 제 분석에는 애플리케이션 개발과 모델 개발 계층의 산출물인 애플리케이션과 모델에 해당하는 저장소도 포함되었습니다. 총 920개의 저장소를 발견했으며, **Figure 1-12**는 각 카테고리의 월별 누적 저장소 수를 보여줍니다.\n",
    " \n",
    "<img src=\"images/fig_01_12.png\" width=800>\n",
    "\n",
    "2023년 Stable Diffusion과 ChatGPT 도입 이후, AI 도구의 수가 크게 증가했음을 보여줍니다. 2023년에 가장 큰 증가를 보인 범주는 애플리케이션과 애플리케이션 개발이었습니다. 인프라스트럭처 계층도 약간의 성장을 보였지만, 다른 계층에서의 성장에 비하면 훨씬 적었습니다. 이는 예상된 결과로, 모델과 애플리케이션이 변화했더라도 리소스 관리, 제공, 모니터링 등과 같은 인프라스트럭처의 요구 사항은 여전히 동일하기 때문입니다.\n",
    "\n",
    "이제 다음 요점으로 넘어가겠습니다. 기본 모델(foundation models)에 대한 흥분감은 새로운 것이지만, AI 애플리케이션 구축의 원칙은 여전히 동일합니다. 기업의 사용 사례에서는 여전히 AI 애플리케이션이 비즈니스 문제를 해결해야 하며, 따라서 비즈니스 지표를 ML 지표와 연결하거나 그 반대로 연결하는 것이 중요합니다. 여전히 체계적인 실험이 필요합니다. 전통적인 ML 엔지니어링에서는 다양한 하이퍼파라미터로 실험을 진행합니다. 반면 기본 모델에서는 다양한 프롬프트와 샘플링 변수로 실험을 진행합니다. (샘플링 변수에 대한 내용은 2장에서 논의됩니다.) 우리는 여전히 모델을 더 빠르고 저렴하게 실행하고자 합니다. 피드백 루프를 설정하여 프로덕션 데이터를 기반으로 애플리케이션을 반복적으로 개선하는 것이 여전히 중요합니다.\n",
    "\n",
    "이는 지난 10년 동안 ML 엔지니어들이 배우고 공유해온 많은 것이 여전히 적용 가능함을 의미합니다. 이러한 공유된 학습은 모두가 AI 애플리케이션 구축을 시작하는 데 더 쉽게 접근할 수 있도록 만듭니다.\n",
    "\n",
    "### **AI 엔지니어링 vs. ML 엔지니어링**\n",
    "\n",
    "AI 애플리케이션을 배포하는 변치 않는 원칙은 좋은 소식입니다. 그러나 이제는 상황이 어떻게 변했는지를 살펴보는 것이 더 중요합니다. 팀은 새로운 AI 사용 사례에 맞게 기존 플랫폼을 적응시키고자 합니다. 개발자들은 새로운 시장에서 경쟁력을 유지하기 위해 어떤 기술을 배워야 하는지에 관심이 있습니다.\n",
    "\n",
    "높은 수준에서 보면, 오늘날 기본 모델을 사용하여 애플리케이션을 구축하는 것은 기존의 ML 엔지니어링과 다음 세 가지 주요 방식에서 다릅니다.\n",
    "\n",
    "1. **기본 모델이 없을 경우**, 애플리케이션을 위해 자체 모델을 훈련해야 합니다. AI 엔지니어링에서는 다른 사람이 이미 훈련한 모델을 사용합니다. 즉, AI 엔지니어링은 모델링과 훈련보다는 프롬프트 엔지니어링과 파인튜닝과 같은 모델 적응 기술에 더 집중합니다.\n",
    "\n",
    "2. **AI 엔지니어링은 기존 ML 엔지니어링보다 더 큰 모델을 다룹니다.** 더 큰 모델은 다루기 더 어렵고, 더 많은 컴퓨팅 리소스를 사용하며, 더 큰 지연 시간을 유발합니다. 이는 더 효율적인 훈련과 추론 최적화에 대한 압박이 커진다는 것을 의미합니다. 계산 집약적인 모델의 결과로, 많은 기업들이 이제 더 많은 GPU를 필요로 하고 이전보다 더 큰 컴퓨팅 클러스터를 사용하게 되었습니다. 이는 GPU와 대형 클러스터를 다룰 줄 아는 엔지니어의 필요성이 증가했음을 의미합니다.\n",
    "\n",
    "3. **AI 엔지니어링은 개방형 출력을 생성할 수 있는 모델을 다룹니다.** 개방형 출력은 모델이 더 많은 작업에 사용될 수 있도록 유연성을 제공하지만, 평가하기가 더 어렵습니다. 이로 인해 평가가 AI 엔지니어링에서 훨씬 더 큰 문제가 됩니다.\n",
    "\n",
    "간단히 말해, AI 엔지니어링은 ML 엔지니어링과 다릅니다. AI 엔지니어링은 모델 개발보다는 모델을 적응시키고 평가하는 데 더 중점을 둡니다. 이 장에서 모델 적응에 대해 여러 번 언급했으므로, 계속하기 전에 모델 적응이 무엇을 의미하는지 같은 이해를 공유하고 싶습니다. 일반적으로, 모델 적응 기술은 모델 가중치를 업데이트해야 하는지 여부에 따라 두 가지 범주로 나눌 수 있습니다.\n",
    "\n",
    "**프롬프트 엔지니어링(prompt engineering)**은 모델 가중치를 업데이트할 필요가 없는 적응 기술입니다. 모델 자체를 변경하지 않고, 컨텍스트 입력에 지침과 예제를 제공하여 모델을 적응시킵니다. RAG(정보 증강 검색, Retrieval Augmented Generation)는 프롬프트 엔지니어링의 한 부분입니다. RAG에서는 외부 데이터베이스에서 검색된 정보를 사용해 프롬프트를 확장합니다. 프롬프트 엔지니어링은 시작하기 쉽고 더 적은 데이터가 필요합니다. 이를 통해 상당한 거리를 나아갈 수 있으며, 많은 성공적인 애플리케이션이 프롬프트 엔지니어링만으로 구축되었습니다. 이러한 사용의 용이성 덕분에 더 많은 모델을 실험할 수 있어, 애플리케이션에 예상외로 적합한 모델을 찾을 가능성이 높아집니다. 그러나 프롬프트 엔지니어링은 복잡한 애플리케이션이나 엄격한 성능 요구 사항을 가진 애플리케이션에는 충분하지 않을 수 있습니다.\n",
    "\n",
    "**파인튜닝(finetuning)**과 **추론 최적화(inference optimization)**는 모델 가중치를 업데이트해야 하는 기술입니다. 모델에 변경을 가해 모델을 적응시키는 과정입니다. 고수준에서 이러한 기술은 더 복잡하고 더 많은 데이터를 필요로 하지만, 품질과 속도 측면에서 모델의 품질을 크게 향상시킬 수 있습니다. 모델 가중치를 변경하지 않고는 불가능한 작업이 많습니다. 예를 들어, 모델의 크기를 줄여 더 빠르고 작게 만들거나, 훈련 중 노출되지 않았던 새로운 작업에 모델을 적응시키는 경우가 이에 해당합니다.\n",
    "\n",
    "이제 애플리케이션 개발 계층과 모델 개발 계층으로 시선을 돌려, AI 엔지니어링과 함께 각 계층이 어떻게 변화했는지 살펴보겠습니다.\n",
    "\n",
    "### **모델 개발(Model development)**\n",
    "\n",
    "모델 개발은 전통적인 ML 엔지니어링과 가장 많이 연관된 계층입니다. 세 가지 주요 책임이 있습니다: **모델링 및 훈련**, **데이터셋 엔지니어링**, **추론 최적화**입니다.\n",
    "\n",
    "### **모델링 및 훈련(Modeling and training)**\n",
    "\n",
    "모델링 및 훈련은 모델 아키텍처를 설계하고 이를 훈련하며 파인튜닝하는 과정을 의미합니다. 이 범주에 포함되는 도구의 예로는 Google의 **TensorFlow**, HuggingFace의 **Transformers**, Meta의 **PyTorch**가 있습니다.\n",
    "\n",
    "ML 모델을 개발하는 데는 전문적인 ML 지식이 필요합니다. 이는 클러스터링, 로지스틱 회귀, 의사 결정 트리, 협업 필터링과 같은 다양한 ML 알고리즘뿐만 아니라, 피드포워드, 순환(Recurrent), 컨볼루션(Convolutional), 트랜스포머(Transformer)와 같은 신경망 아키텍처를 이해하는 것을 요구합니다. 또한, 훈련 과정에 관련된 개념, 예를 들어 경사 하강법, 목적 함수, 손실 함수, 정규화 등도 이해해야 합니다.\n",
    "\n",
    "기본 모델의 가용성 덕분에, ML 지식은 더 이상 AI 애플리케이션을 구축하는 데 필수 조건이 아닙니다. 저는 경사 하강법에 대해 배우는 데 전혀 관심이 없으면서도 멋지고 성공적인 AI 애플리케이션을 구축한 많은 개발자를 만났습니다. 그럼에도 불구하고 ML 지식은 여전히 가치가 있습니다. 이는 기본 모델을 사용자 요구에 맞게 더 잘 적응시키기 위해 사용할 수 있는 도구의 범위를 확장시켜줍니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **훈련, 사전 훈련, 파인튜닝의 차이점에 대하여**\n",
    "\n",
    "**훈련(training)**이라는 용어는 종종 **사전 훈련(pre-training)**과 **파인튜닝(finetuning)** 모두를 대신해서 사용될 수 있습니다. 훈련은 항상 모델의 가중치를 변경하는 작업을 포함하지만, 모델 가중치를 변경하는 모든 작업이 훈련으로 간주되지는 않습니다. 예를 들어, 양자화(quantization)는 모델 가중치의 정밀도를 낮추는 과정인데, 기술적으로 모델 가중치를 변경하지만 훈련으로는 간주되지 않습니다.\n",
    "\n",
    "사전 훈련과 파인튜닝은 서로 다른 훈련 단계에 해당합니다:\n",
    "\n",
    "- **사전 훈련(Pre-training)**: 처음부터 모델을 훈련하는 것으로, 모델의 가중치는 무작위로 초기화됩니다.\n",
    "\n",
    "- **파인튜닝(Finetuning)**: 이전에 훈련된 모델을 계속해서 훈련하는 과정입니다. 모델의 가중치는 이전 훈련 과정에서 얻어진 것입니다. 이미 모델이 훈련되었기 때문에 파인튜닝에 필요한 자원(데이터 및 컴퓨팅 등)은 사전 훈련에 비해 일반적으로 적게 소모됩니다.\n",
    "\n",
    "사전 훈련과 파인튜닝은 하나의 연속된 스펙트럼을 구성합니다. 파인튜닝은 사전 훈련과 별개로 진행될 수 있습니다. 예를 들어, 한 회사가 모델을 사전 훈련시키고, 다른 회사가 이를 파인튜닝할 수도 있습니다. 두 과정의 절차와 도구는 매우 유사하지만, 주요 차이점은 필요한 자원의 양입니다.\n",
    "\n",
    "일부 사람들은 훈련이라는 용어를 **프롬프트 엔지니어링(prompt engineering)**에 사용하기도 하는데, 이는 정확하지 않습니다. 저는 한 **비즈니스 인사이더(Business Insider)** 기사에서 저자가 **ChatGPT를 훈련시켜 자신의 어린 시절을 모방하게 했다**고 말하는 내용을 읽었습니다. 그녀는 자신의 어린 시절 일기를 ChatGPT에 입력하여 이를 수행했다고 설명했습니다.\n",
    "\n",
    "구어체에서 저자가 **training(훈련)**이라는 단어를 사용하는 것은 맞습니다. 그녀는 모델에게 어떤 작업을 가르치고 있기 때문입니다. 하지만 기술적으로는 모델에 컨텍스트 입력을 통해 무엇을 해야 할지 가르치는 경우, 이는 **프롬프트 엔지니어링(prompt engineering)**입니다. 마찬가지로 **finetuning(파인튜닝)**이라는 용어를 사용하는 사람들도 있지만 실제로는 프롬프트 엔지니어링을 하는 경우가 많습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **데이터셋 엔지니어링(Dataset engineering)**\n",
    "\n",
    "**데이터셋 엔지니어링**은 AI 모델 훈련 및 적응에 필요한 데이터를 생성, 선별, 라벨링하는 작업과 특징 엔지니어링을 의미합니다. 데이터셋 엔지니어링의 중요도는 필요한 데이터의 양에 따라 달라집니다. 모델을 처음부터 훈련하는 것은 일반적으로 파인튜닝보다 더 많은 데이터를 요구하며, 파인튜닝은 다시 프롬프트 엔지니어링보다 더 많은 데이터를 필요로 합니다.\n",
    "\n",
    "전통적인 ML 엔지니어링, 특히 테이블형 데이터를 다룰 때는 데이터 조작이 주로 특징 엔지니어링을 중심으로 이루어졌습니다. 하지만 기본 모델의 경우, 데이터 조작은 특징 엔지니어링보다는 중복 제거, 토큰화, 품질 관리에 더 중점을 둡니다. 여기에는 민감한 정보나 유해 데이터를 제거하는 작업도 포함됩니다. 데이터셋 엔지니어링은 **5장**에서 중점적으로 다루게 됩니다.\n",
    "\n",
    "모델 적응에 필요한 데이터 양과 상관없이, 데이터 전문 지식은 매우 유용합니다. 이는 기본 모델에 사용된 훈련 데이터를 이해하는 데 도움을 주며, 모델 성능에 대한 힌트를 제공하고 모델을 가장 효과적으로 사용하는 방법을 파악하는 데 도움이 됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### **추론 최적화(Inference optimization)**\n",
    "\n",
    "**추론 최적화**는 모델을 더 작고, 빠르고, 더 저렴하게 만드는 것을 의미합니다. 추론 최적화 기법의 예로는 양자화(quantization), 증류(distillation), 분해(factorization), 그리고 더 빠른 디코딩을 위한 모델 변경 등이 있습니다.\n",
    "\n",
    "추론 최적화는 항상 ML 엔지니어링에서 중요했습니다. 사용자들은 더 빠른 모델을 항상 선호하며, 기업은 더 저렴한 추론에서 혜택을 얻을 수 있습니다. 그러나 기본 모델이 등장하면서 추론 최적화의 중요성은 더욱 커졌습니다.\n",
    "\n",
    "기본 모델과 관련된 한 가지 도전 과제는 그것들이 종종 **자가회귀(autoregressive)**라는 점입니다. 즉, 출력을 순차적으로 토큰으로 생성합니다. 예를 들어, 모델이 토큰 하나를 생성하는 데 10밀리초가 걸린다면, 100개의 토큰 출력을 생성하는 데 1초가 걸리며 더 긴 출력은 더 많은 시간이 소요됩니다. 사용자는 점점 더 인내심이 부족해지고 있어, AI 애플리케이션의 지연 시간을 일반적인 인터넷 애플리케이션에서 기대되는 **100밀리초** 수준으로 낮추는 것은 큰 도전 과제입니다. 추론 최적화는 산업과 학계 모두에서 활발한 연구 분야가 되었습니다. 추론 최적화 접근법은 **7장**에서 중점적으로 다룰 것입니다.\n",
    "\n",
    "다음은 AI 엔지니어링과 함께 모델 개발의 다양한 범주의 중요성이 어떻게 변화했는지를 보여주는 요약입니다.\n",
    "\n",
    "**Table 1-3. 기본 모델과 함께 모델 개발의 책임이 어떻게 변화했는가**\n",
    "\n",
    "| **범주**                | **전통적인 ML에서의 구축**                              | **기본 모델에서의 구축**                               |\n",
    "|----------------------|--------------------------------------------------|--------------------------------------------------|\n",
    "| **모델링 및 훈련**       | 처음부터 모델을 훈련하려면 ML 지식이 필요합니다.              | ML 지식은 있으면 좋지만 필수는 아닙니다.                    |\n",
    "| **데이터셋 엔지니어링**   | 특징 엔지니어링에 중점을 둡니다, 특히 테이블형 데이터의 경우.     | 특징 엔지니어링보다 데이터 중복 제거, 토큰화, 품질 관리에 더 중점을 둡니다. |\n",
    "| **추론 최적화**          | 중요함                                                | 더 중요함                                               |\n",
    "\n",
    "---\n",
    "\n",
    "### **애플리케이션 개발(Application development)**\n",
    "\n",
    "전통적인 ML 엔지니어링에서는 팀이 독자적인 모델을 사용해 애플리케이션을 구축하며, 모델의 품질이 차별화 요소가 됩니다. 반면, 기본 모델을 사용하는 경우 여러 팀이 동일한 모델을 사용하므로, 차별화는 애플리케이션 개발 과정을 통해 이루어져야 합니다.\n",
    "\n",
    "애플리케이션 개발 계층은 다음과 같은 책임으로 구성됩니다: **평가(evaluation)**, **프롬프트 엔지니어링(prompt engineering)**, **AI 인터페이스(AI interface)**.\n",
    "\n",
    "#### **평가(Evaluation)**\n",
    "\n",
    "**평가(Evaluation)**는 두 가지 목표를 가집니다: **기본 모델을 평가하여 작업에 가장 적합한 모델을 선택하는 것**, 그리고 **선택한 모델을 적응시키는 과정에서의 진행 상황을 평가하는 것**입니다.\n",
    "\n",
    "평가는 ML 엔지니어링에서 항상 중요했지만, 기본 모델에서는 그 중요성이 더욱 커집니다. 그 이유는 두 가지입니다. 첫째, **기본 모델의 출력이 개방형**이기 때문입니다. 전통적인 ML 작업(예: **사기 탐지, 추천 시스템, 수익 예측**)에서는 비교할 수 있는 예상 결과(ground truths)가 명확히 존재합니다. 모델의 출력이 예상 결과와 다르면 모델이 잘못된 것입니다. 하지만 **챗봇이나 이미지 생성**과 같은 작업에서는 프롬프트에 대한 가능한 응답이 너무 많기 때문에 모델의 출력을 비교할 완벽한 결과 목록을 만드는 것이 불가능합니다.\n",
    "\n",
    "둘째 이유는 모델의 용량과 AI 엔지니어링 기술이 계속 발전하고 있기 때문입니다. 새로운 사용 사례가 매일 발견되면서 평가 벤치마크도 뒤처지지 않기 위해 노력하고 있습니다. 벤치마크에서 모델 A가 모델 B보다 더 나은 성능을 보였다고 해서, 실제 프로덕션에서도 항상 모델 A가 더 나은 성능을 보인다는 보장은 없습니다.\n",
    "\n",
    "수많은 평가 기술이 존재하며, 그중 많은 것이 맞춤형(custom)이라는 점도 평가를 더 어렵게 만듭니다. **2023년 12월**, Google은 ChatGPT에 대응하기 위해 **Gemini**를 출시했습니다. 기술 보고서에서 Google은 Gemini가 **MMLU**라는 벤치마크에서 ChatGPT보다 우수하다고 주장했습니다. Google은 자체적으로 개발한 프롬프트 엔지니어링 기법인 **CoT@32**를 사용하여 Gemini를 평가했습니다. 반면, **5-shot 학습**이라는 다른 프롬프트 엔지니어링 기법을 사용할 경우, **ChatGPT**가 더 좋은 성능을 보이는 것으로 나타났습니다. 이는 **Figure 1-13**에 나와 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "**Figure 1-13**: 서로 다른 프롬프트 기법이 모델 성능에 큰 차이를 유발할 수 있음.\n",
    "\n",
    "| **모델**        | **MMLU 점수**                                                                                     |\n",
    "|-----------------|---------------------------------------------------------------------------------------------------|\n",
    "| **Gemini Ultra** | **90.04%** (CoT@32)                                                                             |\n",
    "| **Gemini Pro**   | **79.13%** (CoT@8)                                                                              |\n",
    "| **GPT-4**        | **87.29%** (CoT@32 via API)                                                                      |\n",
    "| **GPT-3.5**      | **70%** (5-shot)                                                                                |\n",
    "| **PaLM 2-L**     | **78.4%** (5-shot)                                                                              |\n",
    "| **Claude 2**     | **78.5%** (5-shot CoT)                                                                          |\n",
    "| **Inflection-2** | **79.6%** (5-shot)                                                                              |\n",
    "| **Grok 1**       | **73.0%** (5-shot)                                                                              |\n",
    "| **LLAMA-2**      | **68.0%** (5-shot)                                                                              |\n",
    "\n",
    "---\n",
    "\n",
    "**Figure 1-13**: 서로 다른 프롬프트는 모델의 성능에 매우 다른 영향을 미칠 수 있습니다. 출처: [Gemini의 기술 보고서](https://examplelink) (2023년 12월).\n",
    "\n",
    "\n",
    "### **프롬프트 엔지니어링과 RAG**\n",
    "\n",
    "**프롬프트 엔지니어링(prompt engineering)**은 모델의 가중치를 변경하지 않고, **컨텍스트**만을 사용해 AI 모델이 원하는 행동을 수행하게 만드는 기술입니다. 프롬프트 엔지니어링은 단순히 모델에 올바른 지시를 제공하는 것뿐만 아니라, 구조화된 출력을 생성하는 작업(예: JSON 형식과 같은 일관된 출력을 얻기), 데이터베이스를 사용해 모델의 컨텍스트를 확장하는 작업(**RAG**, Retrieval-Augmented Generation), 메모리 관리(지속적인 대화에서 사용자가 제공한 정보를 모델이 기억하게 만드는 작업) 등을 포함합니다.\n",
    "\n",
    "위에 언급된 **Gemini 평가 사례**는 프롬프트 엔지니어링이 모델 성능에 미치는 영향을 강조합니다. 다른 프롬프트 엔지니어링 기술을 사용함으로써 **Gemini Ultra**의 **MMLU** 성능은 **83.7%**에서 **90.04%**로 향상되었습니다.\n",
    "\n",
    "\n",
    "### **AI 오케스트레이션**\n",
    "\n",
    "애플리케이션은 여러 단계를 포함할 수 있습니다. AI의 확장된 기능을 고려하면, AI는 응답 생성뿐만 아니라 **의도 분류(intent classification)**, **응답 점수 매기기(response scoring)** 등 다양한 단계에서 활용될 수 있습니다.\n",
    "\n",
    "예를 들어, 사용자의 요청이 주어지면 **의도 분류기(intent classifier)**를 사용하여 사용자의 의도를 먼저 파악한 후 이 요청을 다른 모델에 전달할 수 있습니다. 내부 데이터베이스에서 이 사용자의 최근 주문과 같은 데이터를 활용해 요청을 보강할 수도 있습니다. 또한 생성된 응답을 평가하기 위해 다른 모델을 사용할 수도 있으며, 이를 다시 사용자에게 전송합니다.\n",
    "\n",
    "**AI 오케스트레이션** 도구는 애플리케이션의 실행 단계를 지정할 수 있도록 해줍니다. 애플리케이션의 실행 흐름은 때때로 **체인(chain)**이라고 불립니다. 수백 단계로 구성된 체인을 보는 것도 드문 일이 아닙니다.\n",
    "\n",
    "오케스트레이션은 복잡한 소프트웨어 워크플로우에서 항상 중요한 역할을 해왔으며, AI의 유무에 관계없이 중요합니다. 많은 팀은 기존 워크플로우 오케스트레이션 도구(예: **Airflow**, **Dagster**, **Metaflow**)를 활용해 생성형 AI 작업을 지원합니다. 그러나 많은 팀은 **LangChain**, **Dify**, **Flowise**와 같은 **생성형 AI 작업**에 특화된 오케스트레이션 도구로 시작합니다. 많은 경우 전통적인 소프트웨어 오케스트레이션 도구와 AI 오케스트레이션 도구를 결합해 워크플로우를 관리합니다.\n",
    "\n",
    "오케스트레이션 계층은 이미 AI 도구와 통합되어 있으므로, 많은 AI 오케스트레이션 도구는 **프롬프트 엔지니어링** 및 **RAG**를 지원하는 기능도 제공합니다.\n",
    "\n",
    "### **AI 인터페이스(AI interface)**\n",
    "\n",
    "**AI 인터페이스**는 최종 사용자가 AI 애플리케이션과 상호작용할 수 있도록 인터페이스를 만드는 것을 의미합니다. 기본 모델 이전에는 AI 모델을 개발할 수 있는 충분한 자원을 가진 조직만이 AI 애플리케이션을 개발할 수 있었습니다. 이러한 애플리케이션은 종종 조직의 기존 제품에 통합되었습니다. 예를 들어, **사기 탐지**는 Stripe, Venmo, Paypal에 통합되었고, **추천 시스템**은 Netflix, TikTok, Spotify와 같은 소셜 네트워크 및 미디어 애플리케이션의 일부가 되었습니다.\n",
    "\n",
    "**기본 모델**이 등장하면서 누구나 AI 애플리케이션을 구축할 수 있게 되었습니다. AI 애플리케이션은 독립형 제품일 수도 있고 다른 제품에 통합될 수도 있습니다. 이제 사용자가 이러한 새로운 AI 애플리케이션과 상호작용할 수 있는 새로운 **인터페이스**가 필요하고, 개발자가 AI 애플리케이션을 다른 제품에 통합할 수 있는 새로운 도구 세트가 필요합니다. 다음은 AI 애플리케이션에서 점점 인기를 얻고 있는 인터페이스의 몇 가지 예시입니다:\n",
    "\n",
    "- **웹 및 데스크톱 애플리케이션**  \n",
    "- **브라우저 확장 프로그램** (사용자가 웹 탐색 중 AI 모델에 빠르게 쿼리할 수 있도록 지원)  \n",
    "- **봇** (Slack, Discord, WeChat, WhatsApp 등과 같은 채팅 애플리케이션에서 작동)  \n",
    "- **플러그인** (개발자가 VSCode, Shopify, Microsoft Office와 같은 애플리케이션에 AI를 통합하도록 지원). 플러그인 접근 방식은 **도구를 사용해 복잡한 작업을 수행하는 에이전트(agent)**와 같은 AI 애플리케이션에서 일반적으로 사용됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "다음은 **AI 엔지니어링**과 **ML 엔지니어링**에서 애플리케이션 개발의 다양한 범주의 중요도가 어떻게 변화했는지를 보여주는 요약입니다.\n",
    "\n",
    "**Table 1-4. AI 엔지니어링과 ML 엔지니어링에서 애플리케이션 개발 범주의 중요성**\n",
    "\n",
    "| **범주**            | **전통적 ML 구축**       | **기본 모델을 활용한 구축**      |\n",
    "|-------------------|----------------------|---------------------------|\n",
    "| **AI 인터페이스**     | 덜 중요                  | 중요                          |\n",
    "| **프롬프트 엔지니어링** | 적용되지 않음               | 중요                          |\n",
    "| **오케스트레이션**     | 중요                     | 중요                          |\n",
    "| **평가**             | 중요                     | 더 중요                        |\n",
    "\n",
    "\n",
    "### **AI 엔지니어링 vs. 풀스택 엔지니어링**\n",
    "\n",
    "애플리케이션 개발, 특히 **인터페이스**에 대한 강조가 증가하면서, AI 애플리케이션을 구축하기 위한 **프론트엔드 엔지니어링**에 대한 수요가 높아졌습니다. Exa의 CEO인 Will Bryk에게 AI 엔지니어를 고용할 때 어떤 기술을 가장 중요하게 보는지 물었을 때, **프론트엔드**가 그의 세 가지 주요 항목 중 하나였습니다. 나머지 두 가지는 **프롬프트 엔지니어링**과 **세부 사항에 대한 주의력**이었습니다.\n",
    "\n",
    "프론트엔드 전문성의 중요성이 커지면서 AI 도구의 API에도 변화가 생겼습니다. 전통적으로 ML 엔지니어링은 **파이썬(Python)** 중심이었습니다. 3년 전 가장 인기 있는 ML 프레임워크는 대부분 **Python API**를 중심으로 설계되었습니다. 오늘날 Python은 여전히 인기가 있지만, JavaScript API에 대한 지원도 증가하고 있습니다. 대표적으로 **LangChain.js**, **Transformers.js**, **OpenAI의 Node 라이브러리**, **Vercel의 AI SDK**가 있습니다.\n",
    "\n",
    "이 변화는 AI 엔지니어링을 풀스택 개발에 더 가깝게 만듭니다. 저명한 AI 엔지니어인 Anton Bacaj의 말을 인용하자면:  \n",
    "> **“AI 엔지니어링은 AI 모델이 추가된 소프트웨어 엔지니어링일 뿐이다.”**\n",
    "\n",
    "오늘날 가장 성공적인 AI 엔지니어 중 일부는 프론트엔드 또는 풀스택 배경을 가지고 있다는 것은 놀라운 일이 아닙니다.\n",
    "\n",
    "풀스택 엔지니어는 전통적인 ML 엔지니어에 비해 몇 가지 장점이 있습니다. 그들은 아이디어를 빠르게 **데모**로 구현하고, **피드백**을 받고, 가장 유망한 아이디어를 반복 개선할 수 있습니다. 전통적인 ML 엔지니어링에서는 일반적으로 데이터를 수집하고 모델을 훈련하는 것으로 시작하며, 제품 개발은 마지막에 이루어집니다. 하지만 오늘날 AI 모델이 이미 사용 가능하기 때문에, 먼저 제품을 구축하고, 제품이 유망하다고 판단되면 그때 데이터와 모델에 투자하는 것이 가능합니다.  \n",
    "\n",
    "Shawn Wang은 이 점을 **Figure 1-14**에서 완벽하게 요약했습니다.\n",
    "\n",
    "<img src=\"./images/fig_01_14.png\" alt=\"Figure 1-14\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약:\n",
    "\n",
    "**AI의 빠른 변혁**  \n",
    "최근 AI는 **감독 학습**에서 **자기 지도 학습**, **언어 모델**에서 **기본 모델**, **전통적 ML 엔지니어링**에서 **AI 엔지니어링**으로 빠르게 발전했습니다.\n",
    "\n",
    "**AI 엔지니어링의 급성장**  \n",
    "- AI 엔지니어링은 가장 빠르게 성장하는 엔지니어링 분야 중 하나입니다.  \n",
    "- AI 엔지니어들이 많지만, **AI 애플리케이션** 수요에 비해 여전히 부족합니다.\n",
    "\n",
    "**대형 모델의 발전 배경**  \n",
    "- **ChatGPT**와 **Midjourney**와 같은 대형 모델은 최근에 등장한 것처럼 보이지만, 실제로는 **오랜 준비의 결과**입니다.  \n",
    "- 2012년 **AlexNet 논문**에서는 **더 빠른 GPU와 대규모 데이터셋**의 필요성을 강조했습니다. 공동 저자인 **Ilya Sutskever**는 이후 OpenAI를 공동 설립했습니다.\n",
    "\n",
    "**AI 도입의 원리**  \n",
    "- AI 도입은 **오래된 원리와 기술**을 기반으로 하고 있습니다.  \n",
    "- 이 책은 AI 엔지니어링을 **문제 해결 접근법**으로 다룹니다. 목표를 설정하고, 간단한 솔루션에서 점진적으로 복잡한 솔루션으로 나아가는 방법을 설명합니다.\n",
    "\n",
    "---\n",
    "\n",
    "**각주:**\n",
    "\n",
    "1. **전통적 ML**은 기본 모델 등장 이전의 모든 ML을 의미합니다.  \n",
    "2. **비영어권 언어**의 경우, 유니코드 문자가 여러 토큰으로 표현될 수 있습니다.  \n",
    "3. **마스킹된 언어 모델**은 코드 작성과 같은 작업에 유용합니다.  \n",
    "4. **자가회귀 언어 모델**은 **인과적 언어 모델(causal language models)**이라고도 불립니다.\n",
    "5. **기술적으로**, BERT와 같은 마스킹된 언어 모델도 정말 원하면 생성에 사용할 수 있습니다.  \n",
    "6. 이는 **사람들이 언제 말을 멈춰야 하는지 아는 것이 중요한 것**과 비슷합니다.  \n",
    "7. 학교에서는 **모델 매개변수**가 **모델 가중치**와 **편향**을 모두 포함한다고 배웠습니다. 하지만 오늘날에는 **모델 가중치**를 모든 매개변수를 가리키는 용어로 사용합니다.  \n",
    "8. **직관적이지 않아 보이지만**, 더 큰 모델은 더 많은 훈련 데이터를 필요로 합니다. 모델이 강력하다면 더 적은 예제로 학습할 수 있어야 하지 않을까요? 하지만 우리의 목표는 같은 데이터를 사용해 작은 모델의 성능에 맞추는 것이 아니라, **모델 성능을 극대화하는 것**입니다.  \n",
    "9. **AI가 생성한 텍스트**가 인간이 생성한 텍스트와 구별되기 시작하면 **사회에 부정적인 영향**이 있을 수 있습니다. 이는 **10장**에서 다룹니다.  \n",
    "10. **비교하자면**, 미국의 초·중등 교육에 대한 지출은 약 **9,000억 달러**로, 이는 미국의 AI 투자의 **9배**에 해당합니다.  \n",
    "11. **재미있는 사실**: 2024년 4월 8일 기준, **theresanaiforthat.com** 웹사이트에는 **13,260개의 AI**가 등록되어 있으며, **16,535개 작업**과 **4,847개 직업**이 포함되어 있습니다.  \n",
    "12. 오픈소스 AI 애플리케이션 목록은 제가 **https://huyenchip.com/llama-police**에서 추적합니다. 이 목록은 **6시간마다 업데이트**됩니다.  \n",
    "13. **기업들은 광고와 마케팅에 많은 돈을 쓰기 때문에**, 그 부분에서의 자동화는 막대한 비용 절감을 가져올 수 있습니다. 평균적으로 기업 예산의 **11%**가 마케팅에 사용됩니다. (출처: **WSJ, 2017**, [산업별 마케팅 예산](https://examplelink))  \n",
    "14. 제 가설은 인터넷의 콘텐츠를 너무 불신하게 되어 결국 **우리가 신뢰하는 사람이나 브랜드**가 생성한 콘텐츠만 읽게 될 것이라는 것입니다.  \n",
    "15. Apple과 Amazon이 왜 이렇게 오랫동안 **Siri**와 **Alexa**에 생성형 AI를 통합하지 않는지 이해할 수 없습니다.  \n",
    "16. 현재 Google Photos에는 **40,000장 이상의 사진과 동영상**이 있습니다. **AI가 없었다면**, 원하는 사진을 원하는 시점에 찾는 것은 거의 불가능했을 것입니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
