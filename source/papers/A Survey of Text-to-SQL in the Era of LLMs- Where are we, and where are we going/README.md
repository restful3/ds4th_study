# LLM 시대의 Text-to-SQL 현황 및 미래 전망에 대한 브리핑

## 요약

본 문서는 **대규모 언어 모델(LLM)** 의 등장으로 급격히 발전하고 있는 **Text-to-SQL 기술**의 전체 수명 주기를 종합적으로 분석합니다. **Text-to-SQL**은 사용자의 자연어(NL) 질의를 관계형 데이터베이스에서 실행 가능한 SQL 쿼리로 변환하여 **데이터 접근성을 민주화**하는 핵심 기술입니다. LLM의 발전으로 Text-to-SQL의 성능은 크게 향상되었으나, 실용적인 솔루션을 개발하기 위해서는 여전히 여러 과제를 해결해야 합니다.

이 보고서는 Text-to-SQL의 수명 주기를 모델, 데이터, 평가, 오류 분석의 네 가지 핵심 측면으로 나누어 체계적으로 검토합니다. 먼저, 규칙 기반 모델에서부터 최신 LLM 기반 솔루션에 이르기까지 모델의 진화 과정을 추적하고, 현대 시스템의 특징인 **모듈식 아키텍처(전처리, 변환, 후처리)** 와 다중 에이전트 협업과 같은 새로운 패러다임을 심도 있게 다룹니다. 또한, 기술 발전을 견인한 주요 벤치마크 데이터셋의 특성과 한계를 분석하고, 정확성, 효율성, 강건성을 측정하는 다양한 평가 지표와 도구를 소개합니다. 마지막으로, 모델의 한계를 파악하고 개선 방향을 제시하기 위한 체계적인 오류 분석 방법론을 제안합니다.

궁극적으로 이 문서는 개발자들이 데이터 프라이버시와 보유량에 따라 최적의 LLM 활용 전략을 수립할 수 있는 로드맵과 특정 시나리오에 맞는 기술 모듈을 선택할 수 있는 의사결정 흐름을 제공합니다. 또한, 개방형 도메인 질의 처리, 비용 효율성, 신뢰성 확보와 같은 미해결 과제를 제시하며 Text-to-SQL 분야의 미래 연구 방향을 조망합니다.

## Text-to-SQL의 정의와 과제

### 문제 정의

**Text-to-SQL (또는 NL2SQL)** 은 **자연어 질의(NL)**를 받아 **관계형 데이터베이스(DB)** 에서 실행할 수 있는 해당 **SQL 쿼리**를 생성하는 작업입니다. 이 기술의 목표는 사용자의 의도를 정확하게 반영하여 적절한 결과를 반환하는 SQL을 생성하는 것입니다. 자연어의 모호성이나 데이터베이스 스키마의 복잡성으로 인해 하나의 자연어 질의에 대해 여러 개의 동등한 SQL 쿼리가 존재할 수 있습니다.

### 핵심 과제

Text-to-SQL 기술은 **자연어, 데이터베이스, 그리고 둘 사이의 변환 과정**에서 발생하는 고유한 과제들을 해결해야 합니다.

과제 유형	세부 내용
자연어의 불확실성	어휘적 모호성: 단어가 여러 의미를 갖는 경우 (예: 'bat'은 동물 또는 야구 방망이를 의미).<br>구문적 모호성: 문장 구조가 여러 방식으로 해석될 수 있는 경우.<br>불완전한 명시: 언어 표현에 구체적인 의도를 파악할 정보가 부족한 경우 (예: '노동절'은 국가별로 날짜가 다름).
데이터베이스의 복잡성 및 데이터 품질	복잡한 테이블 관계: 수백 개의 테이블과 그 사이의 복잡한 상호 관계를 정확히 이해해야 함.<br>모호한 속성 및 값: 데이터베이스 내 모호한 값과 속성은 올바른 컨텍스트 식별을 어렵게 함.<br>도메인 특화 스키마: 도메인마다 고유한 스키마 설계 패턴으로 인해 범용 모델 개발이 어려움.<br>대용량 및 오염된 데이터: 대용량 데이터를 효율적으로 처리하고, 결측치나 중복과 같은 오염된 데이터로 인한 오류를 방지해야 함.
Text-to-SQL 변환의 어려움	자유 형식 NL vs. 정형 SQL: 유연한 자연어를 엄격한 구문을 따르는 SQL로 정밀하게 변환해야 함.<br>다수의 SQL 쿼리 가능성: 하나의 자연어 질의가 여러 개의 유효한 SQL 쿼리에 해당될 수 있음.<br>데이터베이스 스키마 의존성: 동일한 자연어 질의라도 데이터베이스 스키마에 따라 다른 SQL이 생성되어야 함.
기술적 과제	비용 효율성: 특히 LLM 기반 모델 배포 시 하드웨어 및 API 비용과 성능 간의 균형이 필요함.<br>모델 및 SQL 효율성: 대화형 시나리오에서는 낮은 지연 시간을 위해 모델의 추론 속도와 생성된 SQL의 실행 성능 최적화가 중요함.<br>훈련 데이터 부족 및 노이즈: 고품질 훈련 데이터를 확보하기 어렵고, 공개 데이터셋에는 노이즈가 포함될 수 있음.<br>신뢰성 및 안정성: 다양한 시나리오에서 일관되게 정확한 결과를 생성하고, 사용자가 그 과정을 이해하고 검증할 수 있어야 함.

## 언어 모델 기반 Text-to-SQL 솔루션의 진화

Text-to-SQL 솔루션은 언어 모델의 발전에 따라 크게 **네 단계**로 진화해왔으며, 각 단계마다 해결할 수 있는 문제의 수준과 대상 사용자가 확대되었습니다.

1. **규칙 기반 단계 (1990년대)**: 초기에는 의미 분석기와 같은 통계적 언어 모델을 사용하여 사전 정의된 규칙에 따라 자연어를 SQL로 변환했습니다. 이 방식은 확장성과 일반화에 한계가 있었고, 주로 단일 테이블 쿼리에 초점을 맞췄습니다.
2. **신경망 기반 단계 (2013~)**: **시퀀스-투-시퀀스 아키텍처**와 **그래프 신경망**을 활용하여 동의어 처리 및 의도 파악 능력을 향상시켰습니다. 연구의 범위가 복잡한 다중 테이블 시나리오로 확장되었으나, 여전히 모델 크기와 훈련 데이터의 한계로 일반화 성능이 제한되었습니다.
3. **사전 훈련 언어 모델(PLM) 기반 단계 (2018~)**: **BERT**, **T5**와 같은 PLM의 등장은 Text-to-SQL 성능을 크게 향상시켰습니다. 대규모 말뭉치로 훈련된 PLM은 자연어 이해 능력을 극대화했지만, 복잡한 데이터베이스 스키마를 처리하는 데에는 여전히 어려움이 있었습니다.
4. **대규모 언어 모델(LLM) 기반 단계 (2020~)**: LLM은 기존 PLM을 뛰어넘는 **창발적 능력(emergent capabilities)**을 통해 Text-to-SQL의 새로운 패러다임을 열었습니다. LLM 기반 모델은 프롬프트만으로도 Text-to-SQL 작업을 수행할 수 있으며, 현재 연구는 효과적인 **프롬프트 설계**와 특정 작업에 대한 **LLM 미세조정(fine-tuning)**에 집중되고 있습니다. 이 단계에서는 자연어 이해의 난제가 상당 부분 해결되면서, 대규모 테이블 처리나 도메인 특화 지식 활용과 같은 **데이터베이스 관련 과제**가 새로운 핵심 연구 주제로 부상했습니다.

LLM 시대의 Text-to-SQL 접근법은 크게 두 가지로 나뉩니다.

* **인컨텍스트 학습 (In-Context Learning)**: LLM의 매개변수를 수정하지 않고, 잘 설계된 **프롬프트(Prompt)**를 통해 LLM이 정확한 SQL을 생성하도록 유도하는 방식입니다.
* **사전 훈련 및 미세조정 (Pre-train and Fine-tune)**: Text-to-SQL 관련 대규모 데이터로 LLM을 **사전 훈련**하거나, 특정 작업 데이터셋으로 **미세조정**하여 모델의 매개변수를 최적화하는 방식입니다.

## 현대 Text-to-SQL 솔루션의 모듈식 아키텍처

최신 Text-to-SQL 솔루션은 단일 모델로 모든 것을 처리하는 대신, 작업을 여러 전문 모듈로 분해하는 **모듈식 설계**를 채택하는 경향이 있습니다. 이는 복잡한 문제를 효율적으로 해결하기 위함이며, 일반적으로 **전처리, 변환, 후처리의 3단계**로 구성됩니다. 최근에는 각 모듈을 독립적인 **에이전트**로 구현하여 협업시키는 **다중 에이전트 아키텍처**도 등장하고 있습니다.

![대규모 언어 모델(LLM) 기반 Text-to-SQL의 모든 것](Text_to_SQL_Overview.png)

### 전처리 전략 (Pre-Processing Strategies)

변환 단계에 앞서 **입력 데이터의 품질을 높이고 모델의 부담을 줄이는**과정입니다.

* **스키마 연결 (Schema Linking)**: 자연어 질의와 관련된 데이터베이스 테이블 및 컬럼을 식별합니다. LLM의 입력 토큰 길이 제한 문제를 완화하는 데 특히 중요합니다. 방법론으로는 전통적인 문자열 매칭, 신경망 기반 의미 관계 분석, LLM의 추론 능력을 활용한 인컨텍스트 학습 등이 있습니다.
* **데이터베이스 콘텐츠 검색 (Database Content Retrieval)**: SQL의 WHERE 절 등에 필요한 특정 셀 값을 데이터베이스에서 효율적으로 추출합니다. 문자열 매칭, 신경망, 그리고 대규모 데이터베이스에서 검색 속도를 높이기 위한 인덱스 전략이 활용됩니다.
* **추가 정보 획득 (Additional Information Acquisition)**: 도메인 지식, 예제, 외부 문서 등 추가적인 컨텍스트 정보를 통합하여 모델의 이해도를 높입니다. 프롬프트에 직접 예제를 포함하는 샘플 기반 방식과, 방대한 지식 베이스에서 유사도 기반으로 관련 정보를 검색하는 검색 기반 방식이 있습니다.

### 변환 방법론 (Translation Methodologies)

전처리된 입력을 받아 실제 SQL 쿼리를 생성하는 핵심 단계입니다.

* **인코딩 전략 (Encoding Strategy)**: 자연어와 스키마 정보를 모델이 처리할 수 있는 내부 표현으로 변환합니다. 입력 전체를 하나의 시퀀스로 처리하는 순차적 인코딩, 데이터베이스의 관계형 구조를 그래프로 표현하는 그래프 기반 인코딩, 입력의 다른 부분을 독립적으로 처리하는 분리 인코딩 전략이 있습니다.
* **디코딩 전략 (Decoding Strategy)**: 인코딩된 내부 표현을 바탕으로 SQL 쿼리를 토큰 단위로 생성합니다. 각 단계에서 가장 확률 높은 토큰 하나만 선택하는 **탐욕 탐색**, 여러 후보 시퀀스를 유지하며 탐색 공간을 넓히는 **빔 탐색**, SQL 문법 제약 조건을 각 생성 단계에 적용하여 유효성을 보장하는 **제약 조건 인식 점진적 디코딩**등이 사용됩니다.
* **작업 특화 프롬프트 전략 (Task-specific Prompt Strategy)**: LLM의 추론 과정을 단계별로 유도하여 정확성과 해석 가능성을 높이는 **사고의 연쇄(Chain-of-Thought, CoT)**, 복잡한 문제를 여러 하위 문제로 나누어 해결하는 **분해 전략**이 대표적입니다.
* **중간 표현 (Intermediate Representation, IR)**: 자유로운 자연어와 엄격한 SQL 사이의 간극을 메우기 위한 구조화된 표현입니다. SQL의 일부 키워드를 제거하여 단순화한 SQL 유사 구문 언어(예: NatSQL)나, SQL의 전체 구조를 템플릿화한 SQL 유사 스케치 구조가 사용됩니다.

### 후처리 전략 (Post-Processing Strategies)

생성된 SQL 쿼리를 검증하고 개선하여 최종 결과물의 품질을 높입니다.

* **SQL 수정 (SQL Correction)**: 생성된 SQL의 구문 오류를 자동으로 탐지하고 수정합니다.
* **출력 일관성 (Output Consistency)**: 여러 번의 추론을 통해 다양한 결과물을 생성하고, 그중 가장 일관된 결과를 최종 답변으로 선택하여 안정성을 높입니다.
* **실행 기반 전략 (Execution-Guided Strategies)**: 생성된 SQL을 실제 데이터베이스에서 실행해보고, 그 결과(오류 또는 NULL 값 등)를 피드백으로 활용하여 쿼리를 수정합니다.
* **N-best 재순위화 (N-best Rerankers Strategies)**: 모델이 생성한 상위 N개의 후보 쿼리들을 더 강력한 모델이나 추가 정보를 사용해 재평가하여 최적의 쿼리를 선택합니다.

## 벤치마크, 평가 및 오류 분석

### Text-to-SQL 벤치마크

Text-to-SQL 기술의 발전을 위해 다양한 **벤치마크 데이터셋**이 개발되었습니다. 초기에는 **ATIS(항공 정보)**, **GeoQuery(지리 정보)**와 같은 **단일 도메인 데이터셋**이 주를 이루었으나, 이후 **WikiSQL**, **Spider**와 같이 여러 도메인을 포괄하는 **교차 도메인 데이터셋**이 등장하며 모델의 일반화 성능 평가가 중요해졌습니다. 최근에는 다음과 같이 특정 과제를 겨냥한 벤치마크들이 등장하고 있습니다.

* 다중 턴(Multi-Turn): SParC, CoSQL (대화의 문맥을 이해해야 함)
* 강건성(Robustness): Spider-Syn (동의어 사용), Dr.Spider (데이터베이스 및 질의에 노이즈 추가)
* SQL 효율성(Efficiency): BIRD (생성된 SQL의 실행 효율까지 평가)
* 지식 증강(Knowledge-Augmented): Spider-DK (도메인 지식을 질의에 포함)
* 모호성(Ambiguity): AmbiQT (하나의 질의가 여러 유효한 SQL로 해석될 수 있는 경우)

다양한 벤치마크에도 불구하고, 현재 데이터셋들은 실제 비즈니스 환경에서 사용되는 **복잡한 중첩 쿼리나 고급 수학 연산**등을 충분히 다루지 못하는 한계가 존재합니다.

### 평가 지표 및 도구

Text-to-SQL 모델의 성능은 다양한 지표로 측정됩니다.

* **실행 정확도 (Execution Accuracy, EX)**: 생성된 SQL과 정답 SQL의 실행 결과가 일치하는지 평가합니다.
* **정확 일치 정확도 (Exact-Match Accuracy, EM)**: 생성된 SQL을 구성 요소별로 분해하여 정답과 구조적으로 완전히 일치하는지 평가합니다.
* **유효 효율성 점수 (Valid Efficiency Score, VES)**: BIRD 벤치마크에서 제안된 지표로, 정확할 뿐만 아니라 실행 시간까지 고려하여 쿼리의 효율성을 평가합니다.
* **질의 변형 테스트 (Query Variance Testing, QVT)**: 동일한 의미를 가진 다양한 형태의 자연어 질의에 대해 모델이 얼마나 일관된 결과를 내는지 측정하여 강건성을 평가합니다.

또한, **MT-TEQL**이나 **NL2SQL360**과 같은 평가 도구들은 표준 벤치마크를 넘어 다양한 시나리오에서 모델의 성능을 다각적으로 분석할 수 있는 프레임워크를 제공합니다.

### 오류 분석 분류 체계

모델의 한계를 명확히 파악하고 개선하기 위해서는 **체계적인 오류 분석**이 필수적입니다. 이를 위해 다음과 같은 원칙(**포괄성, 상호 배타성, 확장성, 실용성**)에 기반한 **2단계 오류 분류 체계**를 제안합니다.

1. **1단계: 오류 위치 파악 (Error Localization)**: SELECT, WHERE, GROUP BY 등 SQL의 어떤 구성 요소에서 오류가 발생했는지 식별합니다.
2. **2단계: 오류 원인 분석 (Cause of Error)**: 해당 오류가 발생한 근본 원인을 분석합니다. 예를 들어 WHERE 절의 값 오류는 모델의 데이터베이스 콘텐츠 검색 능력 부족을 시사할 수 있습니다.

## 실용적 가이드라인 및 향후 과제

### 개발을 위한 실용적 가이드라인

LLM을 Text-to-SQL에 효과적으로 적용하기 위한 **데이터 기반 로드맵**은 다음과 같습니다.

* **데이터 프라이버시**: 민감한 데이터를 다룰 경우 외부 API를 사용하는 **폐쇄형 LLM**보다 자체 구축이 가능한 **오픈소스 LLM**이 선호됩니다.
* **데이터 보유량**:
  * **대량의 데이터 보유 시**: 훈련 단계 최적화가 가능합니다. 수백만 건 이상의 관련 데이터가 있다면 **사전 훈련**, 수백~수천 건의 레이블된 데이터가 있다면 **미세조정**이 효과적입니다.
  * **소량의 데이터 보유 시**: 추론 단계 최적화에 집중합니다. 소량의 예제가 있다면 **퓨샷(Few-shot) 학습**, 예제가 전혀 없다면 **제로샷(Zero-shot) 학습**을 활용합니다.

또한, 특정 시나리오에 따라 적합한 기술 모듈을 선택해야 합니다. 예를 들어, 복잡한 스키마를 가진 데이터베이스에는 **스키마 연결 모듈**이 필수적이지만, 이는 추가적인 처리 시간을 소요합니다. SQL 실행 결과를 확인할 수 있는 환경이라면 **실행 기반 전략**이 정확도를 높이는 데 효과적이지만, 대용량 데이터베이스에서는 지연 시간이 크게 증가할 수 있습니다.

### 한계 및 미해결 과제

LLM 기반 Text-to-SQL은 상당한 발전을 이루었지만 여전히 다음과 같은 한계와 미래 과제를 안고 있습니다.

* **개방형 도메인 Text-to-SQL (Open-Domain Text-to-SQL)**: 현재 모델들은 대부분 **단일 데이터베이스 환경**을 가정합니다. 실세계에서는 여러 데이터베이스에 걸쳐 데이터를 검색하고 종합해야 하는 경우가 많습니다.
* **비용 효율적인 방법론 개발 (Cost-effective Methods)**: LLM의 높은 토큰 소비량은 비용과 지연 시간 문제를 야기합니다. **PLM의 효율성과 LLM의 추론 능력을 결합하는 하이브리드 접근법**이 유망합니다.
* **신뢰할 수 있는 솔루션 구축 (Trustworthy Solutions)**:
  * **해석 가능성**: 모델이 왜 특정 SQL을 생성했는지 사용자가 이해할 수 있도록 설명하는 기술이 필요합니다.
  * **디버깅 도구**: 컴파일러의 디버거처럼, 생성된 SQL의 구문적, 의미적 오류를 탐지하고 수정 과정을 지원하는 도구가 필요합니다.
  * **대화형 도구**: 전문가 사용자가 복잡한 쿼리를 점진적으로 구축하고 수정할 수 있도록 지원하는 대화형 인터페이스가 요구됩니다.
* **적응형 훈련 데이터 합성 (Adaptive Training Data Synthesis)**: 모델의 성능 평가 결과를 바탕으로 취약점을 파악하고, 이를 보완할 수 있는 훈련 데이터를 자동으로 생성하여 모델을 지속적으로 개선하는 연구가 필요합니다.
