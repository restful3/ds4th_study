---
lang: ko
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 3
    theme: cosmo
    embed-resources: true
    code-fold: true
    code-tools: true
    smooth-scroll: true
    css: |
      body {
        margin-top: 0 !important;
        padding-top: 0 !important;
      }
      #quarto-header {
        display: none !important;
      }
      .quarto-title-block {
        display: none !important;
      }
      /* Center content with equal padding */
      body, #quarto-content, .content, #quarto-document-content, main, .main {
        max-width: 100% !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding-left: 1em !important;
        padding-right: 1em !important;
        box-sizing: border-box !important;
      }
      .container, .container-fluid, article {
        max-width: 100% !important;
        width: 100% !important;
        margin: 0 auto !important;
        padding-left: 1em !important;
        padding-right: 1em !important;
        box-sizing: border-box !important;
      }
---

# LLMs 시대의 Text-to-SQL 서베이: 우리는 어디에 있으며, 어디로 가고 있는가?

Xinyu Liu, Shuyu Shen, Boyan Li, Peixian Ma, Runzhi Jiang, Yuxin Zhang, Ju Fan, Guoliang Li, *Fellow, IEEE*, Nan Tang, and Yuyu Luo\*

Text-to-SQL Handbook: https://github.com/HKUSTDial/NL2SQL_Handbook

![](_page_0_Figure_5.jpeg)

그림 1: 서베이 개요: Text-to-SQL 작업의 생명주기(lifecycle).

**초록**—사용자의 자연어 쿼리(natural language queries, NL)를 SQL 쿼리로 변환하는 작업(즉, Text-to-SQL, 또는 NL2SQL로 알려짐)은 관계형 데이터베이스(relational databases)에 대한 접근 장벽을 크게 낮추고 다양한 상업적 응용을 지원할 수 있습니다. Text-to-SQL의 성능은 대규모 언어 모델(Large Language Models, LLMs)의 등장과 함께 크게 향상되었습니다. 본 서베이에서 우리는 LLMs를 기반으로 한 Text-to-SQL 기술에 대한 포괄적인 리뷰를 제공하며, 다음 네 가지 측면에서 전체 생명주기를 다룹니다: (1) 모델(Model): NL의 모호성(ambiguity)과 불충분한 명세(under-specification)를 해결할 뿐만 아니라 NL을 데이터베이스 스키마(database schema) 및 인스턴스(instances)와 적절히 매핑하는 Text-to-SQL 번역 기술; (2) 데이터(Data): 훈련 데이터(training data)의 수집, 훈련 데이터 부족으로 인한 데이터 합성(data synthesis), Text-to-SQL 벤치마크까지; (3) 평가(Evaluation): 다양한 메트릭(metrics)과 세분화(granularities)를 사용하여 다각도에서 Text-to-SQL 방법을 평가; (4) 오류 분석(Error Analysis): Text-to-SQL 오류를 분석하여 근본 원인을 찾고 Text-to-SQL 모델의 진화를 안내.

Xinyu Liu, Shuyu Shen, Boyan Li, Peixian Ma, Runzhi Jiang, Nan Tang, Yuyu Luo는 The Hong Kong University of Science and Technology (Guangzhou), 중국에 소속되어 있습니다. E-mail: {xliu371, sshen190, bli303, rjiang073, pma929}@connect.hkust-gz.edu.cn, {yuyuluo, nantang}@hkust-gz.edu.cn.

Yuxin Zhang, Ju Fan은 Renmin University of China, 베이징, 중국에 소속되어 있습니다. E-mail: {zhangyuxin159, fanj}@ruc.edu.cn. Guoliang Li는 Tsinghua University, 베이징, 중국에 소속되어 있습니다. E-mail: liguoliang@tsinghua.edu.cn.

\*교신 저자(Corresponding Author): Yuyu Luo (yuyuluo@hkust-gz.edu.cn).

또한, 우리는 Text-to-SQL 솔루션 개발을 위한 경험 법칙(rule of thumb)을 제공합니다. 마지막으로, LLMs 시대의 Text-to-SQL 연구 과제와 미해결 문제를 논의합니다.

**색인 용어**—Natural Language to SQL, Database Interface, Large Language Models, Text-to-SQL.

## I. 서론 (INTRODUCTION)

자연어를 SQL로 변환하는 작업(Natural Language to SQL, 즉 Text-to-SQL)은 자연어 쿼리(NL)를 SQL 쿼리로 변환하는 기술로, 관계형 데이터베이스에 대한 접근 장벽을 낮추는 핵심 기술입니다[1]–[7]. 이 기술은 비즈니스 인텔리전스(business intelligence) 및 데이터베이스를 위한 자연어 인터페이스(natural language interfaces for databases)와 같은 다양한 응용 프로그램을 지원하여 데이터 과학의 민주화(democratizing data science)를 향한 핵심 단계가 됩니다[8]–[18]. 최근 언어 모델(language models)의 발전은 Text-to-SQL의 연구 및 응용 영역을 크게 확장했습니다. 동시에, 데이터베이스 벤더들이 Text-to-SQL 솔루션을 제공하려는 추세는 단순한 개념에서 필수 전략으로 진화했습니다[19], [20]. 따라서 우리는 Text-to-SQL에 관한 기본 원리, 기술 및 과제를 이해할 필요가 있습니다.

본 서베이에서 우리는 그림 1에 나타난 바와 같이 새로운 프레임워크를 통해 최근 Text-to-SQL 기술을 체계적으로 검토합니다.

- **언어 모델을 활용한 Text-to-SQL.** 먼저 언어 모델의 관점에서 기존 Text-to-SQL 솔루션을 검토하고, 이를 네 가지 주요 범주로 분류합니다(그림 1(a) 참조). 그런 다음 Text-to-SQL을 위한 사전 훈련 언어 모델(Pre-trained Language Models, PLMs) 및 대규모 언어 모델(Large Language Models, LLMs)의 최근 발전에 중점을 둡니다.
- **벤치마크 및 훈련 데이터 합성.** PLM 및 LLM 기반 Text-to-SQL 모델의 성능은 훈련 데이터의 양과 품질에 크게 의존합니다. 따라서 먼저 기존 벤치마크의 특성을 요약하고 통계 정보(*예:* 데이터베이스 복잡도)를 자세히 분석합니다. 그런 다음 고품질 훈련 데이터를 수집하고 합성하는 방법을 논의하며, 이를 연구 기회로 강조합니다(그림 1(b) 참조).
- **평가.** Text-to-SQL 모델을 포괄적으로 평가하는 것은 다양한 사용 시나리오에 맞는 모델을 최적화하고 선택하는 데 중요합니다. 우리는 Text-to-SQL 작업에 대한 다각도 평가(multi-angle evaluation) 및 시나리오 기반 평가(scenario-based evaluation)를 논의합니다(그림 1(c) 참조). 예를 들어, SQL 특성, NL 변형, 데이터베이스 도메인 등을 기반으로 벤치마크를 필터링하여 특정 컨텍스트에서 Text-to-SQL 모델을 평가할 수 있습니다.
- **Text-to-SQL 오류 분석.** 오류 분석은 제한 사항을 식별하고 모델 강건성(model robustness)을 개선하는 데 Text-to-SQL 연구에서 필수적입니다. 우리는 기존 오류 분류법(error taxonomies)을 검토하고, 그 한계를 분석하며, Text-to-SQL 출력 오류에 대한 포괄적인 분류법 설계 원칙을 제안합니다. 이러한 원칙을 사용하여 2단계 오류 분류법(two-level error taxonomy)을 만들고 이를 활용하여 Text-to-SQL 출력 오류를 요약하고 분석합니다(그림 1(d) 참조).

위 내용 외에도, Text-to-SQL 솔루션 개발을 위한 실용적인 지침을 제공합니다. 여기에는 Text-to-SQL 작업을 위한 LLMs 최적화 로드맵과 다양한 Text-to-SQL 시나리오에 맞춤화된 Text-to-SQL 모듈 선택을 위한 의사결정 흐름도(decision flow)가 포함됩니다. 마지막으로, 개방형 Text-to-SQL 작업(open Text-to-SQL tasks), 비용 효율적인 LLMs 기반 Text-to-SQL, 신뢰할 수 있는 Text-to-SQL 솔루션(trustworthy Text-to-SQL solutions)과 같은 분야의 주요 미해결 문제를 논의합니다.

**기존 서베이와의 차이점.** 본 서베이는 기존 Text-to-SQL 서베이[21]–[28] 및 튜토리얼[29]–[31]과 다음 다섯 가지 측면에서 차별화됩니다.

- 우리는 그림 1에 나타난 바와 같이 *Text-to-SQL 문제의 전체 생명주기*를 체계적으로 검토합니다. 이 생명주기에는 언어 모델을 기반으로 한 다양한 Text-to-SQL 번역 방법론(그림 1(a)), 훈련 데이터 수집 및 합성 방법(그림 1(b)), 다각도 및 시나리오 기반 평가(그림 1(c)), Text-to-SQL 오류 분석 기술(그림 1(d))이 포함됩니다.
- 우리는 Text-to-SQL의 본질적인 과제(inherent challenges)에 대한 보다 상세하고 포괄적인 요약을 제공합니다. 또한, 실제 시나리오를 위한 강건한 Text-to-SQL 솔루션을 개발할 때의 기술적 과제(technical challenges)를 분석하며, 이는 다른 서베이에서 종종 간과됩니다.
- 우리는 특히 최근 *LLM 기반* Text-to-SQL 방법의 발전에 중점을 두며, 핵심 모듈을 요약하고 이 범위 내에서 다양한 전략을 비교합니다. 우리는 방법의 모듈식 요약을 제공하고 각 핵심 모듈(*예:* 데이터베이스 콘텐츠 검색)에 대한 상세한 분석을 제공하는 최초의 서베이입니다.
- 우리는 *다각도 방식으로 Text-to-SQL 방법을 평가*하는 것의 중요성을 강조하고, Text-to-SQL 오류 패턴을 분석하며, 2단계 오류 분류법을 제공합니다.
- 우리는 실무자들에게 LLMs를 Text-to-SQL에 최적화하기 위한 로드맵과 다양한 시나리오에 적합한 Text-to-SQL 모듈 선택을 위한 의사결정 흐름도를 제공합니다.

## 기여 (Contributions)

우리는 다음과 같은 기여를 합니다.

- **언어 모델을 활용한 Text-to-SQL.** 우리는 생명주기 관점에서 기존 Text-to-SQL 기술을 포괄적으로 검토합니다(그림 1). Text-to-SQL 작업 정의를 소개하고, 과제를 논의하며(그림 2), 언어 모델 기반 Text-to-SQL 솔루션의 분류법을 제공하고(그림 3), 언어 모델 기반 Text-to-SQL 솔루션의 핵심 모듈을 요약합니다(그림 5 및 표 I). 다음으로, 사전 처리 전략(Section IV), Text-to-SQL 번역 방법(Section V), 후처리 기술(Section VI)을 포함하여 언어 모델 기반 Text-to-SQL 방법의 각 모듈에 대해 자세히 설명합니다.
- **벤치마크 및 훈련 데이터 합성.** 우리는 특성을 기반으로 기존 Text-to-SQL 벤치마크를 요약합니다(그림 10). 각 벤치마크를 심층적으로 분석하고 장단점을 논의합니다(표 II). (Section VII)
- **평가 및 오류 분석.** 우리는 실용적인 Text-to-SQL 솔루션 개발에서 평가의 중요성을 강조합니다. Text-to-SQL 솔루션을 평가하기 위해 널리 사용되는 평가 메트릭과 툴킷을 검토합니다. Text-to-SQL 방법이 생성하는 일반적인 오류를 요약하기 위한 분류법을 제공합니다. (Section VIII)
- **Text-to-SQL 솔루션 개발을 위한 실용 지침.** 우리는 기존 LLMs를 Text-to-SQL 작업에 최적화하기 위한 로드맵을 제공합니다(그림 11(a)). 또한, 다양한 시나리오에 적합한 모듈을 선택하기 위한 의사결정 흐름도를 설계합니다(그림 11(b)).
- **Text-to-SQL의 미해결 문제.** 우리는 LLM 기반 방법의 한계를 분석하고 개방형 Text-to-SQL 문제(open-world Text-to-SQL problem) 및 비용 효율적인 솔루션을 포함한 새로운 연구 기회를 논의합니다(Section X).
- **Text-to-SQL 핸드북.** 우리는 독자들이 Text-to-SQL 발전 사항을 최신으로 유지할 수 있도록 온라인 핸드북(https://github.com/HKUSTDial/NL2SQL_Handbook)을 관리합니다.


## II. TEXT-TO-SQL 문제 및 배경 (TEXT-TO-SQL PROBLEM AND BACKGROUND)

이 섹션에서는 먼저 Text-to-SQL 작업의 정의를 공식화합니다(Section II-A). 그런 다음 인간이 Text-to-SQL 작업을 수행하는 워크플로(workflow)를 소개하고(Section II-B), 주요 과제를 논의합니다(Section II-C). 마지막으로, 언어 모델의 발전을 기반으로 Text-to-SQL 솔루션의 진화를 설명합니다(Section II-D).

![](_page_2_Figure_1.jpeg)

그림 2: Text-to-SQL 작업 및 그 과제의 예시.

### A. 문제 정식화 (Problem Formulation)

**정의 1** (자연어를 SQL로 변환(Natural Language to SQL, Text-to-SQL)). 자연어를 SQL로 변환(Text-to-SQL), NL2SQL로도 알려진 이 작업은 자연어 쿼리(natural language queries, NL)를 관계형 데이터베이스(relational database, DB)에서 실행할 수 있는 해당 SQL 쿼리(SQL)로 변환하는 작업입니다. 구체적으로, NL과 DB가 주어졌을 때, Text-to-SQL의 목표는 사용자의 의도를 정확히 반영하고 데이터베이스에서 실행될 때 적절한 결과를 반환하는 SQL을 생성하는 것입니다.

**논의.** 경우에 따라 NL에 대응하는 SQL 쿼리는 NL의 모호성(ambiguity) 또는 불충분한 명세(underspecification), 또는 데이터베이스 스키마의 모호성으로 인해 여러 개일 수 있습니다. 또한, NL, 데이터베이스 스키마 및 데이터베이스 콘텐츠가 명확하고 구체적인 경우에도 주어진 NL 질문을 만족시킬 수 있는 여러 동등한 SQL 쿼리가 여전히 존재할 수 있습니다.

### B. Text-to-SQL 인간 워크플로 (Text-to-SQL Human Workflow)

전문 사용자(예: DBA)가 Text-to-SQL 작업을 수행할 때, 먼저 NL 질문을 해석하고, 데이터베이스 스키마와 콘텐츠를 검토한 다음, SQL 전문 지식을 바탕으로 해당 SQL을 구성합니다. 아래에서 그림 2(a)에 나타난 바와 같이 이 프로세스를 자세히 설명합니다.

**Step-1: 자연어 쿼리 이해:** 주어진 NL 쿼리 "Find the names of all customers who checked out books on exactly 3 different genres on Labor Day in 2023"에서, DBA의 첫 번째 작업은 사용자의 의도를 파악하고 핵심 구성 요소를 식별하는 것입니다. 주요 요소는 다음과 같습니다: 1) 엔티티(Entities) 또는 속성(Attributes): "names", "customers", "books", "genres"; 2) 시간적 맥락(Temporal Context): "Labor Day in 2023"; 3) 특정 조건(Specific Conditions): "exactly 3 different genres". 그런 다음 DBA는 NL 쿼리의 전반적인 목적을 더 잘 이해할 수 있습니다. 이 경우, DBA는 특정 날짜의 특정 대출 행동을 기반으로 고객 이름 목록을 검색해야 합니다.

**Step-2: 관련 테이블, 열 및 셀 값 찾기:** 다음으로, DBA는 데이터베이스 스키마와 콘텐츠를 검토하여 SQL을 구성하기 위한 관련 테이블, 열 및 셀 값을 식별합니다. 예를 들어, DBA는 NL에 대한 이해를 바탕으로 "Customer"와 "Book" 테이블이 관련이 있다고 판단할 수 있습니다(그림 2(a)-① 참조). 그런 다음 DBA는 어떤 열을 언급해야 하는지 결정합니다. 예를 들어, 키워드 "genres"는 "LiteraryGenre" 또는 "SubjectGenre"를 참조할 수 있습니다(그림 2(a)-② 참조). 또한, DBA는 맥락을 기반으로 "Labor Day in 2023"을 해석해야 합니다. 미국에서는 "Labor Day in 2023"이 "2023년 9월 4일"을 의미하지만, 중국에서는 "2023년 5월 1일"을 의미합니다. 이 판단은 도메인 지식이나 이용 가능한 추가 정보에 의존합니다(그림 2(a)-⑤ 참조).

Step-2는 최근 언어 모델 기반 Text-to-SQL 솔루션의 *스키마 링킹(schema linking)*, *데이터베이스 콘텐츠 검색(database content retrieval)*, *추가 정보 획득(additional information acquisition)* 개념과 일치합니다(자세한 내용은 그림 5 참조).

**Step-3: NL 및 DB 이해를 기반으로 SQL 작성:** 마지막으로, DBA는 Step-1 및 Step-2에서 얻은 인사이트를 기반으로 해당 SQL을 작성합니다. "Text-to-SQL Translation"으로 알려진 이 프로세스는 DBA의 SQL 전문 지식에 크게 의존합니다. 그러나 NL의 모호성이나 데이터베이스의 복잡성으로 인해 이 프로세스는 매우 어려울 수 있습니다. 예를 들어, 그림 2(a)에서 보듯이 Customer와 Book 테이블을 연결해야 한다는 것을 이해했음에도 불구하고, 자연 조인(natural join) 또는 서브쿼리(subquery)를 사용하는 사용법과 규범에 익숙해야 합니다. 또한, "genres"가 "LiteraryGenre" 또는 "SubjectGenre"를 참조할 수 있기 때문에 여러 가능한 SQL 쿼리가 있을 수 있습니다.

**시사점.** 위의 단계에서 우리는 Text-to-SQL 작업의 세 가지 *본질적* 과제를 직관적으로 식별합니다: 자연어의 불확실성(uncertainty), 데이터베이스의 복잡성(complexity), "자유 형식(free-form)" 자연어 쿼리에서 "제약되고 형식적인(constrained and formal)" SQL 쿼리로의 번역.

### C. Text-to-SQL 작업 과제 (Text-to-SQL Task Challenges)

이 섹션에서는 먼저 Text-to-SQL 작업의 근본적인 과제를 논의합니다. 그런 다음 *기술적* 과제, 즉 실제 시나리오에서 강력한 Text-to-SQL 솔루션을 개발할 때 직면하는 과제를 분석합니다.

**C1: 불확실한 자연어 쿼리.** 자연어 쿼리는 모호성과 불충분한 명세로 인해 불확실성을 포함하는 경우가 많습니다[32]. Text-to-SQL 작업에서 NL과 관련된 과제는 다음과 같이 요약할 수 있습니다:

- **어휘적 모호성(Lexical Ambiguity)**: 이는 단일 단어가 여러 의미를 가질 때 발생합니다. 예를 들어, "bat"이라는 단어는 *동물*, *야구 배트*, 또는 *스윙하는* 동작을 의미할 수 있습니다.
- **구문적 모호성(Syntactic Ambiguity)**: 이는 문장이 여러 방식으로 파싱될 수 있을 때 발생합니다. 예를 들어, "Mary saw the man with the telescope"라는 문장에서 "with the telescope"라는 구는 Mary가 망원경을 사용하여 남자를 보았다는 의미이거나 남자가 망원경을 가지고 있었다는 의미일 수 있습니다.
- **불충분한 명세(Under-specification)**: 이는 언어 표현이 특정 의도나 의미를 명확하게 전달하기에 충분한 세부 사항이 부족할 때 발생합니다. 예를 들어, "Labor Day in 2023"은 미국에서는 9월 4일을, 중국에서는 5월 1일을 의미합니다.

**C2: 복잡한 데이터베이스 및 더러운 콘텐츠.** Text-to-SQL 작업은 테이블 이름, 열, 관계 및 데이터 속성을 포함한 데이터베이스 스키마에 대한 깊은 이해를 요구합니다. 현대 스키마의 복잡성과 대규모 데이터 볼륨은 이 작업을 특히 어렵게 만듭니다.

- **테이블 간 복잡한 관계**: 데이터베이스는 종종 수백 개의 테이블과 복잡한 상호 관계를 포함합니다. Text-to-SQL 솔루션은 SQL을 생성할 때 이러한 관계를 정확하게 이해하고 활용해야 합니다.
- **속성 및 값의 모호성**: 데이터베이스의 모호한 값과 속성은 Text-to-SQL 시스템이 올바른 컨텍스트를 식별하는 것을 복잡하게 만들 수 있습니다.
- **도메인별 스키마 설계**: 다양한 도메인은 종종 고유한 데이터베이스 설계 및 스키마 패턴을 가지고 있습니다. 도메인 간 스키마 설계의 변형은 모든 경우에 적합한 Text-to-SQL 모델을 개발하기 어렵게 만듭니다.
- **대규모이고 더러운 데이터베이스 값**: 대규모 데이터베이스에서 방대한 데이터 볼륨을 효율적으로 처리하는 것은 모든 데이터를 입력으로 처리하는 것이 비실용적이기 때문에 중요합니다. 또한, 누락된 값, 중복 또는 불일치와 같은 더러운 데이터(dirty data)는 적절히 관리되지 않으면 잘못된 쿼리 결과로 이어질 수 있습니다(예: WHERE 절에 영향).

**C3: Text-to-SQL 번역.** Text-to-SQL 작업은 고급 프로그래밍 언어를 저급 기계 언어로 컴파일하는 것과 다르며, 일반적으로 입력 NL, DB와 출력 SQL 간에 *일대다(one-to-many)* 매핑을 가집니다. 구체적으로, Text-to-SQL 작업은 다음과 같은 고유한 과제에 직면합니다:

- **자유 형식 NL vs. 제약되고 형식적인 SQL**: 자연어는 유연하지만, SQL 쿼리는 엄격한 구문을 준수해야 합니다. NL을 SQL로 번역하려면 생성된 쿼리가 실행 가능하도록 정밀성이 필요합니다.
- **여러 가능한 SQL 쿼리**: 단일 NL 쿼리는 쿼리 의도를 충족하는 여러 SQL 쿼리에 해당할 수 있으며, 이는 적절한 SQL 번역을 결정하는 데 모호성을 야기합니다(그림 2(a)의 예 참조).
- **데이터베이스 스키마 의존성**: Text-to-SQL 번역은 기본 데이터베이스 스키마에 크게 의존합니다. 그림 2(a)와 (b)에서 보듯이, 동일한 NL이 스키마 변형에 따라 다른 SQL 쿼리를 생성할 수 있습니다. 이는 Text-to-SQL 모델이 훈련 데이터와 실제 스키마 차이 간의 격차를 메워야 함을 요구합니다.

본질적인 과제 외에도, 개발자는 신뢰할 수 있고 효율적인 Text-to-SQL 시스템을 구축하기 위해 아래에서 논의되는 여러 기술적 장애물을 극복해야 합니다.

**C4: Text-to-SQL 솔루션 개발의 기술적 과제.** 강건한 Text-to-SQL 솔루션을 개발하려면 다음과 같은 몇 가지 주요 기술적 과제를 해결해야 합니다:

- **비용 효율적인 솔루션(Cost-effective Solution)**: Text-to-SQL 모델, 특히 대규모 언어 모델을 사용하는 모델을 배포하려면 하드웨어 및/또는 API 비용과 같은 상당한 리소스가 필요합니다. 모델 성능과 비용 효율성 간의 최적의 균형을 달성하는 것은 여전히 중요한 과제입니다.
- **모델 효율성(Model Efficiency)**: 모델 크기와 성능 사이에는 종종 트레이드오프가 존재하며, 일반적으로 더 큰 모델이 더 나은 결과를 산출합니다. 정확도를 손상시키지 않으면서 효율성을 최적화하는 것은 특히 낮은 지연 시간(low latency)이 필요한 대화형 쿼리 시나리오에서 필수적입니다.
- **SQL 효율성(SQL Efficiency)**: Text-to-SQL 모델이 생성한 SQL은 정확할 뿐만 아니라 성능에 최적화되어야 합니다. 여기에는 조인 연산(join operations), 인덱스 사용 및 쿼리 구조 최적화가 포함됩니다. 효율적인 쿼리는 데이터베이스 부하를 줄이고 시스템 응답성과 처리량을 향상시킵니다.
- **불충분하고 잡음이 많은 훈련 데이터(Insufficient and Noisy Training Data)**: 고품질 Text-to-SQL 훈련 데이터는 얻기 어렵습니다. 공개 데이터셋은 종종 제한적이며 잡음이 있는 주석(annotations)을 포함할 수 있어 모델 성능에 영향을 미칩니다[33], [34]. 주석(annotation)에는 데이터베이스 전문 지식이 필요하여 비용이 증가하며, Text-to-SQL 작업의 복잡성은 종종 오류로 이어집니다.
- **신뢰성 및 안정성(Trustworthiness and Reliability)**: Text-to-SQL 모델은 신뢰할 수 있고 안정적이어야 하며, 다양한 데이터셋과 시나리오에서 일관되게 정확한 결과를 생성해야 합니다. 신뢰성은 투명성을 요구하여 사용자가 생성된 SQL을 이해하고 검증할 수 있도록 합니다.

![](_page_4_Figure_1.jpeg)

그림 4: Text-to-SQL에서 PLM 및 LLM의 분류.

### D. 대규모 언어 모델로 과제 해결하기 (Challenges Solving with Large Language Models)

**난이도 수준.** 우리는 Text-to-SQL의 난이도를 다섯 가지 수준으로 분류하며, 각 수준은 특정 장애물을 다룹니다. 그림 3(a)에 나타난 바와 같습니다. 처음 세 수준은 해결되었거나 현재 해결되고 있는 과제를 다루며, Text-to-SQL 기능의 점진적 진전을 강조합니다. 네 번째 수준은 현재 LLM 기반 솔루션의 초점인 과제를 포함하며, 다섯 번째 수준은 향후 5년 동안 Text-to-SQL 발전에 대한 우리의 비전을 보여주는 미래 과제를 나타냅니다.

![](_page_3_Figure_1.jpeg)

그림 3: 언어 모델의 관점에서 Text-to-SQL 솔루션의 진화.

**Text-to-SQL 솔루션의 진화.** Text-to-SQL 솔루션의 발전은 그림 3(b)에 나타난 바와 같이 네 가지 뚜렷한 단계를 거칩니다: 규칙 기반 단계(rule-based stage), 신경망 기반 단계(neural network-based stage), PLM 기반 단계, LLM 기반 단계. 각 단계에서 우리는 대상 사용자의 변화, 즉 전문가에서 더 광범위한 사용자 그룹으로의 변화와 다양한 Text-to-SQL 과제가 해결되는 정도를 분석합니다.

**1) 규칙 기반 단계:** 초기 단계에서는 통계적 언어 모델(*예:* 의미 파서, semantic parsers)이 사전 정의된 규칙을 사용하여 NL 쿼리를 해석하고 SQL 쿼리로 변환하는 데 사용되었습니다[32], [35]–[37]. 그러나 규칙 기반 Text-to-SQL 방법은 적응성(adaptability), 확장성(scalability) 및 일반화(generalization)에서 과제에 직면합니다. 이 단계에서 자연어 이해는 토큰 수준으로 제한되었으며, 연구는 주로 단일 테이블 SQL 쿼리에 중점을 두었습니다(그림 3(b)-① 참조).

**2) 신경망 기반 단계:** 규칙 기반 방법의 한계를 완화하기 위해 연구자들은 Text-to-SQL 작업을 위해 신경망을 탐구했습니다. 이는 시퀀스-투-시퀀스 아키텍처(sequence-to-sequence architectures) 및 그래프 신경망(graph neural networks) 기반 모델의 개발로 이어졌으며[38]–[40], 동의어 처리(handling synonyms) 및 의도 이해(intent understanding)를 향상시켰습니다. 따라서 연구는 단일 테이블 시나리오에서 더 복잡한 다중 테이블 시나리오로 발전했습니다(그림 3(b)-② 참조). 그러나 이러한 방법의 일반화 능력은 여전히 모델 크기와 충분한 훈련 데이터의 가용성에 의해 제한됩니다.

**3) PLM 기반 단계:** 2018년에 BERT[41] 및 T5[42]와 같은 PLM의 도입은 PLM 기반 Text-to-SQL 방법의 상당한 발전으로 이어졌으며[7], [43], [44], 다양한 벤치마크에서 경쟁력 있는 성능을 달성했습니다(그림 3(b)-③ 참조). 이 단계에서 대규모 코퍼스(large corpora)에서 훈련된 PLM 기반 Text-to-SQL 모델은 자연어 이해를 크게 향상시켜 Spider 데이터셋[45]의 약 80%의 사례를 해결했습니다. 그러나 Spider의 매우 어려운 사례(extra hard cases)에서는 정확도가 약 50%로 떨어집니다[46]. 또한, 이러한 모델은 복잡한 스키마를 처리하는 데 여전히 과제에 직면합니다.

**참고: PLMs vs. LLMs** 그림 4는 LLMs와 PLMs 간의 주요 차이점을 보여줍니다. LLMs는 PLMs의 부분 집합이며, 고급 언어 이해 및 창발적 능력(emergent capabilities)[47], [48]으로 구별됩니다. 창발적 능력은 LLMs가 프롬프트를 사용하여 Text-to-SQL 작업을 직접 수행할 수 있도록 합니다. 반면, PLMs는 일반적으로 허용 가능한 Text-to-SQL 성능을 위해 추가 사전 훈련 또는 파인튜닝이 필요합니다.

**4) LLM 기반 단계:** LLMs는 전통적인 PLMs를 능가하는 NLP 작업에서 고유한 창발적 능력을 보여주며, Text-to-SQL 솔루션에 대한 새로운 패러다임을 표시합니다. 이러한 LLM 기반 Text-to-SQL 방법은 현재 Text-to-SQL 환경에서 가장 대표적인 솔루션이 되었습니다[5], [6], [49], [50]. 현재 연구는 프롬프트 설계 최적화[6] 및 LLMs 파인튜닝[49]에 중점을 둡니다. 예를 들어, DAIL-SQL[6]은 효과적인 프롬프트 엔지니어링 기술과 함께 GPT-4를 활용하여 Spider 데이터셋[45]에서 강력한 결과를 달성합니다. 한편, CodeS[49]는 Text-to-SQL 작업을 위해 특별히 LLM을 구축하여 대규모 Text-to-SQL 관련 코퍼스에서 StarCoder[51]를 사전 훈련하고, BIRD[52]와 같은 벤치마크에서 견고한 성능을 보여줍니다. 이 단계에서 LLMs의 창발적 능력은 자연어 이해를 크게 향상시켜 작업의 초점을 데이터베이스별 과제로 이동시켰습니다. BIRD[52] 및 BULL[50]과 같은 새로운 벤치마크는 대규모 테이블 처리 및 도메인별 솔루션을 강조합니다(그림 3(b)-④ 참조).

**LLMs 시대의 Text-to-SQL 솔루션.** 넓게 말하면, Text-to-SQL을 위해 LLMs의 기능을 활용하는 두 가지 주요 접근 방식이 있습니다: 1) 맥락 내 학습(in-context learning), 2) Text-to-SQL에 특화된 LLMs의 사전 훈련/파인튜닝.

**Text-to-SQL을 위한 맥락 내 학습.** 맥락 내 학습 방법의 경우, 목표는 LLMs를 안내하기 위해 프롬프트 함수 P를 최적화하는 것이며, 다음과 같이 공식화할 수 있습니다:

$$\mathcal{F}_{\mathsf{LLM}}(P \mid \mathsf{NL}, \mathsf{DB}, \mathsf{K}) \to \mathsf{SQL},$$

여기서 K는 NL 또는 DB와 관련된 추가 정보 또는 도메인별 지식을 나타냅니다. P는 입력(NL, DB, K)을 LLMs에 적합한 *텍스트 프롬프트*로 변환하는 *프롬프트 함수*입니다. 잘 설계된 P는 LLMs가 Text-to-SQL 작업을 더 정확하게 수행하도록 효과적으로 안내할 수 있습니다.

Text-to-SQL에 맥락 내 학습 전략을 사용하면 LLMs를 *즉시 사용 가능한(off-the-shelf)* 도구로 취급하여 매개변수를 수정하지 않습니다. 그러나 사용자가 충분한 훈련 데이터 또는 하드웨어 리소스를 가지고 있는 경우, LLMs의 매개변수를 보정하면 성능과 정확도를 향상시킬 수 있으며, 모델이 특정 Text-to-SQL 작업에 더 밀접하게 맞춤화될 수 있습니다.

**Text-to-SQL을 위한 LLMs의 사전 훈련 및 파인튜닝.** Text-to-SQL을 위해 LLMs의 매개변수를 완전히 최적화하는 것은 사전 훈련(pre-train) 및 파인튜닝(fine-tune)의 두 가지 주요 단계를 포함하며, 다음과 같이 공식화됩니다:

$$LLM^* = \mathcal{F}_{fine-tune}\left(\mathcal{F}_{pre-train}(LLM, \mathcal{D}_p), \mathcal{D}_f\right)$$

사전 훈련 동안, LLM은 광범위한 언어 패턴과 도메인 일반 지식을 포함하는 대규모 및 다양한 데이터셋 D_p에서 훈련되어 모델이 강건한 이해 능력을 개발할 수 있도록 합니다.

![](_page_5_Figure_2.jpeg)

그림 5: LLM 시대의 Text-to-SQL 모듈 개요.

후속 파인튜닝 단계에서, 사전 훈련된 모델은 Text-to-SQL 작업과 밀접하게 정렬된 더 전문화된 데이터셋 D_f에서 추가로 조정됩니다. 이 목표 훈련은 모델의 기능을 다듬어 NL 쿼리를 기반으로 SQL을 더 효과적으로 해석하고 생성할 수 있도록 합니다.


## III. 언어 모델 기반 TEXT-TO-SQL 개요 (LANGUAGE MODEL-POWERED TEXT-TO-SQL OVERVIEW)

Text-to-SQL은 초기에 엔드-투-엔드 작업으로 설계되었지만, 최근의 발전, 특히 LLM 시대에는 모듈식 설계(modular design)로 전환되었습니다. 그림 5에 나타난 바와 같이, 현대의 PLM 및 LLM 기반 솔루션은 일반적으로 작업을 세 단계로 분해합니다: 사전 처리(Pre-Processing), 번역(Translation), 후처리(Post-Processing). 각 단계에는 스키마 링킹(schema linking), 중간 표현(intermediate representation), 실행 안내 수정(execution-guided correction)과 같은 전문화된 모듈이 포함됩니다. 이 설계는 Text-to-SQL의 복잡성 증가를 반영하며, 다중 에이전트 또는 다중 모듈 협업의 증가 추세와 일치합니다. 표 I은 최근 솔루션들 간의 주요 설계 선택을 추가로 비교합니다.

**사전 처리 방법(Pre-Processing Methods).** 사전 처리는 입력을 향상시키고 Text-to-SQL 파싱을 개선하는 데 중요한 역할을 합니다[53].

- **스키마 링킹(Schema Linking)**: 이 모듈은 Text-to-SQL을 위해 가장 관련성이 높은 테이블과 열을 식별합니다(Section IV-A).
- **데이터베이스 콘텐츠 검색(Database Content Retrieval)**: 이 핵심 모듈은 SQL 공식화에 필요한 적절한 데이터베이스 콘텐츠 또는 셀 값에 접근합니다(Section IV-B).
- **추가 정보 획득(Additional Information Acquisition)**: 이 핵심 모듈은 도메인별 지식을 통합하여 맥락적 배경을 풍부하게 합니다(Section IV-C).

**번역 방법(Translation Methods).** 이것은 Text-to-SQL 솔루션의 핵심으로, 입력 NL 쿼리를 SQL로 변환하는 역할을 합니다.

- **인코딩 전략(Encoding Strategy)**: 이 중요한 모듈은 입력 NL과 데이터베이스 스키마를 내부 표현으로 변환하여 입력 데이터의 의미론적 및 구조적 정보를 모두 캡처합니다(Section V-A).
- **디코딩 전략(Decoding Strategy)**: 이 핵심 모듈은 내부 표현을 SQL 쿼리로 변환합니다(Section V-B).
- **작업별 프롬프트 전략(Task-specific Prompt Strategy)**: 이 모듈은 Text-to-SQL 모델에 맞춤형 지침을 제공하여 Text-to-SQL 번역 워크플로를 최적화합니다(Section V-C).
- **중간 표현(Intermediate Representation)**: 이 모듈은 NL과 SQL 번역 사이의 브리지 역할을 하며, NL 이해를 추상화, 정렬 및 최적화하고, 복잡한 추론을 단순화하며, 정확한 SQL 쿼리 생성을 안내하는 구조화된 접근 방식을 제공합니다(Section V-D).

**후처리 방법(Post-Processing Methods).** 후처리는 생성된 SQL 쿼리를 더 나은 정확도로 개선하는 중요한 단계입니다.

- **SQL 수정 전략(SQL Correction Strategy)**: 이것은 생성된 SQL에서 구문 오류를 식별하고 수정하는 것을 목표로 합니다(Section VI-A).
- **출력 일관성(Output Consistency)**: 이 모듈은 여러 추론 결과를 샘플링하고 가장 일관성 있는 결과를 선택하여 SQL의 균일성을 보장합니다(Section VI-B).
- **실행 안내 전략(Execution-Guided Strategy)**: SQL의 실행 결과를 사용하여 후속 개선을 안내합니다(Section VI-C).
- **N-best 순위 재조정 전략(N-best Rankers Strategy)**: Text-to-SQL 모델이 생성한 상위 k개 결과를 재순위화하여 쿼리 정확도를 향상시키는 것을 목표로 합니다(Section VI-D).

### LLM 시대의 Text-to-SQL을 위한 다중 에이전트 협업 (Multi-agent Collaboration for Text-to-SQL in LLM Era)

모듈식 설계 원칙을 기반으로, 최근 연구는 Text-to-SQL 작업을 해결하기 위해 다중 에이전트 아키텍처(multi-agent architectures)를 더욱 도입했습니다. 전통적인 모놀리식 시스템과 대조적으로, 다중 에이전트 프레임워크는 각 에이전트에 특정 하위 작업을 처리하는 전문화된 책임을 할당합니다. 이 설계는 향상된 작업 분할과 구성 요소 간의 더 효과적인 조정을 촉진합니다. 예를 들어, MAC-SQL[54]은 스키마 링킹, 쿼리 분해 및 생성, 실행 안내 개선을 위한 별도의 에이전트가 있는 3-에이전트 아키텍처를 채택합니다. 유사하게, CHASE-SQL[55]은 분할 정복 접근 방식을 사용하여 사전 처리 중에 관련 데이터베이스 콘텐츠를 선택하고, 여러 사고 사슬 경로(chain-of-thought pathways)를 통해 SQL 쿼리를 생성하며, 자기 수정 및 순위 지정을 통해 출력을 반복적으로 개선합니다. 경계를 더욱 확장하여, Alpha-SQL[56]은 몬테카를로 트리 탐색(Monte Carlo Tree Search, MCTS)과 결합된 LLMs를 활용하는 계획 중심 자율 에이전트 프레임워크를 제안합니다. 이 에이전트는 맥락적 추론 및 실행 기반 피드백을 기반으로 스키마 링킹 및 SQL 생성과 같은 적절한 모듈을 동적으로 선택하고 활성화합니다. Alpha-SQL의 전략 기반 탐색 및 적응형 제어는 파이프라인 기반 접근 방식의 경직성을 피하면서 강건한 일반화를 제공합니다.

## IV. TEXT-TO-SQL을 위한 사전 처리 전략 (PRE-PROCESSING STRATEGIES FOR TEXT-TO-SQL)

사전 처리 단계는 Text-to-SQL 번역 프로세스에서 중요하며, 관련 테이블과 열을 식별하고(*즉,* 스키마 링킹), SQL 쿼리 생성을 지원하기 위해 필요한 데이터베이스 콘텐츠 또는 셀 값을 검색합니다(*즉,* DB 콘텐츠 검색). 또한, 도메인별 지식을 통합하여(*즉,* 추가 정보 획득) 맥락을 풍부하게 하며, 이는 쿼리 맥락의 이해를 개선하고 오류가 전파되는 것을 방지하기 위해 오류를 수정할 수 있습니다.

### A. 스키마 링킹 (Schema Linking)

스키마 링킹은 주어진 NL 쿼리와 관련된 테이블과 열을 식별하여 제한된 입력 내에서 주요 정보의 정확한 매핑 및 처리를 보장하는 것을 목표로 합니다. 이 단계는 Text-to-SQL 작업의 성능을 개선하는 데 필수적입니다. LLM 시대에는 LLMs의 입력 길이 제한으로 인해 스키마 링킹이 더욱 중요해졌습니다.

우리는 기존 스키마 링킹 전략을 특성에 따라 세 그룹으로 분류합니다: *1) 문자열 매칭 기반 스키마 링킹*, *2) 신경망 기반 스키마 링킹*, *3) 맥락 내 학습을 위한 스키마 링킹*.

**1) 문자열 매칭 기반 스키마 링킹(String Matching-based Schema Linking):** 초기 연구[39], [84], [85]는 주로 스키마 링킹을 위한 문자열 매칭 기술에 중점을 두었습니다. 이러한 방법은 NL 쿼리와 DB 스키마 간의 유사성 측정을 사용하여 관련 매핑을 식별합니다. IRNet[84]은 *정확한 매칭(exact matching)*을 채택하여 후보가 동일하거나 하나가 다른 하나의 부분 문자열일 때 링크를 식별합니다. 간단한 경우에는 효과적이지만, 공유 단어로 인해 거짓 양성(false positives)을 초래할 수 있습니다. 철자 변형을 처리하기 위해, ValueNet[86]은 Damerau–Levenshtein 거리[87]를 통한 *근사 매칭(approximate matching)*을 적용합니다.

그러나 이러한 방법은 동의어를 처리하는 데 어려움을 겪으며, 어휘 변형을 관리하기에 충분히 강건하지 않아 복잡한 Text-to-SQL 작업에서 효과가 제한됩니다.

**2) 신경망 기반 스키마 링킹(Neural Network-based Schema Linking):** 위의 한계를 완화하기 위해, 연구자들은 자연어 쿼리와 데이터베이스 스키마를 정렬하기 위해 심층 신경망을 사용했습니다[7], [53]. 이러한 방법은 NL 쿼리와 데이터베이스 스키마 간의 복잡한 의미론적 관계를 더 잘 파싱할 수 있습니다.

DAE[88]는 스키마 링킹을 순차 태깅 문제로 프레임화하여, 스키마와 NL 간의 의미론적 관계를 캡처하기 위해 2단계 익명화 모델을 사용합니다. SLSQL[53]은 Spider 데이터셋[45]에 스키마 링킹 정보를 주석 처리하여 체계적이고 데이터 기반 연구를 가능하게 합니다. RESDSQL[7]은 스키마 링킹을 위한 순위 향상 인코딩 프레임워크를 도입하여, 교차 인코더(cross-encoder)를 사용하여 분류 확률을 기반으로 테이블과 열의 우선순위를 지정합니다. FinSQL[50]은 병렬 교차 인코더를 사용하여 관련 스키마 요소를 검색하며, 링킹 시간을 크게 단축합니다.

그러나 신경망 기반 방법은 종종 다양한 스키마나 도메인을 가진 데이터베이스에서 일반화하는 데 어려움을 겪으며, 특히 훈련 데이터가 부족할 때 그렇습니다.

**3) 스키마 링킹을 위한 맥락 내 학습(In-Context Learning for Schema Linking):** GPT-4와 같은 LLMs의 발전과 함께, 연구는 스키마 링킹을 위해 강력한 추론 능력을 활용하는 방법을 탐구하고 있습니다. *즉,* NL 쿼리에서 관련 데이터베이스 스키마 구성 요소를 직접 식별하고 링크합니다. 핵심 기술은 맥락 내 학습(In-Context Learning, ICL) 기술[89]로, 이는 LLMs의 복잡한 언어 패턴과 데이터 스키마 내 관계를 이해하는 능력을 활용하여 더 동적이고 유연한 스키마 링킹 프로세스를 가능하게 합니다[5], [54], [59], [67], [90].

C3-SQL[67]은 GPT-3.5와 함께 제로샷 프롬프트를 사용하여 테이블 및 열 링킹에 자기 일관성(self-consistency)을 사용합니다. 테이블 링킹의 경우, 테이블은 관련성에 따라 순위가 매겨지고 나열됩니다. 열 링킹의 경우, 열은 관련 테이블 내에서 순위가 매겨지고 사전으로 출력되며, 질문 용어 또는 외래 키와의 일치를 우선시합니다. MAC-SQL[54]은 Text-to-SQL을 위한 다중 에이전트 협업 프레임워크를 제안하며, *Selector* 에이전트가 데이터베이스 스키마 프롬프트가 지정된 길이를 초과할 때만 활성화되어 스키마 링킹을 처리합니다. CHESS[59]는 GPT-4를 활용하여 NL과 증거(BIRD[52]의 추가 정보) 모두에서 키워드를 추출하고, 다양한 프롬프트와 함께 3단계 스키마 프루닝 프로토콜을 구현합니다.

스키마 링킹에 ICL을 사용하는 것은 유망한 성능을 보여주었습니다. 그러나 LLMs는 처리할 수 있는 맥락의 양에 내재적 제한이 있으므로, 많은 테이블과 열이 있는 복잡한 스키마는 이 제한을 초과할 수 있습니다.

### B. 데이터베이스 콘텐츠 검색 (Database Content Retrieval)

데이터베이스 콘텐츠 검색은 WHERE와 같은 특정 SQL 절에 대한 셀 값을 효율적으로 추출하는 데 중점을 둡니다. 우리는 기존 데이터베이스 콘텐츠 검색 전략을 특성에 따라 세 그룹으로 분류합니다: *1) 문자열 매칭 기반 방법*, *2) 신경망 기반 방법*, *3) 데이터베이스 콘텐츠 검색을 위한 인덱스 전략*.

**1) 문자열 매칭 기반 방법(String Matching-based Methods):** 문자열 매칭 기반 방법은 문자열 매칭을 통해 NL 쿼리와 관련된 셀 값을 식별하고 비교합니다[7], [43], [77], [83], [84], [86].

IRNet[84]은 n-그램을 사용하여 따옴표 사이의 텍스트를 셀 값으로 처리합니다. BRIDGE[83]는 NL에서 셀 값을 자동으로 추출하는 앵커 텍스트 매칭 기술로 이를 발전시킵니다. 휴리스틱을 사용하여 최대 시퀀스 일치를 계산하여 매칭 경계를 정의하고, 관련 없는 부분 문자열을 제외하며, 정확도를 위해 임계값을 조정합니다.

그러나 문자열 매칭 방법은 효과적이지만, 동의어와 어려움을 겪으며 대규모 데이터베이스를 처리할 때 계산 비용이 많이 들 수 있습니다.

**2) 신경망 기반 방법(Neural Network-based Methods):** 이러한 방법은 비선형 변환 계층을 통해 복잡한 데이터 및 의미론적 특징을 캡처하여 동의어 문제를 해결하는 데 도움이 됩니다.

TABERT[91]는 NL 쿼리에 대한 관련 데이터베이스 콘텐츠를 인코딩하기 위해 *데이터베이스 콘텐츠 스냅샷(database content snapshots)*이라는 방법을 사용하며, 다른 행의 셀 값 표현에서 정보를 관리하기 위해 주의 메커니즘을 사용합니다. 또 다른 접근 방식은 그래프 관계를 활용하여 데이터베이스 콘텐츠를 나타냅니다. IRNet[84]는 지식 그래프 ConceptNet[92]를 사용하여 관련 셀 값을 찾고 링크하며, 정확한 일치 또는 부분 일치를 기반으로 유형을 할당합니다. RAT-SQL[80]은 셀 값과 NL 쿼리 간의 관계를 모델링하여 구조적 추론을 더욱 향상시키며, 쿼리 값이 열의 후보 셀 값의 일부인 열-값 관계를 식별합니다.

이러한 방법은 의미론적 특징을 캡처하지만, 모호하거나 맥락 의존적인 NL로 인해 셀 값 검색이 부정확할 수 있습니다. 또한, 신경망 훈련에는 상당한 계산 리소스가 필요합니다.

**3) 데이터베이스 콘텐츠 검색을 위한 인덱스 전략(Index Strategy for Database Content Retrieval):** 관련 셀 값을 효율적으로 검색하는 것은 Text-to-SQL 시스템의 성능에 중요하며, 특히 대규모 데이터셋의 경우 그렇습니다. 인덱싱은 관련 셀 값에 대한 더 빠른 접근을 가능하게 하여 검색 효율성을 개선하는 핵심 방법입니다[49], [59].

![](_page_8_Figure_2.jpeg)

그림 6: 설계 선택을 기반으로 한 Text-to-SQL 번역 방법의 분류.

CHESS[59]는 근사 최근접 이웃 검색(approximate nearest neighbor searches)을 위해 Locality-sensitive Hashing[93]을 사용하여 고유한 셀 값을 인덱싱하여 NL 쿼리와 관련된 상위 일치 항목을 빠르게 찾습니다. 이 접근 방식은 편집 거리 및 의미론적 임베딩을 비교하는 프로세스를 가속화합니다. CodeS[49]는 조대-미세 매칭 전략(coarse-to-fine matching strategy)을 사용합니다. BM25[94]를 사용하여 조대 세분화 검색을 위한 인덱스를 구축하여 후보 값을 식별하고, 이후 Longest Common Substring 알고리즘[95]을 적용하여 NL과의 유사성을 평가하여 가장 관련성이 높은 셀 값을 정확히 찾아냅니다.

인덱싱은 검색 효율성을 크게 향상시키지만, 인덱스 구축은 시간이 많이 걸리며, 데이터베이스 콘텐츠의 빈번한 변경은 지속적인 업데이트를 요구하여 오버헤드를 추가합니다.

### C. 추가 정보 획득 (Additional Information Acquisition)

도메인 지식과 같은 추가 정보는 Text-to-SQL 모델의 NL 쿼리 이해, 스키마 링킹 및 전반적인 Text-to-SQL 번역을 향상시키는 데 중요한 역할을 합니다. 이 정보는 Text-to-SQL 백본 모델 또는 특정 모듈에 대한 시연 예제, 도메인 지식, 공식적 증거 및 형식 정보를 제공하여 생성된 결과의 품질을 향상시킬 수 있습니다. 우리는 기존 전략을 다음 두 그룹으로 분류합니다: *1) 샘플 기반 방법*, *2) 검색 기반 방법*.

**1) 샘플 기반 방법(Sample-based Methods):** LLMs 및 맥락 내 학습 기술의 발전과 함께, 연구자들은 종종 시연 예제와 함께 텍스트 입력(*즉,* 프롬프트)에 추가 정보를 통합합니다[49], [59], [70]. DIN-SQL[5]은 여러 단계에서 퓨샷 학습(few-shot learning)을 통해 추가 정보를 통합합니다. 이는 DIN-SQL이 복잡한 스키마 링크, 여러 테이블 조인 및 중첩 쿼리와 같은 과제를 처리하는 데 도움이 됩니다. 실제로, 실제 데이터베이스는 종종 쿼리 생성을 지원하기 위한 외부 증거로 사용될 수 있는 풍부한 교차 도메인 지식을 포함합니다. 예를 들어, BIRD[52]는 다양한 Text-to-SQL 작업[6], [59]에 중요한 도메인 지식을 포함합니다. 최근 연구[49], [70]는 또한 스키마 메타데이터(예: 데이터 유형)를 자연어로 인코딩하여 맥락 이해를 향상시킵니다.

**2) 검색 기반 방법(Retrieval-based Methods):** 광범위한 도메인 지식 베이스에서 관련 지식과 퓨샷 예제를 추출하면 토큰 사용량이 증가하여 효율성과 계산 비용에 영향을 미칠 수 있습니다[5], [6]. 정확도와 효율성을 향상시키기 위해, 일부 연구자들은 유사성 기반 검색 방법을 사용합니다. 예를 들어, PET-SQL[62]는 질문 프레임과 질문-SQL 쌍의 풀을 구축하여 대상 쿼리와 가장 유사한 k개의 예제를 선택하고, 이를 프롬프트에 사용합니다.

데이터베이스에 텍스트 기반 추가 정보가 부족한 경우, 연구자들은 외부 지식을 검색하고 자연어로 변환하는 방법을 고안합니다. 예를 들어, RE-GROUP[102]는 도메인 간(예: 금융, 운송) 공식적 지식 베이스를 만들고 Dense Passage Retriever[103]를 사용하여 유사성 점수를 계산하며, Erasing-Then-Awakening 모델[104]을 통해 관련 엔티티를 NL 및 스키마와 통합합니다. ReBoost[105]는 2단계 Explain-Squeeze 스키마 링킹 전략을 사용하여, 먼저 LLMs에 일반화된 스키마를 제시한 다음 대상 프롬프트를 적용하여 쿼리-엔티티 매핑 정확도를 향상시킵니다.

검색 기반 방법은 추가 정보 획득의 효과를 개선하지만 컴퓨팅 비용을 증가시킵니다. 또한, 현재 연구는 대부분 도메인별 텍스트에 의존하며, 구조화된 지식의 사용이 제한적입니다. 따라서 다양한 정보 소스를 통합하면 Text-to-SQL 성능, 특히 도메인별 데이터베이스에 대해 더욱 향상될 수 있습니다.


## V. TEXT-TO-SQL 번역 방법 (TEXT-TO-SQL TRANSLATION METHODS)

이 섹션에서는 언어 모델을 사용한 Text-to-SQL 번역 방법을 자세히 설명합니다. 그림 6에 나타난 바와 같이, 인코딩(Section V-A), 디코딩(Section V-B), 작업별 프롬프트 전략(Section V-C)을 자세히 설명합니다. 또한, 중간 표현(intermediate representation)이 Text-to-SQL 번역 프로세스에 어떻게 도움이 되는지 논의합니다(Section V-D).

### A. 인코딩 전략 (Encoding Strategy)

Text-to-SQL 작업에서 인코딩은 NL과 데이터베이스 스키마를 언어 모델 처리에 적합한 구조화된 형식으로 변환하는 것을 의미합니다. 이 단계는 비구조화된 데이터를 SQL 생성에 사용할 수 있는 형식으로 변환하는 데 필수적이며, NL의 의미론과 스키마의 구조를 캡처하여 모델이 사용자 의도를 적절한 SQL에 매핑할 수 있도록 돕습니다. 그림 7에 나타난 바와 같이, 주요 인코딩 전략에는 *1) 순차 인코딩(Sequential Encoding)*, *2) 그래프 기반 인코딩(Graph-based Encoding)*, *3) 별도 인코딩(Separate Encoding)*이 포함됩니다.

![](_page_9_Figure_2.jpeg)

그림 7: 인코딩 전략의 개요.

**1) 순차 인코딩 전략(Sequential Encoding Strategy):** 순차 인코딩은 Text-to-SQL 모델에서 NL과 데이터베이스 스키마를 모두 토큰 시퀀스로 처리하는 전략입니다. 그림 7(a)에 나타난 바와 같이, 모델은 표준 Transformer 기반 아키텍처를 사용하여 전체 입력을 선형 토큰 시퀀스로 처리합니다.

T5[42]와 같은 모델은 연구[68], [77]에서 NL과 데이터베이스 스키마를 순차적으로 인코딩하는 데 사용됩니다. BRIDGE[83]는 NL과 데이터베이스 스키마를 태그된 시퀀스로 나타내고 일치하는 데이터베이스 셀 값(앵커 텍스트라고 함)을 해당 필드 옆에 삽입하여 둘 사이의 정렬을 개선합니다. RESDSQL[7]은 순위 향상 인코더를 사용하여 스키마 항목을 정렬 및 필터링하고, 가장 관련성이 높은 항목의 우선순위를 지정하며 스키마 링킹 복잡성을 줄입니다. LLM 기반 Text-to-SQL 시스템은 종종 입력 인코딩 전략을 명시적으로 정의하지 않지만, 일반적으로 쿼리와 스키마 구성 요소를 연결하여 순차 형식을 암시적으로 채택합니다. 이러한 모델은 자기 주의(self-attention)를 활용하여 전체 시퀀스에서 종속성을 모델링합니다.

이것은 유연한 맥락화를 허용하지만, 이러한 접근 방식은 복잡한 관계형 구조를 캡처하는 데 어려움을 겪을 수 있으며, 깊이 중첩된 SQL 쿼리에서 성능이 제한될 수 있습니다.

**2) 그래프 기반 인코딩 전략(Graph-based Encoding Strategy):** Text-to-SQL 모델의 그래프 기반 인코딩은 NL과 데이터베이스 스키마를 모두 상호 연결된 그래프로 나타내며, 데이터베이스의 관계형 구조와 입력 데이터의 상호 의존성을 활용합니다(그림 7(b) 참조). 순차 인코딩과 달리, 이 접근 방식은 스키마의 토폴로지를 보존하여 각 요소에 대해 더 풍부한 맥락을 제공하고 모델이 정확한 SQL 쿼리를 생성하는 능력을 향상시킵니다[43], [72], [74], [76], [79]–[81].

RAT-SQL[80]은 관계 인식 자기 주의 메커니즘(relation-aware self-attention mechanism)을 도입하여 그래프 구조의 관계 정보를 명시적으로 사용하여 질문과 스키마를 공동으로 인코딩하며, 모델의 구조 정보 이해를 향상시킵니다. S²SQL[79]은 ELECTRA[106] 모델을 사용하여 인코딩 단계에서 구문 구조 정보를 주입하여 의미론적 이해를 향상시킵니다. G³R[73]은 LGESQL[107] 인코더와 Graph Attention Network(GAT)[108]를 사용하여 다중 소스 이질적 정보를 캡처합니다. Graphix-T5[43]는 그래프 인식 계층을 추가하여 인코딩 프로세스에 직접 구조 정보를 통합하며, 여러 벤치마크에서 SQL 쿼리 생성을 크게 개선합니다.

그러나 이 전략은 일반적으로 더 복잡한 그래프 구축 및 처리 알고리즘을 포함합니다. 또한 최적의 성능을 달성하기 위해 대규모 훈련 데이터에 의존하는 경향이 있어 저자원 시나리오에서의 적용 가능성이 제한됩니다.

**3) 별도 인코딩 전략(Separate Encoding Strategy):** Text-to-SQL의 별도 인코딩 전략은 입력의 다양한 부분(일반적으로 NL과 DB 스키마)을 단일 시퀀스로 결합하는 대신 독립적으로 인코딩하는 것을 의미합니다. 이 전략은 시간이 지남에 따라 크게 발전했으며 크게 전통적 형태와 현대적 형태로 분류할 수 있습니다.

전통적인 별도 인코딩에서, SQL-Net[109] 및 Seq2SQL[110]과 같은 초기 모델은 형식 불일치로 인해 NL과 데이터베이스 스키마를 별도로 처리했습니다. 그러나 두 구성 요소 간의 상호 작용 부족은 효과적인 스키마 링킹을 방해하여 성능이 제한되었고, 이 접근 방식은 최근 연구에서 덜 일반적입니다. 그림 7(c)에 나타난 바와 같이 현대적인 별도 인코딩 전략은 Text-to-SQL 작업을 하위 작업으로 분해하고 다양한 측면을 별도로 인코딩하여 모듈식 표현 학습에 중점을 둡니다. TKK[78]는 복잡한 Text-to-SQL 작업을 하위 작업으로 분해하고 지식을 점진적으로 통합하여 작업 분해 및 다중 작업 학습 전략을 사용합니다. 유사하게, SC-Prompt[1]는 텍스트 인코딩을 구조와 콘텐츠의 두 단계로 나누며, 각각 별도로 인코딩됩니다.

별도 인코딩은 여러 처리 단계로 인해 계산 오버헤드를 증가시킬 수 있지만, 쿼리의 다양한 측면에 대한 더 정제된 이해를 허용합니다. 이러한 모듈성은 모델에 다양한 쿼리 작업을 처리할 수 있는 더 큰 유연성을 제공하여 전반적인 성능을 향상시킵니다.

### B. 디코딩 전략 (Decoding Strategy)

디코딩은 Text-to-SQL 번역에서 중요한 단계로, 인코더 생성 표현을 SQL로 변환합니다. 효과적인 디코딩 전략은 생성된 SQL 쿼리가 구문적으로 올바를 뿐만 아니라 NL 쿼리와 의미론적으로 정렬되도록 보장하면서 SQL 실행 효율성을 최적화합니다. 그림 8은 여러 핵심 디코딩 전략을 소개합니다.

![](_page_9_Figure_11.jpeg)

그림 8: 디코딩 전략의 개요.

**1) 탐욕적 검색 기반 디코딩 전략(Greedy Search-based Decoding Strategy):** 탐욕적 검색 기반 디코딩 전략은 각 디코딩 단계에서 가장 높은 확률을 가진 토큰을 선택하는 간단하고 효율적인 방법입니다. 그림 8(a)에 나타난 바와 같이, 미래의 가능성을 고려하지 않고 일련의 지역적으로 최적의 선택을 통해 출력 시퀀스를 구성합니다.

GPT 모델(*예:* GPT-4)은 기본적으로 탐욕적 검색 기반 디코딩을 사용하므로, GPT를 사용하는 많은 Text-to-SQL 솔루션이 이 범주에 속합니다. DeepSeek[111]를 기반으로 한 DTS-SQL[60]도 동일한 접근 방식을 사용합니다. SQLNet[109] 및 Seq2SQL[110]과 같은 초기 모델도 SQL 생성을 위해 탐욕적 검색에 의존합니다.

효율성에도 불구하고, 탐욕적 검색에는 주목할 만한 제한 사항이 있습니다. 즉각적인 토큰 확률에만 집중함으로써 장기 종속성이나 전역 시퀀스 일관성을 고려하지 못합니다. 결과적으로 디코딩 프로세스 초기에 발생한 오류가 전파되어 최적이 아니거나 잘못된 SQL 쿼리로 이어질 수 있으며, 특히 복잡하거나 다단계 질문의 경우 더욱 그렇습니다.

**2) 빔 검색 기반 디코딩 전략(Beam Search-based Decoding Strategy):** 빔 검색은 탐욕적 디코딩에 비해 더 넓은 검색 공간을 탐색하는 널리 사용되는 디코딩 전략으로, 종종 더 높은 품질의 결과로 이어집니다. 각 단계에서 상위 토큰만 선택하는 대신, 고정된 수의 상위 순위 부분 시퀀스(빔이라고 함)를 유지하고 상위 k개의 가장 확률이 높은 다음 토큰을 고려하여 각각을 확장합니다(그림 8(b) 참조).

장점을 고려하여, 여러 Text-to-SQL 모델이 빔 검색을 사용합니다[7], [71], [82]. RAT-SQL[80]은 관계 인식 그래프 구조 인코딩과 빔 검색을 결합하여 여러 SQL 후보를 생성하고 그래프 구조 정보를 기반으로 재순위화합니다. RAT-SQL과 달리, EditSQL[99]은 대화 기록과 함께 빔 검색을 사용하여 후보 SQL 쿼리를 생성하고 정제합니다. SmBoP[81]는 반자동 회귀 상향식 디코딩 접근 방식을 사용하여 하위 트리 구성 및 채점을 병렬화하여 효율성을 개선하며, 대수 시간 복잡도를 가집니다. ZeroNL2SQL[44]은 SQL 스케치 생성 단계에서 상위 k개 가설을 유지하며, 이후 쿼리 및 술어 보정을 위해 정제됩니다.

탐욕적 디코딩과 비교하여, 빔 검색은 각 단계에서 여러 가설을 고려하여 특히 복잡한 시나리오에서 구문적으로 및 의미론적으로 유효한 SQL 쿼리를 생성하는 능력을 향상시킵니다. 그러나 이러한 이점은 계산 복잡성과 메모리 사용량 증가의 비용으로 이루어지며, 디코딩 프로세스를 잠재적으로 느리게 만들 수 있습니다.

**3) 제약 인식 증분 디코딩 전략(Constraint-aware Incremental Decoding Strategy):** 제약 인식 증분 디코딩 전략은 디코딩 프로세스 중에 명시적 제약을 적용하여 SQL 쿼리의 구조적 및 구문적 유효성을 보장하는 것을 목표로 합니다. 그림 8(c)에 나타난 바와 같이, 이러한 전략은 각 단계에서 SQL 문법 제약을 적용하면서 SQL을 증분적으로 생성합니다.

대표적인 구현은 PICARD[77](Parsing Incrementally for Constrained Auto-Regressive Decoding)로, SQL 문법 제약을 디코딩 루프에 통합합니다. 모든 단계에서 부분적으로 생성된 쿼리의 구문적 유효성을 검증하여 각 토큰이 SQL 문법을 준수하도록 보장합니다. 이는 무효하거나 불완전한 쿼리의 생성을 크게 줄입니다. 많은 모델[43], [74]–[78]이 성능을 개선하기 위해 이 패러다임을 채택했습니다.

문법 수준 제약 외에도, 일부 모델은 디코딩 중에 스키마 수준 제약을 통합합니다. BRIDGE[83]는 스키마 일관성 안내 디코딩(Schema-Consistency Guided Decoding)을 도입하여 생성된 SQL 쿼리와 기본 데이터베이스 스키마 간의 정렬을 일관성을 검증하고 그에 따라 디코딩 경로를 조정하여 적용합니다.

이 전략은 토큰별 제약 평가로 인해 추가 계산 오버헤드를 도입하지만, 구문 정확성에 대한 강력한 보장을 제공하며 구조적으로 복잡한 SQL 쿼리를 생성하는 데 특히 효과적입니다.

### C. 작업별 프롬프트 전략 (Task-specific Prompt Strategy)

LLM 시대에 프롬프트 엔지니어링은 다양한 작업에서 LLM 기능을 활용하는 강력한 방법이 되었습니다. Text-to-SQL에서 작업별 프롬프트는 LLMs가 Text-to-SQL 번역을 최적화하도록 안내하기 위해 제작되어 복잡한 NL 쿼리를 정확한 SQL 쿼리로 번역하는 정확도를 향상시킵니다. 넓게 말하면, 작업별 프롬프트 전략에는 두 가지 주요 유형이 있습니다: *1) 사고 사슬 프롬프팅(Chain-of-Thought prompting)*, *2) 분해 전략(Decomposition Strategy)*.

**1) 사고 사슬(Chain-of-Thought, CoT) 프롬프팅:** CoT 프롬프팅[112]은 효과성으로 알려져 있으며, LLM의 추론 프로세스를 보여주어 생성된 결과의 정확성과 해석 가능성을 모두 개선합니다. Text-to-SQL에서 CoT는 모델 성능을 향상시키고 생성된 SQL 문이 인간의 기대와 더 잘 일치하도록 보장합니다[113].

CHESS[59]는 LLMs와 CoT를 활용하는 간소화된 파이프라인을 통해 NL을 SQL 문으로 변환합니다. 이 프로세스에는 엔티티 및 맥락 검색, 스키마 선택, SQL 생성 및 수정이 포함됩니다. 또한, CoT를 다른 기술과 통합하면 Text-to-SQL 모델의 성능을 향상시킬 수 있습니다. 이러한 기술에는 맥락 내 학습[63], [69], 논리 합성[61], 힌트를 사용한 보정[67], [73] 및 다중 에이전트 시스템[54]이 포함됩니다. 구체적으로, 맥락 내 학습 및 논리 합성은 더 깊은 언어 이해를 포함하여 CoT를 풍부하게 하며, SQL 구성에 대한 정확한 의미론적 매핑을 가능하게 합니다[63], [69]. 힌트를 사용한 보정은 모델 응답을 미세 조정하여 NL 뉘앙스와 밀접하게 정렬하여 정확한 의도 번역을 합니다[67], [73]. 또한, 다중 에이전트 프레임워크를 CoT와 통합하면 협업 접근 방식을 촉진하며, 스키마 링킹 및 SQL 생성과 같은 작업을 처리하는 전문 에이전트가 추론을 가속화하고 적응성을 향상시킵니다[54].

전반적으로, 이러한 기술은 더 강건한 Text-to-SQL 프레임워크를 만들어 복잡한 NL 쿼리를 정확한 SQL 문으로 번역하는 데 더 나은 정밀도와 신뢰성을 제공합니다. 그러나 CoT 프롬프팅은 더 긴 추론 체인과 지연 시간을 도입할 수 있으며, 그 효과는 프롬프트 설계 및 작업 복잡성에 민감할 수 있습니다.

**2) 분해 전략(Decomposition Strategy):** 분해 전략은 Text-to-SQL 작업을 순차적 하위 작업으로 나누어 각 하위 모듈이 특정 생성 단계에 집중할 수 있도록 하여 정확성, 품질 및 해석 가능성을 향상시킵니다.

다양한 접근 방식은 하위 작업 분해 세분화에서 다릅니다[54], [60], [66], [73], [78]. TKK[78]는 Text-to-SQL 파싱을 SELECT, FROM 및 WHERE 절에 NL을 매핑하는 것과 같은 하위 작업으로 분해하여 더 세밀한 분해를 적용합니다. 이 접근 방식은 모델이 각 절에 집중하여 문제, 스키마 및 SQL 정렬에 대한 이해를 향상시키는 데 도움이 됩니다. 유사한 전략이 G³R[73] 및 DEA-SQL[66]에서 사용됩니다. 또한, 분해는 모델 복잡성을 줄입니다. 예를 들어, MAC-SQL[54]은 Decomposer 에이전트를 도입하여 사용자의 쿼리를 하위 문제로 분할하여 각 부분에 대한 SQL 생성을 더 관리하기 쉽게 만듭니다.

일반적으로, 분해 전략은 Text-to-SQL 번역 작업을 여러 하위 작업으로 나누어 각 하위 모듈이 특정 출력 향상에 집중할 수 있도록 합니다. 그러나 이 접근 방식은 계산 비용을 증가시켜 모델 훈련 및 배포를 더 복잡하고 리소스 집약적으로 만듭니다.

### D. Text-to-SQL 번역을 위한 중간 표현 (Intermediate Representation for Text-to-SQL Translation)

Text-to-SQL은 NL 쿼리의 복잡성과 모호성, 그리고 SQL의 구문 제약 특성으로 인해 어렵습니다. 이 프로세스를 단순화하기 위해, 연구자들은 "자유 형식" NL 질문과 "제약되고 형식적인" SQL 사이의 브리지 역할을 하는 *문법 없는(grammar-free)* 중간 표현(IR)을 개발했습니다. 이 IR은 SQL의 엄격한 구문 요구 사항 없이 NL 쿼리 내의 필수 구성 요소와 관계를 캡처하는 구조화되지만 유연한 형식을 제공합니다. 그림 9는 아래에서 논의되는 두 가지 유형의 IR 전략을 보여줍니다.

**1) SQL 유사 구문 언어(SQL-like syntax language):** 그림 9(a)에 나타난 바와 같이, SQL 유사 구문 언어는 단순화된 SQL 유사 구조입니다. 초기 접근 방식은 정보 검색 기술을 사용하여 원래 질문과 스키마 데이터를 이 구문에 매핑했습니다[96], [114]. 후속 연구 노력은 SQL 쿼리에서 부분 절 또는 연산을 통합하거나 제거하여 SQL 유사 구문 언어를 단순화하는 데 중점을 두었습니다[97], [98]. SyntaxSQLNet[97]는 FROM 및 JOIN 절의 일부를 제거하여 구문 언어를 단순화합니다. SemQL[98]은 전체 FROM, JOIN, ON 및 GROUP BY 절을 제거하고 WHERE 및 HAVING 조건을 통합된 필터링 표현으로 병합합니다. 최근 연구는 파싱 효율성을 개선하기 위해 구문 언어를 단순화하는 데 중점을 두었습니다[115]. 널리 사용되는 SQL 유사 구문 언어인 NatSQL[100]은 흔하지 않은 SQL 연산자 및 키워드를 제거하여 필요한 스키마 항목을 최소화하여 스키마 링킹을 간소화합니다. PLMs와 결합하여, NatSQL은 다양한 벤치마크에서 강력한 결과를 달성했습니다[7], [68].

SQL 유사 구문 언어는 사용자 쿼리와 데이터베이스를 연결하는 데 잠재력을 보여주었습니다. 그러나 이전 연구는 높은 복잡성과 데이터베이스 구조의 제한된 범위로 인해 과제에 직면합니다[100]. 데이터베이스가 크기와 도메인 특이성에서 성장함에 따라, SQL 유사 구문 언어의 단순성을 유지하는 것이 점점 더 어려워집니다. 또한, 이러한 언어 중 일부는 수동 구성 및 조정이 필요하여 배포 비용과 복잡성을 높입니다.

**2) SQL 유사 스케치 구조(SQL-like sketch structure):** SQL의 구조적 특성을 활용하여, 연구자들은 파싱을 위해 SQL 구조를 반영하는 SQL 유사 스케치를 개발하여 다양한 NL 쿼리를 특정 스케치 공간에 매핑할 수 있도록 하며, 그림 9(b)에 나타난 바와 같습니다. 이 접근 방식은 파싱 복잡성을 줄입니다.

초기 작업은 고정된 스케치 규칙과 신경망을 적용하여 NL을 SQL 유사 스케치 구조로 매핑했습니다[97], [116]. SyntaxSQLNet[97]는 구문 트리와 해당 디코더를 사용하여 디코딩을 연산자, 키워드 및 엔티티를 별도로 예측하는 9개의 하위 모듈로 나누고, 이를 결합하여 최종 SQL을 생성합니다. 최근 몇 년 동안, 언어 모델의 발전으로 연구자들은 파싱을 위해 더 정교한 SQL 유사 스케치 구조를 설계할 수 있게 되었습니다[1], [44], [61], [71]. CatSQL[71]은 초기 자리 표시자 역할을 하는 슬롯이 있는 더 일반적인 템플릿 스케치를 구성합니다. 기본 모델은 이러한 자리 표시자를 채우기 위해 NL 파싱에 중점을 두어 계산 비용을 줄입니다. 또한, 최근 여러 작업이 SQL 유사 구문 언어와 SQL 유사 스케치 전환 방법을 모두 다룹니다. 예를 들어, RESDSQL[7]은 순위 향상 인코딩 및 스켈레톤 인식 디코딩 프레임워크를 도입합니다. 디코딩 단계에서, 디코더는 처음에 SQL 스켈레톤을 생성한 다음 이를 실제 SQL 쿼리로 변환합니다. NatSQL과 결합하면, RESDSQL은 SQL 쿼리 생성 품질을 더욱 향상시키는 능력을 보여줍니다.

일반적으로, SQL 유사 스케치 구조는 분해 전략 또는 SQL 유사 구문 언어 전략과 같은 다른 전략과 더 쉽게 결합될 수 있습니다. 또한, 기존 LLMs의 이해 및 빈칸 채우기 기능을 더 충분히 활용하고 전문가에 대한 의존도를 줄일 수 있습니다.

## VI. TEXT-TO-SQL을 위한 후처리 전략 (POST-PROCESSING STRATEGIES FOR TEXT-TO-SQL)

Text-to-SQL 모델이 SQL을 생성한 후, 후처리를 통해 사용자 기대를 더 잘 충족하도록 개선할 수 있습니다. 이 단계에는 SQL을 향상시키기 위해 추가 정보 또는 모델을 활용하는 것이 포함되며, SQL 수정, 출력 일관성 보장 및 실행 안내 확인에 중점을 둡니다.

### A. SQL 수정 전략 (SQL Correction Strategies)

Text-to-SQL 모델이 생성한 SQL에는 구문 오류가 포함될 수 있습니다. DIN-SQL[5]은 제로샷 설정에서 작동하는 자기 수정 모듈을 도입하며, 모델은 잘못된 SQL만 받고 수정을 시도합니다. 두 가지 프롬프트가 사용됩니다: CodeX에 대한 일반 프롬프트는 오류 식별 및 수정을 직접 요청하고, GPT-4에 대한 온건한 프롬프트는 오류를 가정하지 않고 잠재적 문제를 찾습니다. 잘못된 열 또는 값과 같은 술어 예측의 오류를 처리하기 위해, ZeroNL2SQL[44]는 다중 수준 매칭 접근 방식을 사용합니다. 이 방법은 열, 테이블 및 데이터베이스 전체에서 매칭을 증분적으로 확장하여 매칭된 값을 LLMs에 반환하여 데이터베이스 콘텐츠와 일치하는 SQL 쿼리를 생성할 수 있도록 합니다.

이러한 방법은 구문 오류 수정에 중점을 두지만, 종종 잘못된 테이블 조인, 정렬되지 않은 조건 또는 부정확한 집계와 같은 의미론적 오류[33]를 간과하며, 이는 정확도를 개선하는 데 필수적입니다.

### B. 출력 일관성 (Output Consistency)

출력 일관성을 향상시키기 위해, 자기 일관성(self-consistency)[117]이 도입되었으며, 복잡한 추론 작업에는 단일 정답에 대한 여러 유효한 경로가 있을 수 있다는 아이디어를 기반으로 합니다. 이 접근 방식은 다양한 추론 경로를 샘플링하고 가장 일관성 있는 답변을 선택하여 출력 품질을 개선합니다.

DAIL-SQL[6]은 자기 일관성을 통합하여 이를 사용하지 않는 구성에 비해 0.4%의 성능 향상을 달성합니다. LLM 무작위성을 줄이기 위해, FinSQL[50]은 n개의 후보 SQL 쿼리를 병렬로 생성하고 키워드 일관성을 기반으로 클러스터링하며, 가장 큰 클러스터에서 쿼리를 선택합니다. 자기 일관성 전략은 온도를 높이고 다수결 투표를 통해 최종 결과를 선택하여 LLM 출력 다양성을 향상시킵니다. 그러나 최근 연구[118]는 단일 모델에 의존하면 여전히 제한된 다양성을 초래할 수 있음을 나타냅니다. 이 제한을 극복하기 위해, PET-SQL[62]은 교차 일관성 전략을 도입하며, 여러 LLMs가 더 낮은 온도에서 SQL을 생성하고 실행 결과를 기반으로 투표합니다.

![](_page_12_Figure_2.jpeg)

그림 10: Text-to-SQL 벤치마크 타임라인.

이러한 방법은 여러 실행에서 일관성을 적용하여 정확도를 향상시키지만, 추론 비용과 시간을 크게 증가시킵니다.

### C. 실행 안내 전략 (Execution-Guided Strategies)

Text-to-SQL 작업에서 SQL 쿼리의 실행 결과는 Text-to-SQL 번역 정확도에 대한 중요한 피드백을 제공합니다. 예를 들어, 실행 결과의 오류 또는 NULL 값은 SQL 쿼리의 잠재적 문제를 신호할 수 있습니다.

복잡한 SQL 쿼리를 작성하는 인간 행동을 반영하기 위해, CHESS[59]는 LLMs에 데이터베이스 스키마, 질문, 후보 SQL 쿼리 및 실행 결과를 제공합니다. CHESS는 초안 쿼리로 시작하여 실행 피드백을 기반으로 개선하며, 필요에 따라 구문 오류를 조정합니다. 반면, CodeS[49]는 빔 검색을 통해 완전한 SQL 문을 생성하여 4개의 SQL 후보를 생성하고 첫 번째 실행 가능한 것을 최종 결과로 선택합니다.

실행 안내 전략은 실행 결과를 기반으로 SQL을 개선하여 쿼리가 데이터를 올바르게 검색하도록 보장합니다. 그러나 이 접근 방식은 특히 대규모 데이터베이스의 경우 SQL 생성 시간을 크게 증가시킬 수 있습니다.

### D. N-best 순위 재조정 전략 (N-best Rerankers Strategies)

Text-to-SQL 작업, 특히 교차 도메인 시나리오에서 생성된 SQL 쿼리는 구조 및 의미론에서 미묘하게 다를 수 있습니다. N-best 재순위화는 상위 N개의 모델 출력을 재정렬하며, 종종 더 큰 모델 또는 추가 지식 소스를 활용합니다. 예를 들어, Spider 데이터셋[119]에서 Bertrand-dr로 입증된 BERT 기반 재순위화기를 파인튜닝하는 것은 여러 Text-to-SQL 모델의 성능을 효과적으로 개선했습니다.

그러나 Bertrand-dr의 재순위화 효과는 불안정하고 임계값 설정에 민감할 수 있으며, 때로는 부정적인 효과를 초래하기도 합니다. 이러한 제한 사항을 해결하기 위해, G³R[73]은 추가 매개변수 없이 도메인 격차를 메우는 PLM 기반 하이브리드 프롬프트 튜닝을 사용하여 기능 향상 재순위화기를 도입합니다. 대조 학습은 후보 쿼리 간의 차이를 예리하게 합니다[120]. 유사하게, RefSQL[121]은 검색기 및 생성기 모듈에서 가장 관련성이 높은 결과를 검색하여 최종 답변 품질을 개선합니다.

재순위화 전략은 출력 품질을 향상시킬 수 있지만, 추가 계산 및 모델 훈련 비용이 필요하며, 재순위화기의 설계 및 훈련 품질에 크게 의존합니다.


N-best 재순위화는 PLM 기반 방법에서 SQL 후보를 정제하기 위해 널리 사용되지만, 일반적으로 더 강력한 추론 능력을 가진 LLM 기반 방법에서는 덜 일반적입니다.

## VII. TEXT-TO-SQL 벤치마크 (TEXT-TO-SQL BENCHMARKS)

이 섹션에서는 먼저 그림 10에 나타난 바와 같이 다양한 유형의 Text-to-SQL 데이터셋을 자세히 설명하고, 그 특성을 강조합니다(Section VII-A). 그런 다음 기존 데이터셋에 대한 심층 분석을 수행합니다(Section VII-B).

### A. Text-to-SQL 벤치마크 개요 (An Overview of Text-to-SQL Benchmarks)

Text-to-SQL의 발전과 함께, 그림 10에 나타난 바와 같이 진화하는 과제를 해결하기 위해 다양한 데이터셋이 등장했습니다. 이들은 단순한 쿼리를 가진 단일 도메인 데이터베이스에서 교차 도메인, 다중 턴, 다국어 및 도메인별 시나리오까지 다양하며, Text-to-SQL 솔루션의 진전과 새로운 과제의 출현을 반영합니다.

**단일 도메인 Text-to-SQL 데이터셋(Single-Domain Text-to-SQL Datasets).** 초기 Text-to-SQL 데이터셋은 항공편 정보를 위한 ATIS[122] 및 미국 지리적 사실을 위한 GeoQuery[123]와 같이 비교적 단순한 SQL 쿼리를 가진 특정 도메인에 중점을 두었습니다. 최근에는 특정 시나리오에 맞춘 더 복잡한 데이터베이스 및 SQL 쿼리를 특징으로 하는 더 큰 단일 도메인 데이터셋[50], [131], [133], [142], [147], [148]이 도입되었습니다. 이러한 변화는 특정 도메인 내에서 Text-to-SQL 시스템의 성능과 실용적 유용성을 평가하는 데 대한 강조의 증가를 반영합니다.

**교차 도메인 Text-to-SQL 데이터셋(Cross-Domain Text-to-SQL Datasets).** 초기 단일 도메인 데이터셋의 개발 후, Text-to-SQL 분야는 다양한 SQL 쿼리 및 데이터베이스에서 시스템의 일반화를 테스트하기 위해 교차 도메인 데이터셋으로 전환되었습니다. WikiSQL[110]은 다양한 도메인에서 Wikipedia의 테이블을 가져오는 최초의 교차 도메인 데이터셋이었습니다. 이후 Spider[45]가 도입되어 여러 테이블이 있는 더 복잡한 관계형 데이터베이스를 포함했습니다. 최근 BIRD[52]는 Spider에 없는 SQL 함수 및 연산을 포함하여 복잡성을 더욱 발전시켜 Text-to-SQL에 더 큰 과제를 제공합니다.

**다중 턴 Text-to-SQL 데이터셋(Multi-Turn Text-to-SQL Datasets).** Text-to-SQL의 발전과 함께, 대화형 대화를 지원하기 위해 다중 턴 데이터셋이 개발되었습니다. SParC[128]는 약 4.3K개의 NL 질문을 가진 교차 도메인 및 다중 턴 데이터셋으로, 총 12K개 이상의 (NL, SQL) 쌍을 가지고 있으며, 각 NL 질문은 턴 간 맥락 이해를 요구합니다. Wizard-of-Oz 설정을 사용하여 수집된 CoSQL[129]은 30K개 이상의 턴을 포함하며 답변할 수 없는 질문과 같은 추가 과제를 도입하여 맥락 이해를 더욱 테스트합니다.

**강건성 테스트가 있는 Text-to-SQL 데이터셋(Text-to-SQL Datasets with Robustness Testing).** 실제 응용 프로그램에서 Text-to-SQL 시스템은 다양한 사용자 그룹 및 데이터베이스를 처리해야 하므로 강건성이 강조됩니다. Spider-Syn[138]은 NL 질문에서 동의어를 사용하여 사용자의 스키마 낯섦을 시뮬레이션하며, Dr.Spider[145]는 포괄적인 강건성 평가를 위해 데이터베이스, NL 질문 및 SQL 쿼리에 17가지 유형의 섭동(perturbations)을 적용합니다.

**SQL 효율성 테스트가 있는 Text-to-SQL 데이터셋(Text-to-SQL Datasets with SQL Efficiency Testing).** 실제 데이터베이스는 종종 방대한 양의 데이터를 보유하며, 단일 NL은 실행 효율성이 다른 여러 SQL 쿼리에 해당할 수 있습니다. BIRD[52]는 Valid Efficiency Score(VES)라는 SQL 실행 효율성을 평가하기 위한 메트릭을 도입하며, 이는 Section VIII에서 더 논의될 것입니다.

**지식 증강 Text-to-SQL 데이터셋(Knowledge-Augmented Text-to-SQL Datasets).** 도메인별 지식은 Text-to-SQL 시스템이 실제 응용 프로그램에서 잘 수행하는 데 필수적입니다. KaggleDBQA[141]는 열 및 테이블 설명과 같은 데이터베이스 문서를 포함합니다. 유사하게, Spider-DK[139]는 NL 질문에 5가지 유형의 도메인 지식을 추가하여 Spider 개발 세트를 확장하며, 시스템이 이 정보를 사용하는 능력을 테스트합니다.

**모호한 질문이 있는 Text-to-SQL 데이터셋(Text-to-SQL Datasets with Ambiguous Questions).** 실제 Text-to-SQL 작업에서는 NL의 의미론적 모호성 및 중복되는 데이터베이스 스키마와 같은 모호성이 종종 발생하므로, 모호성 중심 평가가 점점 더 중요해집니다. AmbiQT[146]는 모호성 범위를 평가하도록 설계된 최초의 데이터셋으로, 4가지 모호성 유형을 포함합니다. 각 NL 질문은 특정 모호성을 반영하는 두 개의 유효한 SQL 쿼리에 매핑됩니다.

**합성 Text-to-SQL 데이터셋(Synthetic Text-to-SQL Datasets).** MIMICSQL[131]은 템플릿 기반 접근 방식을 사용하여 초기 템플릿 질문과 해당 SQL 쿼리를 생성하지만, 질문을 더 자연스럽게 만들기 위해 수동 개선이 필요합니다. ScienceBenchmark[147]도 초기 SQL 생성을 위해 템플릿을 사용하지만 SQL-to-NL 번역을 위해 GPT-3을 활용합니다.

### B. 기존 Text-to-SQL 데이터셋의 심층 분석 (In-depth Analysis of Existing Text-to-SQL Datasets)

Text-to-SQL 데이터셋의 복잡성을 분석하고 비교하기 위해, 표 II에 나타난 바와 같이 NL2SQL360[46] 시스템을 통계적 평가에 사용합니다. 우리는 NL 질문의 수, SQL 쿼리 및 그 비율을 포함하는 *중복성(Redundancy)*을 측정합니다. DB 복잡성(DB Complexity)은 총 데이터베이스, 총 테이블, 데이터베이스당 평균 테이블, 테이블당 평균 열 및 데이터베이스당 평균 레코드를 다룹니다. 쿼리 복잡성(Query Complexity)은 각 SQL 쿼리에서 평균 테이블 수, SELECT 키워드, 집계 함수, 스칼라 함수 및 수학적 계산을 측정합니다. CHASE[137]와 같이 공개 dev/test 분할이 없는 데이터셋의 경우, 공개 분할에 대한 통계만 보고됩니다. knowSQL[102]과 같이 공개적으로 사용 가능한 데이터가 없는 데이터셋의 경우, 표 II의 값은 "—"로 표시됩니다.

중복성 측정 관점에서, 우리는 초기 데이터셋에서 최근 데이터셋까지 데이터셋이 크기에서 성장한 추세를 관찰합니다. 구체적으로, MT-TEQL[143]은 NL 질문의 자동 변환으로 인해 대량의 변형을 생성하여 가장 높은 수의 NL 질문과 SQL 쿼리에 대한 NL 질문의 가장 큰 비율로 두드러집니다.

데이터베이스 복잡성 측면에서, 각 데이터셋 내의 데이터베이스 및 테이블 수는 의도된 작업과 일치합니다. BookSQL[148]과 같은 단일 도메인 데이터셋은 일반적으로 더 적은 데이터베이스를 포함하는 반면, Dr.Spider[145] 및 MT-TEQL[143]과 같이 강건성 평가를 목표로 하는 데이터셋은 더 많은 수의 데이터베이스를 포함합니다.

쿼리 복잡성과 관련하여, FIBEN[133] 및 SEDE[142]와 같은 데이터셋은 여러 테이블 및 집계 함수가 있는 SQL 쿼리를 특징으로 하며, 실제 금융 도메인 및 Stack Exchange 사이트의 복잡성을 반영합니다. 최근 데이터셋은 또한 스칼라 함수 및 수학적 계산을 강조하여 구조적 과제를 추가합니다.

**논의(Discussion).** Text-to-SQL 커뮤니티에서 제안된 데이터셋의 수가 증가함에도 불구하고, 실제 시나리오와 비교하여 SQL 복잡성에서 격차가 남아 있습니다. 현재 데이터셋은 일반적으로 더 적은 SELECT 키워드를 특징으로 하며, 이는 중첩 쿼리 및 복잡한 집합 연산의 부족을 나타냅니다. 또한, 스칼라 함수 및 수학적 계산과 관련된 과제는 추가 초점이 필요합니다. 우리는 커뮤니티가 이러한 복잡성을 다루는 데이터셋을 제안하도록 권장합니다.

## VIII. 평가 및 오류 분석 (EVALUATION AND ERROR ANALYSIS)

이 섹션에서는 Text-to-SQL 솔루션에 대한 주요 평가 메트릭을 소개하고(Section VIII-A), 저비용 및 포괄적 평가를 위한 툴킷을 검토하며(Section VIII-B), Text-to-SQL 프로세스에서 SQL 오류를 분석하기 위한 오류 분류법을 제공합니다(Section VIII-C).

### A. 평가 메트릭 (Evaluation Metrics)

평가 메트릭은 Text-to-SQL 성능을 측정하는 데 중요합니다. 우리는 N을 데이터셋 크기로, $Q_i$를 i번째 예제의 NL 질문으로, $V_i$를 정답 SQL 쿼리 $Y_i$의 실행 결과 집합으로, $\hat{V}_i$를 Text-to-SQL 솔루션이 생성한 SQL 쿼리 $\hat{Y}_i$의 실행 결과 집합으로 정의합니다.

**실행 정확도(Execution Accuracy, EX)[45].** 이 메트릭은 정답 SQL 쿼리와 예측 SQL 쿼리의 실행 결과 집합이 동일한지 비교하여 Text-to-SQL 시스템의 성능을 평가합니다. 다음과 같이 계산할 수 있습니다: $EX = \frac{\sum_{i=1}^{N} \mathbb{I}(V_i = \hat{V}_i)}{N}$, 여기서 $\mathbb{I}(\cdot)$는 내부 조건이 만족되면 1이고 그렇지 않으면 0인 지시 함수입니다. 의미론적으로 다른 NL 쿼리에 해당하는 다른 SQL 쿼리가 동일한 실행 결과 집합을 생성할 수 있기 때문에 거짓 음성(false negatives)이 발생할 수 있습니다.

**문자열 일치 정확도(String-Match Accuracy, SM)[110].** 논리 형식 정확도(Logical Form Accuracy)라고도 하는 이 메트릭은 정답 SQL 쿼리와 예측 SQL 쿼리가 문자열로 동일한지 단순히 비교합니다. 올바른 실행 결과 집합을 생성하지만 정답 SQL 쿼리와 정확한 문자열 일치가 없는 SQL 쿼리에 페널티를 줄 수 있습니다. 다음과 같이 계산할 수 있습니다: $SM = \frac{(\sum_{i=1}^{N} \mathbb{1}(Y_i = \hat{Y}_i))}{N}$.

**구성 요소 일치 정확도(Component-Match Accuracy, CM)[45].** 이 메트릭은 정답 SQL 쿼리와 예측 SQL 쿼리 간의 SELECT, WHERE 등과 같은 다양한 SQL 구성 요소의 정확한 일치를 측정하여 Text-to-SQL 시스템의 상세한 성능을 평가합니다. 특정 SQL 구성 요소 C에 대해 다음과 같이 공식화할 수 있습니다:

$$CM^{C} = \frac{\sum_{i=1}^{N} \mathbb{1}(Y_{i}^{C} = \hat{Y}_{i}^{C})}{N},$$

여기서 $Y_i^C$는 SQL 쿼리 $Y_i$의 구성 요소입니다. SQL 구성 요소가 일치하는지 올바르게 결정하기 위해, 일부 SQL 구성 요소(예: WHERE)는 순서 제약을 고려하지 않습니다.

**정확 일치 정확도(Exact-Match Accuracy, EM)[45].** 이 메트릭은 구성 요소 일치 정확도(CM)를 기반으로 하며 예측 SQL 쿼리의 모든 SQL 구성 요소 $\mathbb{C} = \{C_k\}$가 정답 SQL 쿼리와 일치하는지 측정합니다. 다음과 같이 계산할 수 있습니다:

$$EM = \frac{\sum_{i=1}^{N} \mathbb{1}(\bigwedge_{C_k \in \mathbb{C}} Y_i^{C_k} = \hat{Y}_i^{C_k})}{N}.$$

**유효 효율성 점수(Valid Efficiency Score, VES)[52].** 이 메트릭은 유효한 SQL 쿼리의 실행 효율성을 측정합니다. SQL 실행의 정확성과 효율성을 모두 고려하며, 다음과 같이 계산할 수 있습니다:

$$VES = \frac{\sum_{i=1}^{N} \mathbb{1}(V_i = \hat{V}_i) \cdot \mathbf{R}(Y_i, \hat{Y}_i)}{N}, \ \mathbf{R}(Y_i, \hat{Y}_i) = \sqrt{\frac{\mathbf{E}(Y_i)}{\mathbf{E}(\hat{Y}_i)}},$$

여기서 $\mathbf{R}(\cdot)$는 정답 SQL 쿼리와 비교하여 예측 SQL 쿼리의 상대적 실행 효율성을 측정하여 기계 상태로 인한 불확실성을 제거합니다. $\mathbf{E}(\cdot)$는 특정 SQL 쿼리의 효율성을 측정하며, 실행 시간, 메모리 사용량 등을 참조할 수 있습니다.

**쿼리 변형 테스트(Query Variance Testing, QVT)[46].** 이 메트릭은 NL 쿼리의 변형을 처리하는 Text-to-SQL 시스템의 강건성을 측정합니다. 주어진 SQL 쿼리 $Y_i$에 대해, 종종 여러 해당 NL 쿼리가 있으며, 쌍 $\{(Q_1, Y_i), (Q_2, Y_i), \ldots, (Q_m, Y_i)\}$으로 나타냅니다. QVT 메트릭은 다음과 같이 계산됩니다:

$$QVT = \frac{1}{N} \sum_{i=1}^{N} \left( \frac{\sum_{j=1}^{m_i} \mathbb{1} \left( \mathcal{F}(Q_{ij}) = Y_i \right)}{m_i} \right),$$

여기서 $m_i$는 SQL 쿼리 $Y_i$에 대한 다양한 NL 변형의 수이고, $\mathcal{F}(Q_{ij})$는 $Y_i$의 j번째 NL 변형에 대한 예측 SQL 쿼리입니다.

### B. Text-to-SQL 평가 툴킷 (Text-to-SQL Evaluation Toolkits)

최근 Text-to-SQL 솔루션은 다양한 Text-to-SQL 벤치마크에서 놀라운 성능을 달성했습니다. 그러나 실제 응용 프로그램에서는 NL 쿼리 스타일, 데이터베이스 스키마 및 도메인 간 SQL 쿼리 특성의 변형으로 인해 표준 벤치마크 메트릭만으로는 시스템 강건성을 완전히 평가하기 어렵습니다. 이를 해결하기 위해, 최근 툴킷[46], [143]이 실제 시나리오에서 Text-to-SQL 시스템에 대한 보다 포괄적인 평가를 제공하기 위해 개발되었습니다.

**MT-TEQL[143]**은 NL 쿼리 및 데이터베이스 스키마의 실제 변형을 처리하는 Text-to-SQL 시스템의 성능을 평가하기 위한 통합 프레임워크입니다. 메타모픽 테스팅 접근 방식(metamorphic testing approach)을 기반으로 하며, NL 쿼리 및 데이터베이스 스키마의 의미 보존 변환을 구현하여 수동 노력 없이 자동으로 변형을 생성합니다. NL 쿼리에 대한 4가지 유형의 변환(예: *접두사 삽입, Prefix Insertion*)과 데이터베이스 스키마에 대한 8가지 유형의 변환(예: *테이블 섞기, Table Shuffle*)을 포함합니다.

**NL2SQL360[46]**은 다양한 시나리오에서 Text-to-SQL 시스템의 세밀한 평가를 제공하는 다각도 평가 프레임워크입니다(그림 1(c)). MT-TEQL과 달리, 비즈니스 인텔리전스(Business Intelligence) 시나리오의 집계 함수, 중첩 쿼리 또는 top-k 쿼리와 같은 다양한 응용 프로그램에서 다양한 SQL 쿼리 특성을 강조합니다. 6개의 핵심 구성 요소인 *Dataset*, *Model Zoo*, *Metrics*, *Dataset Filter*, *Evaluator*, *Analysis*로 구성되며, NL2SQL360은 체계적인 평가를 위한 통합되고 모델에 구애받지 않는 인터페이스를 제공합니다. 사용자는 공개 및 비공개 데이터셋을 모두 적용하고, 특정 시나리오에 대한 메트릭을 사용자 정의하며, 시나리오별 SQL 특성을 가진 하위 집합에서 성능을 분석하여 응용 프로그램 전반에 걸쳐 Text-to-SQL 시스템 효과에 대한 귀중한 인사이트를 제공할 수 있습니다.

### C. Text-to-SQL 오류 분석을 위한 분류법 (A Taxonomy for Text-to-SQL Errors Analysis)

오류 분석은 모델 오류를 검토하여 한계를 식별하고 개선된 성능을 위한 수정 조치를 안내하는 것을 포함합니다. 이 섹션에서는 먼저 기존 Text-to-SQL 오류 분류법을 검토합니다. 그런 다음 설계 원칙을 제안하고 2단계 Text-to-SQL 오류 분류법을 소개합니다.

**기존 Text-to-SQL 오류 분석 분류법(Existing Taxonomies for Text-to-SQL Errors Analysis).** 최근 Text-to-SQL 연구[5], [33], [59], [151]–[153]는 점점 더 오류 분석을 통합하여 다양한 오류 분류법을 제안하고 있습니다. Ning et al.[152]은 두 가지 차원을 기반으로 한 상세한 오류 분류법을 도입했습니다: (1) *구문 차원(Syntactic dimension)*은 WHERE 및 JOIN과 같은 키워드로 구성된 오류가 발생하는 특정 SQL 부분을 식별합니다. (2) *의미 차원(Semantic dimension)*은 테이블 이름 이해 오류와 같은 자연어 설명의 잘못된 해석을 나타냅니다. SQL-PaLM[153]은 오류를 5가지 유형으로 분류합니다: (1) *스키마 링킹(Schema Linking)*, 관련 없거나 누락된 테이블/열 선택; (2) *데이터베이스 콘텐츠(Database Content)*, 데이터 값 잘못 해석; (3) *지식 증거(Knowledge Evidence)*, 외부 힌트 활용 실패; (4) *추론(Reasoning)*, 중간 논리 단계 부족; (5) *구문(Syntax)*, 유효하지 않은 SQL 형식. NL2SQL-BUGs[33]는 의미론적 오류 분석에 중점을 두며, 9개의 주요 범주와 31개의 하위 범주로 구성합니다. 또한 모델의 오류 감지 능력을 평가하기 위한 새로운 벤치마크를 제안하여 Text-to-SQL에서 자동화된 오류 분석을 발전시킵니다.

**Text-to-SQL 오류 분석을 위한 분류법 원칙(Taxonomy Principles for Text-to-SQL Errors Analysis).** Text-to-SQL의 현재 오류 분류법은 종종 특정 데이터셋에 특정되어 일반적 적용 가능성이 제한됩니다. 이러한 문제를 해결하기 위해, 표준화되고 효과적인 분류법이 필수적입니다. 우리는 Text-to-SQL 오류 분류법 개발을 안내하기 위해 다음 원칙[154]을 제안합니다:

- **포괄성(Comprehensiveness)**: 분류법은 Text-to-SQL 번역 프로세스의 모든 가능한 오류 유형을 다루어야 합니다.
- **상호 배타성(Mutual Exclusivity)**: 각 오류 유형은 분류 모호성을 피하기 위해 명확하게 구별되어야 합니다.
- **확장성(Extensibility)**: 분류법은 Text-to-SQL이 발전함에 따라 새로운 오류 유형을 포함할 수 있도록 적응 가능해야 합니다.
- **실용성(Practicality)**: 사용자가 실제 시나리오에서 오류를 진단하고 해결할 수 있도록 실용적이어야 합니다.

**Text-to-SQL 오류 분석을 위한 우리의 분류법(Our Taxonomy for Text-to-SQL Errors Analysis).** 이러한 원칙을 따라, 우리는 2단계 Text-to-SQL 오류 분석 분류법을 개발했습니다:

- **오류 위치 파악(Error Localization)**: 첫 번째 수준은 SELECT 또는 WHERE 절과 같이 오류가 발생하는 특정 SQL 구성 요소를 식별합니다. 오류 위치를 정확히 파악하면 대상 조정이 가능하고 수정 효율성이 향상됩니다.
- **오류 원인(Cause of Error)**: 두 번째 수준은 오류의 근본 원인에 중점을 둡니다. 예를 들어, WHERE 절 값의 오류는 데이터베이스 콘텐츠 검색 또는 해석에서 모델의 한계를 나타낼 수 있습니다.

**2단계 오류 분류법의 적용 논의(Discuss the Application of the Two-level Error Taxonomy).** 우리는 제안한 분류법을 사용하여 Spider[45]에서 DIN-SQL[5]의 오류를 수집하고 분류했습니다. 그림 1(d)에 나타난 바와 같이, *1.8%*의 오류만이 기타(Others) 범주에 속하여 우리의 분류법이 실용적이고 효과적임을 시사합니다.

그럼에도 불구하고, 우리는 완전하고 보편적으로 적용 가능한 Text-to-SQL 오류 분류법을 개발하는 것이 본질적으로 반복적임을 인식합니다. 우리는 시간이 지남에 따라 이 분류법을 개선하고 확장하기 위한 커뮤니티의 지속적인 노력을 권장합니다.


## IX. TEXT-TO-SQL을 위한 실용 지침 (PRACTICAL GUIDANCE FOR TEXT-TO-SQL)

이 섹션에서는 주요 요인과 시나리오를 고려하여 Text-to-SQL 솔루션 개발을 위한 실용적인 지침을 제공합니다.

### A. Text-to-SQL을 위한 데이터 기반 로드맵 (Data-Driven Roadmap for Text-to-SQL)

그림 11(a)에서 우리는 데이터 프라이버시와 데이터 볼륨을 기반으로 Text-to-SQL 작업을 위해 LLMs를 최적화하도록 설계된 전략적 로드맵을 제시합니다. 데이터 프라이버시는 오픈소스 및 클로즈드소스 LLMs의 선택에 영향을 미치며, 데이터 볼륨은 훈련 및 추론을 위한 최적화 전략에 영향을 미칩니다.

![](_page_16_Figure_2.jpeg)

그림 11: 데이터 기반 로드맵 및 Text-to-SQL 모듈 추천을 위한 의사결정 흐름.

**조건 1: 데이터 프라이버시(Data Privacy).** 프라이버시에 민감한 데이터의 경우, 오픈소스 LLMs가 선호됩니다. 클로즈드소스 모델은 일반적으로 외부 API를 사용하여 데이터가 외부 서버에 노출될 가능성이 있기 때문입니다. 오픈소스 모델은 로컬 훈련 및 추론에 대한 완전한 제어를 허용하여 더 강력한 데이터 프라이버시 보호를 제공합니다.

**조건 2: 데이터 볼륨(Data Volume).** 오픈소스 LLMs의 경우, 훈련 및 추론 단계 모두에서 최적화가 가능하지만, 클로즈드소스 LLMs는 제한된 접근으로 인해 추론 단계 최적화만 허용합니다. 광범위한 Text-to-SQL 데이터가 있는 경우, 사전 훈련(pretraining)이 성능을 향상시킵니다. 파인튜닝(fine-tuning)은 수백에서 수천 개의 (NL, SQL) 쌍이 있는 데이터셋에 적합합니다. 데이터가 적은 시나리오에서는 퓨샷 학습(few-shot learning)이 권장되며, 레이블이 지정된 데이터를 사용할 수 없을 때는 제로샷 방법(zero-shot methods)이 필수적입니다. 하드웨어 리소스 및 API 비용도 최상의 최적화 전략을 선택하는 데 중요한 고려 사항입니다.

### B. Text-to-SQL 모듈 선택의 의사결정 흐름 (Decision Flow of Selecting Text-to-SQL Modules)

그림 11(b)에서 우리는 특정 시나리오를 기반으로 Text-to-SQL 모듈을 선택하기 위한 권장 사항을 제시하며, 이점과 트레이드오프를 모두 강조합니다. 아래에서 두 가지 예를 설명합니다.

**시나리오 1: 수많은 테이블과 열이 있는 복잡한 데이터베이스 스키마(Complex Database Schema with Numerous Tables and Columns).** 이 경우, 스키마 링킹 전략(Schema Linking strategies)을 사용하는 것이 좋습니다. 이는 토큰 비용을 줄이고 관련 없는 스키마 요소의 노이즈를 최소화하여 효율성을 향상시킵니다. 그러나 추가 시간 비용도 발생합니다.

**시나리오 2: 실행 결과에 액세스할 수 있는 경우(Execution Results Can be Accessed).** 여기서는 실행 안내 전략(Execution-Guided Strategies)이 권장됩니다. 실행 불가능한 SQL 쿼리를 필터링하여 시스템 성능을 향상시키기 때문입니다. 단점은 쿼리 실행에 필요한 시간 증가이며, 대규모 데이터베이스의 경우 상당할 수 있습니다.

요약하면, 각 모듈은 특정 Text-to-SQL 시나리오에 대한 고유한 장점을 제공하지만, 시스템 설계에서 이러한 이점과 잠재적 단점의 균형을 맞추는 것이 필수적입니다.

## X. 한계 및 미해결 문제 (LIMITATIONS AND OPEN PROBLEMS)

우리는 LLM 기반 방법의 한계를 분석하고 해당하는 미해결 문제를 제안하여 해결되지 않은 과제를 강조하고 향후 연구 방향을 제안합니다.

**현재 LLM 기반 솔루션의 한계(Limitations of Current LLM-based Solutions).** 최근 LLM 기반 Text-to-SQL 방법이 상당한 진전을 이루었지만, 실제 시나리오에서 복잡한 쿼리를 처리할 때 여전히 여러 과제에 직면합니다. 첫째, 기존 방법은 일반적으로 단일 고정 데이터베이스에서 훈련되고 실행되므로 교차 데이터베이스 쿼리 및 다중 소스 데이터 집계가 필요한 개방 환경을 처리하는 능력이 제한됩니다. 둘째, LLMs는 강력한 자연어 이해 능력을 가지고 있지만, 추론 중에 높은 토큰 소비를 초래하여 높은 비용과 낮은 효율성으로 이어집니다. 또한, 대부분의 Text-to-SQL 방법은 해석 가능성 및 디버깅 메커니즘이 부족하여 사용자가 모델이 SQL을 생성하는 방법을 이해하거나 잠재적인 의미론적 오류를 감지하고 수정하기 어렵습니다. 마지막으로, 현재 방법은 새로운 도메인에 대한 적응성이 제한적이며 고품질 훈련 데이터에 크게 의존합니다. 모델 피드백을 기반으로 대상 훈련 샘플을 자동으로 생성하는 방법은 미해결 문제로 남아 있습니다. 이러한 한계는 교차 데이터베이스 확장성, 추론 효율성, 시스템 신뢰성 및 데이터 적응성의 단점을 드러내며, 더 효율적이고 신뢰할 수 있으며 확장 가능한 Text-to-SQL 솔루션의 필요성을 강조합니다.

**개방 도메인 Text-to-SQL 문제(Open-Domain Text-to-SQL Problem).** 정부 공개 데이터 플랫폼과 같은 실제 시나리오에서 시민들은 여러 데이터베이스를 쿼리하고 결과를 집계해야 하는 질문을 할 수 있습니다. 예를 들어, "지난 5년간 세금 신고서의 평균 처리 시간은 얼마입니까?"라는 질문에 답하려면 여러 데이터베이스(예: 세금 기록, 처리 로그 및 통계 보고서)에서 테이블을 검색하고 이들에 대한 여러 SQL 쿼리를 생성해야 합니다. 사용자가 단일 대상 데이터베이스를 지정하는 전통적인 Text-to-SQL과 달리, 개방 Text-to-SQL(Open Text-to-SQL)은 단일 NL에 대해 다른 데이터베이스에 액세스하는 여러 SQL 쿼리를 생성해야 할 수 있습니다.

따라서 개방 Text-to-SQL 문제는 다음과 같은 고유한 과제를 제시합니다: (1) **데이터베이스 검색(database retrieval)**: 광범위한 데이터 소스에서 관련 데이터베이스를 정확하게 식별하고 검색; (2) **이질적 스키마 처리(handling heterogeneous schemas)**: 다양한 구조와 용어를 가진 데이터 통합, 고급 스키마 매칭 및 링킹 기술 필요; (3) **답변 집계(answer aggregation)**: 데이터베이스 간 여러 SQL 쿼리에서 최종 답변 추론, 쿼리 순서 계획, 충돌 해결 및 일관성 보장 방법 요구; (4) **도메인 적응(domain adaptation)**: 용어 및 구조의 차이를 해결하기 위해 도메인 간 모델 일반화; (5) **확장성 및 효율성(scalability and efficiency)**: 성능을 유지하면서 대량의 데이터 볼륨 관리; (6) **평가 및 벤치마킹(evaluating and benchmarking)**: 개방 Text-to-SQL 솔루션에 대한 실제 복잡성을 정확하게 반영하는 메트릭 및 데이터셋 개발.

**비용 효율적인 Text-to-SQL 방법 개발(Develop Cost-effective Text-to-SQL Methods).** LLM 기반 Text-to-SQL 방법은 큰 잠재력을 보여주지만 높은 토큰 소비로 인해 제한되어 비용 증가 및 느린 추론 시간으로 이어집니다. 대조적으로, PLM 기반 Text-to-SQL 방법은 복잡한 SQL 쿼리를 처리하고 데이터베이스 스키마를 정확하게 해석하는 데 탁월합니다. 유망한 접근 방식은 둘의 장점을 결합하여 모듈식 Text-to-SQL 솔루션을 개발하거나 다중 에이전트 프레임워크를 사용하여 Text-to-SQL 작업을 위해 LLMs와 PLMs를 통합하는 것입니다(표 III 참조). 동시에, LLM 기반 효율성을 개선하기 위한 노력이 이루어졌습니다. EllieSQL[155]은 쿼리를 적합한 LLM 기반 생성기에 할당하여 비용 효율성을 향상시키기 위해 복잡성 인식 라우팅(complexity-aware routing)을 사용합니다.

**Text-to-SQL 솔루션을 신뢰할 수 있게 만들기(Make Text-to-SQL Solutions Trustworthy).** Text-to-SQL 솔루션이 신뢰할 수 있도록 보장하는 것은 정확하고 신뢰할 수 있는 SQL을 생성하고, 위험을 완화하며, 수동 개입의 필요성을 줄이는 데 필수적입니다. 주제는 다음을 포함합니다:

**Text-to-SQL 솔루션 해석(Interpreting Text-to-SQL Solutions).** Text-to-SQL 모델의 성능 뒤에 있는 추론을 이해하면 신뢰성에 대한 신뢰가 향상됩니다. 서로게이트 모델(surrogate models)[158] 및 현저성 맵(saliency maps)[159]과 같은 설명 가능한 AI 기술[156], [157]은 모델 결정을 드러내는 것을 목표로 합니다. 그러나 특히 LLMs와 PLMs를 결합한 Text-to-SQL 맥락에서 그 효과는 미해결 질문으로 남아 있습니다. 또한, 다중 에이전트 LLM 프레임워크[160]는 Text-to-SQL을 전문화된 하위 작업으로 분할하여 신뢰성을 향상시킵니다. 이 접근 방식은 강건성을 향상시키지만, 일관되고 최적화된 성능을 보장하기 위해 에이전트를 조정하는 것은 여전히 주요 과제입니다.

**Text-to-SQL 디버깅 도구(Text-to-SQL Debugging Tools).** 컴파일러 설계에서 영감을 받아, Text-to-SQL용 디버거는 생성된 SQL 쿼리의 의미론적 및 구문적 오류를 측정하여 정확성과 신뢰성을 개선할 수 있습니다. 이러한 도구는 잠재적 오류를 감지하고 사용자가 SQL 생성 프로세스를 검토하고 불일치를 식별할 수 있도록 합니다[33], [34]. 그러나 이 목표를 달성하는 것은 상당한 과제를 제시합니다. 전통적인 코드 컴파일러는 주로 구문 오류를 캡처하지만, Text-to-SQL 디버깅은 의미론적 오류도 해결해야 합니다. *즉,* 생성된 SQL 쿼리가 NL 쿼리의 의도를 정확하게 반영하도록 보장해야 합니다.

**대화형 Text-to-SQL 도구(Interactive Text-to-SQL Tools).** 이러한 도구는 전문 사용자(*예:* DBA)가 여러 데이터베이스에 걸쳐 종종 50줄 이상의 코드를 초과하는 복잡한 SQL 쿼리를 작성할 수 있도록 하는 데 필수적입니다. 핵심 기능은 복잡한 쿼리를 관리 가능한 하위 쿼리로 분해하는 모델의 능력으로, 인지 부하를 줄이고 DBA가 재조립하기 전에 각 부분에 집중할 수 있도록 합니다. 상향식 및 하향식 워크플로를 모두 지원하여, 이러한 도구는 사용자가 출력을 반복적으로 개선하고, SQL 생성을 의도와 정렬하며, 모델 지원을 도메인 전문 지식과 통합할 수 있도록 합니다.

**적응형 훈련 데이터 합성(Adaptive Training Data Synthesis).** 학습 기반 Text-to-SQL 모델은 종종 보이지 않는 도메인으로 일반화하는 데 실패하며, 이는 부분적으로 제한된 훈련 데이터 범위, 품질 및 다양성 때문입니다. 따라서 흥미로운 연구 문제는 모델 성능을 기반으로 자동으로 점진적으로 (NL, SQL) 쌍을 생성하는 것입니다. 구체적으로, 평가 메트릭 및 평가 결과의 인사이트를 통합함으로써 모델의 특정 약점을 식별할 수 있습니다. 이 정보를 사용하여, 우리는 LLMs의 도움으로 더 광범위한 도메인을 다루도록 지속적으로 진화하는 훈련 데이터를 합성할 수 있습니다.

## XI. 결론 (CONCLUSION)

본 논문에서 우리는 LLM 시대의 생명주기 관점에서 Text-to-SQL 기술을 포괄적으로 검토합니다. 우리는 Text-to-SQL 작업을 공식적으로 정의하고, 주요 과제를 논의하며, 기본 언어 모델을 기반으로 한 분류법을 제안합니다. 우리는 사전 처리, 번역 및 후처리 전략을 포함하여 언어 모델 기반 방법의 핵심 모듈을 요약합니다. 또한, 벤치마크 및 평가 메트릭을 분석하여 그 특성과 일반적인 오류를 강조합니다. 우리는 또한 LLMs를 Text-to-SQL 작업에 적응시키기 위한 실용적인 로드맵을 제공하고 최신 발전 사항을 포함한 온라인 핸드북을 관리하며, 지속적인 과제와 미해결 문제를 논의합니다.

## 감사의 글 (ACKNOWLEDGMENTS)

본 논문은 중국 국가 핵심 R&D 프로그램(2023YFB4503600); 중국 NSF(62402409, 62525202, 62232009, 62436010, 및 62441230); 광동성 기초 및 응용 기초 연구 재단(2023A1515110545); 광저우 기초 및 응용 기초 연구 재단(2025A04J3935); 광저우-HKUST(GZ) 공동 펀딩 프로그램(2025A03J3714); 및 광동성 프로젝트(2023CX10X008)의 지원을 받았습니다.

## 참고문헌 (REFERENCES)

- [1] Z. Gu, J. Fan, N. Tang, and et al., "Few-shot text-to-sql translation using structure and content prompt learning," *SIGMOD*, 2023.
- [2] Z. Chen, S. Chen, M. White, R. J. Mooney, and et al., "Text-to-sql error correction with language models of code," in *ACL*, 2023.
- [3] L. Wang and et al., "Proton: Probing schema linking information from pre-trained language models for text-to-sql parsing," in *KDD*, 2022.
- [4] A. Liu, X. Hu, L. Lin, and L. Wen, "Semantic enhanced text-to-sql parsing via iteratively learning schema linking graph," in *KDD*, 2022.
- [5] M. Pourreza and D. Rafiei, "Din-sql: Decomposed in-context learning of text-to-sql with self-correction," *NeurIPS*, 2024.
- [6] D. Gao, H. Wang, Y. Li, and et al., "Text-to-sql empowered by large language models: A benchmark evaluation," *Proc. VLDB Endow.*, 2024.
- [7] H. Li, J. Zhang, C. Li, and H. Chen, "Resdsql: Decoupling schema linking and skeleton parsing for text-to-sql," in *AAAI*, 2023.
- [8] N. Tang, C. Yang, J. Fan, and et al., "Verifai: Verified generative AI," in *CIDR*. www.cidrdb.org, 2024.
- [9] Y. Zhu, S. Du, B. Li, and et al., "Are large language models good statisticians?" *CoRR*, 2024.
- [10] Y. Xie, Y. Luo, G. Li, and N. Tang, "Haichart: Human and AI paired visualization system," *Proc. VLDB Endow.*, 2023.

*(이하 나머지 참고문헌은 원문 영어 그대로 유지됩니다)*

