{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8282208",
   "metadata": {},
   "source": [
    "# 언어 모델을 사용한 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683c039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedfd93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    '''\n",
    "     LSTM 계층을 2개 사용하고 각 층에 드롭아웃을 적용한 모델이다.\n",
    "     아래 [1]에서 제안한 모델을 기초로 하였고, [2]와 [3]의 가중치 공유(weight tying)를 적용했다.\n",
    "     [1] Recurrent Neural Network Regularization (https://arxiv.org/abs/1409.2329)\n",
    "     [2] Using the Output Embedding to Improve Language Models (https://arxiv.org/abs/1608.05859)\n",
    "     [3] Tying Word Vectors and Word Classifiers (https://arxiv.org/pdf/1611.01462.pdf)\n",
    "    '''\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ecb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap07/rnnlm_gen.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "        \n",
    "        \n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eecc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap07/rnnlm_gen.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f5279f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can affect the region.\n",
      " it is n't perceived as he maintains involved warn that virginia politics does n't defend education information.\n",
      " whatever you might go for an investment to the informed problem he survived year-end.\n",
      " one thing in executive argued a restaurant thinks they would think of being employ.\n",
      " mr. roman he 's head of florida a star charges of profit from a group 's purchase of new york 's new york city board chairman tandy.\n",
      " in the national egg reupke mr. assumptions conceded that mr. darman 's well-known yourself he will serve to\n"
     ]
    }
   ],
   "source": [
    "# chap07/generate_text.py\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params('./Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'  # 첫 단어 \n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']  # 샘플링하지 않을 단어\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9a752",
   "metadata": {},
   "source": [
    "## 더 좋은 문장으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "985adce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you 're betting up enough for being annualized rent in the u.s. people hurricane hugo are to take direct goals an image that trade way your change with margins will complete trade deal today sells in the baby pound.\n",
      " board officials said one recent trader told pro sometime in the software criteria coming on imports will be used today translated on a long need for counter because those firms do not cause it that firm price in computer volatility a loss yellow is more confidence without having to cut differences documents.\n",
      " they expect them at the persistent closing\n",
      "--------------------------------------------------\n",
      "the meaning of life is recorded but had been highly effective in what blocks will be had stopped.\n",
      " mr. jones is white damaged ben rowe innovative.\n",
      " when the owner petroleum selling former president on an order to be succeeded in a sharp jewelry session for the end of the pursuit of the current wage settlements avoid on other view by what is a deal overall may sell for a commission at abandoning the moment.\n",
      " real estate results that is every problem is instance it possible to be a linking issue in interest-rate groups.\n",
      " bally does n't see work debt as\n"
     ]
    }
   ],
   "source": [
    "# chap07/generate_better_text.py\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.np import *\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen()\n",
    "model.load_params('./BetterRnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "\n",
    "print(txt)\n",
    "\n",
    "\n",
    "model.reset_state()\n",
    "\n",
    "start_words = 'the meaning of life is'\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]\n",
    "\n",
    "for x in start_ids[:-1]:\n",
    "    x = np.array(x).reshape(1, 1)\n",
    "    model.predict(x)\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids)\n",
    "word_ids = start_ids[:-1] + word_ids\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print('-' * 50)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404bebb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cadf1164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n",
      "[ 3  0  2  0  0 11  5]\n",
      "[ 6  0 11  7  5]\n",
      "71+118 \n",
      "_189 \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import sequence\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('addition.txt', seed=1984)\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)\n",
    "# (45000, 7) (45000, 5)\n",
    "# (5000, 7) (5000, 5)\n",
    "\n",
    "print(x_train[0])\n",
    "print(t_train[0])\n",
    "# [ 3  0  2  0  0 11  5]\n",
    "# [ 6  0 11  7  5]\n",
    "\n",
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))\n",
    "# 71+118\n",
    "# _189"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414f0d2",
   "metadata": {},
   "source": [
    "# seq2seq 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e04936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap07/seq2seq.py\n",
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params  # 리스트\n",
    "        self.grads = self.embed.grads + self.lstm.grads  # 리스트\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]  # 마지막 hidden state\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67941a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44aa7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73c272ed-9f99-47e4-91d1-94b90f06b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chap07/peeky_seq2seq.py\n",
    "# coding: utf-8\n",
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# from common.time_layers import *\n",
    "# from seq2seq import Seq2seq, Encoder\n",
    "\n",
    "\n",
    "class PeekyDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        N, T = xs.shape\n",
    "        N, H = h.shape\n",
    "\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        hs = np.repeat(h, T, axis=0).reshape(N, T, H)  # 매 timestep 입력\n",
    "        out = np.concatenate((hs, out), axis=2)  # concat 후 LSTM으로 입력\n",
    "\n",
    "        out = self.lstm.forward(out)\n",
    "        out = np.concatenate((hs, out), axis=2)  # concat 후 Affine으로 입력\n",
    "\n",
    "        score = self.affine.forward(out)\n",
    "        self.cache = H\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        H = self.cache\n",
    "\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H]\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H]\n",
    "        self.embed.backward(dembed)\n",
    "\n",
    "        dhs = dhs0 + dhs1\n",
    "        dh = self.lstm.dh + np.sum(dhs, axis=1)\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        char_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        H = h.shape[1]\n",
    "        peeky_h = h.reshape(1, 1, H)\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([char_id]).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            out = self.lstm.forward(out)\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            char_id = np.argmax(score.flatten())\n",
    "            sampled.append(char_id)\n",
    "\n",
    "        return sampled\n",
    "\n",
    "\n",
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1c0f3ae-1bf2-4424-9181-d47d23719b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "# font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "# font_name = fm.FontProperties(fname=font_path, size=10).get_name()\n",
    "# plt.rc('font', family=font_name, size=12)\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfabb0c7-141a-4492-8573-5fa2bbb30366",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7eaa6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 151 / 351 | 시간 1[s] | 손실 2.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 3[s] | 손실 1.76\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "baseline 검증 정확도 0.180%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 151 / 351 | 시간 1[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 3[s] | 손실 1.70\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 994 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 400 \n",
      "---\n",
      "baseline 검증 정확도 0.220%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 151 / 351 | 시간 1[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 2[s] | 손실 1.53\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 108 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 648 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 138 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 448 \n",
      "---\n",
      "baseline 검증 정확도 0.560%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 4 |  반복 151 / 351 | 시간 1[s] | 손실 1.42\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 2[s] | 손실 1.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 146 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1189\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 432 \n",
      "---\n",
      "baseline 검증 정확도 1.060%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 151 / 351 | 시간 1[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 2[s] | 손실 1.22\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 145 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1168\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 192 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 431 \n",
      "---\n",
      "baseline 검증 정확도 2.260%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 151 / 351 | 시간 1[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 2[s] | 손실 1.13\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 196 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 412 \n",
      "---\n",
      "baseline 검증 정확도 2.160%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 151 / 351 | 시간 1[s] | 손실 1.09\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 2[s] | 손실 1.07\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 156 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 655 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 148 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 402 \n",
      "---\n",
      "baseline 검증 정확도 2.140%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 8 |  반복 151 / 351 | 시간 1[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 2[s] | 손실 1.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 438 \n",
      "---\n",
      "baseline 검증 정확도 4.080%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 9 |  반복 151 / 351 | 시간 1[s] | 손실 1.02\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 2[s] | 손실 0.99\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1120\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 651 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 412 \n",
      "---\n",
      "baseline 검증 정확도 2.980%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 10 |  반복 151 / 351 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 2[s] | 손실 0.96\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 157 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 403 \n",
      "---\n",
      "baseline 검증 정확도 3.500%\n",
      "| 에폭 11 |  반복 1 / 351 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 11 |  반복 151 / 351 | 시간 1[s] | 손실 0.95\n",
      "| 에폭 11 |  반복 301 / 351 | 시간 2[s] | 손실 0.93\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1108\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 153 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "baseline 검증 정확도 2.420%\n",
      "| 에폭 12 |  반복 1 / 351 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 12 |  반복 151 / 351 | 시간 1[s] | 손실 0.94\n",
      "| 에폭 12 |  반복 301 / 351 | 시간 2[s] | 손실 0.94\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 681 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 171 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 6.880%\n",
      "| 에폭 13 |  반복 1 / 351 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 13 |  반복 151 / 351 | 시간 1[s] | 손실 0.91\n",
      "| 에폭 13 |  반복 301 / 351 | 시간 2[s] | 손실 0.90\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1121\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 658 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "baseline 검증 정확도 4.100%\n",
      "| 에폭 14 |  반복 1 / 351 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 14 |  반복 151 / 351 | 시간 1[s] | 손실 0.91\n",
      "| 에폭 14 |  반복 301 / 351 | 시간 2[s] | 손실 0.89\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 175 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "baseline 검증 정확도 5.340%\n",
      "| 에폭 15 |  반복 1 / 351 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 15 |  반복 151 / 351 | 시간 1[s] | 손실 0.87\n",
      "| 에폭 15 |  반복 301 / 351 | 시간 2[s] | 손실 0.89\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1136\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 676 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 171 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 5.800%\n",
      "| 에폭 16 |  반복 1 / 351 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 16 |  반복 151 / 351 | 시간 1[s] | 손실 0.88\n",
      "| 에폭 16 |  반복 301 / 351 | 시간 2[s] | 손실 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1136\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 420 \n",
      "---\n",
      "baseline 검증 정확도 7.220%\n",
      "| 에폭 17 |  반복 1 / 351 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 17 |  반복 151 / 351 | 시간 1[s] | 손실 0.86\n",
      "| 에폭 17 |  반복 301 / 351 | 시간 2[s] | 손실 0.85\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1161\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "baseline 검증 정확도 11.340%\n",
      "| 에폭 18 |  반복 1 / 351 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 18 |  반복 151 / 351 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 18 |  반복 301 / 351 | 시간 2[s] | 손실 0.85\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 424 \n",
      "---\n",
      "baseline 검증 정확도 9.140%\n",
      "| 에폭 19 |  반복 1 / 351 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 19 |  반복 151 / 351 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 19 |  반복 301 / 351 | 시간 3[s] | 손실 0.83\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 10.960%\n",
      "| 에폭 20 |  반복 1 / 351 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 20 |  반복 151 / 351 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 20 |  반복 301 / 351 | 시간 2[s] | 손실 0.82\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "baseline 검증 정확도 10.040%\n",
      "| 에폭 21 |  반복 1 / 351 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 21 |  반복 151 / 351 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 21 |  반복 301 / 351 | 시간 2[s] | 손실 0.84\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 8.460%\n",
      "| 에폭 22 |  반복 1 / 351 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 22 |  반복 151 / 351 | 시간 1[s] | 손실 0.81\n",
      "| 에폭 22 |  반복 301 / 351 | 시간 2[s] | 손실 0.82\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1130\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 8.640%\n",
      "| 에폭 23 |  반복 1 / 351 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 23 |  반복 151 / 351 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 23 |  반복 301 / 351 | 시간 2[s] | 손실 0.80\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1107\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 670 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "baseline 검증 정확도 10.780%\n",
      "| 에폭 24 |  반복 1 / 351 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 24 |  반복 151 / 351 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 24 |  반복 301 / 351 | 시간 2[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 9.600%\n",
      "| 에폭 25 |  반복 1 / 351 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 25 |  반복 151 / 351 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 25 |  반복 301 / 351 | 시간 2[s] | 손실 0.78\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 677 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 427 \n",
      "---\n",
      "baseline 검증 정확도 6.460%\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 반전 여부 설정 =============================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "vanilla_acc_list_baseline = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad, eval_interval=150)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 5\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    vanilla_acc_list_baseline.append(acc)\n",
    "    print('baseline 검증 정확도 %.3f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c10bd-b9a8-4922-ba75-d9d686a5d2e3",
   "metadata": {},
   "source": [
    "## reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc65433d-1dc1-4a02-8186-3b0028bd3796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 151 / 351 | 시간 1[s] | 손실 2.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 2[s] | 손실 1.76\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1001\n",
      "---\n",
      "reverse 검증 정확도 0.120%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 151 / 351 | 시간 1[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 2[s] | 손실 1.63\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 1000\n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 470 \n",
      "---\n",
      "reverse 검증 정확도 0.400%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 151 / 351 | 시간 1[s] | 손실 1.47\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 2[s] | 손실 1.34\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1148\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 382 \n",
      "---\n",
      "reverse 검증 정확도 1.940%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 4 |  반복 151 / 351 | 시간 1[s] | 손실 1.20\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 2[s] | 손실 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1196\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 419 \n",
      "---\n",
      "reverse 검증 정확도 5.780%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 5 |  반복 151 / 351 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 2[s] | 손실 0.89\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1192\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "reverse 검증 정확도 12.460%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 6 |  반복 151 / 351 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 2[s] | 손실 0.75\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1141\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 14.260%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 7 |  반복 151 / 351 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 2[s] | 손실 0.65\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 17.500%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 8 |  반복 151 / 351 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 2[s] | 손실 0.59\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1134\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "reverse 검증 정확도 23.080%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.55\n",
      "| 에폭 9 |  반복 151 / 351 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 2[s] | 손실 0.54\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 26.540%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.50\n",
      "| 에폭 10 |  반복 151 / 351 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 2[s] | 손실 0.50\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "reverse 검증 정확도 29.820%\n",
      "| 에폭 11 |  반복 1 / 351 | 시간 0[s] | 손실 0.47\n",
      "| 에폭 11 |  반복 151 / 351 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 11 |  반복 301 / 351 | 시간 2[s] | 손실 0.47\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "reverse 검증 정확도 28.500%\n",
      "| 에폭 12 |  반복 1 / 351 | 시간 0[s] | 손실 0.46\n",
      "| 에폭 12 |  반복 151 / 351 | 시간 1[s] | 손실 0.46\n",
      "| 에폭 12 |  반복 301 / 351 | 시간 2[s] | 손실 0.44\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 36.640%\n",
      "| 에폭 13 |  반복 1 / 351 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 13 |  반복 151 / 351 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 13 |  반복 301 / 351 | 시간 2[s] | 손실 0.42\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 424 \n",
      "---\n",
      "reverse 검증 정확도 39.420%\n",
      "| 에폭 14 |  반복 1 / 351 | 시간 0[s] | 손실 0.41\n",
      "| 에폭 14 |  반복 151 / 351 | 시간 1[s] | 손실 0.40\n",
      "| 에폭 14 |  반복 301 / 351 | 시간 2[s] | 손실 0.39\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 36.660%\n",
      "| 에폭 15 |  반복 1 / 351 | 시간 0[s] | 손실 0.38\n",
      "| 에폭 15 |  반복 151 / 351 | 시간 1[s] | 손실 0.38\n",
      "| 에폭 15 |  반복 301 / 351 | 시간 3[s] | 손실 0.38\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 420 \n",
      "---\n",
      "reverse 검증 정확도 41.100%\n",
      "| 에폭 16 |  반복 1 / 351 | 시간 0[s] | 손실 0.36\n",
      "| 에폭 16 |  반복 151 / 351 | 시간 1[s] | 손실 0.36\n",
      "| 에폭 16 |  반복 301 / 351 | 시간 4[s] | 손실 0.36\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 42.700%\n",
      "| 에폭 17 |  반복 1 / 351 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 17 |  반복 151 / 351 | 시간 3[s] | 손실 0.35\n",
      "| 에폭 17 |  반복 301 / 351 | 시간 5[s] | 손실 0.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 42.860%\n",
      "| 에폭 18 |  반복 1 / 351 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 18 |  반복 151 / 351 | 시간 2[s] | 손실 0.34\n",
      "| 에폭 18 |  반복 301 / 351 | 시간 5[s] | 손실 0.33\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "reverse 검증 정확도 40.640%\n",
      "| 에폭 19 |  반복 1 / 351 | 시간 0[s] | 손실 0.34\n",
      "| 에폭 19 |  반복 151 / 351 | 시간 3[s] | 손실 0.33\n",
      "| 에폭 19 |  반복 301 / 351 | 시간 4[s] | 손실 0.32\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 47.540%\n",
      "| 에폭 20 |  반복 1 / 351 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 20 |  반복 151 / 351 | 시간 1[s] | 손실 0.32\n",
      "| 에폭 20 |  반복 301 / 351 | 시간 2[s] | 손실 0.33\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "reverse 검증 정확도 49.900%\n",
      "| 에폭 21 |  반복 1 / 351 | 시간 0[s] | 손실 0.30\n",
      "| 에폭 21 |  반복 151 / 351 | 시간 1[s] | 손실 0.31\n",
      "| 에폭 21 |  반복 301 / 351 | 시간 2[s] | 손실 0.31\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "reverse 검증 정확도 51.060%\n",
      "| 에폭 22 |  반복 1 / 351 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 22 |  반복 151 / 351 | 시간 1[s] | 손실 0.29\n",
      "| 에폭 22 |  반복 301 / 351 | 시간 3[s] | 손실 0.31\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "reverse 검증 정확도 47.720%\n",
      "| 에폭 23 |  반복 1 / 351 | 시간 0[s] | 손실 0.31\n",
      "| 에폭 23 |  반복 151 / 351 | 시간 1[s] | 손실 0.29\n",
      "| 에폭 23 |  반복 301 / 351 | 시간 3[s] | 손실 0.29\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 45.040%\n",
      "| 에폭 24 |  반복 1 / 351 | 시간 0[s] | 손실 0.31\n",
      "| 에폭 24 |  반복 151 / 351 | 시간 1[s] | 손실 0.29\n",
      "| 에폭 24 |  반복 301 / 351 | 시간 2[s] | 손실 0.29\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 421 \n",
      "---\n",
      "reverse 검증 정확도 51.800%\n",
      "| 에폭 25 |  반복 1 / 351 | 시간 0[s] | 손실 0.29\n",
      "| 에폭 25 |  반복 151 / 351 | 시간 1[s] | 손실 0.28\n",
      "| 에폭 25 |  반복 301 / 351 | 시간 2[s] | 손실 0.28\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse 검증 정확도 54.060%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 반전 여부 설정 =============================================\n",
    "is_reverse = True  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "vanilla_acc_list_reverse = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad, eval_interval=150)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 5\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    vanilla_acc_list_reverse.append(acc)\n",
    "    print('reverse 검증 정확도 %.3f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8cfde-a095-4cd7-9ea0-71130127138d",
   "metadata": {},
   "source": [
    "## reverse_peeky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd993f57-3aa5-48ba-8819-50a4f961f062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.57\n",
      "| 에폭 1 |  반복 151 / 351 | 시간 1[s] | 손실 1.99\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 3[s] | 손실 1.76\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1013\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 102 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 1023\n",
      "---\n",
      "reverse_peeky 검증 정확도 0.280%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 151 / 351 | 시간 1[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 3[s] | 손실 1.64\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1200\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 690 \n",
      "---\n",
      "reverse_peeky 검증 정확도 0.400%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.58\n",
      "| 에폭 3 |  반복 151 / 351 | 시간 1[s] | 손실 1.54\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 3[s] | 손실 1.43\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 154 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1033\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 644 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 433 \n",
      "---\n",
      "reverse_peeky 검증 정확도 1.600%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 4 |  반복 151 / 351 | 시간 1[s] | 손실 1.28\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 3[s] | 손실 1.18\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1123\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 165 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "reverse_peeky 검증 정확도 5.140%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 5 |  반복 151 / 351 | 시간 1[s] | 손실 1.03\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 3[s] | 손실 0.93\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1135\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 169 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 9.380%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 6 |  반복 151 / 351 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 3[s] | 손실 0.75\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[91m☒\u001b[0m 423 \n",
      "---\n",
      "reverse_peeky 검증 정확도 15.040%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 0.68\n",
      "| 에폭 7 |  반복 151 / 351 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 3[s] | 손실 0.59\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 156 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 39.120%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 0.51\n",
      "| 에폭 8 |  반복 151 / 351 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 3[s] | 손실 0.39\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[91m☒\u001b[0m 155 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 65.060%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.32\n",
      "| 에폭 9 |  반복 151 / 351 | 시간 1[s] | 손실 0.30\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 3[s] | 손실 0.24\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[91m☒\u001b[0m 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 83.300%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 0[s] | 손실 0.22\n",
      "| 에폭 10 |  반복 151 / 351 | 시간 1[s] | 손실 0.18\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 3[s] | 손실 0.16\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[91m☒\u001b[0m 656 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 88.400%\n",
      "| 에폭 11 |  반복 1 / 351 | 시간 0[s] | 손실 0.13\n",
      "| 에폭 11 |  반복 151 / 351 | 시간 1[s] | 손실 0.12\n",
      "| 에폭 11 |  반복 301 / 351 | 시간 3[s] | 손실 0.11\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 90.940%\n",
      "| 에폭 12 |  반복 1 / 351 | 시간 0[s] | 손실 0.09\n",
      "| 에폭 12 |  반복 151 / 351 | 시간 1[s] | 손실 0.09\n",
      "| 에폭 12 |  반복 301 / 351 | 시간 3[s] | 손실 0.08\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 92.220%\n",
      "| 에폭 13 |  반복 1 / 351 | 시간 0[s] | 손실 0.07\n",
      "| 에폭 13 |  반복 151 / 351 | 시간 1[s] | 손실 0.07\n",
      "| 에폭 13 |  반복 301 / 351 | 시간 3[s] | 손실 0.06\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 94.400%\n",
      "| 에폭 14 |  반복 1 / 351 | 시간 0[s] | 손실 0.05\n",
      "| 에폭 14 |  반복 151 / 351 | 시간 1[s] | 손실 0.05\n",
      "| 에폭 14 |  반복 301 / 351 | 시간 3[s] | 손실 0.06\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 94.060%\n",
      "| 에폭 15 |  반복 1 / 351 | 시간 0[s] | 손실 0.04\n",
      "| 에폭 15 |  반복 151 / 351 | 시간 1[s] | 손실 0.04\n",
      "| 에폭 15 |  반복 301 / 351 | 시간 3[s] | 손실 0.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 94.160%\n",
      "| 에폭 16 |  반복 1 / 351 | 시간 0[s] | 손실 0.03\n",
      "| 에폭 16 |  반복 151 / 351 | 시간 1[s] | 손실 0.04\n",
      "| 에폭 16 |  반복 301 / 351 | 시간 3[s] | 손실 0.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 96.600%\n",
      "| 에폭 17 |  반복 1 / 351 | 시간 0[s] | 손실 0.04\n",
      "| 에폭 17 |  반복 151 / 351 | 시간 1[s] | 손실 0.03\n",
      "| 에폭 17 |  반복 301 / 351 | 시간 3[s] | 손실 0.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 96.040%\n",
      "| 에폭 18 |  반복 1 / 351 | 시간 0[s] | 손실 0.04\n",
      "| 에폭 18 |  반복 151 / 351 | 시간 1[s] | 손실 0.03\n",
      "| 에폭 18 |  반복 301 / 351 | 시간 3[s] | 손실 0.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 97.100%\n",
      "| 에폭 19 |  반복 1 / 351 | 시간 0[s] | 손실 0.02\n",
      "| 에폭 19 |  반복 151 / 351 | 시간 1[s] | 손실 0.02\n",
      "| 에폭 19 |  반복 301 / 351 | 시간 3[s] | 손실 0.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 94.100%\n",
      "| 에폭 20 |  반복 1 / 351 | 시간 0[s] | 손실 0.04\n",
      "| 에폭 20 |  반복 151 / 351 | 시간 1[s] | 손실 0.03\n",
      "| 에폭 20 |  반복 301 / 351 | 시간 3[s] | 손실 0.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 97.500%\n",
      "| 에폭 21 |  반복 1 / 351 | 시간 0[s] | 손실 0.02\n",
      "| 에폭 21 |  반복 151 / 351 | 시간 1[s] | 손실 0.01\n",
      "| 에폭 21 |  반복 301 / 351 | 시간 3[s] | 손실 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 99.240%\n",
      "| 에폭 22 |  반복 1 / 351 | 시간 0[s] | 손실 0.01\n",
      "| 에폭 22 |  반복 151 / 351 | 시간 1[s] | 손실 0.01\n",
      "| 에폭 22 |  반복 301 / 351 | 시간 3[s] | 손실 0.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 92.280%\n",
      "| 에폭 23 |  반복 1 / 351 | 시간 0[s] | 손실 0.04\n",
      "| 에폭 23 |  반복 151 / 351 | 시간 2[s] | 손실 0.02\n",
      "| 에폭 23 |  반복 301 / 351 | 시간 5[s] | 손실 0.01\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 98.280%\n",
      "| 에폭 24 |  반복 1 / 351 | 시간 0[s] | 손실 0.01\n",
      "| 에폭 24 |  반복 151 / 351 | 시간 2[s] | 손실 0.02\n",
      "| 에폭 24 |  반복 301 / 351 | 시간 5[s] | 손실 0.01\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[91m☒\u001b[0m 172 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 94.780%\n",
      "| 에폭 25 |  반복 1 / 351 | 시간 0[s] | 손실 0.03\n",
      "| 에폭 25 |  반복 151 / 351 | 시간 2[s] | 손실 0.02\n",
      "| 에폭 25 |  반복 301 / 351 | 시간 5[s] | 손실 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "\u001b[92m☑\u001b[0m 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "\u001b[92m☑\u001b[0m 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "\u001b[92m☑\u001b[0m 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "\u001b[92m☑\u001b[0m 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "\u001b[92m☑\u001b[0m 422 \n",
      "---\n",
      "reverse_peeky 검증 정확도 97.780%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 반전 여부 설정 =============================================\n",
    "is_reverse = True  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "vanilla_acc_list_reverse_peeky = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad, eval_interval=150)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 5\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    vanilla_acc_list_reverse_peeky.append(acc)\n",
    "    print('reverse_peeky 검증 정확도 %.3f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e341dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='NanumGothicCoding')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(vanilla_acc_list_baseline))\n",
    "plt.plot(x, vanilla_acc_list_baseline, marker='o', label='baseline')\n",
    "plt.plot(x, vanilla_acc_list_reverse, marker='o', label='reverse')\n",
    "plt.plot(x, vanilla_acc_list_reverse_peeky, marker='o', label='reverse_peeky')\n",
    "plt.legend()\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3d324-faf9-4772-aec8-6a1bbd84f81f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.333px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
