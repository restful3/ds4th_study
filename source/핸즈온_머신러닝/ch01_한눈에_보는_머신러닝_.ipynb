{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 한눈에 보는 머신러닝\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 머신 러닝이란\n",
    "\n",
    "머신러닝은 데이터에서 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술) 입니다.\n",
    "\n",
    "조금 더 일반적인 정의는 다음과 같습니다. \n",
    "\n",
    "<img src=\"./img/cap-1.png\" width=\"60%\"></img>\n",
    "\n",
    "조금 더 공학적인 정의는 다음과 같습니다. \n",
    "\n",
    "<img src=\"./img/cap-2.png\" width=\"60%\"></img>\n",
    "\n",
    "스팸 필터는 스팸 메일과 일반 메일의 데이터를 이용해 스팸 메일 구분법을 배울 수 있는 머신러닝 프로그램입니다. \n",
    "\n",
    "> - **훈련 셋트** : 시스템이 학습하는데 사용하는 샘플\n",
    "> - **훈련 사례** : 각각의 훈련 데이터 (혹은 샘플)\n",
    "> - **모델** : 머신러닝 시스템에서 학습하고 예측을 만드는 부분\n",
    ">  - Ex. 신경망(neural network)이나 랜덤 프레스트(random forest)\n",
    "\n",
    "작업 T는 새로운 메일이 스팸인지 구분하는 것이고, \n",
    "\n",
    "> - **훈련 데이터** : 경험 E\n",
    "\n",
    "성능 측정 P는 직접 정의해야 합니다. 예를들면 정확히 분류된 메일의 비율을 P로 사용할수 있습니다. \n",
    "\n",
    "> - **정확도** : 이 성능 측정을 말하며 분류 작업에 주로 사용됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 왜 머신러닝을 사용하나요?\n",
    "\n",
    "전통적인 프로그래밍 기법을 사용해 어떻게 필터를 만들기\n",
    "\n",
    "1. 먼저 스팸이 어떤 단어들이 주로 나타나는지 살펴 봄. '4U', '신용카드', '무료', '굉장한' 단어나 구절이 제목에 나타나는 경향\n",
    "\n",
    "   보낸이의 이름이나 본문, 이메일의 다른 요소에서 다른 패턴을 감지\n",
    "   \n",
    "2. 발견한 패턴을 감지하는 알고리즘을 작성하여 프로그램이 이런 패턴을 발견했을 때 스팸으로 분류.\n",
    "3. 프로그램을 테스트하고 론칭할 만큼 충분한 성능이 나올 때까지 1~2단계를 반복\n",
    "\n",
    "<img src=\"./img/pic1-1.png\" width=\"60%\"> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면 머신러닝 기법은 자주 나타나는 패넡을 감지하여 어떤 단어와 구절이 스팸 메일을 파단하는데 좋은 기준인지 자동으로 학습합니다.\n",
    "\n",
    "<img src=\"./img/pic1-2.png\" width=\"60%\"></img>\n",
    "\n",
    "스팸 메일이 '4U' 대신에 'For U'를 시작할지도 모릅니다. \n",
    "\n",
    "전통적인 방식은 수정이 필요합니다. \n",
    "\n",
    "스팸이 필터에 대항해 계속 단어를 바꾸면 영원히 새로운 규칙을 추가해야 합니다. \n",
    "\n",
    "하지만 머신러닝 기반의 스팸 필터는 사용자가 지정한 메일에 유독 'For U'가 자주 나타나는 것을 인식하고 이 단어를 스팸으로 분류 합니다. \n",
    "\n",
    "<img src=\"./img/pic1-3.png\" width=\"60%\" ></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝이 유용한 또 다른 분야는 너무 복잡하거나 알려진 알고리즘이 없는 문제입니다. \n",
    "\n",
    "**음성 인식(speech rcognition)** 을 예로 들 수 있습니다. \n",
    "\n",
    "'one'과 'two'를 구분할 때, \n",
    "\n",
    "높은 피치(pitch)의 사운드('T')로 시작하므로 높은 피치의 사운드 강도를 측정하는 알고리즘을 하드코딩해서 'one'과 'two'를 구분할 수도 있습니다. \n",
    "\n",
    "당연히 이 방법은 소음이 있는 환경에서 수백만 명이 여러 언어로 말하는 수백만 개의 단어를 구분하도록 확장하기 어렵습니다. \n",
    "\n",
    "우리는 머신러닝을 통해 배울 수도 있습니다. (그림 1-4).\n",
    "\n",
    "예를들어,\n",
    "스팸 필터가 충분한 스팸 메일로 훈련되었다면 스팸을 예측하는데 가장 좋은 단어 및 단어의 조합이 무엇인지 확인할 수 있습니다. \n",
    "\n",
    "가끔 예상치 못한 상관관계나 새로운 추세가 발견되기도 해서 해당 문제를 더 잘 이해하도록 도와줍니다. \n",
    "\n",
    "대용량의 데이터를 분석하여 숨겨진 패턴을 발견하는 것을 \n",
    "\n",
    "> **데이터 마이닝**(data mining)\n",
    "\n",
    "이라고 합니다. \n",
    "\n",
    "<img src=\"./img/pic1-4.png\" width=\"60%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝은 다음 분야에 뛰어납니다.\n",
    "\n",
    "> - **기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제**\n",
    ">   - 머신러닝 모델이 코드를 간단한게 만들고 전통적인 방법보다 더 잘 수해할 수 있습니다. \n",
    "> - **전통적인 방식으로는 해결 방법이 없는 복잡한 문제**\n",
    ">   - 가장 띄어난 머신러닝 기법으로 해별 방법을 찾을 수 있습니다. \n",
    "> - **유동적인 환경**\n",
    ">\n",
    "> - **복잡한 문제와 대량의 데이터에서 인사이트 얻기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 애플리케이션 사례\n",
    "\n",
    "구체적인 머신러닝 작업의 사례와 이를 위한 기술\n",
    "\n",
    "1. 생산 라인에서 제품 이미지를 분석해 자동으로 분류하기\n",
    "   - 이미지 분류 작업입니다. 일반적으로 **합성곱 신경망**(Convolutional neural network CNN, 14장)이나 이따금 **트랜스포머**(transformer, 16장)를 사용하여 수행합니다.\n",
    "2. 뇌를 스캔하여 종양 진단하기\n",
    "   - 시맨틱 분할 작업입니다. 일반적으로 CNN이나 트랜스포머를 사용해 이미지의 각 필셀을 분류합니다. (종양의 정확한 위치와 모양을 결정)\n",
    "\n",
    "3. 자동으로 뉴스 기사 분류하기\n",
    "   - 자연어 처리(natural language processing, NLP). 텍스트 분류이며 순환 신경망(recurrent neural network, RNN)을 사용해 해결할 수 있지만 트랜스포머(16장)이 더 잘 처리합니다. \n",
    "4. 토론 포럼에서 부정적인 코멘트를 자동으로 구분하기\n",
    "   - 텍스트 분류 작업이며 NLP도구를 사용합니다. \n",
    "5. 긴 문서를 자동으로 요약하기\n",
    "   - 텍스트 요약이라 불리는 NLP의 한 분야이며 NLP도구를 사용합니다. \n",
    "6. 챗봇 또는 개인 비서 만들기\n",
    "   - 자연어 이해(natural language understanding, NLU)와 질문-답변(question-answering)모듈을 포함해 여러가지 NLP컴포넌트가 필요합니다. \n",
    "7. 여러 가지 성과 자료를 바탕으로 회사의 내년도 수익 예측하기\n",
    "   - 회귀(regression)작업입니다. 즉, 숫자로 값을 예측합니다. \n",
    "   - 선형회귀나 다항회귀 모델(4장), 회귀 서포트 벡터 머신(5장), 회귀 랜덤 포레스트(7장), 인공 신경망(10장)과 같은 모델을 사용해서 해결할 수 있습니다. \n",
    "   - 과거 성과 데이터를 시퀀스로 고려하고 싶다면 RNN, CNN 또는 트랜스포머(15, 16장)를 사용할 수 있습니다. \n",
    "8. 음성 명령에 반응하는 앱 만들기\n",
    "   - 오디오 샘플을 처리해야 합니다. 이는 길고 복잡한 시퀀스이므로 일반적으로 RNN, CNN 또는 트랜스포머(15, 16장)를 사용합니다. \n",
    "9. 신용카드 부정 거래 감지하기\n",
    "   - 이상치 탐지(outlier detection)작업 입니다. 아이솔레이션 포레스트, 가우스 혼합 모델(9장)이나 오토인코더(17장)를 사요할 수 있습니다. \n",
    "10. 구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획하기\n",
    "      - 군집(clustering) 작업입니다. k-평균(k-means), DBSCAN등을 사용하여 수행할 수 있습니다. (9장)\n",
    "11. 고차원의 복잡한 데이터셋을 명확하고 의미있는 그래프로 표현하기\n",
    "      - 데이터 시각화 작업, 차원 축소(dimenstionality reduction)기법을 많이 사용합니다. (8장))\n",
    "12. 과거 구매 이력을 기반으로 고객이 관심 가실 수 있는 상품 추천하기\n",
    "      - 추천 시스템입니다. 과거 구매 이력을 (그리고 고객에 대한 다른 정보를) 인공 신경망(10장)에 주입하고 다음에 구매할 가능성이 가장 높은 상품을 출력하는 것이 한 가지 방법입니다. \n",
    "      - 일반적으로 모든 고객의 구매 이력을 기반으로 훈련합니다. \n",
    "13. 지능형 게임 봇 만들기\n",
    "      - 보통 강화 학습(reinforcement leaning, RL, 18장)으로 해결합니다. \n",
    "      - 시간이 지나면 (게임 같은) 주어진 환경에서 보상이 최대가 되는 행동을 선택하는 (봇과 같은) 에이전트를 훈련하는 머신러닝의 한 분야입니다. \n",
    "      - 예를 들어 상대 플레이어가 점수를 잃을 때마다 봇이 보상을 받을 수 있습니다. \n",
    "      - 바둑 세계 챔피언을 이긴 유명한 알파고(AlphaGo)가 강화 학습을 사용해 구축되었습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 머신러닝 시스템의 종류\n",
    "\n",
    "머신 러닝 시스템의 종류는 많으므로 넓은 범주에서 분류하면 도움이 됩니다. \n",
    "\n",
    "> - 훈련 지도 방식(지도, 비지도, 자기지도, 강화 학습)\n",
    ">\n",
    "> - 실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습과 배치 학습)\n",
    ">\n",
    "> - 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지\n",
    ">\n",
    "> - 아니면, 과학자들이 하는 것처럼 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지 (사례 기반 학습과 모델 기반 학습)\n",
    "\n",
    "이 범주들은 서로 배타적이지 않으며, 원하는데로 연결할 수 있습니다. \n",
    "\n",
    "예를들어 최첨단 스팸 필터가 심층 신경망 모델을 사용해 스팸과 스팸이 아닌 메일로부터 실시간으로 학습할지도 모릅니다. \n",
    "\n",
    "그렇다면 이 시스템은 온라인이고 모델 기반이며 지도 학습 시스템입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 훈련 지도 방식\n",
    "\n",
    "머신러닝 시스템을 학습하는 동안의 지도 형태나 정보량에 따라 분류할 수 있습니다.\n",
    "\n",
    "- 지도 학습\n",
    "\n",
    "  **지도 학습**(supervised learning)에서 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함됩니다. (그림 1-5)\n",
    "    - 머신러닝에서 레이블의 범주를 클래스(class)라고 부릅니다\n",
    "    \n",
    "    <img src=\"./img/pic1-5.png\" width=\"60%\"></img>\n",
    "\n",
    "  **분류**(classification)가 전형적인 지도학습 작업이며, 스팸 필터가 좋은 예입니다. 스팸 필터는 많은 샘플 이메일과 클래스(class)로 훈련되며 어떻게 새 메일을 분류할지 학습해야 합니다. \n",
    "\n",
    "  **특성**(feature, 주행거리, 연식, 브랜드 등)을 사용해 중고차 가격같은 **타깃**(target)수치를 예측하는 것입니다. \n",
    "  \n",
    "    - 이런 종류의 작업을 **회귀**(regression)라고 부릅니다. (그림 1-6) 시스템을 훈련하려면 특성과 타깃이 포함된 중고자 데이터가 많이 필요합니다. \n",
    "\n",
    "    <img src=\"./img/pic1-6.png\" width=\"60%\"></img>\n",
    "\n",
    "    - 일부 회귀 알고리즘을 분류에 사횽할 수도 있습니다. \n",
    "\n",
    "    - 예를들어 분류에 널리 쓰이는 **로지스틱 회귀**(logistic regression)는 클래스에 속할 확률을 출력합니다. (예, 스팸일 가능성 20%)\n",
    "\n",
    "   <img src=\"./img/cap-3.png\" width=\"60%\"></img>\n",
    "\n",
    "\n",
    "- 비지도 학습  \n",
    "  **비지도 학습**(unsupervised learning)에서는 말 그대로 훈련데이터에 레이블이 없습니다. (그림 1-7) 시스템이 아무런 도움 없이 학습해야 합니다. \n",
    "\n",
    "    <img src=\"./img/pic1-7.png\" width=\"60%\"></img>\n",
    "  \n",
    "    예를 들어 방문자에 대한 데이터가 많이 있는데, 비슷한 방문자들을 그룹으로 묶기 위해 **군집**(clustering) 알고리즘을 적용하려고 합니다. (그림 1-8)\n",
    "\n",
    "    하지만 방문자가 어떤 그룹에 속하는지 알고리즘에 알려줄 수 있는 정보가 없습니다. 그래서 알고리즘이 스스로 방문자 사이의 연결고리를 찾습니다.\n",
    "\n",
    "    **계층 군집**(hierachical clustering)알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화할 수 있습니다. \n",
    "\n",
    "    <img src=\"./img/pic1-8.png\" width=\"60%\"></img>\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **비지도 학습** 종류\n",
    "\n",
    "    1. **시각화**(visualization)알고리즘도 비지도 학습의 좋은 예입니다. \n",
    "\n",
    "        레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어 줍니다. (그림 1-9)\n",
    "\n",
    "        <img src=\"./img/pic1-9.png\" width=\"60%\"></img>\n",
    "\n",
    "        이런 알고르즘은 가능한 한 구조를 그대로 유지하려 하므로 *(예를들어 입력 공간에서 떨어져 있던 클러스터(cluster)는 시각화된 그래프에서 겹쳐지지 않게 유지됩니다)* \n",
    "\n",
    "        데이터가 어떻게 조직되어 있는지 이해할 수 있고 예상하지 못한 패턴을 발견할 수도 있습니다. \n",
    "\n",
    "        비슷한 작업으로는 너무 많은 정보를 잃지 않으면서 데이터를 간소화하려는 **차원 축소**(dimensionality reduction)가 있습니다. \n",
    "    \n",
    "        이렇게 하는 한 가지 방법은 상관관계가 있는 여러 특성을 하나로 합치는 것입니다. \n",
    "\n",
    "        예를 들어 차의 주행 거리는 연식과 강하게 연관되어 있기 때문에 차원 축소 알고리즘으로 두 특성을 차의 마모 정도를 나타내는 하나의 특성을 합칠 수 있습니다.\n",
    "\n",
    "        이를 **특성 추출**(feature extraction)이라고 합니다. \n",
    "        \n",
    "        (**TIP**) (지도 학습 알고리즘 같은) 머신러닝 알고리즘에 데이터를 주입하기 전에 차원 축소 알고리즘을 사용하여 훈련 데이터에 있는 차원의 수를 줄이는 것이 유용할 때가 많습니다. \n",
    "\n",
    "        실행 속도가 훨씬 빨라지고 디스크와 메모리를 차지하는 공간도 줄어듭니다. 경우에 따라서 성능이 좋아지기도 합니다.\n",
    "            \n",
    "    2.  **이상치 탐지**(outlier detection)\n",
    "        \n",
    "        예를들어 부정 거래를 막기 위해 이상한 신용카드 거래를 감지하고, 제조 결함을 잡아내고, \n",
    "        \n",
    "        학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거하는 것 등입니다. \n",
    "\n",
    "        시스템은 훈련하는 동안 대부분 정상 샘플을 만나 이를 인식하도록 훈련됩니다. \n",
    "        \n",
    "        그다음 새로운 샘플을 보고 정상 데이터인지 혹은 이상치인지 판단합니다. (그림 1-10)\n",
    "\n",
    "        <img src=\"./img/pic1-10.png\" width=\"60%\"></img>\n",
    "\n",
    "        비슷한 작업으로 **특이치 탐지**(novelty detection)가 있습니다. \n",
    "        \n",
    "        훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적입니다. \n",
    "        \n",
    "        예를 들어, 강아지 사진 수천 장이 있고 그중 1%가 치와와 사진이라면 특이치 탐지 알고리즘은 새로운 치와와 사진을 특이치로 처리하지 못합니다. \n",
    "        \n",
    "        **이상치 탐지** 알고리즘은 치와와가 매우 드물고 다른 강아지랑 다르다고 인식하여 이상치로 분류할 것입니다. \n",
    "\n",
    "    3. **연관 규칙 학습** (association rule learning)\n",
    "        \n",
    "        널리 사용되는 또 다른 비지도 학습은 대량의 데이터에서 특성 간의 흥미로운 관계를 찾을 수 있습니다. \n",
    "    \n",
    "        판매 기록에 연관 규칙을 적용하면 바비큐 소스와 감자를 구매한 사람이 스테이크도 구매하는 경향이 있다는 것을 찾을지도 모릅니다. \n",
    "\n",
    "- **준지도 학습**\n",
    "    \n",
    "    데이터에 레이블을 다는 것은 일반적으로 시간, 비용이 많이 들기 때문에 레이블이 없는 샘플이 많고 레이블된 샘플은 적은 경우가 많습니다. \n",
    "\n",
    "    어떤 알고리즘은 레이블이 일부만 있는 데이터를 다룰 수 있는데, 이를 **준지도 학습** (semi-supervised learning)이라고 합니다. (그림 1-11)\n",
    "\n",
    "    <img src=\"./img/pic1-11.png\" width=\"60%\"></img>\n",
    "\n",
    "    구글 포토 서비스가 좋은 예입니다. 동일한 사람이 각각 다른 사진에 있다면 이를 인식하는 것입니다. \n",
    "\n",
    "    대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있습니다. \n",
    "    \n",
    "    예를들어, 군집 알고리즘을 사용해 비슷한 샘플을 한 그룹으로 모음 -> 레이블이 없는 샘플에 클러스터에서 가장 많이 등장하는 레이블을 할당 -> 전체 데이터셋에 레이블이 부여되면 지도 학습 알고리즘 사용 가능\n",
    "\n",
    "- **자기 지도 학습**\n",
    "\n",
    "    레이블이 전혀 없는 데이터셋에서 레이블이 완전히 부여된 데이터셋을 생성하면, \n",
    "    \n",
    "    전체 데이터셋에 레이블이 부여되고 나면 어떤 지도 학습 알고리즘도 사용할 수 있는 방법을 말합니다. \n",
    "\n",
    "    예를들어, \n",
    "    \n",
    "    레이블이 없는 이미지로 구성된 대량의 데이터셋이 있다면 각 이미지의 일부분을 랜덤하게 마스킹(masking)하고 모델이 원본 이미지를 복원하도록 훈련할 수 있습니다. (그림 1-12)\n",
    "\n",
    "    <img src=\"./img/pic1-12.png\" width=\"60%\"></img>\n",
    "\n",
    "    훈련하는 동안 마스킹된 이미지는 모델의 입력으로 사용되고 원본 이미지는 레이블로 사용됩니다. \n",
    "\n",
    "    훈련된 모델은 그 자체로 매우 유용합니다. 손상된 이미지를 복원 또는 원치 않는 물체 삭제 가능.\n",
    "\n",
    "    하지만 종종 자기 지도 학습을 사용해 훈련된 모델이 최종 목적이 아닌 경우가 많음. \n",
    "\n",
    "    일반적으로 조금 다르지만 실제 관심 대상인 작업을 위해 모델을 수정하거나 **미세 튜닝**(fine tuning)합니다. \n",
    "\n",
    "    - Ex) 반려동물 분류 모델이 필요\n",
    "        1. 모델은 어떤 품종인지 예측해야함. 레이블이 없는 반려동물 사진으로 구성된 대량의 데이터셋이 있다면 자기 지도 학습을 사용하여 이미지 복원 모델을 먼저 훈련할 수 있습니다.  \n",
    "\n",
    "        2. 모델이 여러 종류의 반려동물을 구별할 수 있어야 합니다. 고양이 사진에 강아지 얼굴을 넣으면 안되기 때문입니다. \n",
    "\n",
    "        3. 모델 구조가 허락한다면(대부분의 신경망(neural network)구조가 가능하지만) 이미지 복원 대신 반려동물 종류를 예측하도록 수정할 수 있음.\n",
    "\n",
    "        4. 마지막 단계는 레이블이 있는 데이터셋에서 모델을 미세 튜닝하는 것입니다. \n",
    "\n",
    "    - 이 모델은 고양이, 강아지 그리고 다른 종류의 반려동물이 어떻게 생겼는지 이미 알고 있습니다. \n",
    "    \n",
    "        따라서 모델이 이미 알고 있는 동물과 기대하는 레이블을 매핑하는 방법을 학습할 뿐입니다.  \n",
    "\n",
    "    - 일부 사람들은 자기 지도 학습이 레이블이 전혀없는 데이터셋을 사용하기 때문에 비지도 학습의 일부라고 생각합니다. \n",
    "    \n",
    "        하지만 자기 지도 학습은 훈련하는 동안 (생성된) 레이블을 사용합니다. 따라서 지도 학습에 더 가깝습니다. \n",
    "\n",
    "        비지도 학습 용어는 일반적으로 군집, 차원 축소, 이상치 탐지 같은 작업을 다룰 때 사용됩니다. \n",
    "\n",
    "        자기 지도 학습은 지도 학습과 동일한 작업(주로 분류와 회귀)에 초점을 맞춥니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **강화 학습**\n",
    "\n",
    "    강화 학습(reinforcement leaning)은 매우 다른 종류의 알고리즘\n",
    "    \n",
    "    - **에이전트** (agent) : 학습하는 시스템\n",
    "    - **보상** (reward) : 환경(environment)을 관찰해서 행동(action)을 실행하고 그 결과\n",
    "    - **벌점** (penalty) : 그림 1-13처럼 부정적인 보상\n",
    "    - **정책** (policy) : 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의\n",
    "\n",
    "    <img src=\"./img/pic1-13.png\" width=\"50%\"></img>\n",
    "    \n",
    "    딥마인드(DeepMind)의 알파고(AlphaGo) 프로그램도 강화 학습의 좋은 예입니다. \n",
    "\n",
    "    - 알파고는 수백만 개의 게임을 분석해서 승리 전략을 학습했으며 자기 자신과 많은 게임을 했습니다. 이를 **오프라인 학습** 이라고 부릅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4.2 배치 학습과 온라인 학습\n",
    "\n",
    "머신러닝 시스템을 분류하는데 사용하는 다른 기준은 **입력 데이터의 스트림(stream)으로부터 점진적으로 학습**할 수 있는지 여부입니다. \n",
    "\n",
    "- **배치 학습** (batch learning)\n",
    "\n",
    "    - 배치 학습에서는 시스템이 점진적으로 학습할 수 없습니다. 가용한 데이터를 모두 사용해 훈련시켜야 합니다. \n",
    "\n",
    "    - 일반적으로 이 방식은 시간과 자원을 많이 소모하므로 오프라인에서 수행됩니다. 먼저 시스템을 훈련시킨 다음 제품 시스템에 적용하면 더 이상의 학습없이 실행됩니다. \n",
    "\n",
    "    - 즉, 학습한 것을 단지 적용만 합니다. 이를 **오프라인 학습** (offline learning)이라고 합니다. \n",
    "\n",
    "    - **모델 부패**(model rot) or **데이터 드리프트**(data drift) : 모델 성능은 시간이 지남에 따라 감소하는 경향을 의미. 모델은 바뀌지 않고 그대로이기 때문.\n",
    "\n",
    "        - 해결 방법 : 최신 데이터에서 모델을 정기적으로 재훈련하는 것. 재훈련 주기는 경우에 따라 다름.\n",
    "\n",
    "    - 새로운 데이터에 대해 학습하려면 이전 데이터를 포함한 전체 데이터를 훈련해야 하고, 이전 모델을 새 모델로 교체합니다. 다행히 자동화 할 수 있습니다. \n",
    "\n",
    "    - 고려해야할 점.\n",
    "        1. 전체 데이터셋을 사용해 훈련하는데 몇 시간이 소요될 수 있습니다. 보통 24시간마다 또는 매주 훈련시킵니다면 빠르게 적응해야 한다면 더 능동적인 방법이 필요합니다. \n",
    "\n",
    "        2. 많은 컴퓨팅 자원이 필요. 데이터 양이 아주 많으면 배치 학습 알고리즘을 사용하는게 불가능할 수도 있음.\n",
    "\n",
    "        3. 자원이 제한된 시스템이 스스로 학습해야한다면 심각한 문제를 일으킵니다. 이런 경우 점진적으로 학습할 수 있는 알고리즘을 사용하는 편이 낫습니다. \n",
    "\n",
    "- **온라인 학습** (online learning)\n",
    "\n",
    "    - 데이터를 순차적으로 한 개씩 또는 **미니배치** (mini-batch)라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킵니다.\n",
    "\n",
    "    - 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있습니다. (그림 1-14)\n",
    "\n",
    "    <img src=\"./img/pic1-14.png\" width=\"60%\"></img>\n",
    "\n",
    "    - **외부 메모리 학습** (out-of-core leaning)\n",
    "\n",
    "        - 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋에서 모델을 훈련하는 학습.\n",
    "    \n",
    "        - 그림 1-15와 같이 알고리즘이 데이터 일부를 읽어들이고 훈련 단계를 수행하며, 전체 데이터가 모두 적용될 때까지 이 과정을 반복 합니다. \n",
    "\n",
    "            - 외부 메모리 학습은 보통 오프라인으로 실행 됩니다. (즉, 실시간이 아님). 그래서 **온라인 학습**이란 이름이 혼란을 줄 수 있습니다. **점진적 학습**(incremental leaning)이라고 생각하세요.\n",
    "\n",
    "    <img src=\"./img/pic1-15.png\" width=\"60%\"></img>\n",
    "\n",
    "    - **학습률** (learning rate) : 변화하는 데이터에 얼마나 빠르게 적응하는 비율.\n",
    "\n",
    "        - 학습률을 높이면 빠르게 적응하지만 예전 데이터를 금방 잊는다.\n",
    "\n",
    "        - 학습률이 낮으면 시스템의 관성이 더 커져서 느리게 학습. 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해집니다.\n",
    "\n",
    "    - **문제점** \n",
    "    \n",
    "        - 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 감소한다. 데이터 품질과 학습률에 따라서 빠르게 감소할 수도 있습니다. \n",
    "\n",
    "            - 운영중인 시스템이라면 고객이 눈치챌지 모릅니다. 버그나 시스템을 속이려는 행위로부터 나쁜 데이터가 올 수 있습니다. \n",
    "        \n",
    "        - 이런 위험을 줄이려면 시스템을 모니터링 하고 성능 감소가 감지되면 즉각 학습을 중지시켜야 합니다. (가능하면 이전 상태로 롤백) \n",
    "\n",
    "        - 비정상 데이터를 잡아낼 수도 있습니다. 예를 들면 이상치 탐지 알고리즘(9장)을 사용합니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 사계 기반 학습과 모델 기반 학습\n",
    "\n",
    "어떻게 **일반화** (generalization)되는가에 따라 머신러닝 시스템을 분류할 수도 있습니다. 대부분의 머신러닝 작업은 예측을 만드는 것입니다. \n",
    "\n",
    "훈련 데이터에서 높은 성능을 내는 것이 좋지만 그게 전부는 아닙니다. 진짜 목표는 **새로운 샘플에 잘 작동하는 모델**입니다. \n",
    "\n",
    "일반화를 위한 두 가지 접근법은 **사례 기반 학습**과 **모델 기반 학습**입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **사례 기반 학습**\n",
    "\n",
    "    - 간단한 형태의 학습은 기억하는 것입니다. 사용자가 스팸이라고 지정한 동일한 메일을 스팸으로 분류합니다. 최악의 방법은 아니지만 최선도 아닙니다. \n",
    "\n",
    "    - 스팸 메일과 매우 유사한 메일을 구분하도록 스팸 필터를 프로그래밍할 수 있습니다. 이렇게 하려면 두 메일의 **유사도** (similarity)를 **측정** (measure)해야 합니다. \n",
    "\n",
    "        - 가장 간단한 측정 방법은 공통으로 포함된 단어의 개수를 세는 것입니다. 공통 단어가 많으면 스팸으로 분류합니다. \n",
    "\n",
    "        - 이를 **사례 기반 학습** (instance-based learning)이라고 합니다. 훈련 샘플을 기억함으로써 학습합니다. \n",
    "    \n",
    "    - 예를들어 [그림 1-16]에서 새로운 샘플은 가장 비슷한 샘플 중 다수가 삼각형이므로 삼각형 클래스로 분류될 것입니다. \n",
    "\n",
    "    <img src=\"./img/pic1-16.png\" width=\"60%\"></img>\n",
    "\n",
    "2. **모델 기반 학습**\n",
    "    \n",
    "    - 샘플들의 모델을 만들어 **예측** (prediction)에 사용하는 것을 **모델 기반 학습** (model-based learning)이라고 합니다. [그림 1-17]\n",
    "\n",
    "    <img src=\"./img/pic1-17.png\" width=\"60%\"></img>\n",
    "    \n",
    "    - 예를 들어 돈이 사람을 행목하게 만드는지 알아본다고 가정합시다. OECD웹사이트에서 **더 나은 삶의 지표** (better Life Index)데이터와 1인당 GDP 데이터를 사용하기 위해 다운 받습니다. \n",
    "\n",
    "        두 데이터 테이블을 합치고 1인당 GDP로 정렬합니다. [표 1-1] \n",
    "    \n",
    "    <img src=\"./img/chart1-1.png\" width=\"40%\"></img>\n",
    "\n",
    "    - 이 국가들을 그래프로 표시했습니다. (그림 1-18)\n",
    "\n",
    "    <img src=\"./img/pic1-18.png\" width=\"50%\"></img>\n",
    "    \n",
    "    - 여기서 어떤 경향을 볼 수 있습니다. \n",
    "    \n",
    "        - 데이터가 **흩어져 있지만** (즉, 어느정도 무작위성이 있지만) 삶의 만족도는 국가의 1인당 GDP가 증가할 수록 거의 선형으로 같이 상승합니다. \n",
    "\n",
    "    - 1인당 GDP의 선형 함수로 삶의 만족도를 모델링 해보겠습니다. 이 단계를 **모델 선택** (model selection)이라고 합니다. \n",
    "    \n",
    "        - 특징 하나를 가진 삶의 만족도에 **선형 모델** (linear model)을 선택했습니다. (식1-1)\n",
    "        \n",
    "        <img src=\"./img/formula1-1.png\" width=\"30%\"></img>\n",
    "\n",
    "    - 이 모델은 두개의 **모델 파라미터** (model parameter) 𝚹0과 𝚹1을 가집니다. [그림 1-19]처럼 어떤 선형 함수를 표현하는 모델을 얻을 수 있습니다. \n",
    "\n",
    "    <img src=\"./img/pic1-19.png\" width=\"50%\"></img>\n",
    "\n",
    "    - 모델을 사용하기 전에 𝚹0과 𝚹1의 값을 정의 해야 합니다. \n",
    "\n",
    "    - 모델이 최상의 성능을 내도록 하는 값을 어떻게 알 수 있을 까요? 이 질문에 답하려면 측정 지표를 정해야 합니다. \n",
    "\n",
    "        1. 모델이 얼마나 **좋은지** 측정하는 **효용 함수** (utility func) (또는 **적합도 함수** (finess func))를 정의\n",
    "\n",
    "        2. 모델이 얼마나 **나쁜지** 측정하는 **비용 함수** (cost func) 를 정의 할 수 있습니다. \n",
    "\n",
    "            - 선형 회귀에서는 보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용함수를 사용합니다. 이 거리를 최소화하는 것이 목표입니다. \n",
    "\n",
    "    - 여기에서 선형회귀(linear regression) 알고리즘이 등장합니다. \n",
    "    \n",
    "        - 알고리즘에 훈련 데이터를 공급하면 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾습니다. \n",
    "\n",
    "        - 이 경우에는 알고리즘이 최적의 파라미터로 𝚹0=3.75와 𝚹1=6.78x10^5을 찾았습니다. \n",
    "\n",
    "        - [그림 1-20]에서 볼 수 있듯이 모델이 훈련 데이터에 (선형 모델로서) 가능한 한 가깝게 맞춰졌습니다. \n",
    "\n",
    "    <img src=\"./img/pic1-20.png\" width=\"50%\"></img>\n",
    "    \n",
    "    - 이제 이 모델을 사용해 예측을 할 수 있습니다. 키프로스(Cyprus) 사람들이 얼마나 행복한지 알아보기 위해 이 모델을 사용할 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import sklearn                  # pip3 install -U scikit-learn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt     # pip3 install matplotlib\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAG7CAYAAAALy3WMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFU0lEQVR4nO3dd3xUVf7/8fcwKRAgBJLQSYFQFGnSNiKhi9jQVVRQxIhd7HXdLxAQVCz8dLGhrhRXwbpW1AUkICgQSuggEJooJqEkIcEQkvP7w80sk4SUyYSZO/N6Ph556D33zJ3PZ85APtx7z7k2Y4wRAACARdTydAAAAABVQfECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALMXripecnBw98MADio6OVp06dXTBBRcoJSXF02EBAAAv4XXFy6233qqFCxfq3Xff1aZNm3TRRRdp8ODBOnjwoKdDAwAAXsDmTQ9mPHHihOrXr6/PP/9cl156qaO9e/fuGjZsmKZMmeLB6AAAgDcI8HQApzt16pQKCwtVu3Ztp/Y6depo+fLlZb4mPz9f+fn5ju2ioiIdOXJE4eHhstlsNRovAABwD2OMcnJy1Lx5c9WqVcGFIeNl4uPjTb9+/czBgwfNqVOnzLvvvmtq1apl2rVrV2b/iRMnGkn88MMPP/zww48P/Bw4cKDCWsGrLhtJ0u7du3XLLbdo2bJlstvtOv/889WuXTutXbtW27ZtK9W/5JmXrKwsRUVFac+ePapfv361YikoKNCSJUs0YMAABQYGVutYVuTP+ftz7hL5+3P+/py75N/5ezr3nJwcxcbG6tixY2rQoEG5fb3qspEktWnTRkuXLlVubq6ys7PVrFkzXXfddWrdunWZ/YODgxUcHFyqvVGjRgoNDa1WLAUFBQoJCVF4eLjffYkl/87fn3OXyN+f8/fn3CX/zt/TuRe/Z2Vu+fC62UbF6tatq2bNmuno0aP67rvvNHz4cE+HBAAAvIDXnXn57rvvZIxR+/bttWvXLj366KPq0KGDEhMTPR0aAADwAl535iUrK0v33HOPOnTooJtuukkXXnihvvvuO787fQcAAMrmdWderr32Wl177bWeDgMAAHgprzvzAgAAUB6KFwAAYCkULwAAwFIoXgAAgKVQvAAAAEuheAEAAJZC8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFIoXgAAgKVQvAAAAEuheAEAAJZC8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFIoXgAAgKVQvAAAAEuheAEAAJZC8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsxeuKl8LCQo0fP16xsbGqU6eO2rRpo6eeekrGGE+HBgAAvECApwMoadq0aXr99dc1Z84cdezYUWvWrFFiYqIaNGig++67z9PhAQAAD/O64uXHH3/U8OHDdemll0qSYmJiNG/ePK1evdrDkQEAAG/gdcXLBRdcoDfffFM///yz2rVrpw0bNmj58uWaPn16mf3z8/OVn5/v2M7OzpYkFRQUqKCgoFqxFL++usexKn/O359zl8jfn/P359wl/87f07lX5X1txstuJikqKtKTTz6p5557Tna7XYWFhZo6dar+9re/ldk/KSlJkyZNKtX+/vvvKyQkpKbDBQAAbpCXl6dRo0YpKytLoaGh5fb1uuJl/vz5evTRR/X888+rY8eOSk1N1QMPPKDp06drzJgxpfqXdealVatWyszMrDD5ihQUFGjhwoUaMmSIAgMDq3UsK/Ln/P05d4n8/Tl/f85d8u/8PZ17dna2IiIiKlW8eN1lo0cffVRPPPGErr/+eklSp06dtG/fPj3zzDNlFi/BwcEKDg4u1R4YGOi2D9+dx7Iif87fn3OXyN+f8/fn3CX/zt9TuVflPb1uqnReXp5q1XIOy263q6ioyEMRAQAAb+J1Z14uv/xyTZ06VVFRUerYsaPWr1+v6dOn65ZbbvF0aAAAwAt4XfEyY8YMjR8/XnfffbfS09PVvHlz3XHHHZowYYKnQwMAAF7A64qX+vXr66WXXtJLL73k6VAAAIAX8rp7XgAAAMpD8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALIXiBQAAWEqApwMAAH+XlnFc+47kKSa8rmIj6no6HFQBY+cZFC8A4CHH8k7qvnmpWrYzw9GW0DZSM0Z2U4OQQA9Ghoowdp7FZSMA8JD75qVqxa5Mp7YVuzJ177z1HooIlcXYeRbFCwB4QFrGcS3bmaFCY5zaC43Rsp0Z2pOZ66HIUBHGzvMoXgDAA/YdySt3/97D/AL0Voyd51G8AIAHRDcKKXd/TDg3f3orxs7zKF4AwANaR9ZTQttI2W02p3a7zaaEtpHMXPFijJ3nUbwAgIfMGNlNfeIinNr6xEVoxshuHorIM9IyjmvJjnRL3SvC2HkWU6UBwEMahARq7the2pOZq72Hc/1urRArTzf297HzNIoXAPCw2Aj//MVX3nTjuWN7eSiqqvHXsfO0ahUvp06d0o4dO3Ts2DEVFhaW2SchIaE6bwEA8EHF041LOn26MUUBzsSl4sUYowkTJmjGjBnKyckpt++ZihoAgP+qzHRjiheciUvFy1NPPaWpU6cqLCxMN910k1q2bKmAAK5AAQAqh+nGqA6XKo533nlH0dHRWrNmjcLDw90dEwDAxxVPN16xK9NppVq7zaY+cRGcdUG5XJoqfejQIV155ZUULgD8mhWn+HqTszndmLHyLS6deYmNjVV2dra7YwEAS7DyFF9vcjamGzNWvsmlMy933XWXvvrqK6Wnp7s7HgDwejxR2L1iI+pqQPvGNXKpiLHyTS6deRk+fLh++OEHXXDBBZowYYLOP/98hYaGltk3KiqqWgECgDdhiq91MFa+y+XLRjabTcYYJSYmnrGfzWbTqVOnXA4OALwNU3ytg7HyXS4VLzfddJNsJR5IBQD+gCm+1sFY+S6XipfZs2e7OQwAsAam+FoHY+W7eKo0AFQRTxS2DsbKN1V7WdwVK1YoNTVV2dnZCg0NVdeuXdWnTx93xAbAD6VlHNe+I3le/ZReb36i8Nn4/KwwRsW8eazgOpeLlx9//FGJiYnatWuXpD+fd1R8H0zbtm01a9YsxcfHuydKAD7PiutxeNMThc/G52fFMSrmTWOF6nPpstGWLVt00UUXaefOnRo8eLCmTp2qWbNm6emnn9aQIUP0888/a+jQodq6dau74wXgo1iPo3rOxufHGMFbuHTmZfLkyTp58qQWLFigiy++2Gnf448/rm+//VZXXHGFJk+erPnz57slUAC+i/U4qudsfH6MEbyJS2dekpOTdc0115QqXIpdfPHFuuaaa7RkyZJqBQfAP1RmPQ6c2dn4/BgjeBOXipesrCzFxsaW2yc2NlZZWVkuBQXAv7AeR/Wcjc+PMYI3cal4ad68uVauXFlun1WrVql58+YuBQXAvxSvx2Evsfil3WZTQttILkdU4Gx8fowRvIlLxcsVV1yh5ORkjR8/Xn/88YfTvj/++EMTJ07UkiVLNHz4cLcECeDM0jKOa8mOdO3JtPZpe9bjqJ6z8fkxRvAWLt2wO378eH311Vd6+umnNXPmTPXq1UtNmjTR77//rpSUFGVkZKh169YaP368u+MF8F9WnrZaFtbjqJ6z8fkxRvAWLhUv4eHhWrlypR577DHNnz9fCxYscOyrXbu2EhMTNW3aNDVq1MhtgQJwVt601blje3koqupjPY7qORufH2MET3N5kbqIiAi98847mjlzprZv3+5YYbdDhw4KDLTev/oAK2HaKgB/Vu3HAwQGBqpTp07uiAVAJVVm2irFCwBfxYMZAQti2ioAf1apMy8DBw6UzWbTnDlz1LJlSw0cOLBSB7fZbFq8eHG1AgRQWvG01RW7MlVojKPdbrOpT1wEZ10A+LRKFS/Jycmy2WzKy8tzbFeGrcR6AADcZ8bIbrp33nqne1+YtgrAH1SqeCkqKip3G8DZx7RVWFVaxnHtO5LHdxYuq/YNuwA8i2mrsApfW5sInuPSDbu33HKLvvjii3L7fPXVV7rllltcCgoA4HvKW5sIqAqXipfZs2crNTW13D4bNmzQnDlzXDk8AMDHFK9NdPoN5pLz2kRAZdXYVOk//vhDAQFclQIAVG5tIqCyXK4uzjSTyBijAwcO6JtvvuGp0gAASaxNBPeq9JmXWrVqyW63y263S5KSkpIc26f/BAQEKDY2VuvWrdP1119fY4EDAKyjeG0ie4l/+NptNiW0jeSmc1RJpc+8JCQkOM62LFu2TFFRUYqJiSnVz263q1GjRho4cKBuu+22KgcUExOjffv2lWq/++679eqrr1b5eACAmlOVac+sTQR3qXTxcvrCdLVq1VJiYqImTJjg9oBSUlJUWFjo2N68ebOGDBmiESNGuP29AACucWXaM2sTwV1cuuelJhepi4yMdNp+9tln1aZNG/Xr16/G3hMAUDXlTXueO7ZXua9lbSJUl0vFyy+//KJ169YpISFBYWFhpfYfPXpUP/zwg7p3764WLVq4HNzJkyf1r3/9Sw899NAZbxDOz89Xfn6+Yzs7O1uSVFBQoIKCApffu/gYp//X3/hz/v6cu0T+/px/ZXLfm5mrVWnpCqhV8peI0aq0dO06lKXo8PJv0PVWjL3ncq/K+9qMKTHpvhLuvPNOffTRR/r1118VHBxcan9+fr5atGih66+/Xq+88kpVD+/w4YcfatSoUdq/f/8ZZy4lJSVp0qRJpdrff/99hYRY8w8PAAD+Ji8vT6NGjVJWVpZCQ0PL7etS8dKuXTt1795d8+bNO2OfUaNGad26ddq+fXtVD+8wdOhQBQUF6csvvzxjn7LOvLRq1UqZmZkVJl+RgoICLVy4UEOGDFFgoP8tXe3P+ftz7hL5+3P+lcl9b2auLntl+RmP8fW9fS195oWx90zu2dnZioiIqFTx4tJlo4MHD+rqq68ut090dHS5RUdF9u3bp0WLFunTTz8tt19wcHCZZ38CAwPd9uG781hW5M/5+3PuEvn7c/7l5d62WZh6t26sFbsynVbMtdts6hMXobimDc5WmDWGsT/7uVflPV1aYTcoKMhxb8mZZGdnn/E+lcqYNWuWGjdurEsvvdTlYwCAL0rLOK4lO9I9uqT+jJHd1CcuwqmNac++wxu+Y+Vx6cxLp06d9OWXX2r69OllnvX4448/9MUXX6hTp04uBVVUVKRZs2ZpzJgxPGIAAP7Lm57KzLRn33XHu2v1/c+HHdve+ORvl868JCYm6pdfftEVV1yhtLQ0p327d+/W8OHD9euvv+rWW291KahFixZp//79PJUaAE7jjU9ljo2oqwHtG1O4+JCVaYedtj39HSuLS6c1EhMTtWDBAn3yySfq0KGDYmNj1aJFCx08eFB79uzRqVOndN111ykxMdGloC666CK5cB8xAPis4qcyl3T6U5kpIFAde/97iejP+5j+d9uHN37HXH6q9Icffqh//OMfiouL086dO5WcnKydO3eqXbt2evXVV8udiQQAqBqeyoyaduCodb5j1Xqq9Lhx4zRu3Djl5uYqKytLDRo0UN263lGVAYAv4anMqGmtGoZoazn7vek75vKZl9PVrVtXzZs3p3ABgBrCU5lR02L++x2ywnfMLcULAKDmMT0ZZ8NfWoc7bXvjd8zly0YHDhzQlClTtGjRIv366686efJkqT42m02nTp2qVoAAfENaxnHtO5LHlNpqYHoyzoaZo7vrl6yTXv0dc6l4SUtLU+/evXX06FF17NhR+fn5io6OVu3atZWWlqaCggJ16dKlzIc2AvAv3rQ2ia/gqcyoad7+HXPpstGkSZOUlZWlxYsXa8OGDZL+nD69bds27d27V1dccYVyc3P18ccfuzVYANbjjWuTALA2l4qXRYsW6ZJLLlG/fv0cbcXrsjRr1kwffPCBJOnJJ590Q4gArKp4bZLCEus2nb5uBABUlUvFS2Zmpjp06ODYDggIUF7e/+aHBwcHa8iQIfrqq6+qHyEAy2JtEgA1waXiJSIiQrm5uU7be/fudeoTEBCgY8eOVSc2ABbH2iQAaoJLxUvbtm21e/dux3avXr303XffOZ5zlJGRoY8//lht2rRxT5QALIm1SQDUBJeKl2HDhmnJkiWOMysPPPCAcnJy1LlzZ/Xs2VPt2rXToUOHdO+997ozVgAWxNokANzNpanSd911l/r37y+73S5J6t+/v+bPn6+kpCRt3rxZ0dHRmjJlim677Ta3BgvAelibBIC7Vap42bhxo5o2barGjRtLkkJDQ9W7d2+nPiNGjNCIESPcHyEAn+Dt60YAsI5KXTbq1q2b3njjDcf2wIEDNXfu3BoLCgAA4EwqVbzY7XYVFhY6tpOTk0vNLgIAADgbKlW8tGzZUqmpqTUcCgAAQMUqdc/L5ZdfrhkzZuicc85Rs2bNJEmzZ89WcnJyua+z2WxavHhxtYMEAAAoVqniZcqUKcrPz9fXX3+tpUuXymazae/evRVeOrKVWNsBAACguip12ah+/fp64403dODAARUWFsoYo6SkJBUVFZX7c/p9MgAAAO7g0iJ1Y8aMUdeuXd0cCgAAQMVcWqRu1qxZ7o4DAACgUlw687Jp0ya98847ys7OdrSdOHFCd911l1q0aKG4uDindWEAAADcxaXiZcqUKRo/frzq16/vaHvyySc1c+ZM5eTk6MCBA7rnnnu0cOFCtwUKAAAguVi8rF69WgMGDHDMJjp16pRmzZqlXr16KT09XXv27FFkZKRefvlltwYLAADgUvGSkZGhVq1aObZTUlKUnZ2tO++8U7Vr11bz5s01fPhwbdiwwW2BAgAASC7esBsQEKD8/HzHdnJysmw2mwYMGOBoCw8PV2ZmZvUjBOCz0jKOa9+RPJ40DaBKXCpeYmJitGTJEsf2Rx99pNjYWEVHRzvaDh48qPDw8OpHCMDnHMs7qfvmpWrZzgxHW0LbSM0Y2U0NQgI9GBkAK3DpstHo0aO1YcMG9e7dWwkJCdqwYYNGjRrl1Gfjxo1q27atW4IE4Fvum5eqFbucz8yu2JWpe+et91BEAKzEpeJl3LhxGjFihNasWaPly5dr2LBhevLJJx37t2zZog0bNmjgwIFuCxSAb0jLOK5lOzNUaIxTe6ExWrYzQ3sycz0UGQCrcOmyUXBwsD744ANlZ2fLZrM5TZmWpCZNmmj9+vWKiYlxR4wAfMi+I3nl7t97OJf7XwCUy6XipVhoaGiZ7REREYqIiKjOoQH4qOhGIeXujwmncAFQPpcuGwGAq1pH1lNC20jZSzx13m6zKaFtJGddAFSoUmdeWrduLZvNpkWLFik2NlatW7eu1MFtNpt2795drQAB+J4ZI7vp3nnrnWYb9YmL0IyR3TwYFQCrqFTxUlRU5FhNt6ztMzElbsgDAElqEBKouWN7aU9mrvYezmWdFwBVUqniZe/eveVuA4ArYiMoWgBUHfe8AAAAS3GpeBk4cKDmzp1bbp9//etfrPMCAADczqXiJTk5ucJLR/v27dPSpUtdOTwAAMAZ1dhlo9zcXAUG8owSAADgXpVepG7//v1O28eOHSvVJkmFhYU6cOCAPvnkE1bYBQAAblfp4iUmJsYxPdpms+nll1/Wyy+/fMb+xhg9//zz1Y8QsKC0jOPadySPKcAAUAMqXbzcdNNNstlsMsZo7ty56tKli7p27Vqqn91uV6NGjTRw4EBdfPHF7owV8HrH8k7qvnmpTouvJbSN1IyR3dQghMuoAOAOlS5eZs+e7fj/pUuXKjExUffdd19NxARY1n3zUrViV6ZT24pdmbp33nrNHdvLQ1EBgG9x6cGMe/bscXccgOWlZRx3OuNSrNAYLduZoT2ZPC0ZANyBReoAN9l3JK/c/XsP556lSADAt7l05kWScnJy9Morr2jRokX69ddflZ+fX6oPD2aEP4luFFLu/phwzroAgDu4VLxkZGToggsu0O7duxUaGqrs7Gw1aNBAJ0+e1IkTJyRJzZs3Z50X+JXWkfWU0DZSK3ZlqvC0h5LabTb1iYvgkhEAuIlLl42SkpK0e/duzZ07V0ePHpUkPfjgg8rNzdWqVavUq1cvxcTEaMuWLW4NFvB2M0Z2U5+4CKe2PnERmjGym4ciAgDf49KZlwULFmjQoEG68cYbS+3r2bOnvvnmG3Xq1EmTJk3StGnTqh0kYBUNQgI1d2wv7cnM1d7DuazzAgA1wKUzL7/99pu6dfvfvyTtdrvjcpEkNWzYUMOGDdOHH35Y/QgBC4qNqKsB7RtTuABADXCpeGnQoIEKCgoc2w0bNtQvv/zi1Cc0NFS///579aIDAAAowaXipXXr1k5Ple7WrZsWLlyow4cPS5JOnDihL7/8UlFRUW4JEgAAoJhLxctFF12kxYsXKy/vz3Ut7rjjDqWnp6tLly4aMWKEzjvvPO3evVs333yzO2MFAABwrXi588479dZbbzmKl7/+9a96/vnnlZubq08++USHDh3SQw89pEcffdStwQIAALg026hZs2a67rrrnNoefvhhPfDAA8rMzFTjxo0dT6AGKosnMQMAKsPlFXbLYrfb1aRJE3ceEn6AJzEDAKrCpctGBw4c0Pfff++4bCRJRUVFmjZtmvr06aNBgwbp66+/dluQ8G3lPYkZAICSXDrzMn78eH355Zc6dOiQo23q1KmaOHGiY3vZsmX68ccf1bNnz+pHCZ/Fk5gBAFXl0pmXFStWaPDgwY5nFxlj9Morr6hDhw7av3+/Vq9erbp16+r55593a7DwPTyJGQBQVS4VL+np6YqOjnZsp6amKiMjQ/fee69atmypHj166Morr1RKSorbAoVv4knMAICqcql4KSoqUlFRkWM7OTlZNptNAwcOdLS1aNHC6bISUJbiJzHbS8xOs9tsSmgbySUjAEApLhUvUVFRWr16tWP7s88+U7NmzdS+fXtH26FDhxQWFlbtAOH7eBIzAKAqXLph9+qrr9bUqVN1zTXXqHbt2lq+fLnGjRvn1Gfr1q1q3bq1S0EdPHhQjz/+uL755hvl5eUpLi5Os2bNUo8ePVw6HrwbT2KuWayfA8DXuFS8PPLII/rPf/6jTz/9VJLUuXNnJSUlOfbv27dPq1ev1hNPPFHlYx89elR9+vTRgAED9M033ygyMlI7d+5Uw4YNXQkVFhIbwS9Xd2L9HAC+yqXiJTQ0VCtXrtTmzZslSeecc47sdrtTn08//dSlMyXTpk1Tq1atNGvWLEdbbGysK2ECfq289XPmju3loagAoPqqtcLueeedV2Z7dHS002ykqvjiiy80dOhQjRgxQkuXLlWLFi10991367bbbiuzf35+vvLz8x3b2dnZkqSCggIVFBS4FEOx4tdX9zhW5c/5Wz33vZm5WpWWroBaJf+QG61KS9euQ1mKDj/zTC+r519d/py/P+cu+Xf+ns69Ku9rM8aYGoylymrXri1JeuihhzRixAilpKTo/vvv1xtvvKExY8aU6p+UlKRJkyaVan///fcVElL+NFwAAOAd8vLyNGrUKGVlZSk0NLTcvl5XvAQFBalHjx768ccfHW333XefUlJS9NNPP5XqX9aZl1atWikzM7PC5CtSUFCghQsXasiQIY4F+fyJP+dv9dz3ZubqsleWn3H/1/f2rfDMi5Xzry5/zt+fc5f8O39P556dna2IiIhKFS9ufTCjOzRr1kznnnuuU9s555yjTz75pMz+wcHBCg4OLtUeGBjotg/fnceyIn/O36q5t20Wpt6tG2vFrkwVnvbvE7vNpj5xEYpr2qBSx7Fq/u7iz/n7c+6Sf+fvqdyr8p5eV7z06dNHO3bscGr7+eefXb6HBq5JyziuvRnZng7DZxRPV7bbbCo05qxMW54xspvunbfeabYR6+cA8AVeV7w8+OCDuuCCC/T000/r2muv1erVq/Xmm2/qzTff9HRofuH06bXBdqPnekl3vLtW/+/67kyvdUFZ05WL1fS0ZdbPAeCrXFphtyb17NlT//73vzVv3jydd955euqpp/TSSy/phhtu8HRofqGs6bUr0w7r3nnrPRSRtZX1eRYrnrZc02Ij6mpA+8YULgB8RrXPvGzdulXbt29Xbm6uRo8e7Y6YdNlll+myyy5zy7FQeWkZx8s8Q1BojJbtzNCezFx+AVbBmT7PYnyuAOAal8+8pKSkqGvXrurUqZNGjBihm2++2bFv2bJlCgkJ0RdffOGOGHGW7DuSV+7+vYdzz1IkvqGiz7MYnysAVI1LxcuWLVs0cOBA7dmzRw8++KCGDRvmtL9v376KiIjQRx995JYgcXZENyp/XZyYcM4OVEVFn2cxPlcAqBqXipeJEydKktauXasXXnhBPXv2dNpvs9kUHx+vlJSU6keIs6Z1ZD0ltI2U3WZzarfbbEpoG8mljSo60+dZjM8VAFzjUvGydOlSXX311YqLiztjn6ioKP32228uBwbPmDGym/rERTi1/aV1ONNrXVTW51mMacsA4BqXbtjNyclR48aNy+1z4sQJFRYWuhSULype58Pbp6uePr12T3qWcnamaObo7n67WFN1lZyuHFDLplNFZ2edFwDwVS4VL61atdKmTZvK7bNu3Tq1adPGpaB8SVnrfNT0+h7uEBtRVy0bBGnBTk9H4htiIyhWAMBdXLpsdNlll+k///mPFi1aVOb+Dz/8UCtXrtSVV15Zndh8QlnrfJyt9T0AAPBFLhUvTz75pJo3b65LLrlEt912m9asWSNJeu211zR69GiNGjVKMTExeuihh9warNUUr/NRWOLZl6ev7wEAAKrGpctGkZGRSk5O1k033aR//vOfjvZx48ZJknr37q158+apQYPKPfzNV1Vm3RQuJQAAUDUur7Dbpk0brVixQqmpqVq5cqWOHDmi0NBQ9e7du9TUaX/FuikAALhfpYqXv/71r7r++ut17bXXSvpzBd2YmBhFRUWpa9eu6tq1a03GaFnF63ys2JXpdOnIbrOpT1wEZ10AAHBBpe55+eyzz7R9+3bH9oABAzR79uyaismnlLXOB+t7+Ia0jONasiOde5cA4Cyr1JmXsLAwZWdnO7ZNiRtQcWYl1/lgfQ/rs+r0dwDwFZUqXs4991zNmzdPPXv2VLNmzSRJe/fu1bJlyyp8bUJCQvUi9BGs8+E7ypv+PndsLw9FBQD+o1LFy4QJE3TllVdq1KhRjrY5c+Zozpw5Fb6WVXbhS4qnv5d0+vR3ilQAqFmVKl4uuugibdu2TYsWLdLBgweVlJSkfv36qV+/fjUdH+BVmP4OAJ5X6anS0dHRGjt2rCQpKSlJ/fv314QJE2osMMAbMf0dADzPpXVe9uzZo7CwMDeHAng/pr8DgOe59HiA6Ohov189F2Xzh+nDTH8HAM+q1JmXyZMny2az6Z577lGjRo00efLkSh3cZrNp/Pjx1QoQ1uBP04eZ/g4AnlWp4iUpKUk2m03XXXedGjVqpKSkpEodnOLFf/jj9GGmvwOAZ1SqeFmyZIkkKSoqymkbkJg+DAA4uypVvJScEs0UaZyO6cMAgLPJpRt2K2PatGkaNGhQTR0eXoTpwwCAs6nGipft27crOTm5pg4PL1I8fdhuszm12202JbSN5KwLAMCtaqx4gX9h+jAA4GxxaZE6eJ+0jOPadyTPY9N2mT4MADhbKF4sztvWV2H6MACgpnHZyOLKW18FAABfRPFiYcXrq5z+jB3JeX0VAAB8TaUvG11yySVVOvCmTZuqHAyqhvVVAAD+qNLFy7ffflvlg9tKTJ2Fe7G+CgDAH1W6eNmzZ09NxgEXFK+vsmJXptOlI7vNpj5xEZx1AQD4pEoXL9HR0TUZB/6rqlOeZ4zspnvnrXeabWTV9VU8Pd0bAGANTJX2Eq5OefaF9VW8bbo3AMC7MdvIS1R3ynNsRF0NaN/YcoWLxHRvAEDVULx4AX+e8uzPuQMAXEPx4gUqM+XZV/lz7gAA11C8eAF/nvLsz7kDAFxD8eIFiqc820usi2O32ZTQNtKS97FUlj/nDgBwDcWLl5gxspv6xEU4tVl1ynNV+XPuAICqY6q0l/CFKc+u8ufcAQBVR/HiZWIj/PcXtz/nDgCoPC4bAQAAS6F4AQAAlkLxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFIoXgAAgKVQvAAAAEuheAEAAJZC8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYitcVL0lJSbLZbE4/HTp08HRYAADASwR4OoCydOzYUYsWLXJsBwR4ZZgAAMADvLIqCAgIUNOmTT0dBgAA8EJeWbzs3LlTzZs3V+3atRUfH69nnnlGUVFRZfbNz89Xfn6+Yzs7O1uSVFBQoIKCgmrFUfz66h7Hqvw5f3/OXSJ/f87fn3OX/Dt/T+delfe1GWNMDcZSZd98842OHz+u9u3b67ffftOkSZN08OBBbd68WfXr1y/VPykpSZMmTSrV/v777yskJORshAwAAKopLy9Po0aNUlZWlkJDQ8vt63XFS0nHjh1TdHS0pk+frrFjx5baX9aZl1atWikzM7PC5CtSUFCghQsXasiQIQoMDKzWsazIn/P359wl8vfn/P05d8m/8/d07tnZ2YqIiKhU8eKVl41OFxYWpnbt2mnXrl1l7g8ODlZwcHCp9sDAQLd9+O48lhX5c/7+nLtE/v6cvz/nLvl3/p7KvSrv6XVTpUs6fvy4du/erWbNmnk6FAAA4AW8rnh55JFHtHTpUu3du1c//vijrrrqKtntdo0cOdLToQEAAC/gdZeNfvnlF40cOVKHDx9WZGSkLrzwQq1cuVKRkZGeDg0AAHgBryte5s+f7+kQAACAF/O6y0YAAADloXgBAACWQvECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFIoXgAAgKVQvAAAAEuheAEAAJZC8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFIoXgAAgKVQvAAAAEuheAEAAJZC8QIAACyF4gUAAFgKxQsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYCsULAACwFIoXAABgKRQvAADAUiheAACApVC8AAAAS6F4AQAAlkLxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFK8unh59tlnZbPZ9MADD3g6FAAA4CW8tnhJSUnRzJkz1blzZ0+HAgAAvIhXFi/Hjx/XDTfcoLfeeksNGzb0dDgAAMCLBHg6gLLcc889uvTSSzV48GBNmTKl3L75+fnKz893bGdlZUmSjhw5ooKCgmrFUVBQoLy8PB0+fFiBgYHVOpYV+XP+/py7RP7+nL8/5y75d/6ezj0nJ0eSZIypsK/XFS/z58/XunXrlJKSUqn+zzzzjCZNmlSqPTY21t2hAQCAGpaTk6MGDRqU28dmKlPinCUHDhxQjx49tHDhQse9Lv3791fXrl310ksvlfmakmdeioqKdOTIEYWHh8tms1UrnuzsbLVq1UoHDhxQaGhotY5lRf6cvz/nLpG/P+fvz7lL/p2/p3M3xignJ0fNmzdXrVrl39XiVWde1q5dq/T0dJ1//vmOtsLCQi1btkyvvPKK8vPzZbfbnV4THBys4OBgp7awsDC3xhUaGup3X+LT+XP+/py7RP7+nL8/5y75d/6ezL2iMy7FvKp4GTRokDZt2uTUlpiYqA4dOujxxx8vVbgAAAD/41XFS/369XXeeec5tdWtW1fh4eGl2gEAgH/yyqnS3iI4OFgTJ04sdVnKX/hz/v6cu0T+/py/P+cu+Xf+Vsrdq27YBQAAqAhnXgAAgKVQvAAAAEuheAEAAJZC8QIAACzFp4qXZ555Rj179lT9+vXVuHFjXXnlldqxY4dTn/79+8tmszn93HnnnU599u/fr0svvVQhISFq3LixHn30UZ06dcqpT3Jyss4//3wFBwcrLi5Os2fPLhXPq6++qpiYGNWuXVu9e/fW6tWr3Z7z6V5//XV17tzZscBQfHy8vvnmG8f+P/74Q/fcc4/Cw8NVr149XX311fr999+djmHV3KWK8/flsS/p2Weflc1m0wMPPOBo8/XxL1ZW7r489klJSaVy69Chg2O/r497Rfn78thL0sGDB3XjjTcqPDxcderUUadOnbRmzRrHfmOMJkyYoGbNmqlOnToaPHiwdu7c6XSMI0eO6IYbblBoaKjCwsI0duxYHT9+3KnPxo0b1bdvX9WuXVutWrXSc889VyqWjz76SB06dFDt2rXVqVMnLViwoGaS/m9iPmPo0KFm1qxZZvPmzSY1NdVccsklJioqyhw/ftzRp1+/fua2224zv/32m+MnKyvLsf/UqVPmvPPOM4MHDzbr1683CxYsMBEREeZvf/ubo09aWpoJCQkxDz30kNm6dauZMWOGsdvt5ttvv3X0mT9/vgkKCjLvvPOO2bJli7nttttMWFiY+f3332ss/y+++MJ8/fXX5ueffzY7duwwTz75pAkMDDSbN282xhhz5513mlatWpnFixebNWvWmL/85S/mggsu8IncK5O/L4/96VavXm1iYmJM586dzf333+9o9/XxLy93Xx77iRMnmo4dOzrllpGR4djv6+NeUf6+PPZHjhwx0dHR5uabbzarVq0yaWlp5rvvvjO7du1y9Hn22WdNgwYNzGeffWY2bNhgrrjiChMbG2tOnDjh6HPxxRebLl26mJUrV5offvjBxMXFmZEjRzr2Z2VlmSZNmpgbbrjBbN682cybN8/UqVPHzJw509FnxYoVxm63m+eee85s3brV/N///Z8JDAw0mzZtqpHcfap4KSk9Pd1IMkuXLnW09evXz+kvtZIWLFhgatWqZQ4dOuRoe/31101oaKjJz883xhjz2GOPmY4dOzq97rrrrjNDhw51bPfq1cvcc889ju3CwkLTvHlz88wzz1Q3rSpp2LChefvtt82xY8dMYGCg+eijjxz7tm3bZiSZn376yRjje7kb87/8jfGPsc/JyTFt27Y1CxcudMrXH8b/TLkb49tjP3HiRNOlS5cy9/nDuJeXvzG+PfaPP/64ufDCC8+4v6ioyDRt2tQ8//zzjrZjx46Z4OBgM2/ePGOMMVu3bjWSTEpKiqPPN998Y2w2mzl48KAxxpjXXnvNNGzY0PF5FL93+/btHdvXXnutufTSS53ev3fv3uaOO+6oXpJn4FOXjUrKysqSJDVq1Mip/b333lNERITOO+88/e1vf1NeXp5j308//aROnTqpSZMmjrahQ4cqOztbW7ZscfQZPHiw0zGHDh2qn376SZJ08uRJrV271qlPrVq1NHjwYEefmlZYWKj58+crNzdX8fHxWrt2rQoKCpxi6tChg6Kiohwx+UruUun8i/n62N9zzz269NJLS8XoD+N/ptyL+fLY79y5U82bN1fr1q11ww03aP/+/ZL8Y9ylM+dfzFfH/osvvlCPHj00YsQINW7cWN26ddNbb73l2L9nzx4dOnTIKa4GDRqod+/eTuMfFhamHj16OPoMHjxYtWrV0qpVqxx9EhISFBQU5OgzdOhQ7dixQ0ePHnX0Ke8zcjevejyAOxUVFemBBx5Qnz59nB4tMGrUKEVHR6t58+bauHGjHn/8ce3YsUOffvqpJOnQoUNOX2JJju1Dhw6V2yc7O1snTpzQ0aNHVVhYWGaf7du3uz3X023atEnx8fH6448/VK9ePf373//Wueeeq9TUVAUFBZV6aGWTJk0qzKt4X3l9vCF36cz5S74/9vPnz9e6deuUkpJSat+hQ4d8evzLy13y7bHv3bu3Zs+erfbt2+u3337TpEmT1LdvX23evNnnx10qP//69ev79NinpaXp9ddf10MPPaQnn3xSKSkpuu+++xQUFKQxY8Y44i8rrtNza9y4sdP+gIAANWrUyKlPbGxsqWMU72vYsOEZP6PiY7ibzxYv99xzjzZv3qzly5c7td9+++2O/+/UqZOaNWumQYMGaffu3WrTps3ZDtPt2rdvr9TUVGVlZenjjz/WmDFjtHTpUk+HddacKf9zzz3Xp8f+wIEDuv/++7Vw4ULVrl3b0+GcVZXJ3ZfHftiwYY7/79y5s3r37q3o6Gh9+OGHqlOnjgcjOzvKy3/s2LE+PfZFRUXq0aOHnn76aUlSt27dtHnzZr3xxhsaM2aMh6OrWT552WjcuHH66quvtGTJErVs2bLcvr1795Yk7dq1S5LUtGnTUnfiF283bdq03D6hoaGqU6eOIiIiZLfby+xTfIyaEhQUpLi4OHXv3l3PPPOMunTpopdffllNmzbVyZMndezYsTPGZPXcpTPnXxZfGvu1a9cqPT1d559/vgICAhQQEKClS5fqH//4hwICAtSkSROfHf+Kci8sLCz1Gl8a+5LCwsLUrl077dq1y2/+3J/u9PzL4ktj36xZM8eZ5WLnnHOO47JZ8XuXF1fTpk2Vnp7utP/UqVM6cuSIW74jNZW/TxUvxhiNGzdO//73v/X999+XOs1VltTUVEl/fgkkKT4+Xps2bXIazIULFyo0NNTxJYmPj9fixYudjrNw4ULHvRVBQUHq3r27U5+ioiItXrzY6f6Ls6GoqEj5+fnq3r27AgMDnWLasWOH9u/f74jJ13Ivfu/8/Pwy9/nS2A8aNEibNm1Samqq46dHjx664YYbHP/vq+NfUe52u73Ua3xp7Es6fvy4du/erWbNmvnln/vT8y+LL419nz59Si0H8vPPPys6OlqSFBsbq6ZNmzrFlZ2drVWrVjmN/7Fjx7R27VpHn++//15FRUWOQi8+Pl7Lli1TQUGBo8/ChQvVvn17NWzY0NGnvM/I7WrkNmAPueuuu0yDBg1McnKy07S4vLw8Y4wxu3btMpMnTzZr1qwxe/bsMZ9//rlp3bq1SUhIcByjeNrcRRddZFJTU823335rIiMjy5w29+ijj5pt27aZV199tcxpc8HBwWb27Nlm69at5vbbbzdhYWFOd7S72xNPPGGWLl1q9uzZYzZu3GieeOIJY7PZzH/+8x9jzJ9TJqOiosz3339v1qxZY+Lj4018fLxP5F5R/r4+9mUpOcvC18f/dKfn7utj//DDD5vk5GSzZ88es2LFCjN48GATERFh0tPTjTG+P+7l5e/rY7969WoTEBBgpk6danbu3Gnee+89ExISYv71r385+jz77LMmLCzMfP7552bjxo1m+PDhZU6V7tatm1m1apVZvny5adu2rdNU6WPHjpkmTZqY0aNHm82bN5v58+ebkJCQUlOlAwICzAsvvGC2bdtmJk6cyFTpypJU5s+sWbOMMcbs37/fJCQkmEaNGpng4GATFxdnHn30Uac5/8YYs3fvXjNs2DBTp04dExERYR5++GFTUFDg1GfJkiWma9euJigoyLRu3drxHqebMWOGiYqKMkFBQaZXr15m5cqVNZW6McaYW265xURHR5ugoCATGRlpBg0a5ChcjDHmxIkT5u677zYNGzY0ISEh5qqrrjK//fab0zGsmrsx5efv62NflpLFi6+P/+lOz93Xx/66664zzZo1M0FBQaZFixbmuuuuc1rnw9fHvbz8fX3sjTHmyy+/NOedd54JDg42HTp0MG+++abT/qKiIjN+/HjTpEkTExwcbAYNGmR27Njh1Ofw4cNm5MiRpl69eiY0NNQkJiaanJwcpz4bNmwwF154oQkODjYtWrQwzz77bKlYPvzwQ9OuXTsTFBRkOnbsaL7++mv3J/xfNmOMqZlzOgAAAO7nU/e8AAAA30fxAgAALIXiBQAAWArFCwAAsBSKFwAAYCkULwAAwFIoXgAAgKVQvADwS0lJSbLZbEpOTvZYDHl5eWrRooXTwwOtYseOHQoICNBrr73m6VDghyhegHKkpqbqzjvv1LnnnqvQ0FAFBQWpadOmGjJkiF588UVlZGSUeo3NZnP6qVOnjpo2baoLL7xQjzzyiDZs2FDme+3du7fUa4OCgtSqVSuNGjVKGzdurOl0/V7xGNx8881n5f2ef/55ZWZm6v/+7/+c2mNiYmSz2cp97Zn67N+/X3fffbfatm2r2rVrq169eoqNjdWll16qadOmKTc316m/q9/X9u3ba+TIkZo0aZJycnKqmDlQPaywC5ShqKhIjz32mF588UXZ7XYlJCSoc+fOqlu3rtLT0/XTTz9py5Ytqlu3rnbs2KEWLVo4Xmuz2RQeHq5x48ZJkgoKCpSZman169crJSVFknTLLbfotddeU3BwsON1e/fuVWxsrNq0aaMbb7xR0p8PmVu5cqVWrFih4OBgLV68WH369DmLn4TvyszMVGZmpqKiohQSEiLpf2MwZswYzZ49u0bfPzs7Wy1atNBVV12luXPnOu2LiYnRvn37VN5fz2X12bBhg/r3769jx46pT58+Ov/881WvXj3t379fP/zwg/bv36+dO3cqLi7O8RpXv6+StGnTJnXu3FlTpkzR3//+92p/JkCl1diDBwALe+KJJ4wkc/7555udO3eW2Wft2rVm8ODBpfZLMu3bty/zNZs2bTJdu3Y1ksyNN97otG/Pnj1Gkhk6dGip1/397383kky/fv1cSwiVUjwGY8aMqfH3euWVV4wks3DhwlL7oqOjTUV/PZfVZ+DAgUaSmTt3bpmv+fHHH83Ro0ed2lz9vhbr3LmziY6ONoWFheXGC7gTxQtQwo4dO4zdbjeRkZGOJ/OWp+QD3Mr7ZWCMMenp6SYyMtJIMqtWrXK0l1e8HDp0yEgyISEhFcYza9YsxwNJP/vsM9OzZ0/HA+cSExPP+JTbtLQ0M3bsWNOqVSsTFBRkmjZtasaMGWP27t1bqm9xIfXLL7+Y0aNHmyZNmhibzWaWLFlSYXz5+flm+vTppkePHqZevXqmbt265pxzzjEPPvigOXLkiKPf999/bxITE027du1M3bp1Td26dU337t2dnmRbVkwHDhww119/vQkPDzd16tQxF1xwQZkFwsSJE40kR8zFn1tZP8V9Dh48aCZMmGB69+5tIiMjTVBQkImOjjZ33XWX+f333yvM/XTdu3c3jRo1KvOXvqvFS506dUxYWFiV4nD1+1psypQpRpJZtGhRld4XqA7ueQFKmDNnjgoLC3XHHXcoMjKywv4BAQFVOn5kZKTuvPNOSdIHH3xQpddWdB/E6T755BONGDFCcXFxeuCBB9SpUyfNmjVLF154oY4ePerUd9WqVerWrZvmzJmj7t276/7771ffvn313nvvqVevXkpLSyt1/MOHDys+Pl4bN27U9ddfr9tvv12hoaHlxnTixAkNHDhQDz30kLKyspSYmKi77rpL7dq108yZM7Vv3z5H32nTpmnZsmXq2bOnxo0bpxtvvFGZmZm644479PDDD5d5/KNHj6pPnz7auXOnbr31Vo0cOVIbNmzQxRdfrM8++6zc2Lp27ar7779fktSlSxdNnDjR8RMTEyNJWrZsmV588UU1adJEI0eO1L333qs2bdro9ddfV3x8vLKyssp9j9PjXL9+vXr16qVatdz313B4eLiOHz+uX3/91W3HrOj7Gh8fL0lavHix294TqJCnqyfA2wwYMMBIMosXL3bp9argX7LGGLN48WIjyfTt29fRVt6ZlwkTJhhJZsCAARW+/+lnEL799lunfcWXw8aNG+doO3nypImJiTH169c369atc+r/ww8/GLvdbi677LJSOUoyiYmJ5tSpUxXGVOzhhx82kszo0aNLve7YsWMmJyfHsZ2Wllbq9QUFBWbIkCHGbrebffv2lRnTqFGjTFFRkaN9w4YNJigoyERGRpq8vDxHe8kzL8ZUfNno999/d4qx2Jw5c4wkM2XKlHLzL/b1118bSebvf/97mftdPfPy0EMPGUkmNjbWTJs2zfz4448mNze33OO4+n0tlpWVZSSZhISEco8BuBPFC1DCOeecYySZbdu2ldq3ZMkSM3HiRKefkpdKKvPLYNu2bUaSOeeccxxtxb8427Rp4zj2I488Yvr27Wskmdq1a5sff/yxwviLi5fBgweX2peTk2PCwsJMaGio43LFp59+aiSZyZMnl3m8v/71r6ZWrVomKyvLKcegoCCTkZFRYTzFCgoKTP369U2DBg2cLg9V1SeffGIkmdmzZzu1SzJ2u73My1xjx441kszHH3/saHOleDmToqIiExoaavr371+p/jNnzjSSzD/+8Y8y97tavJw4ccLcfPPNplatWo5izm63m/PPP9889dRTpe53Mcb17+vpateubVq3bl3uMQB3qtr5bsDPJScna9KkSaXa+/fv77b32L17t+M9AgMD1aRJE40aNUpPPPGEOnXqVOnj9O3bt1RbvXr11LVrVyUnJystLU1xcXFauXKlpD/X7UhKSir1mkOHDqmoqEg///yzevTo4WiPjY1VREREpePZvn27cnJyNHjwYDVs2LDC/jk5OXrhhRf02Wefaffu3aWm+JZ1aSQqKkrR0dGl2vv27at//vOfWr9+va6++upKx1yWTz/9VDNnztS6det09OhRFRYWlhtTWQ4fPixJCgsLq1YsJdWuXVuzZs3SU089pQULFmj16tVavXq11q1bp3Xr1mnmzJlaunSpWrdu7db3bdSokTIzM916TKA8FC9ACU2aNNG2bdv066+/qkOHDk77kpKSHL/g58+fr5EjR7r0HsW/5Mq6p2bo0KH69ttvXTru6Zo0aVJue/H9GUeOHJEkvffee+Uer2TxcKbjn0nx+50+rfxMTp48qf79+2vdunXq1q2bRo8erfDwcAUEBGjv3r2aM2eO8vPzS72usjm76sUXX9QjjzyiyMhIXXTRRWrZsqXq1KkjSXrppZfKjKksxa/5448/ytxffB9MUVHRGe+JKSoqOuM9UC1bttTtt9/uWPxu9+7duuWWW7Rs2TI9+OCD+vzzzysVZ7Hyvq/Sn/cyFU83B84GiheghAsuuEDJyclasmSJBg4cWCPvUbyqa8+ePWvk+JL0+++/l9veoEEDSXLcZPvll1/qsssuq/Txq3LzsPS/swwHDx6ssO/nn3+udevWaezYsXr77bed9s2fP19z5swp83WVzdkVp06d0lNPPaVmzZopNTVVjRs3duwzxui5556r9LGKi4DiwrGk4jgPHz5cZsFgjNGRI0cqnU+bNm00e/ZstW7dWt9//32l4yxW3ve1qKhIWVlZ6tixY5WPC7iK2UZACWPGjFGtWrX05ptv1sip8IyMDM2cOVOSdP3117v9+MV++OGHUm3Hjx9XamqqQkNDHZcOevfuLUn66aefaiwW6c8VWUNDQ5WSklJqtlNJu3fvliQNHz681L6y8iq2f/9+pxlLJV/TrVu3ct/XbrdLktOloGKZmZnKyspSfHy8U+EiSWvWrNGJEyfKPfbpii//7dixo9z9ZxqTjRs3Kjc3V507d670e9arV6/SfU9X0fd1586dKioqqtIlTaC6KF6AEtq1a6fHHntM6enpGjZsmHbt2lVmv2PHjlX52Fu2bNFFF12k9PR0jRkzxukeEndbtGiRvvvuO6e2qVOn6tixY7rpppsclyOGDx+uqKgoTZ8+XcuWLSt1nIKCAi1fvrza8QQEBOiOO+5QVlaW7r///lIFQlZWlo4fPy5JjvtWSr7v0qVL9dZbb53xPQoLC/Xkk086rTq7ceNGvfvuu4qMjNQll1xSbowNGzaUzWbTgQMHSu1r3Lix6tSpo3Xr1ikvL8/RfvToUd17773lHrekTp06qVGjRlq1alWZ+8eMGSNJmjBhQqnvWX5+vh577DFJ0k033eS0b/LkyWXGbozRs88+K0m68MILKx1nZb6vxTn069ev0scFqovLRkAZpk6dqpMnT2r69Onq0KGDEhIS1KVLF4WEhCg9PV0bN27U6tWrHTfAlpSZmem4N+bUqVM6fPiw1q1bp9WrV0uSbr31Vr366qs1msNll12myy+/XNdcc41iYmK0cuVKLVmyRG3atNHkyZMd/YKDg/Xxxx9r2LBh6tevnwYOHKhOnTrJZrNp3759+uGHHxQeHq7t27dXO6bJkydr5cqVevfdd7Vy5UoNGzZMwcHBSktL07fffqvly5era9euuvzyyxUTE6PnnntOmzdv1nnnnacdO3boq6++0lVXXaWPP/64zON37txZy5cvV8+ePTV48GBlZGTogw8+0KlTp/Tmm2867jU5k3r16qlnz55atmyZRo8erbZt26pWrVoaPXq0oqOjdffdd+vFF19Uly5ddPnllys7O1vffPONoqOj1bx580p/DjabTcOHD9fs2bP1yy+/qGXLlk77Bw0apPvvv18vv/yy2rVrpyuuuEJNmzbV4cOHtWDBAu3fv19XXXWVEhMTnV43ffp0JSUlqUePHurevbsaNWqkw4cPa8mSJfr5558VHh6uF198sVQ81fm+Lly4UAEBAVW65AhUm2cnOwHebd26deb22283HTp0MPXq1TOBgYGmSZMmZuDAgeb5558vc1VVlVidNTg42DRu3Nj06dPHPPLII2bDhg1lvld567xUxZlW2A0PDzc333yz+e2338p83S+//GLuv/9+07ZtWxMcHGxCQ0PNOeecY2699dZSa96oGo8q+OOPP8wLL7xgunbtaurUqWPq1atnzj33XPPwww87TeVNS0szV199tYmMjDQhISGmZ8+eZv78+WbJkiVGkpk4cWKZMR04cMBcd911plGjRqZ27domPj7e/Oc//ykVR1lTpY35c4XlSy65xISFhRmbzebU5+TJk2bq1KmOzygqKso8/PDDJicnx0RHR5vo6OhKfw6rVq0yksy0adPO2OeTTz4xQ4cONRERESYgIMCEhYWZhIQE8/bbb5e5Mu+yZcvME088YeLj403z5s1NYGCgqVevnuncubN55JFHzK+//lrqNa5+X40xJjc319SrV89ceeWVlc4bcAcezAj4mNmzZysxMVGzZs06a09H9gY2m039+vVz3FxqBX379lVGRoa2bt3q1pV2z5a3335bt912m5YuXaqEhARPhwM/Yr0/LQDgI55//nnt2LFD8+fP93QoVXbq1Ck9/fTTuuKKKyhccNZxzwsAeMhf/vIXzZw5s8zZTd5u//79uummmzR69GhPhwI/RPECAB5UvJCc1bRu3brMFZmBs4F7XgAAgKVwzwsAALAUihcAAGApFC8AAMBSKF4AAIClULwAAABLoXgBAACWQvECAAAsheIFAABYCsULAACwlP8P7S9ItBkYeAoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.54249547]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd                     # pip3 install pygwalker\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 데이터를 다운로드하고 준비합니다\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values\n",
    "\n",
    "# 데이터를 그래프로 나타냅니다\n",
    "lifesat.plot(kind='scatter', grid=True,\n",
    "             x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()\n",
    "\n",
    "#  선형 모델를 선택합니다\n",
    "model = LinearRegression()\n",
    "\n",
    "# 모델을 훈련합니다\n",
    "model.fit(X, y)\n",
    "\n",
    "# 키프로스에 대해 예측을 만듭니다\n",
    "#X_new = [[37_655.2]]  # 2020년 키프로스 1인당 GDP\n",
    "X_new = [[26_456.3]]  # 2020년 Russia 1인당 GDP\n",
    "print(model.predict(X_new)) # 출력 [[6.30165767]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것이 전형적인 머시러닝 프로젝트의 형태입니다. 2장에서 완전한 프로젝ㅌ를 진행하면서 직접 경험해 보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 머신러닝의 주요 도전 과제\n",
    "\n",
    "모델을 선택해서 어떤 데이터에 훈련시키는 것이 주요 작업이기 때문에 문제가 될 수 있는 것은 **\"나쁜 모델\"**과 **\"나쁜 데이터\"** 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 1 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "어린아이에게 사과에 대해 알려주려면 사과를 가리키면서 \"사과\"라고 말하시만 하면 됩니다. (아마도 여러번 반복...) \n",
    "\n",
    "그러면 아이는 색상과 모양이 달라도 모든 종류의 사과를 구분할 수 있습니다. \n",
    "\n",
    "머신러닝은 아직 이렇게까지는 못합니다. 대부분의 머신러닝 알고리즘이 잘 동작하려면 데이터가 많아야 합니다. \n",
    "\n",
    "아주 간단한 문제에서도 수천 개의 데이터가 필요하고 이미지나 음석 인식 같은 복잡한 문제라면 수백만 개가 필요힐지도 모릅니다.\n",
    "\n",
    "<img src=\"./img/pic1-21.png\" width=\"60%\"></img>\n",
    "\n",
    "- 믿기 힘든 데이터의 효과 \n",
    "\n",
    "    - MS연구자인 미셸 반코와 에익 브릴은 2001년 발표한 논문에서 충분한 데이터가 주어지면 \n",
    "    \n",
    "        책  : 아주 간단한 모델을 포함하여 여러 다른 머신러닝 알고리즘이 복잡한 자연어 중의성해소 문제를 거의 비슷하게 잘 처리한다는 사실을 보여줬습니다. \n",
    "        \n",
    "        변경 : 아주 간단한 다양한 여러 모델을 포함한 머신러닝 알고리즘이 복잡한 자연어 중의성 해소 문제를 거의 비슷하게 잘 처리한다는 사실을 보여줬습니다. \n",
    "\n",
    "### 1.5.2 대표성이 없는 훈련 데이터\n",
    "\n",
    "일반화가 잘되려면 훈련 데이터가 일반화하고 싶은 새로운 사례를 잘 대표하는 것이 중요합니다. \n",
    "\n",
    "예를 들어, \n",
    "\n",
    "앞서 선형 모델을 훈련시키기 위해 사용한 국가 데이터는 1인당 GDP가 $23,500 보다 적거나 $62,500 보다 많은 나라가 빠져있어 대표성이 완벽하지 않습니다. \n",
    "\n",
    "[그림 1-22]는 누락된 나라를 추가했을 때 데이터가 어떻게 나타나는지 보여줍니다.\n",
    "\n",
    "<img src=\"./img/pic1-22.png\" width=\"60%\"></img>\n",
    "\n",
    "    - 이 데이터에 선형 모델을 훈련시키면 실선으로 된 모델을 얻습니다. 반면 이전 모델은 점선으로 나타나 있습니다. \n",
    "\n",
    "    - 누락된 나라를 추가하면 모델이 크게 변경되며 이런 간단한 선형 모델은 잘 동작하지 않는다는 걸 보여줍니다. \n",
    "\n",
    "    - 메우 부유한 나라가 중간정도 나라보다 행복하지 않고(실제로도...) 반대로 일부 가난한 나라가 더 행복한 것 같습니다. \n",
    "\n",
    "실반화하려면 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요하지만 이게 생각보다 어려울 때가 많습니다. \n",
    "\n",
    "- **샘플링 잡읍** (sampling noise) : 샘플이 작을때 생김.\n",
    "\n",
    "- **샘플링 편향** (sampling bias) : 매우 큰샘플도 표본 추출방법이 잘못되면 대표성을 띠지 못할 수 있다는 의미.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 낮은 품질의 데이터\n",
    "\n",
    "훈련 데이터가 오류, 이상치, (성능이 낮은 측정 장치로 인한) 잡음으로 가득하다면 머신러닝 시스템이 내재된 패턴을 찾기 어려워 제대로 작동하지 않을 것입니다.\n",
    "\n",
    "그렇기 때문에 훈련 데이터 정제에 시간을 투자할 만한 가치는 충분합니다. \n",
    "\n",
    "- 훈련 데이터 정제가 필요한 경우\n",
    "\n",
    "    1. 일부 샘플이 이상치라는게 명확하다면 간단히 ㅅ해당 샢플들을 무시 또는 수동으로 고치는 것이 좋습니다. \n",
    "\n",
    "    2. 일부 샘플에 특성 몇개가 빠져있다면 이 특성을 모두 무시할지, 샘플을 무시할지, 빠진 값을 채울지,\n",
    "\n",
    "        또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 결정해야 한다. \n",
    "\n",
    "### 1.5.4 관련없는 특성\n",
    "\n",
    "- 엉터리가 들어가면 엉터리가 나옵니다. (gabage in, gabage out).\n",
    "\n",
    "- **특성 공학** (feature engineering) : 훈련에 사용할 좋은 특성들을 찾는 과정을 의미합니다.\n",
    "\n",
    "> - 특성 선택 (selection) : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택\n",
    ">\n",
    "> - 특성 추출 (extraction) : 특성을 결합하여 더 유용한 특성을 만듭ㄴ다. 앞서 본것 처럼 차원 축소 알고리즘이 도움이 될 수 있습니다. \n",
    ">\n",
    "> - 데이터 수집 : 새로운 데이터를 수집해 새 특성을 만듭니다. \n",
    "\n",
    "### 1.5.5 훈련 데이터 과대적함\n",
    "\n",
    "해외 여행 중에 택시 운전사가 여러분의 물건을 훔쳤다면 여러분은 그 나라의 모든 택시 운전사를 도둑이라고 생각할 수 있습니다. \n",
    "\n",
    "사람은 종종 과도하게 일반화를 하지만 주의하지 않으면 기계도 똑같은 함정에 빠질 수 있습니다. 머신러닝에서 이를 **과대적합** (overfitting)이라고 합니다.\n",
    "\n",
    "[그림 1-23]은 고차원의 다항 회귀 모델이 삶의 만족도 훈련 데이터에 크게 과대적합된 사례를 보여줍니다. \n",
    "\n",
    "    - 간단한 선형 모델보다 이 모델이 훈련 데이터에 더 잘 맞는다 하더라도 실제로 이 예측을 믿기는 힘듭니다. \n",
    "\n",
    "<img src=\"./img/pic1-23.png\" width=\"60%\"></img>\n",
    "\n",
    "- 훈련 세트에 잡음이 많거나 데이터셋이 너무 작으면 (택시 운전사의 예처럼) 샘플링 잡음이 발생하므로 잡음이 섞인 패턴을 감지하게 됩니다. \n",
    "\n",
    "- 예를 들어 삶의 만족도 모델에 나라 이름 같은 관련없는 특성을 많이 추가한다고 가정해 봅시다. \n",
    "\n",
    "    이 경우 복잡한 모델이 이름에 w가 들어간 나라들의 삶의 만족도가 7보다 크다는 패턴을 감지할지 모릅니다. 뉴질랜드(7.6), 노르웨이(7.3), 스웨덴(7.2), 스위스(7.5)가 \n",
    "\n",
    "    여기에 속합니다. 이 w-만족도 규칙을 르완다나 짐바브웨에 일반화 한다면 얼마나 신뢰할 수 있을까요? \n",
    "\n",
    "    확실히 이 패턴은 우연히 훈련 데이터에서 찾은 것이지만 이 패턴이 진짜인지 잡음 데이터로 인한 것인지 모델이 구분해낼 방법은 없습니다. \n",
    "\n",
    "> **(CAUTION)** 과대 적합은 훈련 데이터의 양과 잡음에 비해 모델이 너무 복잡할 때 일어납니다. 해결방법은 다음과 같습니다.\n",
    ">\n",
    ">   1. 파라미터 수가 적은 모델을 선택하거나(예, 고차원 다항 모델보다 선형 모델), 훈련 데이터에 있는 특성 수를 줄이거나 모델에 제약을 가하여 단순화 시킵니다.\n",
    ">\n",
    ">    2. 훈련 데이터를 더 많이 모읍니다.\n",
    ">\n",
    ">    3. 훈련 데이터의 잡음을 줄입니다. (예, 오류 데이터 수정과 이상치 제거)\n",
    "\n",
    "- **규제** (regularization) : 모델을 댠순하게 하고 과대적합의 위험을 줄이기 위해 모델을 제약을 가하는 것.\n",
    "\n",
    "    - 예를 들어 앞서 만든 선형 모델은 두 개의 모델 파라미터 θ0과 θ1을 가지고 있습니다. \n",
    "    \n",
    "        이는 훈련 데이터에 모델을 맞추가 위한 두 개의 **자유도** (dgree of freedom)를 학습 알고리즘에 부여합니다. \n",
    "        \n",
    "        모델은 직선의 절편(θ0)과 기울기(θ1)를 조절할 수 있습니다. 우리가 θ1=0이 되도록 강제하면 알고리즘에 한 개의 자유도만 남게 되고 데이터에 적절하게 맞춰지기 힘들겁니다.\n",
    "\n",
    "        즉, 할 수 있는 것이 훈련 데이터에 가능한 한 가깝게 되도록 직선ㅇ르 올리거나 내리는 것이 전부이므로 결국 평균 근처가 됩니다. \n",
    "\n",
    "        알고리즘이 θ1을 수정하도록 허락하되 작은 값을 갖도록 유지시키면 합습 알고리즘이 자유도 1과 2사이의 적절한 어딘가에 위치할 것입니다.\n",
    "\n",
    "        이는 자유도 2인 모델보다는 단순하고 자유도 1인 모델보다는 복잡한 모델을 만듭니다. 데이터에 완벽히 맞추는 것과일반화를 위해 단순한 모델을 유지하는 것 사이의 올바른 균형을 찾는 것이 좋습니다.\n",
    "\n",
    "    - [그림 1-24]에 세가지 모델이 있습니다. 점선은 (사각형으로 표시된 나라를 제외하고) 동그라미로 표시된나라로 훈련한 원래 모델입니다. \n",
    "\n",
    "        파선은 모든 나라(동그라미와 사각형)를 포함해 훈련한 두 번째 모델이며 실선은 첫 번째 모델과 같은 데이터에 규제를 적용해 만든 선형 모델입니다. \n",
    "\n",
    "        규제가 모델의 기울기를 더 작에 만들었습니다. 이 모델은 훈련 데이터(동그라미)에는 덜 맞지만 훈련하는 동안 못 본 새로운 샘플(사각형)에는 더 잘 일반화됩니다. \n",
    "\n",
    "    <img src=\"./img/pic1-24.png\" width=\"50%\"></img>\n",
    "\n",
    "- 학습하는 동안 적용할 규제의 양은 **하이퍼파라미터** (hyperparameter)가 결정합니다. (모델이 아니라) 학습 알고리즘의 파라미터입니다.\n",
    "\n",
    "    학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있습니다.\n",
    "\n",
    "    규제 하이퍼파라미터를 매우 큰 값으로 지정하면 (기울기가 0에 가까운) 거의 평편한 모델을 얻게 됩니다.\n",
    "\n",
    "    그러면 학습 알고리즘이 훈련 데이터에 과대적합될 가능성은 거의 없겠지만 좋은 모델을 찾지 못합니다. 머신러닝에서 하이퍼파라미터 튜닝은 매우 중요한 과정입니다. 다음장에서 자세한 예를 보겠습니다.\n",
    "\n",
    "### 1.5.6 훈련 데이터 과소적합\n",
    "\n",
    "**과소적합** (nderfitting) : 과대적합의 반대이며, 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어납니다.\n",
    "\n",
    "- 예를 들어, 삶의 만족도에 대한 선행 모델은 과소적합되기 쉽습니다. 현실은 이 모델보다 더 복잡하므로 훈련 샘플에서조차도 부정확한 예측을 만들 것입니다.\n",
    "\n",
    "- 해결 방법\n",
    "\n",
    "    1. 모델 파리미터가 더 많은 강력한 모델을 선택\n",
    "\n",
    "    2. 학습 알고리즘에 더 좋은 특성을 제공 (특성 공학)\n",
    "    \n",
    "    3. 모델의 제약을 줄입니다. (규제 하이퍼파라미터를 감소)\n",
    "\n",
    "### 1.5.7 핵심 요약\n",
    "\n",
    "> 1. 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것입니다.\n",
    ">\n",
    "> 2. 여러 종류의 머신러닝 시스템이 있습니다. 지도-비지도 학습, 배치-온라인 학습, 사례 기반-모델 기반 학습\n",
    ">\n",
    "> 3. 학습 알고리즘이 모델기반이면 훈련 세트에 모델을 맞추가 위해 모델 파라미터를 조정하고(즉, 훈련 세트에서 좋은 예측을 만들기 위해)\n",
    ">\n",
    ">       새로운 데이터에서도 좋은 예측을 만들거라 기대합니다. \n",
    ">\n",
    ">       알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 유사도 측정을 사용하려 학습한 샘플과 새로운 샘플을 비교하는 식으로 새로운 샘플을 일반화 합니다. \n",
    ">\n",
    "> 4. 훈련 세트가 너무 작거나, 대표성이 없거나, 잡음이 많고 관련없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않습니다. (엉터리가 들어가면 엉터리가 나옵니다.)\n",
    ">\n",
    ">       마지막으로 모델이 너무 단순하거나 (과소적합된 경우) 너무 복잡하지 않아야 합니다.(과대적합된 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 테스트와 검증\n",
    "\n",
    "모델이 새로운 샘플에 얼마나 잘 일반화될지 알 수 있는 유일한 방법은 새로운 샘플에 실제로 적용해 보는 것입니다. 실제 서비스에 모델을 넣고 잘 작동하는지 모니터링하는 방법이 있습니다. \n",
    "\n",
    "이 방법이 괜찮긴 하지만 만약 모델이 아주 나쁘다면 고객이 불만을 토로할 테니 좋은 생각은 아닙니다. \n",
    "\n",
    "더 나은 방법은 훈련 데이터를 **훈련 세트**와 **테스트 세트** 두 개로 나누는 것입니다. \n",
    "\n",
    "새로운 샘플에 대한 오차 비율을 **일반화 오차** (generalization eorror)(또는 **외부 샘플 오차** (out-of-sample error))라고 하며\n",
    "\n",
    "테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값(estimation)을 얻습니다.\n",
    "\n",
    "- 이 값은 이전에 본 적이 없는 새로운 샘플에 모델이 얼마나 잘 작동할지 알려줍니다.\n",
    "\n",
    "훈련 오차가 작지만(즉, 훈련 세트에서 모델의 오차가 작음) 일반화 오차가 크다면 이는 모델이 훈련 데이터에 과대적합되었다는 뜻입니다.\n",
    "\n",
    "- (팁) 보통 데이터의 80%를 훈련에 사용하고 20%는 테스트용으로 떼어놓습니다. \n",
    "\n",
    "    하지만 이는 데이터셋 크기에 따라 다릅니다. 샘플이 천만 개일 때 1%를 떼어놓는다고 하면 테스트 셋트에 10만개의 샘플이 있다는 의미입니다. \n",
    "        \n",
    "    아마도 일반화 오차를 추정하는 데 충분한 크기일 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1 하이퍼파라미터 튜닝과 모델 선택\n",
    "\n",
    "선형 모델이 더 잘 일반화 되었다고 가정하고 과대적합을 피하기 위해 규제를 적용하려고 합니다. 이때 하이퍼파라미터 값을 어떻게 선택할까요?\n",
    "\n",
    "100개의 하이퍼파라미터 값으로 100개의 다른 모델을 훈련시키는 방법이 있습니다. 일반화 오차가 가장 낮은 모델(5%라고 합시다)을 만드는 최적의 하이퍼파라미터를 찾았다고 가정합시다. \n",
    "\n",
    "이제 이 모델을 실제 서비스에 투입합니다. 하지만 성능이 예상만큼 좋지 않고 오차가 15%나 됩니다. 왜 그럴까요?\n",
    "\n",
    "- 일반화 오차를 테스트 세트에 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들었기 때문입니다. 이는 모델이 새로운 데이터에 잘 작동하지 않을 수 있다는 뜻입니다.\n",
    "\n",
    "이 문제에 대한 일반적인 해결 방법은 **홀드아웃 검증** (holdout validation)입니다. (그림 1-25)\n",
    "\n",
    "- 간단하게 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택합니다. \n",
    "\n",
    "    이 새로운 홀드아웃 세트를 **검증 세트** (validation set)라고 부릅니다. (이따금 **개발 세트** (development set) 또는 **데브 세트** (dev set)라고도 합니다.)\n",
    "\n",
    "구체적으로 훈련 세트(즉, 전체 훈련 세트에서 검증 세트를 뺀 데티어)에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련합니다.\n",
    "\n",
    "그다음 검증 세트에서 가장 높은 성능을 내는 모델을 선택합니다. 홀드아웃 검증 과정이 끝나면 최선의 모델을 (검증 세트를 포함한) 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만듭니다. \n",
    "\n",
    "마지막으로 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정합니다. \n",
    "\n",
    "<img src=\"./img/pic1-25.png\" width=\"50%\"></img>\n",
    "\n",
    "- 이 방법은 일반적으로 잘 작동합니다. 하지만 검증 세트가 너무 작으면 모델이 정확하게 평가되지 않을 것입니다. 따라서 최적이 아닌 모델을 잘못 선택할 수 있습니다. \n",
    "\n",
    "    반대로 검증 세트가 너무 크면 남은 훈련 세트가 전체 훈련 세트보다 훨씬 작아집니다. 이것은 왜 문제가 될까요? \n",
    "\n",
    "    최종 모델이 전체 훈련 세트에서 훈련되기 때문에 너무 작은 훈련 세트에서 훈련한 후보 모델을 비교하는 것은 이상적이 않습니다. \n",
    "\n",
    "    - 이 문제를 해결하는 한가지 방법은 작은 검증 세트를 여러 개를 사용해 반복적인 **교차 검증** (cross-validation)을 수행하는 것입니다. \n",
    "\n",
    "        검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가합니다. 모든 모델의 평가를 평균하면 훨씬 정확한 성능을 측정할 수 있습니다. \n",
    "\n",
    "        하지만 단점도 있습니다. 훈련 시간이 검증 세트의 개수에 비례해 늘어납니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 데이터 불일치\n",
    "\n",
    "어떤 경우에는 쉽게 많은 양의 훈련 데이터를 얻을 수 있지만 이 데이터가 실제 제품에 사용할 데이터를 완벽하게 대표하지 못할 수 있습니다. \n",
    "\n",
    "예를 들어, 꽃 사진에서 꽃 이름을 자동으로 찾아주는 앱을 만든다고 하면, 웹에서 수백만 개의 꽃을 쉽게 다운로드할 수 있지만 실제 찍은 사진을 완벽하게 대신하지 못합니다. \n",
    "\n",
    "이 경우 가장 중요한 규익을 검증세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 한 잘 대표해야 한다는 것입니다. \n",
    "\n",
    "따라서, 검증 세트와 테스트 세트는 대표성을 가진 사진으로만 구성되어야 합니다. \n",
    "\n",
    "- 만약 웹에서 다운로드한 사진에 모델을 훈련한 다음, 검증 세트에서 모델의 성능을 측정했더니 결과가 매우 실망스럽다고 가정해 보죠. 이 경우 과대적합 때문인지 데이터가 불일치하기 때문인지 알기 어렵습니다. \n",
    "\n",
    "- 한 가지 해결책은 (웹에서 다운로드한) 훈련 사진의 일부를 떼어내 또 다른 세트를 만드는 것입니다. 앤드루 응은 이를 **훈련-개발 세트** (train-dev set)이라고 부릅니다. (그림 1-26)\n",
    "\n",
    "- 모델을 (훈련-개발 세트가 아니라 훈련세트에서) 훈련한 다음 훈련-개발 세트에서 평가합니다. 모델이 잘 작동하지 않으면 훈련 세트에 과대적합된 것입니다.\n",
    "    \n",
    "    따라서 모델을 규제하거나, 더 많은 훈련 데이터를 모으거나, 훈련 데이터 정제를 시도해봐야 합니다. 하지만 잘 작동한다면 검증 세트에서 평가할 수 있습니다. \n",
    "    \n",
    "    만약 성능이 나쁘다면 이 문제는 데이터 불일치에서 오는 것입니다. 웹 이미지를 모바일 앱에서 찍은 사진처럼 보이도록 전처리한 다음 이 모델을 다시 훈련하여 해결할 수 있습니다.\n",
    "\n",
    "    훈련-개발 세트와 검증 세트에서 모두 잘 작동하는 모델을 얻은 다음 마지막으로 테스트 세트에서 평가하여 제품에 사용될 때 얼마나 작동할지 알 수 있습니다. \n",
    "\n",
    "    <img src=\"./img/pic1-26.png\" width=\"50%\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
