{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd55897-c773-4b6e-9ef8-eba28b9f9557",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ch3.Retrieval\n",
    "+ 1. 미지의 데이터를 처리하려면\n",
    "+ 2. 주어진 PDF를 기반으로 답변하는 챗봇만들기\n",
    "+ 3. RetrivalQA\n",
    "+ 4. 준비된 Retrievals를 사용하여 위키백과를 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072b467-5272-497f-9482-a6fb5e20697b",
   "metadata": {},
   "source": [
    "## 1.미지의 데이터를 처리하려면\n",
    "> Retrieval은 모델이 학습하지 않은 개념도 제공하며, 정보처리를 지원하는 모듈\n",
    "- 공개되지 않은 기업의 내용은 chatgpt등 학습 못했기에 답변 어려움 \n",
    "    - RAG(Retriever-Augmented Generation)을 구축, 활용하여 답변 가능해짐\n",
    "- RAG는 어떻게 작동하나?\n",
    "    1. 받은 질문에 관련하여, DATA에서 필요한 문장 찾기\n",
    "    2. 질문과 찾은 문장 조합하여 프롬프트 생성\n",
    "    3. 생성된 프롬프트를 언어모델에 전달\n",
    "- 받은 질문 벡터화 → (미리 벡터화된 )Data에서 유사도 높은 문장 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d466ac9-051d-4943-8893-74cba96c87a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[벡터화된 질문]\n",
      "- 임베딩개수:1536개\n",
      "- 상위5개:[-0.011089965681877331, -0.015286693322979184, 0.014691780295829944, -0.0299784745501317, -0.025658883109909277]\n",
      "문서 1과 질문의 유사도: 0.933\n",
      "문서 2와 질문의 유사도: 0.734\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "OpenAIEmbeddings을 활용하여, 질문과 답변을 임베딩하고, 연관성을 확인해보자\n",
    "'''\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings  #← OpenAIEmbeddings를 가져오기\n",
    "from numpy import dot  #← 벡터의 유사도를 계산하기 위해 dot을 가져오기\n",
    "from numpy.linalg import norm  #← 벡터의 유사도를 계산하기 위해 norm을 가져오기\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings( #← OpenAIEmbeddings를 초기화\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "question = \"비행 자동차의 최고 속도는?\"\n",
    "doc1 = \"비행 자동차의 최고 속도는 시속 150km입니다.\"\n",
    "doc2 = \"닭고기를 적당히 양념한 후 중불로 굽다가 가끔 뒤집어 주면서 겉은 고소하고 속은 부드럽게 익힌다.\"\n",
    "\n",
    "query_vector = embeddings.embed_query(question) #← 질문을 벡터화\n",
    "\n",
    "print(f\"[벡터화된 질문]\\n- 임베딩개수:{len(query_vector)}개\\n- 상위5개:{query_vector[:5]}\") #← 벡터의 일부를 표시\n",
    "\n",
    "document_1_vector = embeddings.embed_query(doc1) #← 문서 1의 벡터를 얻음\n",
    "document_2_vector = embeddings.embed_query(doc2) #← 문서 2의 벡터를 얻음\n",
    "\n",
    "cos_sim_1 = dot(query_vector, document_1_vector) / (norm(query_vector) * norm(document_1_vector)) #← 벡터의 유사도를 계산\n",
    "print(f\"문서 1과 질문의 유사도: {cos_sim_1:.3f}\")\n",
    "cos_sim_2 = dot(query_vector, document_2_vector) / (norm(query_vector) * norm(document_2_vector)) #← 벡터의 유사도를 계산\n",
    "print(f\"문서 2와 질문의 유사도: {cos_sim_2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d2c30-7e01-4607-96b5-2b210fd0b2ae",
   "metadata": {},
   "source": [
    "> 문서1의 유사도가 문서2보다 높으므로, 더 유사한 답변"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653f845-ada8-4c0f-a710-ab369c3e322c",
   "metadata": {},
   "source": [
    "- 벡터유사도 검색에서 RAG를 통합하는 구체적 절차\n",
    "유저의 질문이 전송되었을 때, 원활하게 활용할 수 있는 RAG를 구성하려면 다음의 조건을 확인해야 한다.\n",
    "1. 문서를 불러와서 (langchain.document_loaders)\n",
    "    - PyMuPDFLoader, WebBaseLoader, csv_loader,...\n",
    "2. 문서의 문장 구조를 적절히 분할 (langchain.text_splitter)\n",
    "    - 어느 위치에서 쪼개서 읽는가에 따라 의미 달라짐. 보통 SpacyTextSplitter로 한국어의 주어, 서술어 등을 분석하여 적절한 위치에서 분할\n",
    "3. 임베딩을 활용하여 문서 및 질문을 벡터화 (langchain.embeddings)\n",
    "    - 위에서 OpenAIEmbeddings같이 문장을 비교하여 담아줄 그릇이 필요\n",
    "4. 저장하였는가 (Vector Stores)\n",
    "    - 그릇에 담은 벡터를 저장하는 DB 필요, Pinecorn, ChromaDB 등 많이씀 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ca02f3-551d-4e08-aecf-9d2fec133c5f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2. PDF기반답변챗봇 만들기\n",
    "> PDF에 포함된 정보를 기반으로 질문에 답하는 챗봇을 만들어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb29910-267f-4ddb-82ec-0d2fa5a1a313",
   "metadata": {},
   "source": [
    "### PDF파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ca7c5f3f-25cc-4059-9698-0848b7cc37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 개수: 12\n",
      "첫 번째 문서의 내용: 하늘을 나는 자동차 관련 \n",
      "법제도\n",
      "주의】이 글은 가상의 비행 자동차를 대상으로 한 법률 자동 생성 예시입니다.\n",
      "\n",
      "첫 번째 문서의 메타데이터: {'source': './asset/sample.pdf', 'file_path': './asset/sample.pdf', 'page': 0, 'total_pages': 12, 'format': 'PDF 1.7', 'title': '하늘을 나는 자동차 관련 법제도', 'author': '', 'subject': '', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'creator': 'Microsoft Office Word', 'producer': 'Aspose.Words for .NET 23.11.0', 'creationDate': 'D:20231207125109Z', 'modDate': \"D:20231211174122+09'00'\", 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"./asset/sample.pdf\") #← sample.pdf 로드\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"문서 개수: {len(documents)}\") #← 문서 개수 확인\n",
    "print(f\"첫 번째 문서의 내용: {documents[0].page_content}\") #← 첫 번째 문서의 내용을 확인\n",
    "print(f\"첫 번째 문서의 메타데이터: {documents[0].metadata}\") #← 첫 번째 문서의 메타데이터를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8487ebd4-a35d-482f-833f-131ad4cec51e",
   "metadata": {},
   "source": [
    "## 과제. 다른 파일도 불러와보세요\n",
    "[한경컨센서스](https://consensus.hankyung.com/) 의 관심있는 보고서를 다운받아서 메타데이터를 확인 합니다. 아래 이어지는 내용도 실행한 데이터 기준으로 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477a2af-ae5a-4388-b41f-698dfeb98efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"PDF파일주소\") #← sample.pdf 로드\n",
    "documents = loader.load()\n",
    "\n",
    "\n",
    "# 첫번째 문서의 내용을 확인\n",
    "# 첫 번째 문서의 메타데이터를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b50a5c-a2bb-498a-a61d-e8ca93b1ec74",
   "metadata": {},
   "source": [
    "> .document_loaders 로 가져오면 위와 같이 메타데이터 형태로 가져옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bdb95-7aaa-473b-bc6e-dd04822df6ca",
   "metadata": {},
   "source": [
    "### text_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3492cd-99b9-4998-b867-6796d8089195",
   "metadata": {},
   "source": [
    "- PDF로 문장을 가져온 경우 RAG기법으로 처리하기에 너무 질어질 수도 있기에 text_splitter로 문맥을 유지하면서 문장을 적절히 분리\n",
    "- spacy는 파이썬으로 개발된 NLP라이브러리로, 문장분할, 품사판단, 명사구 추출, 구분분석 가능\n",
    "- spacy와 연동한 langchain의 SpacyTextSplitter로 적절히 분해하기\n",
    "    + SpacyTextSplitter는 한국어의 주어, 서술어 등을 분석하여 적절한 위치에서 분할 할수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf48b6-322e-4689-bc45-3ec5074b427c",
   "metadata": {},
   "source": [
    "lang310가상환경에서 다음을 시행합니다 (한국어 모델 다운로드)\n",
    "```Powershall\n",
    "python -m spacy download ko_core_news_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2ae5e53-1665-47f0-bcc3-bb241e7a7d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 전 문서 개수: 12\n",
      "분할 후 문서 개수: 70\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import SpacyTextSplitter  #← SpacyTextSplitter를 가져옴\n",
    "\n",
    "loader = PyMuPDFLoader(\"./asset/sample.pdf\") \n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = SpacyTextSplitter(  #← SpacyTextSplitter를 초기화\n",
    "    chunk_size=300,  #← 분할할 크기를 설정\n",
    "    pipeline=\"ko_core_news_sm\"  #← 분할에 사용할 언어 모델을 설정\n",
    ")\n",
    "\n",
    "splitted_documents = text_splitter.split_documents(documents) #← 문서를 분할\n",
    "\n",
    "print(f\"분할 전 문서 개수: {len(documents)}\")\n",
    "print(f\"분할 후 문서 개수: {len(splitted_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ee497-7221-4882-bdfe-a3b876e7cb2e",
   "metadata": {},
   "source": [
    "### Vector화\n",
    "- OpenAI의 임베딩을 이용하려면 tiktoken 설치필요, VectorStore는 chromadb 설치\n",
    "```Powershall\n",
    "pip install tiktoken chromadb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49a85bc7-e763-4ac9-a39f-29a9f4b84934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 20:39:23 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "데이터베이스 생성이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings  #← OpenAIEmbeddings 가져오기\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain.vectorstores import Chroma  #← Chroma 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "loader = PyMuPDFLoader(\"./asset/sample.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = SpacyTextSplitter(\n",
    "    chunk_size=300, \n",
    "    pipeline=\"ko_core_news_sm\"\n",
    ")\n",
    "\n",
    "splitted_documents = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings( #← OpenAIEmbeddings를 초기화\n",
    "    model=\"text-embedding-ada-002\", #← 모델명을 지정\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "database = Chroma(  #← Chroma를 초기화\n",
    "    persist_directory=\"./.tik\",  #← 영속화 데이터 저장 위치 지정\n",
    "    embedding_function=embeddings  #← 벡터화할 모델을 지정\n",
    ")\n",
    "\n",
    "database.add_documents(  #← 문서를 데이터베이스에 추가\n",
    "    splitted_documents,  #← 추가할 문서 지정\n",
    ")\n",
    "\n",
    "print(\"데이터베이스 생성이 완료되었습니다.\") #← 완료 알림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d48545-0607-45a7-a50e-e0a093b63213",
   "metadata": {},
   "source": [
    "> 각 질문과 유사도가 높은 부분을 추출해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fabf1f05-67a2-4f42-b4bb-2baa77302a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 관련문서 : 4개\n",
      "[Document(page_content='제2조(정의)\\n이 법에서 \"비행자동차\"라 함은 지상 및 공중을 이동할 수 있는 능력을 가진 차량을 말한다. \\n\\n\\n제3조(일반적 속도제한)\\n\\n\\n1.\\n도심에서 비행 자동차가 비행하는 경우 최대 속도는 시속 150km로 한다.\\n\\n\\n2.\\n\\n도시 외의 지역에서 비행 자동차가 비행하는 경우 최대 속도는 시속 250km로 한다.\\n\\n\\n3.\\n\\n특정 지역이나 시설 상공 또는 특정 비행 코스에서는 별도의 속도 제한이 설정될 수 있다.\\n\\n\\n제4조 (특례 속도 제한)\\n1.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 3, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''}), Document(page_content='비행 자동차 속도 제한법\\n제1조(목적)\\n이 법은 비행자동차의 비행 안전 및 일반 대중의 이익을 보장하기 위해 비행자동차의 비행 속도에 관한 \\n기준을 규정하는 것을 목적으로 한다.\\n\\n\\n제2조(정의)\\n이 법에서 \"비행자동차\"라 함은 지상 및 공중을 이동할 수 있는 능력을 가진 차량을 말한다. \\n\\n\\n제3조(일반적 속도제한)\\n\\n\\n1.\\n도심에서 비행 자동차가 비행하는 경우 최대 속도는 시속 150km로 한다.\\n\\n\\n2.\\n\\n도시 외의 지역에서 비행 자동차가 비행하는 경우 최대 속도는 시속 250km로 한다.\\n\\n\\n3.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 3, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''}), Document(page_content='제3조(일반적 속도제한)\\n\\n\\n1.\\n도심에서 비행 자동차가 비행하는 경우 최대 속도는 시속 150km로 한다.\\n\\n\\n2.\\n\\n도시 외의 지역에서 비행 자동차가 비행하는 경우 최대 속도는 시속 250km로 한다.\\n\\n\\n3.\\n\\n특정 지역이나 시설 상공 또는 특정 비행 코스에서는 별도의 속도 제한이 설정될 수 있다.\\n\\n\\n제4조 (특례 속도 제한)\\n1.\\n\\n긴급차량, 공공기관 차량 및 관련 공적 임무를 수행하는 차량에 대해서는 제3조의 제한 속도를 초\\n과하여 비행할 수 있도록 허용한다.\\n\\n\\n2.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 3, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''}), Document(page_content='비행 자동차 고도 제한법\\n제1조(목적)\\n이 법은 비행자동차의 비행안전 및 주민의 안전을 확보하기 위하여 비행자동차의 비행 고도 제한에 관한 \\n기준을 정함을 목적으로 한다.\\n\\n\\n제2조(정의)\\n이 법에서 \"비행자동차\"라 함은 지상 및 공중을 이동할 수 있는 능력을 가진 차량을 말한다. \\n\\n\\n제3조(일반적인 비행고도 제한)\\n1.\\n\\n도심지에서 비행차가 비행하는 경우 기본 고도는 지상에서 150m에서 300m로 한다.\\n\\n\\n2.\\n\\n도시 외의 지역에서 비행차가 비행하는 경우 기본 고도는 지상에서 300미터에서 500미터로 한다.\\n\\n\\n3.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 2, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''})]\n"
     ]
    }
   ],
   "source": [
    "res = database.similarity_search('비행 자동차의 최고 속도는?')\n",
    "print(f\"총 관련문서 : {len(res)}개\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca7410bd-ceba-41d8-9afc-1f228ccd449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 20:39:46 - Collection langchain is not created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='제6조 (자동비행 및 AI 위반 시 처벌)\\n\\n\\n1.\\n\\n\\n이 법을 위반하여 적절한 자동비행시스템 및 AI를 갖추지 않은 비행체를 운용한 자는 300만 원 이\\n하의 벌금에 처한다.\\n\\n\\n2.\\n\\n중대한 사고를 유발하거나 반복적으로 위반한 경우에는 제1항의 벌금 외에 5년 이하의 징역 \\n또는 5억 원 이하의 벌금에 처한다.\\n\\n\\n제7조(감독 및 지도)\\n국가는 비행차량의 자동비행 및 AI의 준수 여부를 감독하고 필요한 경우 지도 또는 명령을 내릴 수 있다.\\n\\n\\n제8조(법 시행일)\\n이 법은 공포일로부터 6개월 후에 시행한다.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 8, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''}),\n",
       " Document(page_content='제7조(비\\n행자동차 운전자격 위반 시 벌칙)\\n1.\\n\\n이 법을 위반하여 적절한 비행자동차 운전 자격이 없는 자가 비행자동차를 운행한 경우 300만 원 \\n이하의 벌금에 처한다.\\n\\n\\n2.\\n\\n중대한 사고를 유발하거나 반복적으로 위반한 경우에는 제1항의 벌금 외에 5년 이하의 징역 \\n또는 5억 원 이하의 벌금에 처한다.\\n\\n\\n제8조(감독 및 지도)\\n국가는 비행자동차의 운전자격 취득 및 준수여부를 감독하고, 필요한 경우 지도 또는 명령을 내린다.\\n\\n\\n제9조(법 시행일)\\n이 법은 공포일로부터 6개월 후에 시행한다.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 9, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''}),\n",
       " Document(page_content='2.\\n\\n비행 차량 운전자는 특히 야간이나 주택가를 지날 때 소음을 최소화하기 위한 조작을 해야 한다.\\n\\n\\n제4조(소음 규제 위반에 대한 처벌)\\n1.\\n\\n\\n이 법을 위반하여 규정 이상의 소음을 발생시키는 비행체를 제조 또는 운행한 자는 300만 원 이하\\n의 벌금에 처한다.\\n\\n\\n2.\\n\\n중대한 위반행위를 하거나 반복적으로 위반한 경우에는 제1항의 벌금 외에 5년 이하의 징역 또\\n는 5억 원 이하의 벌금에 처한다.\\n\\n\\n제5조(감독 및 지도)\\n국가는 비행차 소음 규제 준수 여부를 감독하고 필요한 경우 지도 또는 명령을 내릴 수 있다.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 10, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''}),\n",
       " Document(page_content='제6조(교육 및 훈련 장소)\\n비행자동차 운전자격 교육 및 훈련 프로그램은 교통관리기관이 인정한 시설에서 실시한다.\\n\\n제7조(비\\n행자동차 운전자격 위반 시 벌칙)\\n1.\\n\\n이 법을 위반하여 적절한 비행자동차 운전 자격이 없는 자가 비행자동차를 운행한 경우 300만 원 \\n이하의 벌금에 처한다.\\n\\n\\n2.\\n\\n중대한 사고를 유발하거나 반복적으로 위반한 경우에는 제1항의 벌금 외에 5년 이하의 징역 \\n또는 5억 원 이하의 벌금에 처한다.', metadata={'author': '', 'creationDate': 'D:20231207125109Z', 'creator': 'Microsoft Office Word', 'file_path': './asset/sample.pdf', 'format': 'PDF 1.7', 'keywords': ', docId:825DD61FFAE9658C7293B36CB13F138C', 'modDate': \"D:20231211174122+09'00'\", 'page': 9, 'producer': 'Aspose.Words for .NET 23.11.0', 'source': './asset/sample.pdf', 'subject': '', 'title': '하늘을 나는 자동차 관련 법제도', 'total_pages': 12, 'trapped': ''})]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "chroma로 저장한 벡터스토어는 Chroma메소드로 가져올수 있음\n",
    "'''\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "db = Chroma(\n",
    "    persist_directory=\"./.tik\", \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "retriever= db.as_retriever()\n",
    "retriever.get_relevant_documents('비행 자동차 벌금은?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be294f1-7952-4a41-b382-6d8ec239164f",
   "metadata": {},
   "source": [
    "### 검색결과와 질문을 조합해서 질문에 답해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ed97b9a-07ed-46ad-bb2c-29d8636c3ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 20:49:53 - Collection langchain is not created.\n",
      "2024-05-05 20:49:54 - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "도심에서는 시속 150km, 도시 외의 지역에서는 시속 250km입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "input_message='비행 자동차의 최고 속도는?'\n",
    "\n",
    "load_dotenv()\n",
    "chat = ChatGroq(model=\"llama3-70b-8192\",\n",
    "               api_key = os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "\n",
    "# 프롬프트템플릿으로 LLM에 보낼 문서를 만들어줍니다.\n",
    "prompt = PromptTemplate(template=\"\"\"문장을 바탕으로 질문에 한국어로 답변\n",
    "\n",
    "문장: \n",
    "{document}\n",
    "\n",
    "질문: {query}\n",
    "\"\"\", input_variables=[\"document\", \"query\"])\n",
    "\n",
    "\n",
    "# embedding 불러오고\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# VectorStore에서 문서를 loading하고\n",
    "db = Chroma(\n",
    "    persist_directory=\"./.data\", \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Retriever를 만들어서 질문과 유사도 높은 문서 탐색\n",
    "retriever = db.as_retriever()\n",
    "documents = retriever.get_relevant_documents(input_message)\n",
    "\n",
    "# 탐색한 문서를 str으로 붙여서 보낼 준비를 합니다.\n",
    "documents_string = \"\"\n",
    "\n",
    "for document in documents:\n",
    "    documents_string += f\"\"\"\n",
    "---------------------------\n",
    "{document.page_content}\n",
    "\"\"\"\n",
    "# print(documents_string)\n",
    "\n",
    "# 참고할 문서를 document에 붙여서 보내고, query를 던집니다.\n",
    "# 위에서 prompt의 input_variables=[\"document\", \"query\"] 로 셋팅했기에 각 변수 입력 가능\n",
    "result = chat([\n",
    "    HumanMessage(content=prompt.format(document=documents_string,\n",
    "                                       query=input_message)) \n",
    "])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91530357-89eb-4c68-b7ab-90a9aca01350",
   "metadata": {},
   "source": [
    "### chainlit으로 채팅 서비스화\n",
    "```\n",
    "conda activate lang310\n",
    "cd d:/drive/SelfStudy/dl.AI/ds4th_study/langchain/03_retrieval\n",
    "chainlit run chat_2.py --port 8001\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636461b3-f304-4698-85ff-50ebdfb9a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "다음 코드를 빈문서에 넣고 chat_2.py로 저장하여 실행 \n",
    "위의 코드와 동일하나, 함수를 채팅창의 각 메소드에 동기화 하는 코드 추가\n",
    "'''\n",
    "import chainlit as cl\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = PromptTemplate(template=\"\"\"문장을 바탕으로 질문에 답하세요.\n",
    "\n",
    "문장: \n",
    "{document}\n",
    "\n",
    "질문: {query}\n",
    "\"\"\", input_variables=[\"document\", \"query\"])\n",
    "\n",
    "database = Chroma(\n",
    "    persist_directory=\"./.data\", \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "@cl.on_chat_start # 채팅이 시작될때의 함수를 정의\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"준비되었습니다! 메시지를 입력하세요!\").send()\n",
    "\n",
    "@cl.on_message # 메시지 보낼 때 실행할 함수를 정의\n",
    "async def on_message(input_message):\n",
    "    print(\"입력된 메시지: \" + input_message)\n",
    "    documents = database.similarity_search(input_message)\n",
    "\n",
    "    documents_string = \"\"\n",
    "\n",
    "    for document in documents:\n",
    "        documents_string += f\"\"\"\n",
    "    ---------------------------\n",
    "    {document.page_content}\n",
    "    \"\"\"\n",
    "\n",
    "    result = chat([\n",
    "        HumanMessage(content=prompt.format(document=documents_string,\n",
    "                                           query=input_message)) #← input_message로 변경\n",
    "    ])\n",
    "    await cl.Message(content=result.content).send() #← 챗봇의 답변을 보냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632289c7-c13a-484f-a7d9-3357e14b1c39",
   "metadata": {},
   "source": [
    "### 채팅시작 시 파일업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0107c273-ff74-4332-ac7c-25e1fe218f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = PromptTemplate(template=\"\"\"문장을 기반으로 질문에 답하세요. \n",
    "\n",
    "문장: \n",
    "{document}\n",
    "\n",
    "질문: {query}\n",
    "\"\"\", input_variables=[\"document\", \"query\"])\n",
    "\n",
    "text_splitter = SpacyTextSplitter(chunk_size=300, pipeline=\"ko_core_news_sm\")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    files = None #← 파일이 선택되어 있는지 확인하는 변수\n",
    "\n",
    "    while files is None: #← 파일이 선택될 때까지 반복\n",
    "        files = await cl.AskFileMessage(\n",
    "            max_size_mb=20,\n",
    "            content=\"PDF를 선택해 주세요\",\n",
    "            accept=[\"application/pdf\"],\n",
    "            raise_on_timeout=False,\n",
    "        ).send()\n",
    "    file = files[0]\n",
    "\n",
    "    if not os.path.exists(\"tmp\"): #← tmp 디렉터리가 존재하는지 확인\n",
    "        os.mkdir(\"tmp\") #← 존재하지 않으면 생성\n",
    "    with open(f\"tmp/{file.name}\", \"wb\") as f: #← PDF 파일을 저장\n",
    "        f.write(file.content) #← 파일 내용을 작성\n",
    "\n",
    "    documents = PyMuPDFLoader(f\"tmp/{file.name}\").load() #← 저장한 PDF 파일을 로드\n",
    "    splitted_documents = text_splitter.split_documents(documents) #← 문서를 분할\n",
    "\n",
    "    database = Chroma( #← 데이터베이스 초기화\n",
    "        embedding_function=embeddings,\n",
    "        # 이번에는 persist_directory를 지정하지 않음으로써 데이터베이스 영속화를 하지 않음\n",
    "    )\n",
    "\n",
    "    database.add_documents(splitted_documents) #← 문서를 데이터베이스에 추가\n",
    "\n",
    "    cl.user_session.set(  #← 데이터베이스를 세션에 저장\n",
    "        \"database\",  #← 세션에 저장할 이름\n",
    "        database  #← 세션에 저장할 값\n",
    "    )\n",
    "\n",
    "    await cl.Message(content=f\"`{file.name}` 로딩이 완료되었습니다. 질문을 입력하세요.\").send() #← 불러오기 완료를 알림\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    print(\"입력된 메시지: \" + input_message)\n",
    "\n",
    "    database = cl.user_session.get(\"database\") #← 세션에서 데이터베이스를 가져옴\n",
    "\n",
    "    documents = database.similarity_search(input_message)\n",
    "\n",
    "    documents_string = \"\"\n",
    "\n",
    "    for document in documents:\n",
    "        documents_string += f\"\"\"\n",
    "    ---------------------------\n",
    "    {document.page_content}\n",
    "    \"\"\"\n",
    "    \n",
    "    result = chat([\n",
    "        HumanMessage(content=prompt.format(document=documents_string,\n",
    "                                           query=input_message)) #← input_message로 변경\n",
    "    ])\n",
    "    await cl.Message(content=result.content).send()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864de536-1d62-4405-a012-93c968eab455",
   "metadata": {},
   "source": [
    "## 3. RetrievalQA\n",
    "- RAG 기능을 활용한 QA 시스템 개발을 보다 쉽고 다기능으로 만들어줌\n",
    "- 검색, 프롬프트구축, 언어모델호출처리 구현을 단순화하여 코드호출을 줄임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "05fc4056-70be-4404-ad10-fb48c19e4a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 21:55:39 - Collection langchain is not created.\n",
      "도심에서는 최대 속도가 시속 150km이고, 도시 외의 지역에서는 최대 속도가 시속 250km입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI  #← ChatOpenAI 가져오기\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate  #← PromptTemplate 가져오기\n",
    "from langchain.schema import HumanMessage  #← HumanMessage 가져오기\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "database = Chroma(\n",
    "    persist_directory=\"./.data\", \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "query = \"비행 자동차의 최고 속도는?\"\n",
    "\n",
    "documents = database.similarity_search(query)\n",
    "\n",
    "documents_string = \"\" #← 문서 내용을 저장할 변수를 초기화\n",
    "\n",
    "for document in documents:\n",
    "    documents_string += f\"\"\"\n",
    "---------------------------\n",
    "{document.page_content}\n",
    "\"\"\" #← 문서 내용을 추가\n",
    "\n",
    "prompt = PromptTemplate( #← PromptTemplate를 초기화\n",
    "    template=\"\"\"문장을 바탕으로 질문에 답하세요.\n",
    "\n",
    "문장: \n",
    "{document}\n",
    "\n",
    "질문: {query}\n",
    "\"\"\",\n",
    "    input_variables=[\"document\",\"query\"] #← 입력 변수를 지정\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI( #← ChatOpenAI를 초기화\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "result = chat([\n",
    "    HumanMessage(content=prompt.format(document=documents_string, query=query))\n",
    "])\n",
    "\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4faedd06-99bf-4d9f-9f0e-088dab05c321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 22:01:58 - Collection langchain is not created.\n",
      "도심에서 비행 자동차가 비행하는 경우 최대 속도는 시속 150km이며, 도시 외의 지역에서 비행 자동차가 비행하는 경우 최대 속도는 시속 250km입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA  #← RetrievalQA를 가져오기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "database = Chroma(\n",
    "    persist_directory=\"./.data\", \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "retriever = database.as_retriever() #← 데이터베이스를 Retriever로 변환\n",
    "\n",
    "# qa안에 llm, retriever를 한번에 설정하여 document, query를 별도 입력할 필요가 없음 (암묵적 수행)\n",
    "qa = RetrievalQA.from_llm(  #← RetrievalQA를 초기화\n",
    "    llm=chat,  #← Chat models를 지정\n",
    "    retriever=retriever,  #← Retriever를 지정\n",
    "    return_source_documents=True,  #← 응답에 원본 문서를 포함할지를 지정\n",
    ")\n",
    "\n",
    "result = qa(\"비행 자동차의 최고 속도를 알려주세요\")\n",
    "\n",
    "print(result[\"result\"]) #← 응답을 표시\n",
    "\n",
    "# print(result[\"source_documents\"]) #← 원본 문서를 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9e2b8-cb84-4d98-be57-1ea89d8c1929",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 4.준비된 Retrievers 활용\n",
    "> pdf문서가 없어도 wikipedia를 활용하여 답변을 생성할 수 있다. WikipediaRetriever를 사용\n",
    "- 키워드를 명사중심으로 검색해야 명확하게 검색이 됨ㅁ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "562f9142-138b-4d62-aef4-3d95537c4e80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과: 3건\n",
      "---------------검색한 메타데이터---------------\n",
      "{'title': '피카츄', 'summary': '피카츄(일본어: ピカチュウ 피카추[*] 문화어: 삐까쮸)는 《포켓몬스터》에 등장하는 가상의 생명체이다. 애니메이션과 비디오 게임에서는 오타니 이쿠에가 그 목소리를 맡고 있다. 귀여운 전기 포켓몬을 그려달라는 스기모리 켄의 주문을 받아 니시다 아츠코가 디자인하였다. 게임 프리크와 닌텐도가 만든 1996년 일본 비디오 게임 《포켓몬스터 레드·그린》에 처음 등장했으며 1998년 《포켓몬스터 레드·블루》로 미국에 출시되었다. 피카츄는 전기 능력을 가진 노란색 쥐처럼 생긴 생물이다. 피카츄는 포켓몬 프랜차이즈의 주요 캐릭터이며, 마스코트이자 닌텐도의 주요 마스코트 역할을 한다.\\n피카츄는 가장 인기 있고 잘 알려진 1세대 포켓몬인데, 포켓몬스터 TV 애니메이션에서 주인공 지우의 첫 포켓몬이자 파트너로 등장하기 때문이다. 1998년부터 지금까지 포켓몬스터의 애니메이션 주인공 지우와 함께 모험하고 있다. 피카츄는 대부분의 목소리 출연을 오타니 이쿠에가 담당했지만, 실사 애니메이션 영화 《명탐정 피카츄》에서 라이언 레이놀즈가 담당했다. 피카츄는 특히 귀여움으로 호평받으며 일본 대중문화의 아이콘으로 여겨지고 있다.', 'source': 'https://ko.wikipedia.org/wiki/%ED%94%BC%EC%B9%B4%EC%B8%84'}\n",
      "---------------검색한 텍스트---------------\n",
      "피카츄(일본어: ピカチュウ 피카추[*] 문화어: 삐까쮸)는 《포켓몬스터》에 등장하는 가상의 생명체이다. 애니메이션과 비디오 게임에서는 오타니 이쿠에가 그 목소리를 맡고 있다. 귀여\n",
      "---------------검색한 메타데이터---------------\n",
      "{'title': '포켓몬스터 피카츄', 'summary': '《포켓몬스터 피카츄》(일본어: ポケットモンスター ピカチュウ )는 1998년 출시 된, 포켓몬스터 청의 후속작이다. 애니메이션의 대 성공으로 인한 후속작 성격에 가깝다. 스타팅은 이상해씨, 파이리, 꼬부기 중 한 마리가 아닌, 피카츄이다. 그러나 포켓몬스터 애니메이션의 한지우처럼 파이리, 꼬부기, 이상해씨 모두를 얻을 수 있다. 그리고 이 게임의 스타팅 포켓몬으로 지급되는 피카츄는 라이츄로의 진화를 거부하며 이 외에도 게임 내용이 애니메이션에 가깝게 수정되었다. 그리고 전체적인 색감도 애니메이션과 비슷하게 만들어졌고, 일부 포켓몬들은 하양, 검정, 노랑, 빨강으로만 표현이 되었다.', 'source': 'https://ko.wikipedia.org/wiki/%ED%8F%AC%EC%BC%93%EB%AA%AC%EC%8A%A4%ED%84%B0_%ED%94%BC%EC%B9%B4%EC%B8%84'}\n",
      "---------------검색한 텍스트---------------\n",
      "《포켓몬스터 피카츄》(일본어: ポケットモンスター ピカチュウ )는 1998년 출시 된, 포켓몬스터 청의 후속작이다. 애니메이션의 대 성공으로 인한 후속작 성격에 가깝다. 스타팅은 이\n",
      "---------------검색한 메타데이터---------------\n",
      "{'title': '포켓몬스터 레츠고! 피카츄·레츠고! 이브이', 'summary': '《포켓몬스터 레츠고! 피카츄》와 《포켓몬스터 레츠고! 이브이》는 2018년 11월 16일에 발매된 포켓몬스터 시리즈의 닌텐도 스위치용 롤플레잉 비디오 게임으로 게임프리크에서 개발, 닌텐도와 주식회사 포켓몬에서 배급한다. 1998년 발매된 포켓몬스터 피카츄를 바탕으로 플레이 방법과 시나리오를 새롭게 구축하였다. 해당 게임은 포켓몬 GO, 소프트웨어와 함께 발매된 몬스터볼 플러스와 연동된다.', 'source': 'https://ko.wikipedia.org/wiki/%ED%8F%AC%EC%BC%93%EB%AA%AC%EC%8A%A4%ED%84%B0_%EB%A0%88%EC%B8%A0%EA%B3%A0!_%ED%94%BC%EC%B9%B4%EC%B8%84%C2%B7%EB%A0%88%EC%B8%A0%EA%B3%A0!_%EC%9D%B4%EB%B8%8C%EC%9D%B4'}\n",
      "---------------검색한 텍스트---------------\n",
      "《포켓몬스터 레츠고! 피카츄》와 《포켓몬스터 레츠고! 이브이》는 2018년 11월 16일에 발매된 포켓몬스터 시리즈의 닌텐도 스위치용 롤플레잉 비디오 게임으로 게임프리크에서 개발,\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "pip install wikipedia\n",
    "'''\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "\n",
    "retriever = WikipediaRetriever(  #← WikipediaRetriever를 초기화\n",
    "    lang=\"ko\",  #← Wikipedia의 언어를 지정\n",
    ")\n",
    "documents = retriever.get_relevant_documents( #← Wikipedia에서 관련 문서를 가져옴\n",
    "    \"피카츄\" #← 검색할 키워드를 지정\n",
    ")\n",
    "\n",
    "print(f\"검색 결과: {len(documents)}건\") #← 검색 결과 건수를 표시\n",
    "\n",
    "for document in documents:\n",
    "    print(\"---------------검색한 메타데이터---------------\")\n",
    "    print(document.metadata) #← 메타데이터를 표시\n",
    "    print(\"---------------검색한 텍스트---------------\")\n",
    "    print(document.page_content[:100]) #← 텍스트의 첫 100글자를 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1122a3f-9e71-4fc1-ab90-9c40754970f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제가 알기로는 피카츄는 1996년에 처음 출시되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA  #← RetrievalQA를 가져오기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "input_text = \"피카츄는 언제 출시 되었어?\"\n",
    "input_ = '피카츄'\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "retriever = WikipediaRetriever(  #← WikipediaRetriever를 초기화\n",
    "    lang=\"ko\",  #← Wikipedia의 언어를 지정\n",
    ")\n",
    "documents = retriever.get_relevant_documents( #← Wikipedia에서 관련 문서를 가져옴\n",
    "    input_ #← 검색할 키워드를 지정\n",
    ")\n",
    "\n",
    "retriever = database.as_retriever() #← 데이터베이스를 Retriever로 변환\n",
    "\n",
    "# qa안에 llm, retriever를 한번에 설정하여 document, query를 별도 입력할 필요가 없음 (암묵적 수행)\n",
    "qa = RetrievalQA.from_llm(  #← RetrievalQA를 초기화\n",
    "    llm=chat,  #← Chat models를 지정\n",
    "    retriever=retriever,  #← Retriever를 지정\n",
    "    return_source_documents=True,  #← 응답에 원본 문서를 포함할지를 지정\n",
    ")\n",
    "\n",
    "result = qa(input_text)\n",
    "\n",
    "print(result[\"result\"]) #← 응답을 표시\n",
    "\n",
    "# print(result[\"source_documents\"]) #← 원본 문서를 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2229a-47f2-4e76-9c04-c6f2847a8015",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LLMChain, RePhraseQueryRetriever 활용하여 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "26a8653f-a001-4b91-8d67-1e7043297ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-05 22:24:45 - Re-phrased question: 키워드: 라면, 소주\n",
      "[Document(page_content='보쌈(영어: bossam)은 쌈의 일종으로서 돼지고기를 삶은 수육(삶아서 물기를 뺀 고기)에 상추나 절인 배춧잎으로 쌈을 해서 먹는 한국 요리다. 대개 소, 중, 대 등으로 양을 구분해 판매한다. 한국인이 소주를 마실 때 많이 찾는 요리 중 하나다. 본래 고기를 삶아 피와 기름을 빼서 먹는 것이 보쌈고기의 가장 큰 특징과 일부 체인점에서는 기름맛을 내기 위해 삶지 않고 찌기도 한다. 참고로 보쌈의 보는 한자어로 보자기(포대기)를 의미한다.\\n돼지고기를 삶을 때에는 생강을 이용해서 고기 자체의 비린내를 제거하는데 맛을 좋게 하기 위해 여러 가지 한약재, 무, 양파 등을 같이 넣어 삶기도 한다.\\n 보쌈을 먹을 때에는 쌈장을 찍어서 상추와 깻잎에 싸 먹는다. 새우젓을 함께 찍어 먹기도 하며, 무말랭이 따위가 함께 나오는 것도 흔한 편이다. 굴을 함께 낸 굴보쌈도 있다.\\n대한민국에는 많은 보쌈 요리 체인점이 있으며, 서울특별시 종로구 종로3가 인근에는 보쌈 골목이 있다.\\n\\n\\n== 각주 ==', metadata={'title': '보쌈', 'summary': '보쌈(영어: bossam)은 쌈의 일종으로서 돼지고기를 삶은 수육(삶아서 물기를 뺀 고기)에 상추나 절인 배춧잎으로 쌈을 해서 먹는 한국 요리다. 대개 소, 중, 대 등으로 양을 구분해 판매한다. 한국인이 소주를 마실 때 많이 찾는 요리 중 하나다. 본래 고기를 삶아 피와 기름을 빼서 먹는 것이 보쌈고기의 가장 큰 특징과 일부 체인점에서는 기름맛을 내기 위해 삶지 않고 찌기도 한다. 참고로 보쌈의 보는 한자어로 보자기(포대기)를 의미한다.\\n돼지고기를 삶을 때에는 생강을 이용해서 고기 자체의 비린내를 제거하는데 맛을 좋게 하기 위해 여러 가지 한약재, 무, 양파 등을 같이 넣어 삶기도 한다.\\n 보쌈을 먹을 때에는 쌈장을 찍어서 상추와 깻잎에 싸 먹는다. 새우젓을 함께 찍어 먹기도 하며, 무말랭이 따위가 함께 나오는 것도 흔한 편이다. 굴을 함께 낸 굴보쌈도 있다.\\n대한민국에는 많은 보쌈 요리 체인점이 있으며, 서울특별시 종로구 종로3가 인근에는 보쌈 골목이 있다.', 'source': 'https://ko.wikipedia.org/wiki/%EB%B3%B4%EC%8C%88'}), Document(page_content=\"소득주도성장론(所得主導成長論, Income-led growth)은 가계의 임금과 소득을 늘리면 소비도 늘어나 경제성장이 이루어진다는 이론을 바탕으로한 문재인 정부의 경제정책이다. 포스트케인지언(Post-Keynesian) 경제학자들이 주장한 임금주도성장론(賃金主導成長論, Wage-led growth)을 바탕으로 하고 있다.\\n\\n\\n== 배경 ==\\n대한민국은 그동안 투자와 수출 진흥 정책에 중점을 두고 이른바 '한강의 기적'이라는 고도의 경제 발전을 보였지만, 세계적인 경제 침체와 불균형으로 수출주도 성장이 한계에 이르렀다는 주장이 제기되었다. 또한 세계적으로는 미국발 금융위기가 터지면서 정부개입 최소화, 규제 완화, 자유무역, 민영화 등 신자유주의적 정책에 대한 비판이 제기되었다.따라서 이런 경제 침체와 성장 둔화의 원인을 총수요 요인 중 내수와 소비 부족, 소득분배 불균형 문제로 보고, 노동자들의 임금을 늘리고 소득을 분배해 총수요를 늘려 경제성장을 달성할 수 있다는 소득주도성장론이 \", metadata={'title': '소득주도성장론', 'summary': '소득주도성장론(所得主導成長論, Income-led growth)은 가계의 임금과 소득을 늘리면 소비도 늘어나 경제성장이 이루어진다는 이론을 바탕으로한 문재인 정부의 경제정책이다. 포스트케인지언(Post-Keynesian) 경제학자들이 주장한 임금주도성장론(賃金主導成長論, Wage-led growth)을 바탕으로 하고 있다.', 'source': 'https://ko.wikipedia.org/wiki/%EC%86%8C%EB%93%9D%EC%A3%BC%EB%8F%84%EC%84%B1%EC%9E%A5%EB%A1%A0'}), Document(page_content='2019년 대한민국의 일본 제품 불매 운동(Korean boycotts of Japanese products in 2019)은 대한민국 내에서 2019년 7월부터 시작하여 하반기에 계속된 일본, 또는 관련 기업의 제품을 구매하거나, 소비하지 않겠다는 취지의 운동이다.\\n대한민국 대법원의 기존의 강제 징용 관련 판결 이후, 삼성전자나 SK하이닉스 등의 대한민국 국내 기업에서 반도체 생산에 필요한 원자재 수출을 일본이 규제하면서 발생한 한일 무역 분쟁으로 인해서 본격적으로 촉발되었다. 불매운동이 길어지면서 판매랑이 급 감소한 한국닛산은 8년 보증을 약속하고 철수하였다.\\n\\n\\n== 대한민국의 반응 ==\\n7월 3일, 인터넷 커뮤니티 클리앙의 한 유저가 ‘NO, BOYCOTT JAPAN’이라는 로고를 만들어 비영리 목적으로 사용하는 조건으로 자유롭게 쓸 수 있도록 하여 배포하였다. 이 로고는 메시지를 간명하게 전달하는 점이 인터넷 상에서 큰 인기를 끌며 다양하게 패러디되었고, 이후 오프라인과 온', metadata={'title': '2019년 대한민국의 일본 제품 불매 운동', 'summary': '2019년 대한민국의 일본 제품 불매 운동(Korean boycotts of Japanese products in 2019)은 대한민국 내에서 2019년 7월부터 시작하여 하반기에 계속된 일본, 또는 관련 기업의 제품을 구매하거나, 소비하지 않겠다는 취지의 운동이다.\\n대한민국 대법원의 기존의 강제 징용 관련 판결 이후, 삼성전자나 SK하이닉스 등의 대한민국 국내 기업에서 반도체 생산에 필요한 원자재 수출을 일본이 규제하면서 발생한 한일 무역 분쟁으로 인해서 본격적으로 촉발되었다. 불매운동이 길어지면서 판매랑이 급 감소한 한국닛산은 8년 보증을 약속하고 철수하였다.', 'source': 'https://ko.wikipedia.org/wiki/2019%EB%85%84_%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%BC%EB%B3%B8_%EC%A0%9C%ED%92%88_%EB%B6%88%EB%A7%A4_%EC%9A%B4%EB%8F%99'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers import WikipediaRetriever, RePhraseQueryRetriever #← RePhraseQueryRetriever를 가져오기\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "retriever = WikipediaRetriever( \n",
    "    lang=\"ko\", \n",
    "    doc_content_chars_max=500 \n",
    ")\n",
    "\n",
    "llm_chain = LLMChain( #← LLMChain을 초기화\n",
    "    llm = ChatOpenAI( #← ChatOpenAI를 지정\n",
    "        temperature = 0\n",
    "    ), \n",
    "    prompt= PromptTemplate( #← PromptTemplate을 지정\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"아래 질문에서 Wikipedia에서 검색할 키워드를 추출해 주세요.\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "re_phrase_query_retriever = RePhraseQueryRetriever( #← RePhraseQueryRetriever를 초기화\n",
    "    llm_chain=llm_chain, #← LLMChain을 지정\n",
    "    retriever=retriever, #← WikipediaRetriever를 지정\n",
    ")\n",
    "\n",
    "documents = re_phrase_query_retriever.get_relevant_documents(\"나는 라면을 좋아합니다. 그런데 소주란 무엇인가요?\")\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34779828-7863-4839-90b0-f89b699cfe81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 과제> 질문으로 키워드 불러오는 것을 자동화 하였으니, 다시 자동 검색으로 적용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f1710189-d5ee-43cb-a959-44d3980735fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA  #← RetrievalQA를 가져오기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import LLMChain\n",
    "from langchain.retrievers import WikipediaRetriever, RePhraseQueryRetriever #← RePhraseQueryRetriever를 가져오기\n",
    "\n",
    "input_text = \"피카츄는 언제 출시 되었어?\"\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "retriever = WikipediaRetriever( \n",
    "    lang=\"ko\", \n",
    "    doc_content_chars_max=500 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6297ec3-fa7b-44f2-b560-24e0822c2ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "152fc6e7-3846-4146-a8da-40a16180f299",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 답안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad9b0f-b1c5-46ac-a037-3e3b23dd20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA  #← RetrievalQA를 가져오기\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import LLMChain\n",
    "from langchain.retrievers import WikipediaRetriever, RePhraseQueryRetriever #← RePhraseQueryRetriever를 가져오기\n",
    "\n",
    "input_text = \"피카츄는 언제 출시 되었어?\"\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "retriever = WikipediaRetriever( \n",
    "    lang=\"ko\", \n",
    "    doc_content_chars_max=500 \n",
    ")\n",
    "\n",
    "llm_chain = LLMChain( #← LLMChain을 초기화\n",
    "    llm = ChatOpenAI( #← ChatOpenAI를 지정\n",
    "        temperature = 0), \n",
    "    prompt= PromptTemplate( #← PromptTemplate을 지정\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"아래 질문에서 Wikipedia에서 검색할 키워드를 추출해 주세요.\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "re_phrase_query_retriever = RePhraseQueryRetriever( #← RePhraseQueryRetriever를 초기화\n",
    "    llm_chain=llm_chain, #← LLMChain을 지정\n",
    "    retriever=retriever, #← WikipediaRetriever를 지정\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_llm(  #← RetrievalQA를 초기화\n",
    "    llm=chat,  #← Chat models를 지정\n",
    "    retriever=re_phrase_query_retriever,  #← Retriever를 지정\n",
    "    return_source_documents=True,  #← 응답에 원본 문서를 포함할지를 지정\n",
    ")\n",
    "\n",
    "result = qa(input_text)\n",
    "\n",
    "print(result[\"result\"]) #← 응답을 표시\n",
    "\n",
    "# print(result[\"source_documents\"]) #← 원본 문서를 표시"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang310",
   "language": "python",
   "name": "lang310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
