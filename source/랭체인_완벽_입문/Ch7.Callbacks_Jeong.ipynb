{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e82aca-347a-45e5-9346-02ec4911c840",
   "metadata": {},
   "source": [
    "# Ch7.Callbacks - ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ ë°œìƒ ì‹œ ì²˜ë¦¬í•˜ê¸°\n",
    "- 1. Callbacks ëª¨ë“ˆë¡œ í•  ìˆ˜ ìˆëŠ” ì¼ ì•Œì•„ë³´ê¸°\n",
    "- 2. Callbacks ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì—°ë™í•˜ê¸°\n",
    "- 3. ë¡œê·¸ë¥¼ í„°ë¯¸ë„ì— í‘œì‹œí•  ìˆ˜ ìˆëŠ” Callbacks ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6ea66a-d1c2-494c-810a-b6cc7e469f25",
   "metadata": {},
   "source": [
    "## 1. Callbacks ëª¨ë“ˆë¡œ í•  ìˆ˜ ìˆëŠ” ì¼ ì•Œì•„ë³´ê¸°\n",
    "> ë¡œê·¸ ìˆ˜ì§‘ ë° ëª¨ë‹ˆí„°ë§, ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ì—°ë™ ê°€ëŠ¥\n",
    "\n",
    "<img src=\"./img/lang_7_1.png\" width=\"70%\" height=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a29d1f7-b60e-481c-8290-d440dbc37c6c",
   "metadata": {},
   "source": [
    "## 2. Callbacks ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì—°ë™í•˜ê¸°\n",
    ">  chainlitì—ì„œ ì œê³µí•˜ëŠ” ë­ì²´ì¸ê³¼ ì—°ë™ì„ ìœ„í•œ ê¸°ëŠ¥ì„ í†µí•´ callbacksëª¨ë“ˆì˜ ì‘ë™ì„ ì•Œì•„ë³¸ë‹¤.\n",
    "```\n",
    "chainlit.exe run chainlit_callback.py --port 8001\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9659fba9-16d6-4979-96fb-b2b35d772f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "chainlit_callback.py íŒŒì¼ì—ì„œ ê²€ìƒ‰agentë¥¼ ì–´ì¹˜ë©´ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "'''\n",
    "import chainlit as cl\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0,  \n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "tools = load_tools( \n",
    "    [\n",
    "        \"serpapi\",\n",
    "    ],\n",
    "    serpapi_api_key=os.getenv(\"SERP_API_KEY\")\n",
    ")\n",
    "\n",
    "agent = initialize_agent(tools=tools, llm=chat, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"Agent ì´ˆê¸°í™” ì™„ë£Œ\").send() \n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    result = agent.run( #â† Agentë¥¼ ì‹¤í–‰\n",
    "        input_message, #â† ì…ë ¥ ë©”ì‹œì§€\n",
    "        callbacks=[ #â† ì½œë°±ì„ ì§€ì •\n",
    "            cl.LangchainCallbackHandler() #â† chainlitì— ì¤€ë¹„ëœ Callbacksë¥¼ ì§€ì •\n",
    "        ]\n",
    "    )\n",
    "    await cl.Message(content=result).send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab391321-607b-405a-a4c2-3cb0b74c1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "callbackí•¨ìˆ˜ë¥¼ ì§ì ‘ ë§Œë“¤ì–´ì„œ ì‹¤í–‰ë„ ê°€ëŠ¥ \n",
    "'''\n",
    "\n",
    "import chainlit as cl\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0,  \n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "tools = load_tools( \n",
    "    [\n",
    "        \"serpapi\",\n",
    "    ],\n",
    "    serpapi_api_key=os.getenv(\"SERP_API_KEY\")\n",
    ")\n",
    "\n",
    "class MyCustomHandlerOne(BaseCallbackHandler):\n",
    "    def on_llm_start(\n",
    "        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"on_llm_start {serialized['name']}\")\n",
    "\n",
    "    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:\n",
    "        print(f\"on_new_token {token}\")\n",
    "\n",
    "    def on_llm_error(\n",
    "        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any\n",
    "    ) -> Any:\"\"\"Run when LLM errors.\"\"\"\n",
    "\n",
    "    def on_chain_start(\n",
    "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"on_chain_start {serialized['name']}\")\n",
    "\n",
    "    def on_tool_start(\n",
    "        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"on_tool_start {serialized['name']}\")\n",
    "\n",
    "    def on_agent_action(self, action: AgentAction, **kwargs: Any) -> Any:\n",
    "        print(f\"on_agent_action {action}\")\n",
    "\n",
    "handler = MyCustomHandlerOne()\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm =chat,\n",
    "    agent = AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True)\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"Agent ì´ˆê¸°í™” ì™„ë£Œ\").send() \n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    result = agent.run( #â† Agentë¥¼ ì‹¤í–‰\n",
    "        input_message, #â† ì…ë ¥ ë©”ì‹œì§€\n",
    "        callbacks=[ #â† ì½œë°±ì„ ì§€ì •\n",
    "            handler #â† chainlitì— ì¤€ë¹„ëœ Callbacksë¥¼ ì§€ì •\n",
    "        ]\n",
    "    )\n",
    "    await cl.Message(content=result).send()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d527f7-b711-4b8c-a78e-b5dc5dd3018f",
   "metadata": {},
   "source": [
    "## 3. ë¡œê·¸ë¥¼ í„°ë¯¸ë„ì— í‘œì‹œí•  ìˆ˜ ìˆëŠ” Callbacks ë§Œë“¤ê¸°\n",
    "> ì´ë²¤íŠ¸ ë°œìƒì‹œ ë¡œê·¸ë¥¼ í„°ë¯¸ë„ì— í‘œì‹œí•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ë§Œë“¤ì–´ Callbacksëª¨ë“ˆì˜ ì‚¬ìš©ë²•ì„ ì•Œì•„ë³´ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb5c3b9c-8404-43be-bdbe-3136a5e7db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\miniconda\\envs\\lang310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat models ì‹¤í–‰ ì‹œì‘....\n",
      "ì…ë ¥: [[HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”!')]]\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler #â† BaseCallbackHandler ê°€ì ¸ì˜¤ê¸°\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "class LogCallbackHandler(BaseCallbackHandler): #â† Callbackì„ ìƒì„±\n",
    "\n",
    "    def on_chat_model_start(self, serialized, messages, **kwargs): #â† Chat models ì‹¤í–‰ ì‹œì‘ ì‹œ í˜¸ì¶œë˜ëŠ” ì²˜ë¦¬ë¥¼ ì •ì˜\n",
    "        print(\"Chat models ì‹¤í–‰ ì‹œì‘....\")\n",
    "        print(f\"ì…ë ¥: {messages}\")\n",
    "\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs): #â† Chain ì‹¤í–‰ ì‹œì‘ ì‹œ í˜¸ì¶œë˜ëŠ” ì²˜ë¦¬ë¥¼ ì •ì˜\n",
    "        print(\"Chain ì‹¤í–‰ ì‹œì‘....\")\n",
    "        print(f\"ì…ë ¥: {inputs}\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    callbacks=[ #â† Chat models ì´ˆê¸°í™” ì‹œ Callbackì„ ì§€ì •\n",
    "        LogCallbackHandler() #â† ìƒì„±í•œ LogCallbackHandlerë¥¼ ì§€ì •\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = chat([\n",
    "    HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”!\"),\n",
    "])\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bcd09-ab57-4ba7-9803-47fab535e344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang310",
   "language": "python",
   "name": "lang310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
