{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd95be7e-987a-44d1-a495-4a21e5270899",
   "metadata": {},
   "source": [
    "# Ch4. Memory - 과거의 대화를 장 단기 기억하기\n",
    "- 1. 언어모델에서 대화란 무엇인가\n",
    "- 2. 문맥에 맞는 답변을 할 수 있는 챗봇 만들기\n",
    "- 3. 히스토리를 데이터베이스에 저장하고 영속화하기\n",
    "- 4. 여러개의 대화를 가질 수 있는 챗봇 만들기\n",
    "- 5. 매우 긴 대화기록에 대응"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22050d8b-2f66-4336-9c08-db88bcc6286d",
   "metadata": {},
   "source": [
    "## 1.언어모델에서 대화란 무엇인가\n",
    "> 언어모델과의 상호작용을 저장/복원하여 기억을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcff07-447e-4893-a7bd-33bf02309267",
   "metadata": {},
   "source": [
    "- 일회성으로 불러온 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36754dbf-ac7a-4a63-a172-acc94dff2d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계란찜을 만드는데 필요한 재료는 다음과 같습니다:\n",
      "\n",
      "- 계란\n",
      "- 물\n",
      "- 소금\n",
      "- 설탕\n",
      "- 간장\n",
      "- 다진 마늘\n",
      "- 다진 파\n",
      "- 다진 양파\n",
      "- 다진 고추\n",
      "- 참기름\n",
      "- 후추\n",
      "\n",
      "이 외에도 취향에 따라 다양한 재료를 추가할 수 있습니다. 계란찜을 더 맛있게 만들기 위해 고기나 채소를 넣어도 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI  \n",
    "from langchain.schema import HumanMessage  \n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(  \n",
    "    model=\"gpt-3.5-turbo\",  \n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature = 0.5\n",
    ")\n",
    "\n",
    "result = chat( \n",
    "    [\n",
    "        HumanMessage(content=\"계란찜을 만드는 재료를 알려주세요\"),\n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c964c45-f631-423d-b6b5-fa4dbeffb1fa",
   "metadata": {},
   "source": [
    "- 대화를 이어가며 번역하려면 소스코드를 수정하고 다시 언어모델을 호출해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee7e3b8-0114-4182-a9a6-a7fd010152c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the ingredients needed to make steamed egg:\n",
      "\n",
      "- Eggs\n",
      "- Water\n",
      "- Salt\n",
      "- Sugar\n",
      "- Soy sauce\n",
      "- Minced garlic\n",
      "- Minced green onions\n",
      "- Minced onions\n",
      "- Minced chili peppers\n",
      "- Sesame oil\n",
      "- Pepper\n",
      "\n",
      "In addition, you can add various ingredients according to your preference. You can also add meat or vegetables to make the steamed egg more delicious.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(  \n",
    "    model=\"gpt-3.5-turbo\",  \n",
    ")\n",
    "\n",
    "result = chat([\n",
    "    HumanMessage(content=\"계란찜을 만드는 재료를 알려주세요\"),\n",
    "    AIMessage( #← 이 언어모델에 AIMessage로 응답 추가\n",
    "        content=\"\"\"계란찜을 만드는데 필요한 재료는 다음과 같습니다:\n",
    "\n",
    "- 계란\n",
    "- 물\n",
    "- 소금\n",
    "- 설탕\n",
    "- 간장\n",
    "- 다진 마늘\n",
    "- 다진 파\n",
    "- 다진 양파\n",
    "- 다진 고추\n",
    "- 참기름\n",
    "- 후추\n",
    "\n",
    "이 외에도 취향에 따라 다양한 재료를 추가할 수 있습니다. 계란찜을 더 맛있게 만들기 위해 고기나 채소를 넣어도 좋습니다.\"\"\"),\n",
    "    HumanMessage(content=\"위의 답변을 영어로 번역하세요\")#← 메시지를 추가해 번역시킴\n",
    "])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4131e-ef84-48f3-a12c-b0ab1e4ac2fe",
   "metadata": {},
   "source": [
    "> 이렇게 매번 수기로 하지 않아도 대화 기록을 저장/불러올수 있는 Memory모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d2861-41f0-4cb4-93f5-0b8cd9ece8c8",
   "metadata": {},
   "source": [
    "## 2. 문맥에 맞는 답변을 할 수 있는 챗봇 만들기\n",
    "> 대화기록을 저장하고 불러오는 기능을 만들어보고, 문맥에 맞는 대답을 하는 챗봇서비스를 만들 예정\n",
    "- ConversationBufferMemory로 메모리 기능을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6b1fdd-b296-4a83-8147-8a8231122c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='안녕하세요!'), AIMessage(content='안녕하세요! 잘 지내고 계신가요? 궁금한 점이 있으면 알려 주세요. 어떻게 도와드릴까요?'), HumanMessage(content='오늘 날씨가 좋네요'), AIMessage(content='저는 AI이기 때문에 실제 날씨를 느낄 수는 없지만, 날씨가 좋은 날은 외출이나 활동을 즐기기에 좋은 날입니다!')]}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "가장 기본적인 속성인 ConversationBufferMemory를 알아보자\n",
    "'''\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory \n",
    "memory = ConversationBufferMemory( #← 메모리 초기화\n",
    "    return_messages=True, # chat models에서 memory모듈을 사용할수 있으려면 True로 설정\n",
    ") \n",
    "memory.save_context( # save_context로 메모리에 메시지를 추가\n",
    "    {\n",
    "        \"input\": \"안녕하세요!\"\n",
    "    },\n",
    "    {\n",
    "        \"output\": \"안녕하세요! 잘 지내고 계신가요? 궁금한 점이 있으면 알려 주세요. 어떻게 도와드릴까요?\"\n",
    "    }\n",
    ")\n",
    "memory.save_context( #← 메모리에 메시지를 추가\n",
    "    {\n",
    "        \"input\": \"오늘 날씨가 좋네요\"\n",
    "    },\n",
    "    {\n",
    "        \"output\": \"저는 AI이기 때문에 실제 날씨를 느낄 수는 없지만, 날씨가 좋은 날은 외출이나 활동을 즐기기에 좋은 날입니다!\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\n",
    "    memory.load_memory_variables({}) #← 메모리 내용을 확인\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4c10b-7356-4d5e-bf09-afae9a12937e",
   "metadata": {},
   "source": [
    "- 히스토리로 HumanMessage, AIMessage 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2fb928-7ca0-4872-a3fb-124b96d1890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "전과 다르게 메모리를 활용하여 문맥을 기억하는 챗봇을 만들자\n",
    "chainlit run chat_memory_1.py --port 8001\n",
    "'''\n",
    "import chainlit as cl\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory  #← ConversationBufferMemory 가져오기\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory( #← 메모리 초기화\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변할 수 있는 채팅봇입니다. 메시지를 입력하세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: str):\n",
    "    memory_message_result = memory.load_memory_variables({}) #←유저입력을 넘기기 전 메모리 내용부터 로드\n",
    "\n",
    "    messages = memory_message_result['history'] #← 메모리 내용에서 메시지(human+AI)만 얻음\n",
    "\n",
    "    messages.append(HumanMessage(content=message)) # 리스트처럼 append로 방금 메시지(human+AI)를 추가\n",
    "\n",
    "    result = chat( \n",
    "        messages #← Chat models에 messages를 넘긴다\n",
    "    )\n",
    "\n",
    "    memory.save_context(  #← 메모리에 메시지를 추가\n",
    "        {\n",
    "            \"input\": message,  #← 사용자의 메시지를 input으로 저장\n",
    "        },\n",
    "        {\n",
    "            \"output\": result.content,  #← AI의 메시지를 output으로 저장\n",
    "        }\n",
    "    )\n",
    "    await cl.Message(content=result.content).send() #← AI의 메시지를 송신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c47792a5-4c3b-4b85-993a-ed43bb536f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ConversationChain을 활용하면, 코드가 짧아짐\n",
    "chat_memory_2.py의 내용을 아래 내용으로 변경후\n",
    "chainlit run chat_memory_2.py --port 8001\n",
    "'''\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain  #← ConversationChain을 가져오기\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory( # ConversationBufferMemory로 메모리생성\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = ConversationChain( #← ConversationChain으로 memory+llm 파이프라인 생성\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변할 수 있는 채팅봇입니다. 메시지를 입력하세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: str):\n",
    "\n",
    "    result = chain( #← 위의 chain 가져옴\n",
    "        message #← 사용자 메시지를 인수로 지정\n",
    "    )\n",
    "\n",
    "    await cl.Message(content=result[\"response\"]).send()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c1acfb-721e-4055-b7b7-2174dac5be34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. 히스토리를 데이터베이스에 저장하고 영속화\n",
    "> 대화를 데이터베이스에 저장해 프로그램이 종료되도 기록이 삭제되지 않도록 한다\n",
    "- 대화기록을 저장할 데이터베이스로 Redis를 활용\n",
    "    + 레디스는 캐시, 메시징큐, 단기메모리 등으로 사용되는 고속 오픈소스 인메모리저장시스템\n",
    "    + key-value 쌍으로 저장되며 다양한 유형 지원(목록열,집합,해시,비트맵,하이퍼로그등)\n",
    "    + 메인 메모리에 데이터를 저장하기에 디스크기반 db보다 빠름\n",
    "    + 메모리 내 데이터는 휘발성이 있지만, 레디스는 주기적으로 디스크에 데이터를 기록함으로 영속성 제공\n",
    "    + 확장성과 고가용성을 보장하기 위한 복제/샤딩 기능도 갖추고 있음\n",
    "[upstash](https://upstash.com/)에서 redis를 이용하자\n",
    "[Langchain가이드라인](https://python.langchain.com/docs/integrations/memory/upstash_redis_chat_message_history/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6817f2f4-a5a5-4814-be99-050e2953b8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coroutine object Redis.execute at 0x000001FC39514EB0>\n"
     ]
    }
   ],
   "source": [
    "# # for sync client\n",
    "# from upstash_redis import Redis\n",
    "\n",
    "# redis = Redis(url=\"UPSTASH_URL\", token=\"UPSTASH_REDIS_REST_TOKEN\")\n",
    "\n",
    "# for async client\n",
    "from upstash_redis.asyncio import Redis\n",
    "\n",
    "redis = Redis(url=os.getenv(\"UPSTASH_REDIS_REST_URL\"), token=os.getenv(\"UPSTASH_REDIS_REST_TOKEN\"))\n",
    "redis.set(\"foo\", \"bar\")\n",
    "value = redis.get(\"foo\")\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fcc813a-6e58-46d4-bd6a-bdef89ff6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import (\n",
    "    UpstashRedisChatMessageHistory,)\n",
    "\n",
    "URL = \n",
    "TOKEN = \n",
    "\n",
    "history = UpstashRedisChatMessageHistory(\n",
    "    url=os.getenv(\"UPSTASH_REDIS_REST_URL\"), token=os.getenv(\"UPSTASH_REDIS_REST_TOKEN\"), \n",
    "    ttl=10, \n",
    "    session_id=\"my-test-session\"\n",
    ")\n",
    "\n",
    "history.add_user_message(\"hello llm!\")\n",
    "history.add_ai_message(\"hello user!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eba0d75-b442-4f14-90d1-3a607a0071d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-06 11:22:24 - Loaded .env file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\miniconda\\envs\\lang310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-06 11:22:29 - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'네, 계란찜 만드는 방법은 다음과 같습니다:\\n\\n준비물:\\n- 계란 6개\\n- 다진 파 2큰술\\n- 액젓 1큰술\\n- 설탕 1작은술\\n- 소금 약간\\n- 물 1과 1/2컵\\n\\n만드는 방법:\\n1. 계란을 그릇에 담아 물을 부어 섞어줍니다. 파, 액젓, 설탕, 소금을 넣고 다시 잘 섞어줍니다.\\n2. 준비한 그릇을 찜통에 넣고 20분 정도 찌면 됩니다. \\n3. 중간에 한 두 번 계란을 저어주면 부드러운 질감의 계란찜을 만들 수 있습니다.\\n4. 계란이 완전히 익으면 그릇을 꺼내 식힌 후 담아내면 완성입니다.\\n\\n계란의 신선도와 개인의 맛 선호도에 따라 약간씩 조절하면 더 맛있는 계란찜을 만들 수 있습니다. 궁금한 점이 더 있다면 물어보세요.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  #← 환경변수를 얻기 위해 os를 가져오기\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.chat_message_histories import UpstashRedisChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "message = '계란찜 만드는 방법 알려줘'\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    api_key=os.getenv(\"Anthropic_API_KEY\")\n",
    ")\n",
    "# 장기기억으로 upstash의 redis 이용\n",
    "'''\n",
    "대화내역이 redis에 저장되지 때문에 애플리케이션 종료 후에도 내역이 유지됨\n",
    "'''\n",
    "history = UpstashRedisChatMessageHistory(\n",
    "    url=os.getenv(\"UPSTASH_REDIS_REST_URL\"), token=os.getenv(\"UPSTASH_REDIS_REST_TOKEN\"), \n",
    "    session_id=\"my-test-session\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    chat_memory=history,  #← 채팅 기록을 지정\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "result = chain(message)\n",
    "result[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264064fe-140e-41a7-8c4a-e1d4a81c511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "기존의 내용을 기억하는 챗봇을 실행하고, 종료했다가 다시 이어서 실행해보세요\n",
    "chat_memory_3.py의 내용을 아래 내용으로 변경후\n",
    "chainlit run chat_memory_3.py --port 8002\n",
    "'''\n",
    "import os  #← 환경변수를 얻기 위해 os를 가져오기\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_message_histories import     UpstashRedisChatMessageHistory\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    api_key=os.getenv(\"Anthropic_API_KEY\")\n",
    ")\n",
    "\n",
    "history = UpstashRedisChatMessageHistory(\n",
    "    url=os.getenv(\"UPSTASH_REDIS_REST_URL\"),\n",
    "    token=os.getenv(\"UPSTASH_REDIS_REST_TOKEN\"), \n",
    "    session_id=\"chat_history\")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    chat_memory=history,  #← 채팅 기록을 지정\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변할 수 있는 채팅봇입니다. 메시지를 입력하세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: str):\n",
    "\n",
    "    result = chain(message)\n",
    "\n",
    "    await cl.Message(content=result[\"response\"]).send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a58332-cd63-45fc-9e6d-f275ad12ed56",
   "metadata": {},
   "source": [
    "> 어플리케이션을 새로 시작해도 history의 session_id 만 같으면 전의 내용을 기억합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea39f95-3e03-4482-a85a-fb417068717b",
   "metadata": {},
   "source": [
    "## 4. 여러개의 대화기록을 가질 수 있는 챗봇 만들기\n",
    "> 기존 시스템은 session_id를 변경이 불가능하여, 다른 대화를 할 수 없었다. 이를 할 수 있도록 하여, 이전에 어떤 대화를 했는지 복원하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ef82e-4418-4420-b6f2-a879918f8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.memory import ConversationBufferMemory, RedisChatMessageHistory\n",
    "from langchain_community.chat_message_histories import     UpstashRedisChatMessageHistory\n",
    "\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    api_key=os.getenv(\"Anthropic_API_KEY\"),\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    thread_id = None\n",
    "    while not thread_id: #← 스레드 ID가 입력될 때까지 반복\n",
    "        res = await cl.AskUserMessage(content=\"저는 대화의 맥락을 고려해 답변할 수 있는 채팅봇입니다. 스레드 ID를 입력하세요.\", timeout=600).send() #← AskUserMessage를 사용해 스레드 ID 입력\n",
    "        if res:\n",
    "            thread_id = res['content']\n",
    "\n",
    "    history = UpstashRedisChatMessageHistory(\n",
    "    url=os.getenv(\"UPSTASH_REDIS_REST_URL\"),\n",
    "    token=os.getenv(\"UPSTASH_REDIS_REST_TOKEN\"), \n",
    "    session_id=\"my-test-session\"\n",
    ")\n",
    "\n",
    "\n",
    "    memory = ConversationBufferMemory( #← 새로 채팅이 시작될 때마다 초기화하도록 on_chat_start로 이동\n",
    "        return_messages=True,\n",
    "        chat_memory=history,\n",
    "    )\n",
    "\n",
    "    chain = ConversationChain( #← 새로 채팅이 시작될 때마다 초기화하도록 on_chat_start로 이동\n",
    "        memory=memory,\n",
    "        llm=chat,\n",
    "    )\n",
    "\n",
    "    memory_message_result = chain.memory.load_memory_variables({}) #← 메모리 내용 가져오기\n",
    "\n",
    "    messages = memory_message_result['history']\n",
    "\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage): #← 사용자가 보낸 메시지인지 판단\n",
    "            await cl.Message( #← 사용자 메시지이면 authorUser를 지정해 송신\n",
    "                author=\"User\",\n",
    "                content=f\"{message.content}\",\n",
    "            ).send()\n",
    "        else:\n",
    "            await cl.Message( #← AI의 메시지이면 ChatBot을 지정해 송신\n",
    "                author=\"ChatBot\",\n",
    "                content=f\"{message.content}\",\n",
    "            ).send()\n",
    "    cl.user_session.set(\"chain\", chain) #← 기록을 세션에 저장\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: str):\n",
    "    chain = cl.user_session.get(\"chain\") #← 세션에서 기록을 가져오기\n",
    "\n",
    "    result = chain(message)\n",
    "\n",
    "    await cl.Message(content=result[\"response\"]).send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7cd1bf-90f1-4abc-bbe7-96efeee3621d",
   "metadata": {},
   "source": [
    "## 5. 매우 긴 대화 기록에 대응\n",
    "> 대화 기록을 영속화하고 과거 대화 기록도 가져올 수 있게 되었다. 하지만 대화가 매우 길어지면, LLM 입력에 한계가 있기에 에러가 발생한다. 이러한 에러를 해결해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6c6ace-a3cb-48b0-8ca8-6b58f3d532c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-06 21:05:16 - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "{ChatGPT의 답변인 볶음밥 만드는 방법}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "에러가 발생하는 사례 \n",
    "'''\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "load_dotenv()\n",
    "chain = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "result = chat([\n",
    "    HumanMessage(content=\"계란찜 만드는 방법을 알려줘\"),\n",
    "    AIMessage(content=\"{ChatGPT의 답변인 계란찜 만드는 방법}\"),\n",
    "    HumanMessage(content=\"만두 빚는 방법을 알려줘\")    ,\n",
    "    AIMessage(content=\"{ChatGPT의 답변인 만두 빚는 방법}\"),\n",
    "    HumanMessage(content=\"볶음밥 만드는 방법을 알려줘\")\n",
    "])   \n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5733b153-84b9-4343-aeb6-e02d69391e72",
   "metadata": {},
   "source": [
    "### 오래된 대화 삭제하기\n",
    "- 최근 k개의 대화를 남기고 오래된 대화를 삭제\n",
    "- ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e61e1-9fec-4926-aeef-f2158a6c70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "오래된 대화를 단순 삭제, 예>최근 3개만 기억\n",
    "chainlit run custom_memory_1.py --port 8002\n",
    "'''\n",
    "\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory  # ConversationBufferWindowMemory 가져오기\n",
    "load_dotenv()\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=3 # 3번 주고받은 메시지를 기억\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변할 수 있는 채팅봇입니다. 메시지를 입력하세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: str):\n",
    "    messages = chain.memory.load_memory_variables({})[\"history\"] # 저장된 메시지 가져오기\n",
    "\n",
    "    print(f\"저장된 메시지 개수: {len(messages)}\" # 저장된 메시지 개수를 표시\n",
    "          )\n",
    "\n",
    "    for saved_message in messages: # 저장된 메시지를 1개씩 불러옴\n",
    "        print(saved_message.content # 저장된 메시지를 표시\n",
    "              )\n",
    "\n",
    "    result = chain(message)\n",
    "\n",
    "    await cl.Message(content=result[\"response\"]).send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9c75d-e1e0-442f-9356-13fc95876203",
   "metadata": {},
   "source": [
    "### 지난 대화를 요약하여 토큰수 제한에 대응\n",
    "- 대화별 내용 요약\n",
    "- ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed030e-ea3e-413f-b099-f6b1cb4c802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "오래된 대화를 단순 삭제, 예>최근 3개만 기억\n",
    "chainlit run custom_memory_2.py --port 8002\n",
    "'''\n",
    "\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory  # ConversationBufferWindowMemory 가져오기\n",
    "load_dotenv()\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=chat,     # 요약 모델 지정\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변할 수 있는 채팅봇입니다. 메시지를 입력하세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(message: str):\n",
    "    messages = chain.memory.load_memory_variables({})[\"history\"] # 저장된 메시지 가져오기\n",
    "\n",
    "    print(f\"저장된 메시지 개수: {len(messages)}\") # 저장된 메시지 개수를 표시\n",
    "         \n",
    "\n",
    "    for saved_message in messages: # 저장된 메시지를 1개씩 불러옴\n",
    "        print(saved_message.content) # 저장된 메시지를 표시\n",
    "              \n",
    "    result = chain(message)\n",
    "    await cl.Message(content=result[\"response\"]).send()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang310",
   "language": "python",
   "name": "lang310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
