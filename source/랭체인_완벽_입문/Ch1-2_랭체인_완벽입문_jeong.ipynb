{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882ea644-96f4-459e-b319-a8c83bf1a5de",
   "metadata": {},
   "source": [
    "# ëª©ì°¨\n",
    "- Chapter1. ì±—GPTì™€ ë­ì²´ì¸\n",
    "    + 1. ì±—GPTì™€ ì–¸ì–´ëª¨ë¸ ì•Œì•„ë³´ê¸°\n",
    "    + 2. ë­ì²´ì¸ê°œìš” \n",
    "    + 3. ë­ì²´ì¸ í™œìš©ì˜ˆì‹œ \n",
    "    + 4. ì‹¤ìŠµì¤€ë¹„\n",
    "    + 5. OPENAIì˜ API í˜¸ì¶œ\n",
    "- Chapter2. Model I/O\n",
    "    + 1. ì–¸ì–´ëª¨ë¸ì„ ì´ìš©í•œ ì‘ìš©í”„ë¡œê·¸ë¨ ì‘ë™ë°©ì‹\n",
    "    + 2. ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ Language Models\n",
    "    + 3. Templates\n",
    "    + 4. Output parsers\n",
    "- Chapter3. Retrieval\n",
    "- Chapter4. Memory\n",
    "- Chapter5. Chains\n",
    "- Chapter6. Agents\n",
    "- Chapter7. Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555679b9-3c61-4293-889e-64814590668e",
   "metadata": {},
   "source": [
    "# Ch1. ì±—GPTì™€ ë­ì²´ì¸\n",
    "    + 1. ì±—GPTì™€ ì–¸ì–´ëª¨ë¸ ì•Œì•„ë³´ê¸°\n",
    "    + 2. ë­ì²´ì¸ê°œìš” \n",
    "    + 3. ë­ì²´ì¸ í™œìš©ì˜ˆì‹œ \n",
    "    + 4. ì‹¤ìŠµì¤€ë¹„\n",
    "    + 5. OPENAIì˜ API í˜¸ì¶œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a8ef7-bdd5-4b23-872d-a6c7521a612a",
   "metadata": {},
   "source": [
    "## 1. ì±—GPTì™€ ì–¸ì–´ëª¨ë¸ ì•Œì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1cc9a7-3ad7-488f-b8d9-2f73be980775",
   "metadata": {},
   "source": [
    "- OpenAIì˜ APIì—ì„œ ê°œë°œí•˜ëŠ” ì–¸ì–´ëª¨ë¸ì€ í¬ê²Œ ë‘ê°€ì§€ ë¶„ë¥˜ : 'Chat', 'Complete'\n",
    "    + Chat : ëŒ€í™”í˜• ìƒí˜¸ì‘ìš© íŠ¹í™”, ì§ˆë¬¸ ëŒ“ê¸€ ì˜ê²¬ ë“±ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê³  ê·¸ ë‹µë³€ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™” ë‚˜ëˆ”\n",
    "    + Complete : ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì— ì´ì–´ í…ìŠ¤íŠ¸ ìƒì„±, ì–´ëŠì •ë„ ì •ë³´/ì´ì•¼ê¸°ë¥¼ ì‹œì‘ ì œê³µí•˜ë©´ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìë™ ë³´ì™„\n",
    "        - í˜„ì¬ gpt-4ë‚˜ claud-3ëŠ” complete ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ\n",
    "- ëª¨ë¸ ì„ íƒ ì‹œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (í† í°ìˆ˜) ê³ ë ¤ í•„ìš” : ì¼ë°˜ëª¨ë¸ì€ 4k, 16këŠ” 16000ê°œê¹Œì§€ ì²˜ë¦¬ê°€ëŠ¥\n",
    "    + gpt-3.5-turbo ë“± ë’¤ì— 4ìë¦¬ê°€ ì—†ëŠ” ëª¨ë¸ì€ ìµœì‹ ëª¨ë¸ì„ì„ ì˜ë¯¸, ì—…ë°ì´íŠ¸ì‹œ ìë™ìœ¼ë¡œ ë°˜ì˜\n",
    "    + gpt-3.5-turbo-0613 ë“± ë’¤ì— 4ìë¦¬ ë¶™ì€ ëª¨ë¸ì€ íŠ¹ì • ë²„ì „ì´ ê³ ì •ëœ ê²ƒìœ¼ë¡œ ì—…ë°ì´íŠ¸ê°€ ë°˜ì˜ë˜ì§€ ì•ŠìŒ . íŠ¹ì •ê²°ê³¼ í•„ìš”í•˜ê±°ë‚˜ ë³€ë™ì„± í”¼í•˜ê³  ì‹¶ì„ë•Œ ì„ íƒ\n",
    "    + gpt-3.5-turbo-instructëŠ” ë¬¸ì œí•´ê²°, ë¬¸ì¥ìƒì„±, ì§ˆë¬¸ì‘ë‹µ, ëŒ€í™”ìƒì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì— í™œìš©\n",
    "    + claude2ëŠ” 100k í† í°ê¹Œì§€ ì…ë ¥ê°€ëŠ¥ : í”„ë¡œì íŠ¸ ì „ì²´ ì†ŒìŠ¤ì½”ë“œë¥¼ ìƒì„±í•˜ê³  ë²„ê·¸ ìˆ˜ì •ë„ ê°€ëŠ¥\n",
    "    + LLaMa3ëŠ” ì˜¤í”ˆì†ŒìŠ¤ì´ë‚˜, ì„±ëŠ¥ë©´ì—ì„œ íƒ€ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì••ë„, íŠ¹íˆ 70bëª¨ë¸ì€ claude3ë‚˜ GPT4ì˜ ì„±ëŠ¥ì— ê·¼ì ‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe86032-637a-456d-8db1-a712b879940f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Groqì„ ì¨ì„œ ë¡œì»¬ëª¨ë¸ë„ ë¬´ë£Œë¡œ ëŒë¦¬ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed605c-1049-4496-b14b-1593572f200b",
   "metadata": {},
   "source": [
    "- Groqì„ ì“°ë©´ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ë°›ì„ í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ì†ë„ëŠ” ì‹¬ì§€ì–´ AWS, Azureë³´ë‹¤ 10ë°°ì´ìƒ ë¹ ë¦…ë‹ˆë‹¤.\n",
    "- ë¬´ë£Œì´ë©°, ê¸°ì—…ìš©ì€ ë³„ë„ë¡œ ë¹„ìš©ì´ ë°œìƒ ì˜ˆìƒí•©ë‹ˆë‹¤, [API ë°œê¸‰](https://console.groq.com/docs/quickstart) í›„ ì‚¬ìš©í•˜ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64f501b2-b80b-4afd-9eb8-2a7cdf3ff480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì¹˜ì•„ í•˜nin! AIì‹œëŒ€ì— ì¤€ë¹„í•  ê°€ì¹˜ê°€ ìˆëŠ” ê°€ì¥ ê¸°ì´ˆì ì¸ ê²ƒ ê°™ì§€ëŠ” ì•Šë‚˜ìš”?ó §ó ¢ó ¥ó ®ó §ó ¿\n",
      "\n",
      "ìš°ì„ , AIì˜ ë°œì „í•˜ê³  ìˆëŠ” ì†ë„ì— ë§ì¶° ìš°ë¦¬ ìŠ¤ìŠ¤ë¡œë¥¼ ì—…ê·¸ë ˆì´ë“œí•˜ëŠ” ê²ƒì€ ì •ë§ ì¤‘ìš”í•  ê²ƒ ê°™ì•„ìš”. ì˜ˆë¥¼ ë“¤ì–´, ìƒˆë¡œìš´ ê¸°ìˆ ê³¼ ê°™ì€ ì •ë³´ë¥¼ í•´ë¶€í•˜ê³ , AIë¥¼ ì ‘ëª©ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ì— ì°¸ê°€í•˜ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”. Ñ‚Ğ¸Ğ¼ì— ìˆëŠ” ì¹œêµ¬ë“¤ì€ ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆê¹Œ?ğŸ¤”\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "load_dotenv()\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "               {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ì¡´ëŒ“ë§ ì“°ì§€ë§ê³ , ì¹œí•œì¹œêµ¬ì²˜ëŸ¼ í•œêµ­ì–´ë¡œ ë‹µë³€\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"AIì‹œëŒ€ì— ìš°ë¦° ë¬´ì—‡ì„ ì¤€ë¹„í•´ì•¼ í• ê¹Œ?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content) # ì •ì ìœ¼ë¡œ ì°ì„ ë•Œ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fd031fb-81d9-4471-8f4f-7edebf764e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™€ìš°, ì§„ì§œ ì¢‹ì€ ì§ˆë¬¸ì´ì•¼! ğŸ˜Š\n",
      "\n",
      "ì†”ì§íˆ, ê²°í˜¼í•˜ê³  ì•  í‚¤ìš°ëŠ” ê±´ ì„ íƒì˜ ë¬¸ì œì•¼. í•˜ì§€ë§Œ, ë§ì€ ì‚¬ëŒë“¤ì´ ê·¸ë ‡ê²Œ ì„ íƒí•˜ëŠ” ì´ìœ ëŠ” ì—¬ëŸ¬ ê°€ì§€ì•¼.\n",
      "\n",
      "ì²«ì§¸, ì‚¬ë‘í•˜ëŠ” ì‚¬ëŒê³¼ í•¨ê»˜ ì‚´ì•„ë‚¨ëŠ” ê±´ ì¸ê°„ì˜ ê¸°ë³¸ì ì¸ ìš•êµ¬ì•¼. ìš°ë¦¬ëŠ” ì‚¬íšŒì  ë™ë¬¼ì´ë¼, ê°€ì¡±ì´ë‚˜ ì¹œì²™ë“¤ê³¼ì˜ ìœ ëŒ€ê°ì´ í•„ìš”í•´. ê²°í˜¼í•˜ê³  ì•  í‚¤ìš°ëŠ” ê±´ ì´ëŸ¬í•œ ìœ ëŒ€ê°ì„ ê°•í™”í•˜ê³ , ì„œë¡œë¥¼ ì§€ì§€í•˜ê³  ì§€ì›í•˜ëŠ” ê´€ê³„ë¥¼ í˜•ì„±í•˜ëŠ” ê±°ì•¼.\n",
      "\n",
      "ë‘˜ì§¸, ì¸ê°„ì€ ìƒì¡´ê³¼ ë²ˆì˜ì„ ìœ„í•´ ë…¸ë ¥í•˜ëŠ” ìƒë¬¼ì´ì•¼. ê²°í˜¼í•˜ê³  ì•  í‚¤ìš°ëŠ” ê±´ ì´ëŸ¬í•œ ìƒì¡´ ë³¸ëŠ¥ì„ ì¶©ì¡±í•˜ëŠ” ë°©ë²•ì´ì•¼. ìš°ë¦¬ëŠ” ê°€ì¡±ì„ í†µí•´ ë‹¤ìŒ ì„¸ëŒ€ë¥¼ ì´ì–´ë‚˜ê°€ê³ , ìš°ë¦¬ì˜ ìœ ì‚°ì„ ë‚¨ê¸°ëŠ” ê±°ì•¼.\n",
      "\n",
      "ì…‹ì§¸, ê²°í˜¼í•˜ê³  ì•  í‚¤ìš°ëŠ” ê±´ ê°œì¸ì˜ ì„±ì¥ê³¼ ë°œì „ì„ ìœ„í•´ í•„ìš”í•œ ê±°ì•¼. ìš°ë¦¬ëŠ” ì•„ì´ë“¤ì„ í†µí•´ ìƒˆë¡œìš´ ê²½í—˜ê³¼ ì§€ì‹ì„ ì–»ì„ ìˆ˜ ìˆê³ , ë¶€ëª¨ë¡œì„œì˜ ì±…ì„ê°ì„ ëŠê»´. ì´ëŸ¬í•œ ê²½í—˜ì€ ìš°ë¦¬ì˜ ì„±ì¥ê³¼ ë°œì „ì„ ìœ„í•´ í•„ìš”í•œ ê±°ì•¼.\n",
      "\n",
      "ë„·ì§¸, ê²°í˜¼í•˜ê³  ì•  í‚¤ìš°ëŠ” ê±´ ì‚¬íšŒì  ì±…ì„ê°ì„ ëŠê»´. ìš°ë¦¬ëŠ” ì‚¬íšŒì˜ êµ¬ì„±ì›ìœ¼ë¡œì„œ, ë‹¤ìŒ ì„¸ëŒ€ë¥¼ ì´ì–´ë‚˜ê°€ê³ , ì‚¬íšŒì˜ ë°œì „ì„ ìœ„í•´ ê¸°ì—¬í•˜ëŠ” ê±°ì•¼.\n",
      "\n",
      "ë¬¼ë¡ , ì´ëŸ¬í•œ ì´ìœ ë“¤ì´ ëª¨ë“  ì‚¬ëŒì—ê²Œ ì ìš©ë˜ëŠ” ê±´ ì•„ë‹ˆì•¼. í•˜ì§€ë§Œ, ë§ì€ ì‚¬ëŒë“¤ì´ ê²°í˜¼í•˜ê³  ì•  í‚¤ìš°ëŠ” ê²ƒì€ ì´ëŸ¬í•œ ì´ìœ ë“¤ ë•Œë¬¸ì´ì•¼. ğŸ¤”None"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "load_dotenv()\n",
    "\n",
    "client = Groq(\n",
    " api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    #\n",
    "    # Required parameters\n",
    "    #\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ì¹œí•œì¹œêµ¬ì²˜ëŸ¼, ì¡´ëŒ“ë§ ì“°ì§€ë§ê³  ë‹µë³€\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì™œ ê²°í˜¼ì„ í•˜ê³ , ì• ë¥¼ í‚¤ìš°ë©° ì‚´ì•„ì•¼ í• ê¹Œ?\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    model=\"llama3-70b-8192\",\n",
    "\n",
    "    # íŒŒë¼ë¯¸í„° ì…‹íŒ…\n",
    "    #\n",
    "    # Controls randomness: lowering results in less random completions.\n",
    "    # As the temperature approaches zero, the model will become deterministic\n",
    "    # and repetitive.\n",
    "    temperature=0.5,\n",
    "\n",
    "    # The maximum number of tokens to generate. Requests can use up to\n",
    "    # 32,768 tokens shared between prompt and completion.\n",
    "    max_tokens=1024,\n",
    "\n",
    "    # Controls diversity via nucleus sampling: 0.5 means half of all\n",
    "    # likelihood-weighted options are considered.\n",
    "    top_p=0.7,\n",
    "\n",
    "    # A stop sequence is a predefined or user-specified text string that\n",
    "    # signals an AI to stop generating content, ensuring its responses\n",
    "    # remain focused and concise. Examples include punctuation marks and\n",
    "    # markers like \"[end]\".\n",
    "    stop=None,\n",
    "\n",
    "    # If set, partial message deltas will be sent.\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# stream=True ë¡œ ì„¤ì •ì‹œ, chunkë¡œ ë£¨í”„ëŒë ¤ì„œ choices[0].deltaë¡œ ê°€ì ¸ì˜´\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1d6ef-1e0b-41d9-abdb-6f5c04293b5d",
   "metadata": {},
   "source": [
    "## 2. ë­ì²´ì¸ê°œìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef3fb6-ff16-4caf-81fa-24950cc46cd2",
   "metadata": {},
   "source": [
    "- ê³ ì„±ëŠ¥ ì–¸ì–´ëª¨ë¸ì˜ ë“±ì¥ìœ¼ë¡œ ê¸°ì¡´ ì ˆì°¨ì  í”„ë¡œê·¸ë˜ë°ì—ì„œ ì–´ë ¤ì› ë˜ ê¸°ëŠ¥ì„ ì‰½ê²Œ ì²˜ë¦¬ (ìì—°ì–´ ì²˜ë¦¬ ë° í‘œí˜„ ìˆ˜ì • ë“±)\n",
    "    - í•œê³„ :  ë…¼ë¦¬ì  ë³µì¡í•œ ë¬¸ì œë‚˜ í•™ìŠµì§€ì‹ì˜ ë²”ìœ„ ë²—ì–´ë‚˜ëŠ” ì •ë³´ ëŒ€ì¡ ì–´ë ¤ì›€\n",
    "- ì´ëŸ° í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì–¸ì–´ëª¨ë¸ì´ ì•Œì§€ëª»í•˜ëŠ” ì •ë³´ë„ ëŒ€ë‹µí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” RAG (Retrieval-Augmented Generation), ì¶”ë¡ ê³¼ í–‰ë™ì„ ì–¸ì–´ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ ì¸í„°ë„·ê²€ìƒ‰ì´ë‚˜ íŒŒì¼ ì €ì¥ ë“±ì„ ììœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê²Œ í•˜ëŠ” React(Reasoming And Acting, ì¶”ë¡  ë° í–‰ë™)\n",
    "- Langchainì˜ 6ê°œ ëª¨ë“ˆ : [ë­ì²´ì¸ ë‹¤íë¨¼íŠ¸ ì°¸ê³ ](https://python.langchain.com/docs/get_started/introduction.html)\n",
    "    - Model I/O : ì–¸ì–´ëª¨ë¸ í˜¸ì¶œ/í”„ë¡¬í”„íŠ¸ ì¤€ë¹„/ê²°ê³¼ìˆ˜ì‹ \n",
    "    - Retrieval : PDF, CSV, VectorDB ë“±ì—ì„œ ì—°ê´€ëœ ì •ë³´ë¥¼ ì…ì¶œë ¥ì €ì¥\n",
    "    - Memory : ëŒ€í™”ë¥¼ ì¥/ë‹¨ê¸°ì  ì €ì¥\n",
    "    - Chains : ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ í†µí•©/ë³µì¡í•œ ê¸°ëŠ¥ê°œë°œì„ ì‰½ê²Œ ì§„í–‰\n",
    "    - Agents : ëª¨ë¸ì™¸ë¶€ì™€ ìƒí˜¸ì‘ìš©í•˜ì—¬ ê¸°ëŠ¥ í™•ì¥ (ì˜ˆ> ê´€ë ¨ëœ ë…¼ë¬¸ ê²°ê³¼ë¥¼ í¬ë¡¤ë§, Ragë¡œ ì €ì¥, ì´ë¯¸ì§€ ì¸ì‹)\n",
    "    - Callbacks : ì´ë²¤íŠ¸ ë°œìƒì‹œ ì²˜ë¦¬ ìˆ˜í–‰ (ë¡œê·¸ ì¶œë ¥ì´ë‚˜ ì™¸ë¶€ë¼ì´ë¸ŒëŸ¬ë¦¬ì—°ë™ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244977b5-0435-488b-833e-722c743c9002",
   "metadata": {},
   "source": [
    "## 3. ë­ì²´ì¸ í™œìš©ì˜ˆì‹œ\n",
    "> ë­ì²´ì¸ìœ¼ë¡œ ì–´ë–¤ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ìˆ˜ ìˆì„ê¹Œ\n",
    "- ì–¸ì–´ëª¨ë¸ì´ ëª¨ë¥´ëŠ” ì •ë³´ê°€ ìˆëŠ” PDFë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì§ˆë¬¸í•˜ê±°ë‚˜ ìš”ì•½í•  ìˆ˜ ìˆëŠ” ì±—ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±\n",
    "- ëª…ë ¹ì„ í†µí•´ í–‰ë™í•˜ëŠ” ë¹„ì„œì—­í• ì˜ ì„œë¹„ìŠ¤ \n",
    "    + ì˜ˆ > ë¶€ì‚°ì— ê°ˆë§Œí•œ ê³³ì„ ê²€ìƒ‰í•˜ê³  2ë°•3ì¼ ì¼ì •í‘œë¥¼ ì§œì„œ iternery.csvíŒŒì¼ì— í•œêµ­ì–´ë¡œ ì €ì¥í•´ì¤˜\n",
    "- ì±—ì§€í”¼í‹°ëŠ” ì¼ë°˜ì¸ì´ í”ŒëŸ¬ê·¸ì¸ì„ ì„¤ì¹˜í•´ì„œ ë‹¨ìˆœ ì‚¬ìš©í•œë‹¤ë©´, ë­ì²´ì¸ì€ ê°œë°œìê°€ ë³´ë‹¤ í™•ì¥ì„± ìˆê²Œ ì–¸ì–´ëª¨ë¸ì´ í• ìˆ˜ ì—†ëŠ” ì¼ì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ìˆ˜ ìˆë‹¤\n",
    "    + ì˜ˆ > êµ¬ê¸€ìº˜ë¦°ë”, ì§€ë©”ì¼ì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ ë§¤ì¼ ì•„ì¹¨ slackì—ì„œ ì˜¤ëŠ˜ ì¼ì •ê³¼ í• ì¼ ëª©ë¡ì„ ì œì•ˆ\n",
    "    \n",
    "> ë‚˜ë§Œì˜ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì–´ ë³´ì\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22f330-c6c3-4c38-8bab-dd290415def0",
   "metadata": {},
   "source": [
    "## 4. ì‹¤ìŠµì¤€ë¹„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e2415-778c-47db-87aa-f3c1fe83ca83",
   "metadata": {},
   "source": [
    "- [1. ë¹„ì£¼ì–¼ ìŠ¤íŠœë””ì˜¤ ì„¤ì¹˜](https://azure.microsoft.com/ko-kr/products/visual-studio-code) ë° [íŒŒì´ì¬ë‹¤ìš´ë¡œë“œ](https://www.python.org/downloads/)\n",
    "- [2.ì£¼í”¼í„°ë© ì„¤ì¹˜](https://youtu.be/kuhtXwYlvjc?si=UWjIARPutkrWffa8)\n",
    "- [3.ê°€ìƒí™˜ê²½ì„¤ì¹˜ ë° ì£¼í”¼í„°ë©ì—ë„ìš°ê¸°](https://github.com/restful3/ds4th_study/blob/main/source/%EB%9E%AD%EC%B2%B4%EC%9D%B8_%EC%99%84%EB%B2%BD_%EC%9E%85%EB%AC%B8/langchain/langchain%20%ED%99%98%EA%B2%BD%20%EC%84%A4%EC%A0%95.md)\n",
    "- [4. OPENAI APIë‹¤ìš´ë°›ê¸°](https://openai.com/blog/openai-api)\n",
    "- [5. dotenv ì„¤ì •í•˜ê¸°](https://hyunhp.tistory.com/718)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aaee27-3528-4080-93ca-b1ae43d46d4a",
   "metadata": {},
   "source": [
    "## 5. OPENAIì˜ APIë¥¼ í˜¸ì¶œí•´ë³´ì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cd8282-01e1-4e3e-96cb-9103b0bf4bf7",
   "metadata": {},
   "source": [
    "[dotenv](https://hyunhp.tistory.com/718) ì„¤ëª…ì„ ì°¸ì¡°í•˜ì—¬ API Passwordë¥¼ ì €ì¥í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e8bd9f2-512a-4aba-b0a9-43eb499f7a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMì´ ê°‘ìê¸° ëœ¬ ì´ìœ ëŠ” ë‹¤ì–‘í•  ìˆ˜ ìˆê² ì§€ë§Œ, ê·¸ ì¤‘ ì¼ë°˜ì ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì´ìœ ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ë§ˆì¼€íŒ… í™œë™: LLMì´ ê°‘ìê¸° ëœ¬ ì´ìœ  ì¤‘ í•˜ë‚˜ëŠ” ë§ˆì¼€íŒ… í™œë™ì´ ì„±ê³µì ìœ¼ë¡œ ì´ë¤„ì¡Œê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ê´‘ê³  ìº í˜ì¸, ì†Œì…œ ë¯¸ë””ì–´ í™ë³´, í˜¹ì€ ìƒˆë¡œìš´ ì œí’ˆ ëŸ°ì¹­ ë“±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. ì´ë²¤íŠ¸ë‚˜ í–‰ì‚¬ ì°¸ì—¬: LLMì´ ê°‘ìê¸° ëœ¨ê²Œ ëœ ì´ìœ  ì¤‘ í•˜ë‚˜ë¡œëŠ” ì–´ë–¤ ì´ë²¤íŠ¸ë‚˜ í–‰ì‚¬ì— ì°¸ì—¬í•˜ê±°ë‚˜ ì£¼ëª©ì„ ë°›ì•˜ê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì¸ì§€ë„ê°€ ì¦ëŒ€ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. ì»¤ë®¤ë‹ˆí‹°ë‚˜ ì˜¨ë¼ì¸ ì»¨í…ì¸ ì—ì„œ ì£¼ëª©ì„ ë°›ìŒ: LLMì´ ì»¤ë®¤ë‹ˆí‹°ë‚˜ ì˜¨ë¼ì¸ ì»¨í…ì¸ ì—ì„œ í™”ì œê°€ ë˜ì—ˆê¸° ë•Œë¬¸ì— ê°‘ìê¸° ëœ¬ ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì–´ë–¤ ì´ìŠˆì— ëŒ€í•œ ë…¼ë€ì´ ìˆì—ˆë‹¤ë©´, í•´ë‹¹ ì´ìŠˆì— ê´€ë ¨ëœ LLMì´ ê´€ë ¨ì„±ì„ ì–»ì—ˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ì´ìœ ë“¤ì´ LLMì´ ê°‘ìê¸° ëœ¬ ì´ìœ  ì¤‘ ì¼ë¶€ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ìƒí™©ì´ë‚˜ ë°°ê²½ ì •ë³´ì— ë”°ë¼ ë‹¤ë¥¸ ì´ìœ ê°€ ìˆì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ê¸°ë³¸ ì±—íŒ…ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ì„ ë¶ˆëŸ¬ì™€ ë´…ì‹œë‹¤.\n",
    "'''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "# from openai import OpenAI\n",
    "\n",
    "# ëª¨ë¸ë³„ API pwë¥¼ ì €ì¥í•©ë‹ˆë‹¤ .env íŒŒì¼ì— ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# \n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"LLMì´ ê°‘ìê¸° ëœ¬ ì´ìœ ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6508f577-07c2-4854-9491-56e3044b2aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-9JKtM2LT6Vi9GFC8Qf9ZuTFKzIxl3', 'choices': [CompletionChoice(finish_reason='stop', index=0, logprobs=None, text=' ì¢‹ë‹¤'), CompletionChoice(finish_reason='stop', index=1, logprobs=None, text=' ì¢‹ë‹¤\\n\\nì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë§¤ìš° ì¢‹ì•„ì„œ ê¸°ë¶„ë„ ì¢‹ì•„ìš”')], 'created': 1714395568, 'model': 'gpt-3.5-turbo-instruct', 'object': 'text_completion', 'system_fingerprint': None, 'usage': CompletionUsage(completion_tokens=30, prompt_tokens=18, total_tokens=48)}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=\"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë§¤ìš° ì¢‹ê³  ê¸°ë¶„ì´\",\n",
    "    stop=\".\",  #â†ë¬¸ìê°€ ë‚˜íƒ€ë‚˜ë©´ ë¬¸ì¥ ì¢…ë£Œ\n",
    "    max_tokens=100,  #â† ìµœëŒ€ í† í° ìˆ˜\n",
    "    n=2,  #â† ìƒì„±í•  ë¬¸ì¥ ìˆ˜\n",
    "    temperature=0.5  #â†ë‹¤ì–‘ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë§¤ê°œë³€ìˆ˜\n",
    "    \n",
    ")\n",
    "# Convert the Completion object to a dictionary\n",
    "response_dict = response.__dict__\n",
    "\n",
    "# Print the dictionary as JSON\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9322102-e52f-4c36-bb22-67f037aa594b",
   "metadata": {},
   "source": [
    "- ì¢‹ì€ ê²°ê³¼ë¥¼ ìœ„í•´ì„œëŠ” ë”  ë§¥ë½ì„ ê³ ë ¤í•œ í”„ë¡¬í”„íŠ¸ ì…ë ¥ì´ í•„ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f101232-d386-408c-96d4-7393163b58d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMì¸ ChatGPTëŠ” OpenAIì—ì„œ ê°œë°œí•œ ëŒ€í™”í˜• ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ GPT-3 ëª¨ë¸ì— ëŒ€í™” ê´€ë ¨ ëŠ¥ë ¥ì„ ì¶”ê°€í•œ ê²ƒìœ¼ë¡œ, ë§Œì•½ ì•„ì§ LLMì´ ëŒ€ë‘ë˜ê¸° ì „ì´ë¼ë©´, ê·¸ ë°°ê²½ì€ GPT-3ì˜ ì„±ê³µì ì¸ ì¶œì‹œì™€ ëŒ€í™” ìƒì„± ë¶„ì•¼ì—ì„œì˜ ëŒ€ë‹¨í•œ ì„±ê³¼ì— ê¸°ì¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "ChatGPTëŠ” ë†€ë¼ìš´ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì–´ ê¸°ì—… ë° ê°œì¸ì´ ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì—ì„œ í™œìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì•¼ì—ì„œëŠ” ê³ ê° ì„œë¹„ìŠ¤ ì§ˆì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´, ChatGPTë¥¼ ìƒë‹´ì›ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ëŒ€í™”ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ChatGPTëŠ” íŠ¹ì • ë„ë©”ì¸ì— íŠ¹í™”ëœ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì§€ì‹ì„ í•™ìŠµí•˜ê³  ì‚¬ìš©ìì—ê²Œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆëŠ” ì—­í• ë„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë˜í•œ ChatGPTëŠ” ê°œë³„ì ì¸ ì‚¬ìš©ì ìŠ¤íƒ€ì¼ì— ë§ê²Œ í•™ìŠµë  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•¨ìœ¼ë¡œì¨ ê°œì¸í™”ëœ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ì‚¬ìš©ìì˜ ì“°ëŠ” ìŠ¤íƒ€ì¼ê³¼ ê´€ì‹¬ì‚¬ë¥¼ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ChatGPTì˜ ì˜í–¥ë ¥ì€ ì´ë¯¸ ìƒë‹¹íˆ í½ë‹ˆë‹¤. ìƒìš©í™”ë˜ë©´ì„œ ë§ì€ ê¸°ì—…ë“¤ì€ ChatGPTë¡œ ê³ ê° ì„œë¹„ìŠ¤ì™€ ì¸í„°ë™ì…˜ì„ ê°œì„ í•˜ê±°ë‚˜, ëŒ€í™” ë°ì´í„°ë¥¼ ìƒì„±í•¨ìœ¼ë¡œì¨ ëŒ€í™” ë°ì´í„°ì…‹ì„ í™•ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ChatGPTëŠ” ë˜í•œ ì—”í„°í…Œì¸ë¨¼íŠ¸ ë¶„ì•¼ì—ì„œë„ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ChatGPTëŠ” ë„“ì€ ë²”ìœ„ì˜ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ê±°ë‚˜, ê°€ìƒì˜ ì¸ë¬¼ê³¼ ëŒ€í™”í•˜ëŠ” ë“± í˜„ì‹¤ ì„¸ê³„ì™€ ê°€ìƒ ì„¸ê³„ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì•ìœ¼ë¡œëŠ” ChatGPTì™€ ê°™ì€ LLMì˜ ë°œì „ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤. OpenAIëŠ” ê³„ì†í•´ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ìˆìœ¼ë©°, ê°œë°œìë“¤ì—ê²Œ ë‹¤ì–‘í•œ APIì™€ ë„êµ¬ë¥¼ ì œê³µí•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” ë° ë„ì›€ì„ ì£¼ê³  ìˆìŠµë‹ˆë‹¤. LLMì€ ì§€ì‹ì˜ ì „ë‹¬, ê°œì¸í™”ëœ ì»¨í…ì¸  ìƒì„±, ê³ ê° ì„œë¹„ìŠ¤ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.\n",
      "\n",
      "ë˜í•œ, OpenAIëŠ” LLMì˜ ì‚¬ìš©ì— ê´€í•œ ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ê³¼ ê°€ëŠ¥í•œ í•œ ë¶€ì •ì ì¸ ì˜í–¥ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ê¸°ìˆ ì  ë° ì œí•œì  ì œì–´ ë°©ë²•ì„ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ChatGPTì™€ LLMê³¼ ê´€ë ¨ëœ ì´ëŸ¬í•œ ì§„ë³´ë“¤ì€ ì‹œê°„ì´ íë¥¸ ë’¤ ìš°ë¦¬ì˜ ì¼ìƒ ìƒí™œê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” ëª¨ìŠµì„ ë„“ê²Œ ë°”ê¿€ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë” ê¸´ë¬¸ì¥ì„ í˜¸ì¶œí•  ë•Œ ëª¨ë¸ì„ ë°”ê¿ˆ\n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ChatGPT ê°™ì€ LLMì´ ìš”ì¦˜ì— í•«í•œë°, ëŒ€ë‘ê°€ ëœ ë°°ê²½ê³¼ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìœ¼ë©°, \\\n",
    "             ì•ìœ¼ë¡œëŠ” ì–´ë–»ê²Œ ë°”ë€”ì§€ ìƒì„¸íˆ ì•Œë ¤ì¤˜ \",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed8724-1ad4-43f0-8400-761f04f79bd8",
   "metadata": {},
   "source": [
    "- openaiì—ì„œ antroprophicìœ¼ë¡œ ë°”ê¿€ ê²½ìš° ì½”ë“œí˜¸ì¶œì´ ë¶ˆê°€ëŠ¥\n",
    "- ê·¸ë˜ì„œ language model(langchainë“±)ì„ ì“°ëŠ”ì´ìœ ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd5954-b92a-4374-992e-900cb707f7c0",
   "metadata": {},
   "source": [
    "# Ch2. Model I/O\n",
    "    + ì–¸ì–´ëª¨ë¸ì„ ì´ìš©í•œ ì‘ìš©í”„ë¡œê·¸ë¨ ì‘ë™ë°©ì‹\n",
    "    + ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ Language Models\n",
    "    + Templates\n",
    "    + Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756212d-2ab2-4e42-a681-2d1a68e5ee3a",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1. ì–¸ì–´ëª¨ë¸ì„ ì´ìš©í•œ ì‘ìš©í”„ë¡œê·¸ë¨ ì‘ë™ë°©ì‹\n",
    " - ê° íšŒì‚¬ì˜ ëª¨ë¸ì„ ì‰½ê²Œ ê°€ì ¸ë‹¤ ì“¸ ìˆ˜ ìˆìŒ\n",
    " - í”„ë¡¬í”„íŠ¸í…œí”Œë¦¿ì„ í†µí•´ ë³€ìˆ˜ë¥¼ ë°”ê¿”ê°€ë©° ì…ë ¥ ê°€ëŠ¥\n",
    " - output parsers ëª¨ë“ˆì€ ì–¸ì–´ëª¨ë¸ì—ì„œ ì–»ì€ ì¶œë ¥ì„ ë¶„ì„/ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6fc7c25-3444-4329-9c7f-208488f7d6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë„ì™€ë“œë¦´ ì¼ì´ ìˆë‚˜ìš”? :)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI  #chat ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° : openaië¿ ì•„ë‹ˆë¼ claudeë„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ\n",
    "from langchain.schema import HumanMessage  #â† ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì¸ HumanMessage ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "## ëª¨ë¸ê°ì²´ ë§Œë“¤ê¸°\n",
    "chat = ChatOpenAI(  #â† í´ë¼ì´ì–¸íŠ¸ë¥¼ ë§Œë“¤ê³  chatì— ì €ì¥\n",
    "    model=\"gpt-3.5-turbo\",  #â† í˜¸ì¶œí•  ëª¨ë¸ ì§€ì •\n",
    ")\n",
    "\n",
    "## ìœ„ì—ì„œ ë§Œë“  ê°ì²´ ì‹¤í–‰í•˜ê¸°\n",
    "result = chat( #â† ì‹¤í–‰í•˜ê¸°\n",
    "    [\n",
    "        HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”!\"),\n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20061e-01c1-4f5e-a005-3bdf02629dca",
   "metadata": {},
   "source": [
    "### AIMessageë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¸ì–´ëª¨ë¸ì˜ ì‘ë‹µì„ í‘œí˜„í•  ìˆ˜ ìˆìŒ\n",
    "- ëŒ€í™”í˜•ì‹ì˜ ìƒë¡œì‘ìš©ì„ í‘œí˜„ ìœ„í•´ AI Messageë„ ì¤€ë¹„ë¨. \n",
    "    - ì²«ë²ˆì§¸ HumanMessageì— ë ˆì‹œí”¼ë¥¼ ë°˜í™˜,\n",
    "    - ì•„ë˜ì™€ ê°™ì€ ëŒ€í™”íë¦„ì—ì„œ ì–´ë–»ê²Œ í‘œí˜„í•˜ëŠ”ì§€ ë³´ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40f10afc-8a01-4251-9d91-7f8aa8e5ac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” í•œêµ­ì–´ë§Œ ì§€ì›í•˜ê³  ìˆì–´ì„œ ì¸ë„ë„¤ì‹œì•„ì–´ë¡œ ë²ˆì—­í•´ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì£„ì†¡í•©ë‹ˆë‹¤. í˜¹ì‹œ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "result = chat( #â† ì‹¤í–‰í•˜ê¸°\n",
    "    [\n",
    "        HumanMessage(content=\"Kpopë¬¸í™”ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"),\n",
    "        AIMessage(content=\"{ChatModelì˜ ë‹µë³€}\"),\n",
    "        HumanMessage(content=\"ì¸ë„ë„¤ì‹œì•„ì–´ë¡œ ë²ˆì—­í•´ì¤˜\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c465e6-e9eb-4139-bba6-832e69c34f4c",
   "metadata": {},
   "source": [
    "> HumanMessage, AIMessageë¥¼ í†µí•´ ìƒí˜¸ì‘ìš©ì„ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.\n",
    "ìœ„ì˜ ë­ê·€ì§€ ëª¨ë¸ë§Œìœ¼ë¡œëŠ” ë§¤ë²ˆ ì†ŒìŠ¤ì½”ë“œë¥¼ ë‹¤ì‹œ ì‘ì„±í•´ì•¼ í•˜ë¯€ë¡œ ë²ˆê±°ë¡œì›€\n",
    "- ìƒí˜¸ì‘ìš©ì„ ì§€ì›í•˜ê¸° ìœ„í•´ Memoryëª¨ë“ˆì´ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae5981-315e-4219-8e08-1a419f5eee11",
   "metadata": {},
   "source": [
    "### SystemMessageë¥¼ í†µí•´ ë©”íƒ€ ì§€ì‹œ ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8cc92f6-f4f7-404f-8480-4aa2941c1f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•! ë°¥ì€ ì•„ì§ ì•ˆ ë¨¹ì—ˆì–´. ë„ˆëŠ” ë¨¹ì—ˆë‹ˆ?\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "result = chat( #â† ì‹¤í–‰í•˜ê¸°\n",
    "    [\n",
    "        SystemMessage(content=\"ì¹œí•œì¹œêµ¬ì²˜ëŸ¼, ì¡´ëŒ“ë§ ì“°ì§€ë§ê³  ì†”ì§í•˜ê²Œ ë‹µë³€\"),\n",
    "        HumanMessage(content=\"ì•ˆë…•? ë°¥ì€ ë¨¹ì—ˆë‹ˆ\"),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03907583-0565-4a16-8063-0c7bb1392554",
   "metadata": {},
   "source": [
    "### ì–¸ì–´ëª¨ë¸ ë°”ê¿”ë³´ì ì•¤íŠ¸ë¡œí”½ìœ¼ë¡œ!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830094b3-4501-4b6c-91bf-e30644e4570c",
   "metadata": {},
   "source": [
    "[ì—”íŠ¸ë¡œí”½API](https://console.anthropic.com/settings/keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd52c76-5cc2-4141-9480-cbfee6e6e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.anthropic.ChatAnthropic` was deprecated in langchain-community 0.0.28 and will be removed in 0.2. An updated version of the class exists in the langchain-anthropic package and should be used instead. To use it run `pip install -U langchain-anthropic` and import as `from langchain_anthropic import ChatAnthropic`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë„¤, ë°¥ì€ ì˜ ë¨¹ì—ˆì–´ìš”.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "load_dotenv()\n",
    "anthropic_api_key = os.getenv(\"Anthropic_API_KEY\")\n",
    "\n",
    "chat = ChatAnthropic(\n",
    "    model=\"claude-2\",\n",
    "    anthropic_api_key=anthropic_api_key\n",
    ")\n",
    "\n",
    "result = chat([\n",
    "    SystemMessage(content=\"ì¹œí•œì¹œêµ¬ì²˜ëŸ¼, ì¡´ëŒ“ë§ ì“°ì§€ë§ê³  ì†”ì§í•˜ê²Œ ë‹µë³€\"),\n",
    "    HumanMessage(content=\"ì•ˆë…•? ë°¥ì€ ë¨¹ì—ˆë‹ˆ\"),\n",
    "])\n",
    "\n",
    "print(result.content) # claude2ëŠ” ì¢€ ë©ì²­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a285843d-db5c-46d1-99a5-ebc91b94be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentBlock(text='Tentu saja, saya akan menjelaskan tentang budaya K-pop (Korean pop) dalam bahasa Indonesia.\\n\\nK-pop atau Korean pop adalah genre musik pop yang berasal dari Korea Selatan. Budaya K-pop telah menjadi fenomena global yang sangat populer di kalangan remaja dan anak muda di seluruh dunia, termasuk di Indonesia.\\n\\nBeberapa karakteristik utama budaya K-pop antara lain:\\n\\n1. Musik dan tarian: Lagu-lagu K-pop dikenal dengan aransemen musik yang kaya, lirik yang catchy, dan tarian koreografi yang enerjik dan terkoordinasi dengan baik.\\n\\n2. Idola K-pop: Para idola K-pop biasanya tergabung dalam grup vokal atau grup tari yang beranggotakan remaja atau anak muda yang tampan dan cantik. Mereka digemari karena talenta menyanyi, menari, dan penampilan yang menarik.\\n\\n3. Fandom yang besar: Budaya K-pop didukung oleh basis penggemar (fandom) yang sangat besar dan loyal di seluruh dunia yang disebut K-popers.\\n\\n4. Industri hiburan yang terorganisir: Budaya K-pop didukung oleh industri hiburan Korea yang terorganisir dengan baik, seperti agensi manajemen besar yang menaungi grup idola.\\n\\n5. Pengaruh budaya Korea: K-pop juga mempopulerkan budaya Korea lainnya seperti drama, film, makanan, fashion, dan bahasa Korea.\\n\\nDemikianlah penjelasan singkat tentang budaya K-pop yang telah menjadi fenomena global dan digemari oleh banyak orang di berbagai belahan dunia, termasuk di Indonesia.', type='text')]\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=anthropic_api_key\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-sonnet-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"ì¸ë„ë„¤ì‹œì•„ì–´ë¡œ ë‹µë³€í•´ì¤˜\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Kpopë¬¸í™”ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content) # claude3-sonnet ë˜‘ë˜‘í•œë° ë­ì²´ì¸ì—ì„œ ì•„ì§ ì‚¬ìš© ë¶ˆê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95ec9b-d70a-43c6-a820-23a78ec9e157",
   "metadata": {},
   "source": [
    "### PromptTemplateì„ ì“°ë©´ ì‰½ê²Œ ë³€ìˆ˜ë¥¼ ë°”ê¿”ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ìˆ˜ ìˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0d26783-0ac4-4e1e-9851-6ea5d72ef213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¹ˆì§€ë…¸ëŠ” ì–´ëŠ í•™êµ ì¶œì‹ ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate  #â† PromptTemplate ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "prompt = PromptTemplate(  #â† PromptTemplate ì´ˆê¸°í™”í•˜ê¸°\n",
    "    template=\"{influencer}ëŠ” ì–´ëŠ í•™êµ ì¶œì‹ ï¼Ÿ\", \n",
    "    input_variables=[\n",
    "        \"product\"  #â† influencer ì…ë ¥í•  ë³€ìˆ˜ ì§€ì •\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt.format(influencer=\"ë¹ˆì§€ë…¸\")) # influencer= ë¡œ ë§¤ê°œë³€ìˆ˜ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd224576-c31b-4289-85bd-0ac8151e0aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¹€êµ¬ë¼ëŠ” ì–´ëŠ í•™êµ ì¶œì‹ ï¼Ÿ\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(influencer=\"ê¹€êµ¬ë¼\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f150573-d0e3-4996-ab15-bcbccb1e3901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'influencer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\prompts\\prompt.py:132\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:190\u001b[0m, in \u001b[0;36mFormatter.format\u001b[1;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\utils\\formatting.py:18\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:194\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[1;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[0;32m    193\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m--> 194\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:234\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[1;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[0;32m    230\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:299\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[1;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[0;32m    297\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[1;32m--> 299\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[1;32mE:\\miniconda\\envs\\tw311\\Lib\\string.py:256\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[1;34m(self, key, args, kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'influencer'"
     ]
    }
   ],
   "source": [
    "print(prompt.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa0371-1360-4c50-bdae-46c05ad95d9d",
   "metadata": {},
   "source": [
    "> í‚¤ë¥¼ ë„£ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ ë°œìƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950e3fd-c4a0-4a23-8a71-d31ef49e4ec2",
   "metadata": {},
   "source": [
    "### LanguageModel+PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0d219ec-64c6-40a3-a3b3-486b508602e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´ìœ ëŠ” ê²½ê¸°ê³ ë“±í•™êµë¥¼ ì¡¸ì—…í•œ í›„ í•œêµ­ì˜ˆìˆ ì¢…í•©í•™êµì— ì…í•™í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(  #â† í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° chatì— ì €ì¥\n",
    "    model=\"gpt-3.5-turbo\",  #â† í˜¸ì¶œí•  ëª¨ë¸ ì§€ì •\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(  #â† PromptTemplateì„ ì‘ì„±\n",
    "    template=\"{influencer}ëŠ” ì–´ëŠ í•™êµ ì¶œì‹ ì´ì•¼\",  #â† {product}ë¼ëŠ” ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì‘ì„±í•˜ê¸°\n",
    "    input_variables=[\n",
    "        \"influencer\"  #â† productì— ì…ë ¥í•  ë³€ìˆ˜ ì§€ì •\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = chat( #â† ì‹¤í–‰\n",
    "    [\n",
    "        SystemMessage(content=\"ì¹œí•œì¹œêµ¬ì²˜ëŸ¼, ì¡´ëŒ“ë§ ì“°ì§€ë§ê³  ì†”ì§í•˜ê²Œ ë‹µë³€\"),\n",
    "        HumanMessage(content=prompt.format(influencer=\"ê°€ìˆ˜ ì•„ì´ìœ \")),\n",
    "        AIMessage(content=\"{ChatModelì˜ ë‹µë³€}\"),\n",
    "        SystemMessage(content=\"ì¹œí•œì¹œêµ¬ì²˜ëŸ¼, ì¡´ëŒ“ë§ ì“°ì§€ë§ê³  ì†”ì§í•˜ê²Œ ë‹µë³€\"),\n",
    "        HumanMessage(content=\"ë§ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸í•˜ê³  ë‹µë³€í•´ì¤˜\"),\n",
    "    ]\n",
    ")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b1738-8217-437e-a578-1fddcb3c0446",
   "metadata": {},
   "source": [
    "### Promptì €ì¥/í™œìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e2bc4-56fc-42cd-a360-8a7b8d8e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(  #â† PromptTemplateì„ ì‘ì„±\n",
    "    template=\"{influencer}ëŠ” ì–´ëŠ í•™êµ ì¶œì‹ ì´ì•¼\",  #â† {product}ë¼ëŠ” ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì‘ì„±í•˜ê¸°\n",
    "    input_variables=[\n",
    "        \"influencer\"  #â† productì— ì…ë ¥í•  ë³€ìˆ˜ ì§€ì •\n",
    "    ]\n",
    "\n",
    "prompt_json = prompt.save('prompt.json') # í”„ë¡¬í”„íŠ¸í…œí”Œë¦¿ì„ jsonìœ¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1d9dea-de3e-4d83-a0c2-8bcba2c109e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°•ëª…ìˆ˜ëŠ” ì–´ëŠ í•™êµ ì¶œì‹ ì´ì•¼\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "prompt = load_prompt('prompt.json')\n",
    "print(prompt.format(influencer='ë°•ëª…ìˆ˜'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306d396-42aa-4e1d-90aa-336fc502209b",
   "metadata": {},
   "source": [
    "### Output Parsers\n",
    "- ì–¸ì–´ëª¨ë¸ì—ì„œ ë°›ì€ ê²°ê³¼ë¥¼ ì›í•˜ëŠ” ì¶œë ¥ì˜ í˜•íƒœë¡œ êµ¬ì¡°í™”\n",
    "- CommaSeparatedListOutputParserëŠ” ê²°ê³¼ë¥¼ ëª©ë¡í˜•íƒœë¡œ ë°›ì•„ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "945b31a9-b25d-4391-a457-c42ae1257769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í‘œ ìƒí’ˆ => ì•„ì´í°\n",
      "ëŒ€í‘œ ìƒí’ˆ => ì•„ì´íŒ¨ë“œ\n",
      "ëŒ€í‘œ ìƒí’ˆ => ë§¥ë¶\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import \\\n",
    "    CommaSeparatedListOutputParser  #â† Output Parserì¸ CommaSeparatedListOutputParserë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser() #â† CommaSeparatedListOutputParser ì´ˆê¸°í™”\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", )\n",
    "\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=\"ì• í”Œì´ ê°œë°œí•œ ëŒ€í‘œì ì¸ ì œí’ˆ 3ê°œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\"),\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),  #â† output_parser.get_format_instructions()ë¥¼ ì‹¤í–‰í•˜ì—¬ ì–¸ì–´ëª¨ë¸ì— ì§€ì‹œì‚¬í•­ ì¶”ê°€í•˜ê¸°\n",
    "    ]\n",
    ")\n",
    "\n",
    "output = output_parser.parse(result.content) #â† ì¶œë ¥ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•œë‹¤.\n",
    "\n",
    "for item in output: #â† ëª©ë¡ì„ í•˜ë‚˜ì”© êº¼ë‚´ì–´ ì¶œë ¥í•œë‹¤.\n",
    "    print(\"ëŒ€í‘œ ìƒí’ˆ => \" + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a99ba081-31a1-4918-8271-2f394876e539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•„ì´í°, ì•„ì´íŒ¨ë“œ, ë§¥ë¶', response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 58, 'total_tokens': 74}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a3f57030-19d9-4575-ab89-3687d7684475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ì•„ì´í°', 'ì•„ì´íŒ¨ë“œ', 'ë§¥ë¶']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41a674-3ab2-4691-9f91-e2496eed7eaf",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ Language Models\n",
    "- ë­ì²´ì¸ì˜ ëª¨ë¸ : ëŒ€í™”í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ chat_models, complete ëª¨ë¸ê³¼ ê°™ì€ ëª¨ë¸ì˜ ì—°ì†ì„ ì¤€ë¹„í•˜ëŠ” llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "14d33e31-fe29-4193-95bb-64072dfc275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "E:\\miniconda\\envs\\tw311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë“ì—¬ë¨¹ëŠ”ë‹¤\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\" #â† í˜¸ì¶œí•  ëª¨ë¸ ì§€ì •\n",
    "             )\n",
    "\n",
    "result = llm(\n",
    "    \"ë§›ìˆëŠ” ë¼ë©´ì„\",  #â† ì–¸ì–´ëª¨ë¸ì— ì…ë ¥ë˜ëŠ” í…ìŠ¤íŠ¸\n",
    "    stop=\".\"  #â† \".\" ê°€ ì¶œë ¥ëœ ì‹œì ì—ì„œ ê³„ì†ì„ ìƒì„±í•˜ì§€ ì•Šë„ë¡\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96843c31-58de-4150-bea3-23eca4d0b207",
   "metadata": {},
   "source": [
    "### ì¤‘ë³µë˜ì§€ ì•Šê²Œ ì¬ì‚¬ìš©, cashe\n",
    "- ì „ì†¡ íšŸìˆ˜ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ apiì‚¬ìš©ë¹„ ë§ì•„ì§. íš¨ìœ¨ì ìœ¼ë¡œ ìºì‹±í•˜ëŠ” ê¸°ëŠ¥ cashe\n",
    "    + InMemoryCache ë¥¼ llm_casheë¡œ ì„¤ì •í•´ë‘ë©´ ë™ì¼í•œ ìš”ì²­ì— ëŒ€í•´ ìºì‹œì— ì €ì¥ëœ ë‚´ìš©ì„ ë°”ë¡œ ì‚¬ìš©í•˜ê¸°ì— APIì— ë¶ˆí•„ìš”í•œ í˜¸ì¶œì„ í•˜ì§€ ì•ŠëŠ”ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41633ed0-ef5a-472c-a984-5a61fe63d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\miniconda\\envs\\tw311\\Lib\\typing.py:864: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  code = compile(arg_to_compile, '<string>', 'eval')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë„ì™€ë“œë¦´ê²Œ ìˆë‚˜ìš”?\n",
      "ì‹¤í–‰ ì‹œê°„: 3.3740170001983643ì´ˆ\n",
      "ì•ˆë…•í•˜ì„¸ìš”! ë„ì™€ë“œë¦´ê²Œ ìˆë‚˜ìš”?\n",
      "ì‹¤í–‰ ì‹œê°„: 0.00099945068359375ì´ˆ\n"
     ]
    }
   ],
   "source": [
    "import time  #â† ì‹¤í–‰ ì‹œê°„ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ time ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°\n",
    "import langchain\n",
    "from langchain.cache import InMemoryCache  #â† InMemoryCache ê°€ì ¸ì˜¤ê¸°\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "langchain.llm_cache = InMemoryCache() #â† llm_cacheì— InMemoryCache ì„¤ì •\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "start = time.time() #â† ì‹¤í–‰ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "result = chat([ #â† ì²« ë²ˆì§¸ ì‹¤í–‰ì„ ìˆ˜í–‰\n",
    "    HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”!\")\n",
    "])\n",
    "\n",
    "end = time.time() #â† ì‹¤í–‰ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡\n",
    "print(result.content)\n",
    "print(f\"ì‹¤í–‰ ì‹œê°„: {end - start}ì´ˆ\")\n",
    "\n",
    "start = time.time() #â† ì‹¤í–‰ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "result = chat([ #â† ê°™ì€ ë‚´ìš©ìœ¼ë¡œ ë‘ ë²ˆì§¸ ì‹¤í–‰ì„ í•¨ìœ¼ë¡œì¨ ìºì‹œê°€ í™œìš©ë˜ì–´ ì¦‰ì‹œ ì‹¤í–‰ ì™„ë£Œë¨\n",
    "    HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”!\")\n",
    "])\n",
    "\n",
    "end = time.time() #â† ì‹¤í–‰ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡\n",
    "print(result.content)\n",
    "print(f\"ì‹¤í–‰ ì‹œê°„: {end - start}ì´ˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab35d7-0245-4da4-a24d-956713b95e1d",
   "metadata": {},
   "source": [
    "### í”„ë¡œì„¸ìŠ¤ë¥¼ ìˆœì°¨ì  í‘œì‹œ, Straming + callback\n",
    "- chatgptì‚¬ì´íŠ¸ ì²˜ëŸ¼ ìˆœì°¨ì ìœ¼ë¡œ ë‹µë³€ì„ í•´ì¤€ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c30a1371-d098-4653-a94b-09a9c3f0da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ë¥¼ êµ½ëŠ” ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. ìŠ¤í…Œì´í¬ëŠ” ëƒ‰ì¥ê³ ì—ì„œ êº¼ë‚´ì–´ ëƒ‰ê¸°ë¥¼ ì‹íŒ í›„ ë£¸ì˜¨ ì˜¨ë„ë¡œ ì•½ 30ë¶„ ì •ë„ ë°©ì¹˜í•´ì£¼ì„¸ìš”.\n",
      "2. íŒ¬ì´ë‚˜ ê·¸ë¦´ì„ ë¯¸ë¦¬ ì˜ˆì—´í•´ì£¼ì„¸ìš”. ì˜¨ë„ëŠ” ê³ ì˜¨ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "3. ìŠ¤í…Œì´í¬ì— ì†Œê¸ˆê³¼ í›„ì¶”ë¥¼ ê³¨ê³ ë£¨ ë¿Œë ¤ì£¼ì„¸ìš”. ë‹¤ì–‘í•œ ì–‘ë…ì„ ì‚¬ìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "4. íŒ¬ì´ë‚˜ ê·¸ë¦´ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ìŠ¤í…Œì´í¬ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”. í•œìª½ ë©´ì€ 2~3ë¶„ ì •ë„ ìµí˜€ì£¼ì„¸ìš”.\n",
      "5. ìŠ¤í…Œì´í¬ë¥¼ ë’¤ì§‘ì–´ ë‹¤ë¥¸ ë©´ë„ 2~3ë¶„ ì •ë„ ìµí˜€ì£¼ì„¸ìš”. ì´ë•Œ ê³ ê¸°ê°€ ê³ ê¸°ë¥¼ ê³ ê¸°ê°€ ë¹ ì§ˆ ë•Œê¹Œì§€ ë’¤ì§‘ì–´ì£¼ì„¸ìš”.\n",
      "6. ê³ ê¸°ê°€ ìµëŠ” ì •ë„ì— ë”°ë¼ ë” ìµíˆê³  ì‹¶ìœ¼ë©´ ì‹œê°„ì„ ì¡°ì ˆí•´ì£¼ì„¸ìš”.\n",
      "7. ìµì€ ìŠ¤í…Œì´í¬ë¥¼ ë¯¸ë¦¬ ì¤€ë¹„í•œ ì ‘ì‹œì— ì˜®ê²¨ ë‘ì–´ 5ë¶„ ì •ë„ ì‰¬ì–´ì£¼ì„¸ìš”. ì´ë ‡ê²Œ í•˜ë©´ ê³ ê¸°ì˜ ì£¼ìŠ¤ê°€ ê³ ë¥´ê²Œ í¼ì§€ê²Œ ë©ë‹ˆë‹¤.\n",
      "8. ìŠ¤í…Œì´í¬ë¥¼ ì˜ë¼ì„œ ê·¸ë¦‡ì— ë‹´ê³  ì±„ì†Œë‚˜ ê°ì ë“±ê³¼ í•¨ê»˜ ë‚´ì–´ì£¼ì„¸ìš”.ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ë¥¼ ì¦ê²¨ ë³´ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    streaming=True,  #â† streamingì„ Trueë¡œ ì„¤ì •í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ì‹¤í–‰\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()  #â† StreamingStdOutCallbackHandlerë¥¼ ì½œë°±ìœ¼ë¡œ ì„¤ì •\n",
    "    ]\n",
    ")\n",
    "resp = chat([ #â† ìš”ì²­ ë³´ë‚´ê¸°\n",
    "    HumanMessage(content=\"ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ êµ½ëŠ” ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d36d0-8234-4748-b9fc-fcc6acfe27b3",
   "metadata": {},
   "source": [
    "ê²°ê³¼ë¥¼ í‘œì‹œí•œ í›„ì— ì†ŒìŠ¤ì½”ë“œë¥¼ ë‹¤ë£¨ê³  ì‹¶ë‹¤ë©´~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8c07028e-4d82-4637-a685-423237d29db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ë¥¼ êµ½ëŠ” ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. ìŠ¤í…Œì´í¬ëŠ” ëƒ‰ì¥ê³ ì—ì„œ êº¼ë‚´ì–´ ëƒ‰ê¸°ë¥¼ ì‹íŒ í›„ ë£¸ì˜¨ ì˜¨ë„ë¡œ ì•½ 30ë¶„ ì •ë„ ë°©ì¹˜í•´ì£¼ì„¸ìš”.\\n2. íŒ¬ì´ë‚˜ ê·¸ë¦´ì„ ë¯¸ë¦¬ ì˜ˆì—´í•´ì£¼ì„¸ìš”. ì˜¨ë„ëŠ” ê³ ì˜¨ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.\\n3. ìŠ¤í…Œì´í¬ì— ì†Œê¸ˆê³¼ í›„ì¶”ë¥¼ ê³¨ê³ ë£¨ ë¿Œë ¤ì£¼ì„¸ìš”. ë‹¤ì–‘í•œ ì–‘ë…ì„ ì‚¬ìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\\n4. íŒ¬ì´ë‚˜ ê·¸ë¦´ì— ì‹ìš©ìœ ë¥¼ ë‘ë¥´ê³  ìŠ¤í…Œì´í¬ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”. í•œìª½ ë©´ì€ 2~3ë¶„ ì •ë„ ìµí˜€ì£¼ì„¸ìš”.\\n5. ìŠ¤í…Œì´í¬ë¥¼ ë’¤ì§‘ì–´ ë‹¤ë¥¸ ë©´ë„ 2~3ë¶„ ì •ë„ ìµí˜€ì£¼ì„¸ìš”. ì´ë•Œ ê³ ê¸°ê°€ ê³ ê¸°ë¥¼ ê³ ê¸°ê°€ ë¹ ì§ˆ ë•Œê¹Œì§€ ë’¤ì§‘ì–´ì£¼ì„¸ìš”.\\n6. ê³ ê¸°ê°€ ìµëŠ” ì •ë„ì— ë”°ë¼ ë” ìµíˆê³  ì‹¶ìœ¼ë©´ ì‹œê°„ì„ ì¡°ì ˆí•´ì£¼ì„¸ìš”.\\n7. ìµì€ ìŠ¤í…Œì´í¬ë¥¼ ë¯¸ë¦¬ ì¤€ë¹„í•œ ì ‘ì‹œì— ì˜®ê²¨ ë‘ì–´ 5ë¶„ ì •ë„ ì‰¬ì–´ì£¼ì„¸ìš”. ì´ë ‡ê²Œ í•˜ë©´ ê³ ê¸°ì˜ ì£¼ìŠ¤ê°€ ê³ ë¥´ê²Œ í¼ì§€ê²Œ ë©ë‹ˆë‹¤.\\n8. ìŠ¤í…Œì´í¬ë¥¼ ì˜ë¼ì„œ ê·¸ë¦‡ì— ë‹´ê³  ì±„ì†Œë‚˜ ê°ì ë“±ê³¼ í•¨ê»˜ ë‚´ì–´ì£¼ì„¸ìš”.ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.ë§›ìˆëŠ” ìŠ¤í…Œì´í¬ë¥¼ ì¦ê²¨ ë³´ì„¸ìš”!'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_text = resp.content\n",
    "res_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed8206-603f-4e0c-8af9-f2c233ad97d3",
   "metadata": {},
   "source": [
    "## 3. Templates-í”„ë¡¬í”„íŠ¸êµ¬ì¶•ì˜ íš¨ìœ¨í–¥ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e9c50-e31a-4513-ab97-82b6f42bf5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tw311",
   "language": "python",
   "name": "tw311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
