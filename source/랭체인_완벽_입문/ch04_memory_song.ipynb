{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abca29e-ac15-4209-9368-37b0f060afe9",
   "metadata": {},
   "source": [
    "# 언어 모델에서 대화란 무엇인가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27248688-4479-4bff-bc94-32812ee43517",
   "metadata": {},
   "source": [
    "## HumanMessage와 AIMessage를 번갈아 가며 대화한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c57ab-b473-4b11-b792-a67f2f4f2509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"계란찜을 만드는 재료를 알려주세요.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffdb33-c0d4-48f6-be19-2440f5a3f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "result = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"계란찜을 만드는 재료를 알려주세요.\"),\n",
    "        AIMessage(content=\"\"\"\n",
    "계란찜을 만드는데 필요한 재료는 다음과 같습니다.\n",
    "\n",
    "1. 계란 - 4개\n",
    "2. 물 - 1컵\n",
    "3. 소금 - 1/2 작은술\n",
    "4. 설탕 - 1/2 작은술\n",
    "5. 다진파 - 약간 (선택사항)\n",
    "6. 다진마늘 - 약간 (선택사항)\n",
    "7. 소금 - 약간 (선택사항)\n",
    "8. 후추 - 약간 (선택사항)        \n",
    "        \n",
    "        \"\"\"),\n",
    "        HumanMessage(content=\"위의 답변을 영어로 번역하세요\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81122b6a-9b5f-4140-807b-5216279dbe39",
   "metadata": {},
   "source": [
    "# 문맥에 맞는 답변을 할 수 있는 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206116c-226e-4eca-a97b-212ff7d28855",
   "metadata": {},
   "source": [
    "## Chat models로 대화 기록을 기반으로 한 응답을 하게 하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1986f-19b9-4170-ae73-32e16eada472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True\n",
    ")\n",
    "memory.save_context(\n",
    "    {\n",
    "        \"input\":\"안녕하세요!\"\n",
    "    },\n",
    "    {\n",
    "        \"output\":\"안녕하세요! 잘 지내고 계신가요? 궁금한 점이 있으면 알려주세요. 어떻게 도와 드릴까요\"\n",
    "    }\n",
    ")\n",
    "memory.save_context(\n",
    "    {\n",
    "        \"input\":\"오늘 날씨가 좋네요\"\n",
    "    },\n",
    "    {\n",
    "        \"output\":\"저는 AI이기 때문에 실제 날씨를 느낄 수는 없지만, 날씨가 좋은 날은 외출이나 활동을 즐기기에 좋은 날 입니다.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b6356-da2a-44b5-90c5-0488749fc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory = memory,\n",
    "    llm = chat\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변을 할 수 있는 채팅 봇 입니다. 메시지를 입력해 주세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    message = input_message.content\n",
    "    result = chain(message)\n",
    "   \n",
    "    await cl.Message(content=result['response']).send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f61b3-02f1-49f7-bcce-332adf2678d3",
   "metadata": {},
   "source": [
    "# 히스토리를 데이터베이스에 저장하고 영속화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c7eeb-675b-42d7-bdc0-f8ffcce51d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import RedisChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "history = RedisChatMessageHistory(\n",
    "    session_id=\"chat_history\",\n",
    "    url=os.environ.get('REDIS_URL'),\n",
    "\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    chat_memory=history\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory = memory,\n",
    "    llm = chat\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변을 할 수 있는 채팅 봇 입니다. 메시지를 입력해 주세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    message = input_message.content\n",
    "    result = chain(message)\n",
    "   \n",
    "    await cl.Message(content=result['response']).send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d4944-6fec-4d31-a6b4-79a9f51f9e94",
   "metadata": {},
   "source": [
    "# 여러 개의 대화 기록을 가질 수 있는 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3743f26-b000-42ac-b9d9-3a8178402165",
   "metadata": {},
   "source": [
    "## 세션 ID를 바꿔서 대화 기록 전환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7c39e-869e-4020-9773-04e98938cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, RedisChatMessageHistory\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    thread_id = None\n",
    "    while not thread_id:\n",
    "        res = await cl.AskUserMessage(content=\"저는 대화의 맥락을 고려해 답변을 할 수 있는 채팅 봇 입니다. 스레드 ID를 입력하세요.\", timeout=600).send()\n",
    "        if res:\n",
    "            print(res)\n",
    "            thread_id = res['output']\n",
    "\n",
    "    history = RedisChatMessageHistory(\n",
    "        session_id=thread_id,\n",
    "        url=os.environ.get('REDIS_URL'),\n",
    "\n",
    "    )\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        return_messages=True,\n",
    "        chat_memory=history\n",
    "    )\n",
    "\n",
    "    chain = ConversationChain(\n",
    "        memory = memory,\n",
    "        llm = chat\n",
    "    )\n",
    "\n",
    "    memory_message_result = chain.memory.load_memory_variables({})\n",
    "    \n",
    "    messages = memory_message_result['history']\n",
    "\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            await cl.Message(\n",
    "                author='User',\n",
    "                content=f'{message.content}'\n",
    "            ).send()\n",
    "        else:\n",
    "            await cl.Message(\n",
    "                author='ChatBot',\n",
    "                content=f'{message.content}'\n",
    "            ).send()\n",
    "    cl.user_session.set('chain', chain)\n",
    "\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    message = input_message.content\n",
    "    chain = cl.user_session.get('chain')\n",
    "    result = chain(message)\n",
    "   \n",
    "    await cl.Message(content=result['response']).send()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d8d572-13c8-4b91-bb0c-95a68e5400e7",
   "metadata": {},
   "source": [
    "# 매우 긴 대회 기록에 대응한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f53ed1-8661-4fd8-90e5-ae1182f46ae7",
   "metadata": {},
   "source": [
    "## 대화를 요약해 토큰 수 제한에 대응"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe385af-d142-4560-803b-f44731b67d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import RedisChatMessageHistory\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "history = RedisChatMessageHistory(\n",
    "    session_id=\"chat_history\",\n",
    "    url=os.environ.get('REDIS_URL'),\n",
    "\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=chat,\n",
    "    return_messages=True,\n",
    "    chat_memory=history\n",
    ")\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory = memory,\n",
    "    llm = chat\n",
    ")\n",
    "\n",
    "@cl.on_chat_start\n",
    "async def on_chat_start():\n",
    "    await cl.Message(content=\"저는 대화의 맥락을 고려해 답변을 할 수 있는 채팅 봇 입니다. 메시지를 입력해 주세요.\").send()\n",
    "\n",
    "@cl.on_message\n",
    "async def on_message(input_message):\n",
    "    message = input_message.content\n",
    "    messages = chain.memory.load_memory_variables({})['history']\n",
    "    print(f'저장된 메시지 개수 : {len(messages)}')\n",
    "    for saved_message in messages:\n",
    "        print(saved_message.content)\n",
    "        \n",
    "    result = chain(message)\n",
    "   \n",
    "    await cl.Message(content=result['response']).send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442ac94-29a8-4117-8f73-16c14a635563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
