{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12장. 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.org/github/rickiepark/machine-learning-with-python-cookbook/blob/master/12.ipynb\"><img src=\"https://jupyter.org/assets/share.png\" width=\"60\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/machine-learning-with-python-cookbook/blob/master/12.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 완전 탐색을 사용해 최선의 모델 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 로지스틱 회귀 모델을 만듭니다.\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# 페널티(penalty) 하이퍼파라미터 값의 후보를 만듭니다.\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# 규제 하이퍼파라미터 값의 후보 범위를 만듭니다.\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# 하이퍼파라미터 후보 딕셔너리를 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# 그리드 서치 객체를 만듭니다.\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(0, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 페널티: l1\n",
      "가장 좋은 C 값: 7.742636826811269\n"
     ]
    }
   ],
   "source": [
    "# 최선의 하이퍼파라미터를 확인합니다.\n",
    "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타깃 벡터를 예측합니다.\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 랜덤 서치를 사용하여 최선의 모델 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from scipy.stats import uniform\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 로지스틱 회귀 모델을 만듭니다.\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# 페널티 하이퍼파라미터 후보를 만듭니다. penalty hyperparameter values\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# 규제 하이퍼파라미터 값의 후보를 위한 분포를 만듭니다.\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# 하이퍼파라미터 옵션을 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# 랜덤 서치 객체를 만듭니다.\n",
    "randomizedsearch = RandomizedSearchCV(\n",
    "    logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0,\n",
    "    n_jobs=-1)\n",
    "\n",
    "# 랜덤 서치를 수행합니다.\n",
    "best_model = randomizedsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.21040174, 2.33820775, 0.83689626, 0.37988461, 1.19209251,\n",
       "       0.80272488, 3.28702566, 1.91900098, 2.17726454, 0.57514635])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~4 사이의 균등 분포를 정의하고 10개의 값을 샘플링합니다.\n",
    "uniform(loc=0, scale=4).rvs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 페널티: l1\n",
      "가장 좋은 C 값: 1.668088018810296\n"
     ]
    }
   ],
   "source": [
    "# 최선의 하이퍼파라미터를 확인합니다.\n",
    "print('가장 좋은 페널티:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('가장 좋은 C 값:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타깃 벡터를 예측합니다.\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 여러 학습 알고리즘에서 최선의 모델 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 랜덤 시드를 설정합니다.\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 파이프라인을 만듭니다.\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "\n",
    "# 후보 학습 알고리즘과 하이퍼파라미터로 딕셔너리를 만듭니다.\n",
    "search_space = [{\"classifier\": [LogisticRegression(solver='liblinear', max_iter=1000)],\n",
    "                 \"classifier__penalty\": ['l1', 'l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)},\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_features\": [1, 2, 3]}]\n",
    "\n",
    "# 그리드 서치 객체를 만듭니다.\n",
    "gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=7.742636826811269, max_iter=1000, penalty='l1',\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최선의 모델을 확인합니다.\n",
    "best_model.best_estimator_.get_params()[\"classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타깃 벡터를 예측합니다.\n",
    "best_model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 전처리와 함께 최선의 모델 선택하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 랜덤 시드를 설정합니다.\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# StandardScaler와 PCA를 포함한 전처리 객체를 만듭니다.\n",
    "preprocess = FeatureUnion([(\"std\", StandardScaler()), (\"pca\", PCA())])\n",
    "\n",
    "# 파이프라인을 만듭니다.\n",
    "pipe = Pipeline([(\"preprocess\", preprocess),\n",
    "                 (\"classifier\", LogisticRegression(solver='liblinear', max_iter=1000))])\n",
    "\n",
    "# 후보 값을 정의합니다.\n",
    "search_space = [{\"preprocess__pca__n_components\": [1, 2, 3],\n",
    "                 \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)}]\n",
    "\n",
    "# 그리드 서치 객체를 만듭니다.\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = clf.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최선의 주성분 개수를 확인합니다.\n",
    "best_model.best_estimator_.get_params()['preprocess__pca__n_components']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 붙임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 , -2.68412563]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.named_steps[\"preprocess\"].transform(features[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"std\", StandardScaler()),\n",
    "                 (\"pca\", PCA()),\n",
    "                 (\"classifier\", LogisticRegression(solver='liblinear', max_iter=1000))],\n",
    "                 memory='cache')\n",
    "\n",
    "# 후보 값을 정의합니다.\n",
    "search_space = [{\"pca__n_components\": [1, 2, 3],\n",
    "                 \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)}]\n",
    "\n",
    "# 그리드 서치 객체를 만듭니다.\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = clf.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최선의 주성분 개수를 확인합니다.\n",
    "clf.best_estimator_.get_params()['pca__n_components']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.64026976,  5.2040413 , -2.48862071]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.named_steps[\"pca\"].transform(features[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 병렬화로 모델 선택 속도 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 로지스틱 회귀 모델을 만듭니다.\n",
    "logistic = linear_model.LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# 규제 페널티의 후보를 만듭니다.\n",
    "penalty = [\"l1\", \"l2\"]\n",
    "\n",
    "# C 값의 후보 범위를 만듭니다.\n",
    "C = np.logspace(0, 4, 1000)\n",
    "\n",
    "# 하이퍼파라미터 옵션을 만듭니다.\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# 그리드 서치 객체를 만듭니다.\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
     ]
    }
   ],
   "source": [
    "# 하나의 코어만 사용하는 그리드 서치 객체를 만듭니다.\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=1, verbose=1)\n",
    "\n",
    "# 그리드 서치를 수행합니다.\n",
    "best_model = clf.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 알고리즘에 특화된 기법을 사용하여 모델 선택 수행 속도 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=100, max_iter=1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 교차검증 로지스틱 회귀 모델을 만듭니다.\n",
    "logit = linear_model.LogisticRegressionCV(max_iter=1000, Cs=100)\n",
    "\n",
    "# 모델을 훈련합니다.\n",
    "logit.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7 모델 선택 후 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666668"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 로지스틱 회귀 모델을 만듭니다.\n",
    "logistic = linear_model.LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Create range of 20 candidate values for C\n",
    "C = np.logspace(0, 4, 20)\n",
    "\n",
    "# 하이퍼파라미터 옵션을 만듭니다.\n",
    "hyperparameters = dict(C=C)\n",
    "\n",
    "# 그리드 서치 객체를 만듭니다.\n",
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, n_jobs=-1, verbose=0)\n",
    "\n",
    "# 중첩 교차검증을 수행하고 평균 점수를 출력합니다.\n",
    "cross_val_score(gridsearch, features, target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(logistic, hyperparameters, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "best_model = gridsearch.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gridsearch, features, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
