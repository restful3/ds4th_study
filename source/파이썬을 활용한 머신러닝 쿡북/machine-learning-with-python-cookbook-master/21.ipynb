{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMBl_KpjBHKk"
   },
   "source": [
    "# 21장. 훈련된 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8yJwbLyBHKm"
   },
   "source": [
    "이 노트북을 주피터 노트북 뷰어(nbviewer.jupyter.org)로 보거나 구글 코랩(colab.research.google.com)에서 실행할 수 있습니다.\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.org/github/rickiepark/machine-learning-with-python-cookbook/blob/master/21.ipynb\"><img src=\"https://jupyter.org/assets/share.png\" width=\"60\" />주피터 노트북 뷰어로 보기</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/machine-learning-with-python-cookbook/blob/master/21.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8udQSkVWBHKm"
   },
   "source": [
    "**Note: 텐서플로에 포함된 tf.keras API를 사용하지 않고 멀티백엔드 케라스를 사용하려면 `from tensorflow.keras`를 `from keras`로 바꾸세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cBZ-pzKBHKn"
   },
   "source": [
    "## 21.1 사이킷런 모델을 저장하고 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I96FEJNJBHKn",
    "outputId": "b7571dd1-f281-4817-a9b9-6fb06e04ecfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "import joblib\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 결정 트리 분류기 객체를 만듭니다.\n",
    "classifer = RandomForestClassifier()\n",
    "\n",
    "# 모델을 훈련합니다.\n",
    "model = classifer.fit(features, target)\n",
    "\n",
    "# 모델을 피클 파일로 저장합니다.\n",
    "joblib.dump(model, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xwEwjIAqBHKo"
   },
   "outputs": [],
   "source": [
    "# 파일에서 모델을 복원합니다.\n",
    "classifer = joblib.load(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2TbxC4KBHKp",
    "outputId": "8c2cdd4c-9612-4b6b-e251-0c09e4c2501d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 샘플을 만듭니다.\n",
    "new_observation = [[ 5.2,  3.2,  1.1,  0.1]]\n",
    "\n",
    "# 샘플의 클래스를 예측합니다.\n",
    "classifer.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yi9Jn9AFBHKp",
    "outputId": "643caec0-6104-4e43-8164-d5e791e83307"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_0.22.2.post1.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import sklearn\n",
    "\n",
    "# 사이킷런 버전을 구합니다.\n",
    "scikit_version = sklearn.__version__\n",
    "\n",
    "# 모델을 피클 파일로 저장합니다.\n",
    "joblib.dump(model, \"model_{version}.pkl\".format(version=scikit_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOb_t7HZBHKq"
   },
   "source": [
    "## 21.2 케라스 모델을 저장하고 복원하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjcHKTjkBHKq",
    "outputId": "3cca40c0-35c9-4de0-e13c-bb02091f5496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리를 임포트합니다.\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 랜덤 시드를 지정합니다.\n",
    "np.random.seed(0)\n",
    "\n",
    "# 원하는 특성 개수를 설정합니다.\n",
    "number_of_features = 1000\n",
    "\n",
    "# 영화 리뷰 데이터와 타깃 벡터를 로드합니다.\n",
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# 영화 리뷰 데이터를 원-핫 인코딩된 특성 행렬로 변환합니다.\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "train_features = tokenizer.sequences_to_matrix(train_data, mode=\"binary\")\n",
    "test_features = tokenizer.sequences_to_matrix(test_data, mode=\"binary\")\n",
    "\n",
    "# 신경망을 모델을 만듭니다.\n",
    "network = models.Sequential()\n",
    "\n",
    "# ReLU 활성화 함수를 사용한 완전 연결 층을 추가합니다.\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# 시그모이드 활성화 함수를 사용한 완전 연결 층을 추가합니다.\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# 신경망 모델의 설정을 완료합니다.\n",
    "network.compile(loss=\"binary_crossentropy\", # 크로스 엔트로피\n",
    "                optimizer=\"rmsprop\", # 최적화 알고리즘\n",
    "                metrics=[\"accuracy\"]) # 정확도\n",
    "\n",
    "# 신경망을 훈련합니다.\n",
    "history = network.fit(train_features, # 특성\n",
    "                      train_target, # 타깃 벡터\n",
    "                      epochs=3, # 에포크 횟수\n",
    "                      verbose=0, # 출력 없음\n",
    "                      batch_size=100, # 배치 샘플 수\n",
    "                      validation_data=(test_features, test_target)) # 테스트 데이터\n",
    "\n",
    "# 신경망 모델을 저장합니다.\n",
    "network.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5G90k3SxBHKr"
   },
   "outputs": [],
   "source": [
    "# 신경망 모델을 복원합니다.\n",
    "network = load_model(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "21.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
