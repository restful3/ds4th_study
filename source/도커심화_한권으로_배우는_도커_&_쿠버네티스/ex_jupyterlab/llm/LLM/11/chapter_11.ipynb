{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfGDQ7Yh6oY2"
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==2.7.0 datasets==2.19.0 huggingface_hub==0.23.0 faiss-cpu==1.8.0 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.1 사전 학습된 언어 모델을 불러와 문장 임베딩 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LHjlDu99e-U"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "transformer_model = models.Transformer('klue/roberta-base')\n",
    "\n",
    "pooling_layer = models.Pooling(\n",
    "    transformer_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "embedding_model = SentenceTransformer(modules=[transformer_model, pooling_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.2 실습 데이터셋 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EXo9p2J9gSg"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "klue_sts_train = load_dataset('klue', 'sts', split='train')\n",
    "klue_sts_test = load_dataset('klue', 'sts', split='validation')\n",
    "klue_sts_train[0]\n",
    "\n",
    "# {'guid': 'klue-sts-v1_train_00000',\n",
    "#  'source': 'airbnb-rtt',\n",
    "#  'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
    "#  'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.',\n",
    "#  'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.3 학습 데이터에서 검증 데이터셋 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jReqteWU9hbo"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터셋의 10%를 검증 데이터셋으로 구성한다.\n",
    "klue_sts_train = klue_sts_train.train_test_split(test_size=0.1, seed=42)\n",
    "klue_sts_train, klue_sts_eval = klue_sts_train['train'], klue_sts_train['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.4 label 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDM07tw29igA"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "# 유사도 점수를 0~1 사이로 정규화 하고 InputExample 객체에 담는다.\n",
    "def prepare_sts_examples(dataset):\n",
    "    examples = []\n",
    "    for data in dataset:\n",
    "        examples.append(\n",
    "            InputExample(\n",
    "                texts=[data['sentence1'], data['sentence2']],\n",
    "                label=data['labels']['label'] / 5.0)\n",
    "            )\n",
    "    return examples\n",
    "\n",
    "train_examples = prepare_sts_examples(klue_sts_train)\n",
    "eval_examples = prepare_sts_examples(klue_sts_eval)\n",
    "test_examples = prepare_sts_examples(klue_sts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.5 학습에 사용할 배치 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHLp9-KR9j5g"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.6 검증을 위한 평가 객체 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7Jpiw349lAW"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "eval_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_examples)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.7 언어 모델을 그대로 활용할 경우 문장 임베딩 모델의 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpuNY9nj9mOg"
   },
   "outputs": [],
   "source": [
    "test_evaluator(embedding_model)\n",
    "# 0.36460670798564826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.8 임베딩 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4gN6gn09nWp"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "num_epochs = 4\n",
    "model_name = 'klue/roberta-base'\n",
    "model_save_path = 'output/training_sts_' + model_name.replace(\"/\", \"-\")\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "# 임베딩 모델 학습\n",
    "embedding_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=eval_evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=100,\n",
    "    output_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.9 학습한 임베딩 모델의 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR10AXe49vwX"
   },
   "outputs": [],
   "source": [
    "trained_embedding_model = SentenceTransformer(model_save_path)\n",
    "test_evaluator(trained_embedding_model)\n",
    "# 0.8965595666246748"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.10 허깅페이스 허브에 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vC60rAr9xIO"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "login(token='허깅페이스 허브 토큰 입력')\n",
    "api = HfApi()\n",
    "repo_id=\"klue-roberta-base-klue-sts\"\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=model_save_path,\n",
    "    repo_id=f\"본인의 허깅페이스 아이디 입력/{repo_id}\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.11 실습 데이터를 내려받고 예시 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f25yzmTI9zhX"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "klue_mrc_train = load_dataset('klue', 'mrc', split='train')\n",
    "klue_mrc_train[0]\n",
    "# {'title': '제주도 장마 시작 … 중부는 이달 말부터',\n",
    "#  'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.',\n",
    "#  'news_category': '종합',\n",
    "#  'source': 'hankyung',\n",
    "#  'guid': 'klue-mrc-v1_train_12759',\n",
    "#  'is_impossible': False,\n",
    "#  'question_type': 1,\n",
    "#  'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?',\n",
    "#  'answers': {'answer_start': [478, 478], 'text': ['한 달가량', '한 달']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.12 기본 임베딩 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ud7kcr2O92U5"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer('shangrilar/klue-roberta-base-klue-sts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.13 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUg-013c93ij"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "klue_mrc_train = load_dataset('klue', 'mrc', split='train')\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "\n",
    "df_train = klue_mrc_train.to_pandas()\n",
    "df_test = klue_mrc_test.to_pandas()\n",
    "\n",
    "df_train = df_train[['title', 'question', 'context']]\n",
    "df_test = df_test[['title', 'question', 'context']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.14 질문과 관련이 없는 기사를 irrelevant_context 컬럼에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvpowrWg942C"
   },
   "outputs": [],
   "source": [
    "def add_ir_context(df):\n",
    "  irrelevant_contexts = []\n",
    "  for idx, row in df.iterrows():\n",
    "    title = row['title']\n",
    "    irrelevant_contexts.append(df.query(f\"title != '{title}'\").sample(n=1)['context'].values[0])\n",
    "  df['irrelevant_context'] = irrelevant_contexts\n",
    "  return df\n",
    "\n",
    "df_train_ir = add_ir_context(df_train)\n",
    "df_test_ir = add_ir_context(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.15 성능 평가에 사용할 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yimb_gk_96Ct"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "examples = []\n",
    "for idx, row in df_test_ir[:100].iterrows():\n",
    "  examples.append(\n",
    "      InputExample(texts=[row['question'], row['context']], label=1)\n",
    "  )\n",
    "  examples.append(\n",
    "      InputExample(texts=[row['question'], row['irrelevant_context']], label=0)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.16 기본 임베딩 모델의 성능 평가 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xu_K-HnC97QC"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    examples\n",
    ")\n",
    "evaluator(sentence_model)\n",
    "# 0.8151553052035344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.17 긍정 데이터만으로 학습 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUpR2kCg98iJ"
   },
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "for idx, row in df_train_ir.iterrows():\n",
    "    train_samples.append(InputExample(\n",
    "        texts=[row['question'], row['context']]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.18 중복 학습 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UjvLeg599qC"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import datasets\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "loader = datasets.NoDuplicatesDataLoader(\n",
    "    train_samples, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.19 MNR 손실 함수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U4bmhiZ9-tj"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.MultipleNegativesRankingLoss(sentence_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.20 MRC 데이터셋으로 미세 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQFZUGRv-AGo"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "save_path = './klue_mrc_mnr'\n",
    "\n",
    "sentence_model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=100,\n",
    "    output_path=save_path,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.21 미세 조정한 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUcRE3w6-Blm"
   },
   "outputs": [],
   "source": [
    "evaluator(sentence_model)\n",
    "# 0.8600968992433692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.22 허깅페이스 허브에 미세 조정한 모델 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq5tR4Ci-Civ"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "repo_id = \"klue-roberta-base-klue-sts-mrc\"\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=save_path,\n",
    "    repo_id=f\"본인의 아이디 입력/{repo_id}\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.23 교차 인코더로 사용할 사전 학습 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w6sT7BVi-EaG"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "cross_model = CrossEncoder('klue/roberta-small', num_labels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.24 미세 조정하지 않은 교차 인코더의 성능 평가 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76t4-RUp-Fia"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "ce_evaluator = CECorrelationEvaluator.from_input_examples(examples)\n",
    "ce_evaluator(cross_model)\n",
    "# 0.003316821814673943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.25 교차 인코더 학습 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO29wIUc-Gn9"
   },
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "for idx, row in df_train_ir.iterrows():\n",
    "    train_samples.append(InputExample(\n",
    "        texts=[row['question'], row['context']], label=1\n",
    "    ))\n",
    "    train_samples.append(InputExample(\n",
    "        texts=[row['question'], row['irrelevant_context']], label=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.26 교차 인코더 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjaEECgx-H-R"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 1\n",
    "model_save_path = 'output/training_mrc'\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "cross_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=100,\n",
    "    output_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.27 학습한 교차 인코더 평가 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-hVmkxh-JLo"
   },
   "outputs": [],
   "source": [
    "ce_evaluator(cross_model)\n",
    "# 0.8650250798639563"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.28 학습을 마친 교차 인코더를 허깅페이스 허브에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RO5GL2sn-KgV"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "repo_id = \"klue-roberta-small-cross-encoder\"\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=model_save_path,\n",
    "    repo_id=f\"본인의 아이디 입력/{repo_id}\",\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.29 평가를 위한 데이터셋을 불러와 1,000개만 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsQp7k48-MGT"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "klue_mrc_test = klue_mrc_test.train_test_split(test_size=1000, seed=42)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.30 임베딩을 저장하고 검색하는 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFq-RSVn-NQi"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "def make_embedding_index(sentence_model, corpus):\n",
    "\tembeddings = sentence_model.encode(corpus)\n",
    "\tindex = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\tindex.add(embeddings)\n",
    "\treturn index\n",
    "\n",
    "def find_embedding_top_k(query, sentence_model, index, k):\n",
    "\tembedding = sentence_model.encode([query])\n",
    "\tdistances, indices = index.search(embedding, k)\n",
    "\treturn indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.31 교차 인코더를 활용한 순위 재정렬 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-SyjEsv-Oc9"
   },
   "outputs": [],
   "source": [
    "def make_question_context_pairs(question_idx, indices):\n",
    "  return [[klue_mrc_test['question'][question_idx], klue_mrc_test['context'][idx]] for idx in indices]\n",
    "\n",
    "def rerank_top_k(cross_model, question_idx, indices, k):\n",
    "  input_examples = make_question_context_pairs(question_idx, indices)\n",
    "  relevance_scores = cross_model.predict(input_examples)\n",
    "  reranked_indices = indices[np.argsort(relevance_scores)[::-1]]\n",
    "  return reranked_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.32 성능 지표(히트율)와 평가에 걸린 시간을 반환하는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deZbs_Nt-P4k"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def evaluate_hit_rate(datasets, embedding_model, index, k=10):\n",
    "  start_time = time.time()\n",
    "  predictions = []\n",
    "  for question in datasets['question']:\n",
    "    predictions.append(find_embedding_top_k(question, embedding_model, index, k)[0])\n",
    "  total_prediction_count = len(predictions)\n",
    "  hit_count = 0\n",
    "  questions = datasets['question']\n",
    "  contexts = datasets['context']\n",
    "  for idx, prediction in enumerate(predictions):\n",
    "    for pred in prediction:\n",
    "      if contexts[pred] == contexts[idx]:\n",
    "        hit_count += 1\n",
    "        break\n",
    "  end_time = time.time()\n",
    "  return hit_count / total_prediction_count, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.33 기본 임베딩 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPByX73v-RSL"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "base_embedding_model = SentenceTransformer('shangrilar/klue-roberta-base-klue-sts')\n",
    "base_index = make_embedding_index(base_embedding_model, klue_mrc_test['context'])\n",
    "evaluate_hit_rate(klue_mrc_test, base_embedding_model, base_index, 10)\n",
    "# (0.88, 13.216430425643921)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.34 미세 조정한 임베딩 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfyImVSV-STC"
   },
   "outputs": [],
   "source": [
    "finetuned_embedding_model = SentenceTransformer('shangrilar/klue-roberta-base-klue-sts-mrc')\n",
    "finetuned_index = make_embedding_index(finetuned_embedding_model, klue_mrc_test['context'])\n",
    "evaluate_hit_rate(klue_mrc_test, finetuned_embedding_model, finetuned_index, 10)\n",
    "# (0.946, 14.309881687164307)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.35 순위 재정렬을 포함한 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhdBe1NM-Ten"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_hit_rate_with_rerank(datasets, embedding_model, cross_model, index, bi_k=30, cross_k=10):\n",
    "  start_time = time.time()\n",
    "  predictions = []\n",
    "  for question_idx, question in enumerate(tqdm(datasets['question'])):\n",
    "    indices = find_embedding_top_k(question, embedding_model, index, bi_k)[0]\n",
    "    predictions.append(rerank_top_k(cross_model, question_idx, indices, k=cross_k))\n",
    "  total_prediction_count = len(predictions)\n",
    "  hit_count = 0\n",
    "  questions = datasets['question']\n",
    "  contexts = datasets['context']\n",
    "  for idx, prediction in enumerate(predictions):\n",
    "    for pred in prediction:\n",
    "      if contexts[pred] == contexts[idx]:\n",
    "        hit_count += 1\n",
    "        break\n",
    "  end_time = time.time()\n",
    "  return hit_count / total_prediction_count, end_time - start_time, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 11.36 임베딩 모델과 교차 인코드를 조합해 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kj18XVoD-UqY"
   },
   "outputs": [],
   "source": [
    "hit_rate, cosumed_time, predictions = evaluate_hit_rate_with_rerank(klue_mrc_test, finetuned_embedding_model, cross_model, finetuned_index, bi_k=30, cross_k=10)\n",
    "hit_rate, cosumed_time\n",
    "# (0.973, 1103.055629491806)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
