{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Gd5PVm7H7o7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dgKU45fCffl"
   },
   "source": [
    "# 3.1절 허깅페이스 트랜스포머란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6olgr_ite6K"
   },
   "source": [
    "## 예제 3.1. BERT와 GPT-2 모델을 활용할 때 허깅페이스 트랜스포머 코드 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kAwjIEiKIBVj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "text = \"What is Huggingface Transformers?\"\n",
    "# BERT 모델 활용\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "encoded_input = bert_tokenizer(text, return_tensors='pt')\n",
    "bert_output = bert_model(**encoded_input)\n",
    "# GPT-2 모델 활용\n",
    "gpt_model = AutoModel.from_pretrained('gpt2')\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "encoded_input = gpt_tokenizer(text, return_tensors='pt')\n",
    "gpt_output = gpt_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUIzXEp9CleZ"
   },
   "source": [
    "# 3.3절 허깅페이스 라이브러리 사용법 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oo8e5smt8gB"
   },
   "source": [
    "## 예제 3.2. 모델 아이디로 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vsj_ZOu-CobD"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a0e00fab2e4668950c171360ab7d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  33%|###3      | 147M/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\masta\\.cache\\huggingface\\hub\\models--klue--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDARA5SpuJgt"
   },
   "source": [
    "## 예제 3.4. 분류 헤드가 포함된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XdfQpfUuCrdy"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e70478675048d39b54214984f9e278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\masta\\.cache\\huggingface\\hub\\models--SamLowe--roberta-base-go_emotions. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7381aea3e4354800997dc2c0d883dcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPfN9HZluWeW"
   },
   "source": [
    "## 예제 3.6. 분류 헤드가 랜덤으로 초기화된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KnQbDV3JCtwE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_id = 'klue/roberta-base'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeYgt5UzuwGC"
   },
   "source": [
    "## 예제 3.8. 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GOS1p907u1CO"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2d1b82ad104a70980d1d1a04682035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452fb3bbca6d4f9d82366d185fab065a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d612100fa474d398cad60ed1dcfeac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120603bbb4dd469485099d7d92c6628c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKssSh_tu8v-"
   },
   "source": [
    "## 예제 3.9. 토크나이저 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iaX4LD4Eu3RL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 20950, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나눈다', '[SEP]']\n",
      "[CLS] 토크나이저는 텍스트를 토큰 단위로 나눈다 [SEP]\n",
      "토크나이저는 텍스트를 토큰 단위로 나눈다\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(\"토크나이저는 텍스트를 토큰 단위로 나눈다\")\n",
    "print(tokenized)\n",
    "# {'input_ids': [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 20950, 2],\n",
    "#  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))\n",
    "# ['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나눈다', '[SEP]']\n",
    "\n",
    "print(tokenizer.decode(tokenized['input_ids']))\n",
    "# [CLS] 토크나이저는 텍스트를 토큰 단위로 나눈다 [SEP]\n",
    "\n",
    "print(tokenizer.decode(tokenized['input_ids'], skip_special_tokens=True))\n",
    "# 토크나이저는 텍스트를 토큰 단위로 나눈다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjqS0r-avFl-"
   },
   "source": [
    "## 예제 3.10. 토크나이저에 여러 문장 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vmcZndW0vGqC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2], [0, 864, 1141, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['첫 번째 문장', '두 번째 문장'])\n",
    "\n",
    "# {'input_ids': [[0, 1656, 1141, 3135, 6265, 2], [0, 864, 1141, 3135, 6265, 2]],\n",
    "# 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On7iLMjHvMQd"
   },
   "source": [
    "## 예제 3.11. 하나의 데이터에 여러 문장이 들어가는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oe9aqgr-vTOv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2, 864, 1141, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([['첫 번째 문장', '두 번째 문장']])\n",
    "\n",
    "# {'input_ids': [[0, 1656, 1141, 3135, 6265, 2, 864, 1141, 3135, 6265, 2]],\n",
    "# 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oaV-a3lvcQK"
   },
   "source": [
    "## 예제 3.12. 토큰 아이디를 문자열로 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GxIG352EvdDi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 첫 번째 문장 [SEP] 두 번째 문장 [SEP]']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tokenized_result = tokenizer(['첫 번째 문장', '두 번째 문장'])['input_ids']\n",
    "tokenizer.batch_decode(first_tokenized_result)\n",
    "# ['[CLS] 첫 번째 문장 [SEP]', '[CLS] 두 번째 문장 [SEP]']\n",
    "\n",
    "second_tokenized_result = tokenizer([['첫 번째 문장', '두 번째 문장']])['input_ids']\n",
    "tokenizer.batch_decode(second_tokenized_result)\n",
    "# ['[CLS] 첫 번째 문장 [SEP] 두 번째 문장 [SEP]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e22TcuvUvk3E"
   },
   "source": [
    "## 예제 3.13. BERT 토크나이저와 RoBERTa 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0vDO4KJ_vlUv"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0fffd8bf6c436d929056af1088f48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\masta\\.cache\\huggingface\\hub\\models--klue--bert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28275b02cc646e2bcd0cb764f6c7da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9b169ce61b40a0a3e75b0223a6b2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d70e1cd3b14df185ad4c63c3ca6fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21985aebdef9432e92ad3ff543bbe9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1cf0263d9c4bc5b638fb0b565472e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\masta\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6192d7adbefb44df8da3a7a4af7b3d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f6b73fa8d94c06b04c0c5d31e436fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f0cf53f13b4a54a254d47bfb76613d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30452ee78bc436999a012d6b756c80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "bert_tokenizer([['첫 번째 문장', '두 번째 문장']])\n",
    "# {'input_ids': [[2, 1656, 1141, 3135, 6265, 3, 864, 1141, 3135, 6265, 3]],\n",
    "# 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "roberta_tokenizer([['첫 번째 문장', '두 번째 문장']])\n",
    "# {'input_ids': [[0, 1656, 1141, 3135, 6265, 2, 864, 1141, 3135, 6265, 2]],\n",
    "# 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
    "\n",
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "en_roberta_tokenizer([['first sentence', 'second sentence']])\n",
    "# {'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8TSCJ_rvux1"
   },
   "source": [
    "## 예제 3.14. attention_mask 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lj8XkTM9vvwu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2073, 1599, 2062, 18, 2, 1, 1, 1, 1, 1, 1], [0, 864, 1141, 3135, 6265, 2073, 1656, 1141, 3135, 6265, 3632, 831, 647, 2062, 18, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['첫 번째 문장은 짧다.', '두 번째 문장은 첫 번째 문장 보다 더 길다.'], padding='longest')\n",
    "\n",
    "# {'input_ids': [[0, 1656, 1141, 3135, 6265, 2073, 1599, 2062, 18, 2, 1, 1, 1, 1, 1, 1],\n",
    "# [0, 864, 1141, 3135, 6265, 2073, 1656, 1141, 3135, 6265, 3632, 831, 647, 2062, 18, 2]],\n",
    "# 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    "# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9hRNhL6v8J3"
   },
   "source": [
    "## 예제 3.15. KLUE MRC 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h6rED4n6v-dg"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db0d7e03fe94eb09e905f352a301bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3f4c5d62f143a7b7cd1a3539cd3c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164bcbf7bb4b447c9d919c3a146c1d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f380861c3a8a41d1a1bc1b26f6fc3b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b061d7bb9042ff95d13cf50937db75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc')\n",
    "# klue_mrc_dataset_only_train = load_dataset('klue', 'mrc', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28cdd3vPwF-x"
   },
   "source": [
    "## 예제 3.16. 로컬의 데이터 활용하기\n",
    "(안내) 아래 코드를 실행하기 위해서는 구글 코랩에 csv 파일이 업로드 되어야 합니다. 허깅페이스 datasets 형식으로 쉽게 변환할 수 있다는 점을 보여주기 위한 예시 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "c7FfgbFUDBQg"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '//twsynol/desktop/study/llm/03\\my_file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0fa88f1e16f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 로컬의 데이터 파일을 활용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"my_file.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 파이썬 딕셔너리 활용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2586\u001b[0m     \u001b[1;31m# Create a dataset builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2587\u001b[1;33m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[0;32m   2588\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2589\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2257\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2258\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2259\u001b[1;33m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[0;32m   2260\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2261\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1798\u001b[0m             \u001b[0mdownload_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1799\u001b[1;33m         ).get_module()\n\u001b[0m\u001b[0;32m   1800\u001b[0m     \u001b[1;31m# Try locally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\load.py\u001b[0m in \u001b[0;36mget_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1139\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         )\n\u001b[1;32m-> 1141\u001b[1;33m         data_files = DataFilesDict.from_patterns(\n\u001b[0m\u001b[0;32m   1142\u001b[0m             \u001b[0mpatterns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns_for_key\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m             out[key] = (\n\u001b[1;32m--> 715\u001b[1;33m                 DataFilesList.from_patterns(\n\u001b[0m\u001b[0;32m    716\u001b[0m                     \u001b[0mpatterns_for_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mbase_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 data_files.extend(\n\u001b[1;32m--> 620\u001b[1;33m                     resolve_pattern(\n\u001b[0m\u001b[0;32m    621\u001b[0m                         \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m                         \u001b[0mbase_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\miniconda\\envs\\lang310\\lib\\site-packages\\datasets\\data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[1;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mallowed_extensions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf\" with any supported extension {list(allowed_extensions)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unable to find '//twsynol/desktop/study/llm/03\\my_file.csv'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# 로컬의 데이터 파일을 활용\n",
    "dataset = load_dataset(\"csv\", data_files=\"my_file.csv\")\n",
    "dataset = load_dataset(\"csv\", data_files=\"my_file.csv\")\n",
    "\n",
    "# 파이썬 딕셔너리 활용\n",
    "from datasets import Dataset\n",
    "my_dict = {\"a\": [1, 2, 3]}\n",
    "dataset = Dataset.from_dict(my_dict)\n",
    "\n",
    "# 판다스 데이터프레임 활용\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbdIGz7YDQ8q"
   },
   "source": [
    "# 3.4절 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE1cIGmdwT8n"
   },
   "source": [
    "## 예제 3.17. 모델 학습에 사용할 연합뉴스 데이터셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uHjb8Rd6DSDh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73420da0fe684bad9933a7cc798b9301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84042d9f5274db1bc1ce2d0620cc967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/847k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509fd42323c945238053894f04aa359b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4974699c19247468645ba6695cd3b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9107 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['guid', 'title', 'label', 'url', 'date'],\n",
       "    num_rows: 45678\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "klue_tc_train = load_dataset('klue', 'ynat', split='train')\n",
    "klue_tc_eval = load_dataset('klue', 'ynat', split='validation')\n",
    "klue_tc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "z90M9sisDUmr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'ynat-v1_train_00000',\n",
       " 'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n",
       " 'label': 3,\n",
       " 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n",
       " 'date': '2016.06.30. 오전 10:36'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HpQ3OqhoDWPY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].names\n",
    "# ['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qnb6SqInweAW"
   },
   "source": [
    "## 예제 3.18. 실습에 사용하지 않는 불필요한 컬럼 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wr6cX9laDX9Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'label'],\n",
       "    num_rows: 45678\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train = klue_tc_train.remove_columns(['guid', 'url', 'date'])\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(['guid', 'url', 'date'])\n",
    "klue_tc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAjvDdjqwoXY"
   },
   "source": [
    "## 예제 3.19. 카테고리를 문자로 표기한 label_str 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "W2YoqY7jDZVN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef63d6996dd4bfda9558f39f9555630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영', 'label': 3, 'label_str': '생활문화'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label']\n",
    "# ClassLabel(names=['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'], id=None)\n",
    "\n",
    "klue_tc_train.features['label'].int2str(1)\n",
    "# '경제'\n",
    "\n",
    "klue_tc_label = klue_tc_train.features['label']\n",
    "\n",
    "def make_str_label(batch):\n",
    "  batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "  return batch\n",
    "\n",
    "klue_tc_train = klue_tc_train.map(make_str_label, batched=True, batch_size=1000)\n",
    "\n",
    "klue_tc_train[0]\n",
    "# {'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영', 'label': 3, 'label_str': '생활문화'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzAkPNnmwumM"
   },
   "source": [
    "## 예제 3.20. 학습/검증/테스트 데이터셋 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xNbew6U5Da9r"
   },
   "outputs": [],
   "source": [
    "train_dataset = klue_tc_train.train_test_split(test_size=10000, shuffle=True, seed=42)['test']\n",
    "dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle=True, seed=42)\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000, shuffle=True, seed=42)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd7D7qxEw1mS"
   },
   "source": [
    "## 예제 3.21. Trainer를 사용한 학습: (1) 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OYfOFc06w37p"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2712a608be841daa1c12a92cd88ad53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49daf38f07c847458b50f06b871bb4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5459a09733a49b783998a31df7fe16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"title\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "model_id = \"klue/roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOH98qOLw9yn"
   },
   "source": [
    "## 예제 3.22. Trainer를 사용한 학습: (2) 학습 인자와 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ryZVReVmxAn0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALNfYD95xGsq"
   },
   "source": [
    "## 예제 3.23. Trainer를 사용한 학습 - (3) 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "id": "sGBbSFcAE2mm",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:04:21] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 14:04:21] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 14:04:21] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 14:04:21] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 14:04:21] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon WARNING @ 14:04:23] We saw that you have a AMD Ryzen 5 5600G with Radeon Graphics but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 14:04:23] CPU Model on constant consumption mode: AMD Ryzen 5 5600G with Radeon Graphics\n",
      "[codecarbon INFO @ 14:04:23] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 14:04:23]   Platform system: Windows-10-10.0.22621-SP0\n",
      "[codecarbon INFO @ 14:04:23]   Python version: 3.10.14\n",
      "[codecarbon INFO @ 14:04:23]   CodeCarbon version: 2.3.5\n",
      "[codecarbon INFO @ 14:04:23]   Available RAM : 63.795 GB\n",
      "[codecarbon INFO @ 14:04:23]   CPU count: 12\n",
      "[codecarbon INFO @ 14:04:23]   CPU model: AMD Ryzen 5 5600G with Radeon Graphics\n",
      "[codecarbon INFO @ 14:04:23]   GPU count: 1\n",
      "[codecarbon INFO @ 14:04:23]   GPU model: 1 x NVIDIA GeForce RTX 3060\n",
      "[codecarbon WARNING @ 14:04:25] Unable to access geographical location through primary API. Will resort to using the backup API - Exception : HTTPSConnectionPool(host='get.geojs.io', port=443): Read timed out. (read timeout=0.5) - url=https://get.geojs.io/v1/ip/geo.json\n",
      "[codecarbon WARNING @ 14:04:26] Unable to access geographical location. Using 'Canada' as the default value - Exception : HTTPSConnectionPool(host='ip-api.com', port=443): Max retries exceeded with url: /json/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000025F47EE9D20>, 'Connection to ip-api.com timed out. (connect timeout=0.5)')) - url=https://get.geojs.io/v1/ip/geo.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 13:25, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.518973</td>\n",
       "      <td>0.851000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 14:04:41] Energy consumed for RAM : 0.000100 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:04:41] Energy consumed for all GPUs : 0.000556 kWh. Total GPU Power : 133.12063269339538 W\n",
      "[codecarbon INFO @ 14:04:41] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:04:41] 0.000833 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:04:56] Energy consumed for RAM : 0.000199 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:04:56] Energy consumed for all GPUs : 0.001234 kWh. Total GPU Power : 162.71009658436634 W\n",
      "[codecarbon INFO @ 14:04:56] Energy consumed for all CPUs : 0.000355 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:04:56] 0.001788 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:05:11] Energy consumed for RAM : 0.000299 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:05:11] Energy consumed for all GPUs : 0.001912 kWh. Total GPU Power : 162.50762273277516 W\n",
      "[codecarbon INFO @ 14:05:11] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:05:11] 0.002743 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:05:26] Energy consumed for RAM : 0.000399 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:05:26] Energy consumed for all GPUs : 0.002590 kWh. Total GPU Power : 162.78350332356595 W\n",
      "[codecarbon INFO @ 14:05:26] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:05:26] 0.003698 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:05:41] Energy consumed for RAM : 0.000498 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:05:41] Energy consumed for all GPUs : 0.003263 kWh. Total GPU Power : 161.34017551916395 W\n",
      "[codecarbon INFO @ 14:05:41] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:05:41] 0.004647 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:05:56] Energy consumed for RAM : 0.000598 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:05:56] Energy consumed for all GPUs : 0.003938 kWh. Total GPU Power : 162.07431774100633 W\n",
      "[codecarbon INFO @ 14:05:56] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:05:56] 0.005600 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:06:11] Energy consumed for RAM : 0.000698 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:06:11] Energy consumed for all GPUs : 0.004607 kWh. Total GPU Power : 160.36363784003933 W\n",
      "[codecarbon INFO @ 14:06:11] Energy consumed for all CPUs : 0.001241 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:06:11] 0.006545 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:06:26] Energy consumed for RAM : 0.000797 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:06:26] Energy consumed for all GPUs : 0.005272 kWh. Total GPU Power : 159.52275483341353 W\n",
      "[codecarbon INFO @ 14:06:26] Energy consumed for all CPUs : 0.001418 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:06:26] 0.007487 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:06:41] Energy consumed for RAM : 0.000897 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:06:41] Energy consumed for all GPUs : 0.005931 kWh. Total GPU Power : 158.27885239853248 W\n",
      "[codecarbon INFO @ 14:06:41] Energy consumed for all CPUs : 0.001595 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:06:41] 0.008423 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:06:56] Energy consumed for RAM : 0.000997 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:06:56] Energy consumed for all GPUs : 0.006586 kWh. Total GPU Power : 157.17550121198295 W\n",
      "[codecarbon INFO @ 14:06:56] Energy consumed for all CPUs : 0.001772 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:06:56] 0.009355 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:07:11] Energy consumed for RAM : 0.001096 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:07:11] Energy consumed for all GPUs : 0.007233 kWh. Total GPU Power : 155.3196688900639 W\n",
      "[codecarbon INFO @ 14:07:11] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:07:11] 0.010279 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:07:26] Energy consumed for RAM : 0.001196 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:07:26] Energy consumed for all GPUs : 0.007884 kWh. Total GPU Power : 156.06725880707043 W\n",
      "[codecarbon INFO @ 14:07:26] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:07:26] 0.011206 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:07:41] Energy consumed for RAM : 0.001295 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:07:41] Energy consumed for all GPUs : 0.008529 kWh. Total GPU Power : 154.80299798860952 W\n",
      "[codecarbon INFO @ 14:07:41] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:07:41] 0.012128 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:07:56] Energy consumed for RAM : 0.001395 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:07:56] Energy consumed for all GPUs : 0.009174 kWh. Total GPU Power : 154.85620052831476 W\n",
      "[codecarbon INFO @ 14:07:56] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:07:56] 0.013049 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:08:11] Energy consumed for RAM : 0.001495 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:08:11] Energy consumed for all GPUs : 0.009816 kWh. Total GPU Power : 154.12990052390498 W\n",
      "[codecarbon INFO @ 14:08:11] Energy consumed for all CPUs : 0.002658 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:08:11] 0.013969 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:08:26] Energy consumed for RAM : 0.001594 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:08:26] Energy consumed for all GPUs : 0.010452 kWh. Total GPU Power : 152.460110218087 W\n",
      "[codecarbon INFO @ 14:08:26] Energy consumed for all CPUs : 0.002835 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:08:26] 0.014881 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:08:41] Energy consumed for RAM : 0.001694 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:08:41] Energy consumed for all GPUs : 0.011088 kWh. Total GPU Power : 152.8101785321788 W\n",
      "[codecarbon INFO @ 14:08:41] Energy consumed for all CPUs : 0.003012 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:08:41] 0.015794 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:09:00] Energy consumed for RAM : 0.001817 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:09:00] Energy consumed for all GPUs : 0.011233 kWh. Total GPU Power : 28.16800520718271 W\n",
      "[codecarbon INFO @ 14:09:00] Energy consumed for all CPUs : 0.003231 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:09:00] 0.016281 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:09:15] Energy consumed for RAM : 0.001916 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:09:15] Energy consumed for all GPUs : 0.011280 kWh. Total GPU Power : 11.107426864605848 W\n",
      "[codecarbon INFO @ 14:09:15] Energy consumed for all CPUs : 0.003408 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:09:15] 0.016604 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:09:30] Energy consumed for RAM : 0.002016 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:09:30] Energy consumed for all GPUs : 0.011325 kWh. Total GPU Power : 10.85697730926579 W\n",
      "[codecarbon INFO @ 14:09:30] Energy consumed for all CPUs : 0.003585 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:09:30] 0.016926 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:09:45] Energy consumed for RAM : 0.002116 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:09:45] Energy consumed for all GPUs : 0.011841 kWh. Total GPU Power : 123.97655032863591 W\n",
      "[codecarbon INFO @ 14:09:45] Energy consumed for all CPUs : 0.003762 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:09:45] 0.017719 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:10:00] Energy consumed for RAM : 0.002215 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:10:00] Energy consumed for all GPUs : 0.012515 kWh. Total GPU Power : 161.69170333402667 W\n",
      "[codecarbon INFO @ 14:10:00] Energy consumed for all CPUs : 0.003939 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:10:00] 0.018670 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:10:15] Energy consumed for RAM : 0.002315 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:10:15] Energy consumed for all GPUs : 0.013180 kWh. Total GPU Power : 159.4117646394672 W\n",
      "[codecarbon INFO @ 14:10:15] Energy consumed for all CPUs : 0.004116 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:10:15] 0.019611 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:10:30] Energy consumed for RAM : 0.002415 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:10:30] Energy consumed for all GPUs : 0.013816 kWh. Total GPU Power : 152.6709070812453 W\n",
      "[codecarbon INFO @ 14:10:30] Energy consumed for all CPUs : 0.004294 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:10:30] 0.020524 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:10:45] Energy consumed for RAM : 0.002514 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:10:45] Energy consumed for all GPUs : 0.014456 kWh. Total GPU Power : 153.54672053213417 W\n",
      "[codecarbon INFO @ 14:10:45] Energy consumed for all CPUs : 0.004471 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:10:45] 0.021441 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:11:00] Energy consumed for RAM : 0.002614 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:11:00] Energy consumed for all GPUs : 0.015092 kWh. Total GPU Power : 152.55462566731762 W\n",
      "[codecarbon INFO @ 14:11:00] Energy consumed for all CPUs : 0.004648 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:11:00] 0.022354 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:11:15] Energy consumed for RAM : 0.002714 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:11:15] Energy consumed for all GPUs : 0.015726 kWh. Total GPU Power : 152.09954092499135 W\n",
      "[codecarbon INFO @ 14:11:15] Energy consumed for all CPUs : 0.004825 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:11:15] 0.023265 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:11:30] Energy consumed for RAM : 0.002813 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:11:30] Energy consumed for all GPUs : 0.016360 kWh. Total GPU Power : 152.1618622796946 W\n",
      "[codecarbon INFO @ 14:11:30] Energy consumed for all CPUs : 0.005002 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:11:30] 0.024176 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:11:45] Energy consumed for RAM : 0.002913 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:11:45] Energy consumed for all GPUs : 0.016993 kWh. Total GPU Power : 151.75659647474814 W\n",
      "[codecarbon INFO @ 14:11:45] Energy consumed for all CPUs : 0.005179 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:11:45] 0.025085 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:12:00] Energy consumed for RAM : 0.003012 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:12:00] Energy consumed for all GPUs : 0.017624 kWh. Total GPU Power : 151.42974183223805 W\n",
      "[codecarbon INFO @ 14:12:00] Energy consumed for all CPUs : 0.005357 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:12:00] 0.025993 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:12:15] Energy consumed for RAM : 0.003112 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:12:15] Energy consumed for all GPUs : 0.018248 kWh. Total GPU Power : 149.76531663128287 W\n",
      "[codecarbon INFO @ 14:12:15] Energy consumed for all CPUs : 0.005534 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:12:15] 0.026894 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:12:30] Energy consumed for RAM : 0.003212 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:12:30] Energy consumed for all GPUs : 0.018879 kWh. Total GPU Power : 151.08864177021525 W\n",
      "[codecarbon INFO @ 14:12:30] Energy consumed for all CPUs : 0.005711 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:12:30] 0.027801 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:12:45] Energy consumed for RAM : 0.003311 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:12:45] Energy consumed for all GPUs : 0.019503 kWh. Total GPU Power : 149.757133534508 W\n",
      "[codecarbon INFO @ 14:12:45] Energy consumed for all CPUs : 0.005888 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:12:45] 0.028702 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:13:00] Energy consumed for RAM : 0.003411 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:13:00] Energy consumed for all GPUs : 0.020130 kWh. Total GPU Power : 150.52513179269226 W\n",
      "[codecarbon INFO @ 14:13:00] Energy consumed for all CPUs : 0.006065 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:13:00] 0.029606 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:13:15] Energy consumed for RAM : 0.003511 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:13:15] Energy consumed for all GPUs : 0.020756 kWh. Total GPU Power : 150.12522558683975 W\n",
      "[codecarbon INFO @ 14:13:15] Energy consumed for all CPUs : 0.006243 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:13:15] 0.030509 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:13:30] Energy consumed for RAM : 0.003610 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:13:30] Energy consumed for all GPUs : 0.021378 kWh. Total GPU Power : 149.301859542045 W\n",
      "[codecarbon INFO @ 14:13:30] Energy consumed for all CPUs : 0.006420 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:13:30] 0.031408 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:13:45] Energy consumed for RAM : 0.003710 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:13:45] Energy consumed for all GPUs : 0.022002 kWh. Total GPU Power : 149.79889567892192 W\n",
      "[codecarbon INFO @ 14:13:45] Energy consumed for all CPUs : 0.006597 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:13:45] 0.032309 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:14:05] Energy consumed for RAM : 0.003843 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:14:05] Energy consumed for all GPUs : 0.022249 kWh. Total GPU Power : 44.45710233395605 W\n",
      "[codecarbon INFO @ 14:14:05] Energy consumed for all CPUs : 0.006833 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:14:05] 0.032925 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:14:20] Energy consumed for RAM : 0.003942 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:14:20] Energy consumed for all GPUs : 0.022297 kWh. Total GPU Power : 11.412567885307363 W\n",
      "[codecarbon INFO @ 14:14:20] Energy consumed for all CPUs : 0.007010 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:14:20] 0.033249 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:14:35] Energy consumed for RAM : 0.004042 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:14:35] Energy consumed for all GPUs : 0.022344 kWh. Total GPU Power : 11.473465938085125 W\n",
      "[codecarbon INFO @ 14:14:35] Energy consumed for all CPUs : 0.007187 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:14:35] 0.033574 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:14:50] Energy consumed for RAM : 0.004142 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:14:50] Energy consumed for all GPUs : 0.022833 kWh. Total GPU Power : 117.28479252772894 W\n",
      "[codecarbon INFO @ 14:14:50] Energy consumed for all CPUs : 0.007364 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:14:50] 0.034339 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:15:05] Energy consumed for RAM : 0.004241 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:15:05] Energy consumed for all GPUs : 0.023513 kWh. Total GPU Power : 163.05145581648816 W\n",
      "[codecarbon INFO @ 14:15:05] Energy consumed for all CPUs : 0.007542 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:15:05] 0.035296 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:15:20] Energy consumed for RAM : 0.004341 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:15:20] Energy consumed for all GPUs : 0.024172 kWh. Total GPU Power : 158.0294418288932 W\n",
      "[codecarbon INFO @ 14:15:20] Energy consumed for all CPUs : 0.007719 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:15:20] 0.036231 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:15:35] Energy consumed for RAM : 0.004441 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:15:35] Energy consumed for all GPUs : 0.024805 kWh. Total GPU Power : 151.89875668734206 W\n",
      "[codecarbon INFO @ 14:15:35] Energy consumed for all CPUs : 0.007896 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:15:35] 0.037142 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:15:50] Energy consumed for RAM : 0.004540 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:15:50] Energy consumed for all GPUs : 0.025434 kWh. Total GPU Power : 150.8091580004779 W\n",
      "[codecarbon INFO @ 14:15:50] Energy consumed for all CPUs : 0.008073 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:15:50] 0.038047 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:16:05] Energy consumed for RAM : 0.004640 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:16:05] Energy consumed for all GPUs : 0.026065 kWh. Total GPU Power : 151.47850554435067 W\n",
      "[codecarbon INFO @ 14:16:05] Energy consumed for all CPUs : 0.008250 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:16:05] 0.038955 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:16:20] Energy consumed for RAM : 0.004740 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:16:20] Energy consumed for all GPUs : 0.026696 kWh. Total GPU Power : 151.36101457348877 W\n",
      "[codecarbon INFO @ 14:16:20] Energy consumed for all CPUs : 0.008427 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:16:20] 0.039863 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:16:35] Energy consumed for RAM : 0.004839 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:16:35] Energy consumed for all GPUs : 0.027319 kWh. Total GPU Power : 149.68045886911352 W\n",
      "[codecarbon INFO @ 14:16:35] Energy consumed for all CPUs : 0.008605 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:16:35] 0.040763 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:17:03] Energy consumed for RAM : 0.005022 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:17:03] Energy consumed for all GPUs : 0.027883 kWh. Total GPU Power : 73.78110205468342 W\n",
      "[codecarbon INFO @ 14:17:03] Energy consumed for all CPUs : 0.008929 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:17:03] 0.041834 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:17:18] Energy consumed for RAM : 0.005121 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:17:18] Energy consumed for all GPUs : 0.027930 kWh. Total GPU Power : 11.359158884388416 W\n",
      "[codecarbon INFO @ 14:17:18] Energy consumed for all CPUs : 0.009106 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:17:18] 0.042158 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:17:33] Energy consumed for RAM : 0.005221 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:17:33] Energy consumed for all GPUs : 0.027977 kWh. Total GPU Power : 11.111192223900066 W\n",
      "[codecarbon INFO @ 14:17:33] Energy consumed for all CPUs : 0.009283 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:17:33] 0.042481 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:17:48] Energy consumed for RAM : 0.005321 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:17:48] Energy consumed for all GPUs : 0.028523 kWh. Total GPU Power : 131.0246830201402 W\n",
      "[codecarbon INFO @ 14:17:48] Energy consumed for all CPUs : 0.009461 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:17:48] 0.043304 kWh of electricity used since the beginning.\n",
      "[codecarbon INFO @ 14:17:55] Energy consumed for RAM : 0.005369 kWh. RAM Power : 23.92322301864624 W\n",
      "[codecarbon INFO @ 14:17:55] Energy consumed for all GPUs : 0.028859 kWh. Total GPU Power : 165.9722356812402 W\n",
      "[codecarbon INFO @ 14:17:55] Energy consumed for all CPUs : 0.009547 kWh. Total CPU Power : 42.5 W\n",
      "[codecarbon INFO @ 14:17:55] 0.043775 kWh of electricity used since the beginning.\n",
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\codecarbon\\output.py:168: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame.from_records([dict(data.values)])])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4699426591396332,\n",
       " 'eval_accuracy': 0.861,\n",
       " 'eval_runtime': 19.8066,\n",
       " 'eval_samples_per_second': 50.488,\n",
       " 'eval_steps_per_second': 6.311,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(test_dataset) # 정확도 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHVobEq8xS0j"
   },
   "source": [
    "## 예제 3.24. Trainer를 사용하지 않는 학습: (1) 학습을 위한 모델과 토크나이저 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pdTjuT3txUeX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "def tokenize_function(examples): # 제목(title) 컬럼에 대한 토큰화\n",
    "    return tokenizer(examples[\"title\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 모델과 토크나이저 불러오기\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"klue/roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I4D0Vs_xamC"
   },
   "source": [
    "## 예제 3.25 Trainer를 사용하지 않는 학습: (2) 학습을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3UA738ljxcmh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3093eb6bee054ee8a94339311279e225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84d5e7cece14b2d8df44f3c6c52f3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08e9add84fe434b9de82b99880dc426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_dataloader(dataset, batch_size, shuffle=True):\n",
    "    dataset = dataset.map(tokenize_function, batched=True).with_format(\"torch\") # 데이터셋에 토큰화 수행\n",
    "    dataset = dataset.rename_column(\"label\", \"labels\") # 컬럼 이름 변경\n",
    "    dataset = dataset.remove_columns(column_names=['title']) # 불필요한 컬럼 제거\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "# 데이터로더 만들기\n",
    "train_dataloader = make_dataloader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_dataloader = make_dataloader(valid_dataset, batch_size=8, shuffle=False)\n",
    "test_dataloader = make_dataloader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg5ertQLxtSK"
   },
   "source": [
    "## 예제 3.26. Trainer를 사용하지 않는 학습: (3) 학습을 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "my5ujdBkxvQX"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device) # 모델에 입력할 토큰 아이디\n",
    "        attention_mask = batch['attention_mask'].to(device) # 모델에 입력할 어텐션 마스크\n",
    "        labels = batch['labels'].to(device) # 모델에 입력할 레이블\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels) # 모델 계산\n",
    "        loss = outputs.loss # 손실\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 모델 업데이트\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqfUWSpYxv6w"
   },
   "source": [
    "## 예제 3.27. Trainer를 사용하지 않는 학습: (4) 평가를 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "a4Vo66qkx0LK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hi1pEAU8x17j"
   },
   "source": [
    "## 예제 3.28 Trainer를 사용하지 않는 학습: (5) 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "m7mXY8iBx6un"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd09a1418c2e48258c60fe1c3ed53e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4437697387352586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150ae9381c564e5a91fccb522ed4257c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.7276501641869545\n",
      "Validation accuracy: 0.776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea2bf4f18d34bd7bb6a43163aeb5794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.778\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer)\n",
    "    print(f\"Training loss: {train_loss}\")\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_dataloader)\n",
    "    print(f\"Validation loss: {valid_loss}\")\n",
    "    print(f\"Validation accuracy: {valid_accuracy}\")\n",
    "\n",
    "# Testing\n",
    "_, test_accuracy = evaluate(model, test_dataloader)\n",
    "print(f\"Test accuracy: {test_accuracy}\") # 정확도 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqanaywJyDOq"
   },
   "source": [
    "## 예제 3.29. 허깅페이스 허브에 모델 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "rj62Q5Dm4wDN"
   },
   "outputs": [],
   "source": [
    "# 모델의 예측 아이디와 문자열 레이블을 연결할 데이터를 모델 config에 저장\n",
    "id2label = {i: label for i, label in enumerate(train_dataset.features['label'].names)}\n",
    "label2id = {label: i for i, label in id2label.items()}\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "03EY1lJ0ISzC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\masta\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13942c4b5d64ce4a962d6dab1dd352c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979180426079432192780558dd4c0fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\lang310\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\masta\\.cache\\huggingface\\hub\\models--wooseok0303--roberta-base-klue-ynat-classification. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/wooseok0303/roberta-base-klue-ynat-classification/commit/906326eca59b0dd3e415bfa3f33363e8ffc9333d', commit_message='Upload tokenizer', commit_description='', oid='906326eca59b0dd3e415bfa3f33363e8ffc9333d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")\n",
    "repo_id = \"wooseok0303/roberta-base-klue-ynat-classification\"\n",
    "# Trainer를 사용한 경우\n",
    "trainer.push_to_hub(repo_id)\n",
    "# 직접 학습한 경우\n",
    "model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WheFaA_obmWG"
   },
   "source": [
    "# 3.5절 모델 추론하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrzXul13ygjb"
   },
   "source": [
    "## 예제 3.30. 학습한 모델을 불러와 pipeline을 활용해 추론하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Gzm7n_fgjnO"
   },
   "outputs": [],
   "source": [
    "# 실습을 새롭게 시작하는 경우 데이터셋 다시 불러오기 실행\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"klue\", \"ynat\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNIST 신현석 교수팀 초저유전율 절연체 비정질 질화붕소 개발',\n",
       " '고랭지 작업 내외국인 탄 승합차 삼척 급커브서 꽝 13명 사상종합3보',\n",
       " '2020 자랑스러운 한양언론인상 수상자',\n",
       " '선진 노사문화 공헌…경남도 산업평화상 후보 접수',\n",
       " '안동 어린이집 94곳 105일 만에 다시 문 연다',\n",
       " '리니지M 소개하는 정진수 엔씨소프트 부사장',\n",
       " 'ICAS 우수학술도서상 한국어 부문에 돌궐 유목제국사',\n",
       " 'LG전자 임직원 찾아가는 수해복구',\n",
       " '계명산·닭바위 닭 관련 지명 293개…정유년 맞아 분석',\n",
       " '루푸스 맞춤치료 가능성 찾았다…글리벡도 효과',\n",
       " 'KT 해외 로밍용 LTE 에그 등 신제품 3종 출시',\n",
       " '한중 연구진 한약재 지황 암세포사멸 유도 확인',\n",
       " '예멘 정부 남부 아덴 주요시설서 분리주의세력 철수',\n",
       " '비누 성분 넣은 반도체 잉크 개발…유독성 잉크 대체 가능',\n",
       " '私黨논란 우려 安 조연 자처…한상진 지각변동 있을것',\n",
       " 'SNS돋보기 中 세계 최대 전파망원경으로 펄서 발견…우리는 언제',\n",
       " '안전확보가 군민 행복의 기본 장성군 방범 CCTV 추가 설치',\n",
       " '서울 마포구 공중화장실 7곳에 안심스크린 설치',\n",
       " '하반기경제 주택대출 때 신용대출액도 고려…가계부채 질 개선',\n",
       " '인천서만 시행된 온라인 학력평가',\n",
       " '신간 고마워요 유행가·지능혁명',\n",
       " '전파자원 블루오션 밀리미터파 기술 선점 경쟁 후끈',\n",
       " '항생제 콜레라균 증식 환경 조성 확인',\n",
       " '희망과 절망의 만남…선종훈·하태형 리베라 메 전',\n",
       " 'K리그 대표 선수들 이미지 담은 게토레이 스페셜 패키지 출시',\n",
       " '국립발레단 박슬기·이재우 등 브누아 드 라 당스 수상 실패종합',\n",
       " '대전 코로나19 확산에 대학생들 대면시험 안돼 목소리 커져',\n",
       " '맛좋고 건강한 슬로피시 아시나요…해양생물학자의 인문학',\n",
       " '北 위안부 화해·치유재단 설립 사대매국 행위',\n",
       " '朴대통령 중앙노동위 위원장에 박준성 내정',\n",
       " '유은혜 수도권 학교 3단계 미리 준비…조희연 원격 전환해야종합3보',\n",
       " '캄보디아 훈센 총리 페이스북 댓글 모니터링…가짜뉴스 차단',\n",
       " '항결핵제 치료 효과 높이는 방법 찾았다',\n",
       " '도종환 문체부 장관 獨 ARD 콩쿠르 우승 손정범에게 축전',\n",
       " '대통령경호실 차장에 이영석 경호본부장 내정',\n",
       " '게시판 키움증권 미국주식 무거래 고객에게 40달러 지원',\n",
       " '중러 원자로 건설 2조원 계약 맺는다',\n",
       " '룽투코리아 용현BM 지분 추가 인수 계획 없어',\n",
       " 'GS 허창수 회장 작년 연봉 78억원…정택근 부회장 26억',\n",
       " '아시안게임 응원석엔 하나된 함성 벤치엔 우정의 미소…...',\n",
       " '2019 노벨문학상 수상작가 페터 한트케 연보',\n",
       " '이달의 KIST인상 5월 수상자에 최경민 박사',\n",
       " '진상조사위 합의 이행하라 이재학PD 대책위 1박2일 집회',\n",
       " '안양 보육시설 관련 2명 추가 확진…누적 12명',\n",
       " '주 1회 등교해 고작 2시간 수업…이러려면 왜 가나',\n",
       " '기업의 꿈에 가치 매겨야…한투증권 주가꿈비율PDR 개발',\n",
       " '경기교육청 내년 유·초·특수학교 교사 1천950명 선발',\n",
       " '법의날 기념식',\n",
       " '안보리 대북결의안 2270호 이행보고서 제출한 나라 70개 육박',\n",
       " '택배연대노조 제28회 전태일노동상 단체부문 수상',\n",
       " '과학전람회 대통령상에 충북과학고생 최경준·손승연',\n",
       " '김혜경 한문연 회장 전국 100여곳 누볐죠',\n",
       " '타계 100주기 바움의 동시집 아빠 거위 출간',\n",
       " '금산분리 규제 비합리적…금융그룹 통합감독체계 필요',\n",
       " '시도교육감협의회 전교조 노조 지위 회복 대법원 판결 환영',\n",
       " '대체식 받는 초등학생들',\n",
       " 'KTB투자 OCI 도쿠야마말레이시아 인수시 최고 효과',\n",
       " '朴대통령 스캐퍼로티 연합사령관에 보국훈장 통일장 수여',\n",
       " '여성영화채널 씨네프 소확행 영화제',\n",
       " '강원교육청 개학 추가 연기에 긴급돌봄교실 운영 점검',\n",
       " '충북도시·군 미취업 청년 5천명에 구직활동비 30만원씩 지원',\n",
       " '생일 같은 한국테크놀로지그룹 형제 경영권 갈등 없을까',\n",
       " '보노보노랑 놀자…명언집·베스트 컬렉션 출간',\n",
       " '그래픽 전국 코로나19 확진자 현황종합',\n",
       " '서울시 장애인 활동지원사에 정신건강검진비·교육수당 지원',\n",
       " '관장이 전시 일일해설사로…서울시립미술관 통일테마전',\n",
       " '이주단체 20t 이상 규모 선박 이주노동자도 최저임금 적용돼야',\n",
       " '게시판 CJ올리브영 온라인으로 유네스코 소녀교육 캠페인',\n",
       " '구글 순정 OS 담은 스마트폰 LG Q9 원 15일 출시',\n",
       " '하상욱 짠하다는 느낌 받았으면…자신에게 관대해지세요',\n",
       " '한국 드라마 터키·서남아시아에서도 인기',\n",
       " '김경린·오장환·문익환…탄생 100주년 문인들 돌아본다',\n",
       " '독일 외딴 시골 이상한 미술관을 아시나요',\n",
       " '은성수 현산 인수 무산시 아시아나에 기안기금 투입 시사종합',\n",
       " '英 존슨 총리 염문설 美 기업인 성관계 여부 즉답 안 해',\n",
       " '연천 임진강 상류에 연강 나룻길 개장…첫 걷기행사',\n",
       " '우정 노사 집배 업무강도 진단시스템 폐지 최종 합의',\n",
       " '김동철 교육정책 뒤죽박죽…김상곤 즉시 사퇴하라',\n",
       " 'KBS노조 이정현 유죄판결에 언론자유 숭고함 일깨워',\n",
       " '쿠르드 자치정부 개전 이후 민간인 218명 숨져',\n",
       " '이천물류창고 참사를 추모하며',\n",
       " '사이테크 플러스 자동차 바퀴에 깔려도 사는 괴물곤충 외골격의 비밀 풀렸다',\n",
       " '신간 문화권력·유동론·지형학의 기초',\n",
       " '이란 음악가 후세인 알리자데 아시아 월드뮤직 어워드 수상',\n",
       " '모욕·폭행·성희롱까지…법 시행 6개월에도 여전한 직장갑질',\n",
       " '대한항공 사우회 3자 연합이 의결권 권리 침해',\n",
       " '김명환 민주노총 위원장 보건의료노동자 간담회 발언',\n",
       " '바리스타 로봇이 주문받고 커피 제조 5G 카페 개점',\n",
       " '서울시·사랑의열매 취약계층 월동준비 6억원 지원',\n",
       " 'IS공습중단 공약 탓…캐나다 연합국 국방장관회의 제외논란',\n",
       " '브루스 커밍스가 총정리한 잊힌 전쟁 한국전쟁의 모든 것',\n",
       " '어젯밤 꿀잠 잤을까…LGU IoT숙면알리미 출시',\n",
       " '여야 물밑접촉도 공회전…기약없는 쟁점법안·선거구',\n",
       " '화순 남면 자연학습장 해바라기 활짝',\n",
       " '속보 학생 11명·교직원 3명 코로나19 신규 확진',\n",
       " '대륙철도 상징조형물 잇다 공개',\n",
       " '불굴의 샤페코엔시…항공기 참사 딛고 남미 클럽대항전 진출',\n",
       " '모다 가상화폐 거래소업체 제스트씨앤티 지분취득 취소',\n",
       " '오바마 마지막 칠면조 사면…우리에겐 차이보다 공통점 많아',\n",
       " '우간다 장관 글래머 여성 관광 촉진에 활용 발언했다 역풍',\n",
       " '허위공시 중국원양자원 이번엔 호재성 공시 쏟아내종합',\n",
       " '임대차법 시행 3개월간 서울 전셋값 7.5% 뛰었다종합',\n",
       " '성범죄자 취업제한 위반 적발 10명 중 3명 학원등 사교육 취업',\n",
       " '발언하는 박준식 위원장',\n",
       " '장휘국 광주교육감 부인 청탁금지법 위반…교육감 사과',\n",
       " '북핵 극도로 우려…아태지역의 가장 위험하고 예측불가한 나라',\n",
       " '게시판 키움증권 2020 키움 영웅전 실전투자대회',\n",
       " '페이스북 인터넷 드론 아퀼라 실물 첫 시험비행 성공',\n",
       " '접근성vs군 작전 운용…새 대구공항 최적지는',\n",
       " '스위스 의회 이민제한법 완화…英 브렉시트 협상서 고심',\n",
       " '온라인 수업 참관하는 박백범 차관',\n",
       " '신문협회 신문기자 진로탐색 프로그램 참가학교 모집',\n",
       " '행사장으로 이동하는 박영선 장관과 구현모 KT 대표',\n",
       " '우크라 녹취록으로 본 트럼프…변덕스럽고 아첨에 약해',\n",
       " '신간 창백한 말·금색기계·백설공주 살인사건',\n",
       " '국방부 한일군사정보협정 우리가 건의…靑하명 없었다',\n",
       " '노동부 임금 체불 청산 지원 융자 이율 1%p 인하',\n",
       " '그래픽 서울 11월 일강수량 추이',\n",
       " '장애인고용공단 올해 장애인 고용 신뢰기업 신청 접수',\n",
       " '근로자·사업주·청소년 교육기관 한국고용노동교육원 출범',\n",
       " '본드카 애스턴마틴 발할라 국내 전시…500대만 생산',\n",
       " '구직 열기',\n",
       " 'kt 게레로 등 코치 인선 완료…박기혁도 은퇴 후 코치로',\n",
       " '음성·충주 8개교 등교중지…이천 코로나19 집단감염 영향',\n",
       " '위안부 지킴이 혼다 동료의원한인들 아쉬움속 아름다운 작별',\n",
       " '신정뉴타운 21구역 단지명 래미안 목동아델리체로',\n",
       " '코스피 4.9% 급락해 10년만에 1600선 붕괴종합',\n",
       " '합법노조 전교조 해직교사 대부분 복직…문정부 사과해야',\n",
       " 'LG벨벳 물방울 카메라 등 스펙 공개…다음 달 15일 출시',\n",
       " '울산소식 제20회 울산옥외광고대상전 입상작 40점 선정',\n",
       " '국민카드 교육 특화 이지 스터디 티타늄 카드 출시',\n",
       " '美 시리아 북동부에 다국적 감시군 추진…미군 400명 잔류',\n",
       " '광주관광컨벤션뷰로광주대 관광 인재 양성',\n",
       " '서강대서 무단으로 파쿠르 훈련하고 영상 찍은 유튜버 고발돼',\n",
       " '굴욕겪은 문명대국 중국·그리스 약탈문화재 반환에 합심',\n",
       " '공포에 질린 주식시장…증시 공포지수 11년여만에 최고종합',\n",
       " '브리핑장 향하는 반기수 화성연쇄살인사건 수사본부장',\n",
       " '러와 갈등 우크라 사상 처음으로부터 미국산 원유 직수입',\n",
       " '신기한 봄꽃',\n",
       " '미소 짓는 김경수',\n",
       " '핵심만 짚는다 tvN 시사 레슨 커버스토리',\n",
       " '10대 의붓딸 수차례 성폭행한 계부 징역 7년',\n",
       " '주말 N 여행 영남권 벌써 크리스마스∼…17ｍ 대형트리 불 켠 부산 광복로',\n",
       " '충북 노사민정 코로나19 경제 위기 극복 힘 모으자',\n",
       " '시부터 방랑기까지…서정주 전집 20권으로 완간',\n",
       " '엑세스바이오 최대주주 우리들제약으로 변경',\n",
       " '멕시코 표현주의 화가 프란시스코 톨레도 별세',\n",
       " '충주소식 여름 근로활동 대학생 100명 모집',\n",
       " '中 웨이하이 국제식품박람회에 한국관 개설',\n",
       " '상주적십자병원으로 이송되는 코로나19 환자들',\n",
       " '펀드매니저 700명 첫 돌파…1인당 3천300억 굴린다',\n",
       " '공공운수노조 중대재해기업처벌법 제정 촉구 기자회견',\n",
       " '출연연 우수 연구성과에 블랙홀 관측·치매 약물 후보 개발',\n",
       " '대사관 상급자가 부하 성추행…법원 국가는 감독책임 없어',\n",
       " '삼성 갤럭시S10 보급형 S10 라이트 출시할 듯…라인업 세분화',\n",
       " '그래픽 국내 시장별 평균 주식보유 기간',\n",
       " '전세계 소득 하위 20% 가정 딸 3명중 1명 학교 못 다녔다',\n",
       " '칸막이 사이에 두고 식사',\n",
       " '승격 실패한 부산 최만희 사장·최윤겸 감독 동반 사퇴',\n",
       " '맘고생 끝 이재영 다행히 제가 강한 사람입니다',\n",
       " '7월 과학기술자상에 변재형 KAIST 교수',\n",
       " '인문사회 분야 유망 연구자 지원한다…총 120억원 규모',\n",
       " '학교 들어가기 전 거리 두며 대기',\n",
       " '내년부터 서울 중·고교 신입생에 입학준비금 30만원 지원종합',\n",
       " '증시신상품 유안타증권 유동원 글로벌 홈런안타 랩 출시',\n",
       " '무대와 방송 오간 원로 연극인 박용기씨 별세',\n",
       " '수서고속철 6월부터 역무분야 근로 월 7시간 줄인다',\n",
       " '코로나19 충격에 제조업 고용 악화일로…청년층도 타격 커',\n",
       " '흑석동 재개발 지역 도로 법원경매서 6억원에 낙찰된 까닭',\n",
       " '우리은행 우리미술대회 본선대회 온라인 개최',\n",
       " '특징주 신양오라컴 자금조달 기대감에 급등',\n",
       " '교육부 17일 공주대서 지역혁신 사업 충청권 간담회',\n",
       " '롯데 임원인사 여진…최춘석 롯데슈퍼 대표 사표',\n",
       " '전남 스트라이커 하태균 영입…4년만에 K리그 복귀',\n",
       " '울산서도 돌봄전담사들 파업…절반 이상은 오후에 복귀',\n",
       " '북 수소탄실험 긴박했던 靑 하루…北발표대로 속단 어려워',\n",
       " '농업도 4차 산업혁명 ④ 농촌에 미래를 건다 스마트 파머들',\n",
       " '전준혁 영국 로열발레단 입단…수석무용수가 꿈종합',\n",
       " 'KIST 목질계 바이오매스로부터 바이오연료 생산',\n",
       " '삼성SDI 노사 첫 단체교섭 상견례',\n",
       " '전남대 신천지 교회로 향하는 북문 폐쇄',\n",
       " '美 간판급 제조업체들 줄줄이 깜짝실적…세계경제 화창',\n",
       " '도심서 단풍 즐겨요…강남구 6∼12일 양재천서 축제',\n",
       " '한국 여자배구에 태국 경계령…김연경 꺼리는 팀',\n",
       " '제19회 세계한인언론인대회',\n",
       " '김정은 전용열차 블라디 교외지역으로 이동…보안조치',\n",
       " '워즈니악 아이폰 X 출시 첫날 사지 않은 첫 아이폰 될 것',\n",
       " '선거 후보자 남녀 동수로…獨브란덴부르크州서 법안 가결',\n",
       " '벼랑 끝에 몰린 삼성화재 박철우·박상하까지 부상이탈',\n",
       " '셧다운에 줄줄이 격리…방송가도 코로나 직격탄',\n",
       " '페트로브라스 저유가 딜레마…유전 80% 사업성 의문',\n",
       " '12월 과학기술인상에 천정희 서울대 교수',\n",
       " '공무원노조 충남 민간 개방형 읍면동장 임용계획 철회 촉구',\n",
       " '우리은행 캄보디아 자회사 2곳 합병…현지 5위 저축은행',\n",
       " 'LG유플러스 30만원대 휴대용 고화질 빔프로젝터 출시',\n",
       " '6월항쟁 30주년에 다시 쓴 민중가요…촛불 의미 담았죠',\n",
       " '영상 꼭두 이야기 김수안 언젠가는 저도 저승 갈 날이 오겠죠',\n",
       " '270억대 소송사기 허수영 영장 기각…롯데 수사 제동',\n",
       " '연 20% 이상 고리대출자 대상 17%대 햇살론 9월에 나온다',\n",
       " '팩트체크 평양행 손사래 친 국회의장단과 야당 대표…과거 정상회담때는',\n",
       " '아동신간 역사 속 크라임씬·완두의 여행이야기',\n",
       " '론스타하나금융 손해배상 결과 이달 나온다…국가소송 예고편',\n",
       " '한경연 작년 가계 순처분가능소득 증가율 역대 최저',\n",
       " '날씨 내일 미세먼지 낀 밸런타인데이…곳곳에 눈·비도',\n",
       " '美 남중국해 판결 최종적이고 구속력 있어…당사자들 지켜야1보',\n",
       " '검찰 간부급 인사 그 후',\n",
       " '사우디 새 외무장관에 파이살 왕자…대외이미지 개선 의도',\n",
       " '법원 웅동학원 채용비리 뒷돈 전달책에 실형 선고',\n",
       " '伊 나폴리 버스 산통 시작된 임부 표없다 강제 하차시켜',\n",
       " '전국 미분양 주택 2만8천831가구…5년 3개월만 최저',\n",
       " '경기도 코로나19 대규모 선별검사센터 운영',\n",
       " '가맹본부 점주에 묻지마 판촉비 떠넘기기 못한다',\n",
       " '하나금투 종근당 2분기 무난한 실적 전망',\n",
       " '이철 전 VIK 대표 기자 편지 보고 검사와의 관련성 확신',\n",
       " '끝없는 터널 같아 꽉 막힌 취업길에 눈물짓는 취준생들',\n",
       " '온라인 대전미래교육박람회에서 인사말 하는 설동호 대전교육감',\n",
       " '캐나다서 10년간 성병 급증…앨버타주는 매독 비상 선포',\n",
       " '방통위 이통점 신분증 스캐너 96% 보급…정착 노력',\n",
       " '영하 10도에 맨몸으로 얼음물에 풍덩…러시아 예수세례 축일',\n",
       " '게시판 숭실OB남성합창단 창단 46주년 연주회',\n",
       " '이란 美 이란이 했다라면 끝나나…유조선 공격 강력부인종합',\n",
       " '靑 6자회담 틀 내 5자공조 강화로 최대한 대북 압박해야',\n",
       " '전교조 충청권지부 노동부는 법외노조처분 직권취소하라',\n",
       " 'MLB 클리블랜드 프랑코나 감독과 2년 계약 연장',\n",
       " '올림픽 지구촌 화합 새긴다…평창·강릉 공공미술 전시',\n",
       " '신종코로나 약세장에 구원투수 될까…새해 신규 상장 주목',\n",
       " '인사말 하는 민주노총 김명환 위원장',\n",
       " '폴란드 소비보르 유대인수용소 최후 생존자 96세 일기로 사망',\n",
       " '동강대 온라인 외국어 학습지원 프로그램 운영',\n",
       " '신간 인생의 밀도·요즘 무슨 책 읽으세요',\n",
       " '부시 정부 상무장관 트럼프 싫다…클린턴 리퍼블리컨 가세',\n",
       " '프로배구 OK저축은행 코치에 김천재·이강주·강영준 확정',\n",
       " '게시판 LG전자 노인복지관서 사랑의 떡국나눔 행사',\n",
       " '바그너 악극 링 4부작 첫 한국 제작…2020년까지 공연',\n",
       " '독립야구단 성남 블루팬더스 19일 창단식…감독 마해영',\n",
       " '세포 속 폐기물 처리과정 오토파지 조절신호 규명',\n",
       " '충북소식 과학교육원 21일 부분일식 온라인 관측회',\n",
       " '만 18세 선거권 토론회에서 인사말하는 조승래',\n",
       " '유가증권시장 공시 우수법인에 LG유플러스 등 9개사 선정',\n",
       " '현대건설 작년 영업이익 8천821억원…전년 대비 5% 증가종합',\n",
       " '유엔 소말리아 국민 170만명 식량난 직면할 것',\n",
       " 'DLF 등 구조화상품 투자자 절반 판매직원 권유로 가입',\n",
       " '배구 U대회 남자대표팀 코치에 장영기·송병일…선수 12명 소집',\n",
       " '혈액 만드는 조혈줄기세포 제작법 개발',\n",
       " '발언하는 권정오 전교조 위원장',\n",
       " '상위계층은 공교육에 기대 없어…코로나 계기로 학교 바뀌어야',\n",
       " '부산 청년 취·창업 지원사업 2차 참여자 모집',\n",
       " '원자력연구원장에 박원석·전자통신연구원장에 김명준',\n",
       " '게시판 한화투자증권 2019년 CEO배 자선 볼링대회',\n",
       " '해양경찰청 코로나19 여파로 올해 첫 공채 5∼6월로 연기',\n",
       " '그래픽 한진칼 지분 현황…조 회장 연임 성공종합',\n",
       " '올림픽 최명광강성일 북측 응원단에 화답',\n",
       " '괴짜가 세상을 구한다…서울교육청 메이커 괴짜축제 개최',\n",
       " '즉석조리 배달 서비스 셰플리 서울 강북 지역에 오픈',\n",
       " '4월 과학기술인상에 KAIST 허원도 교수',\n",
       " '경기도고려대 노동대학원 업무협약…노동 존중 사회 맞손',\n",
       " '상장주식 50만주 미만 우선주 30분 단위 단일가매매',\n",
       " '증시신상품 ABL글로벌자산운용 달러기준가형 재간접 펀드 3종',\n",
       " 'LG 가르시아∼강승호∼양석환 역대 70번째 삼중살',\n",
       " '코바코 4월 광고시장도 순풍…식음료업종 증가세 뚜렷',\n",
       " '잉글랜드 월드컵 성적 무관 사우스게이트 대표팀 감독직 보장',\n",
       " '미국을 사로잡은 예지 올여름 단독 내한공연',\n",
       " '삼청동서 천재작가 박이소 유작 우리는 행복해요 못본다',\n",
       " '삼성운용 홍콩 핀테크업체와 협약…자문서비스 해외 확대',\n",
       " '일본야구 우에하라 눈물의 은퇴 좀더 하고 싶었지만…종합',\n",
       " '호신술 배우는 여성안전수호단',\n",
       " '자가격리 해제 하루 남기고 공원 산책하던 50대 적발',\n",
       " '시혼을 담는 그릇…시인수첩 시인선 나온다',\n",
       " '96세 英 스쿠버 다이버 다이빙 최고령 기록 비공식 경신',\n",
       " '현대캐피탈 센터 줄부상…차영석홍민기가 공백 메울까',\n",
       " '경남도 청년 구직활동 지원 드림카드사업 추가 모집',\n",
       " '김병기 금메달리스트도 지도자로 군복무…병역법 개정안 발의',\n",
       " '민주노총 위원장 후보들 사회적 대화·정파 구도 놓고 설전',\n",
       " '마스크 쓰고 기다리는 응시생들',\n",
       " '민주노총 위원장 코로나19 극복 비용 재벌이 적극 부담해야',\n",
       " '시진핑의 반부패 캠페인 탄력…前 윈난성 당서기도 자수',\n",
       " '2020 고졸인재 일자리 콘서트',\n",
       " '우리나라 좋은동시문학상에 오은영 시인',\n",
       " '평균적인 사람은 아무도 없다…개개인성에 맞춘 교육 필요',\n",
       " '올해 공인회계사 1천9명 합격…작년보다 105명 증가',\n",
       " 'KT 레드닷 디자인 어워드 2년 연속 최고상',\n",
       " '지투하이소닉 최종인수 예정자로 녹원씨엔아이 선정',\n",
       " '이슬람 명절 앞두고 불법 이민자 대이동…말레이 국경 비상',\n",
       " '방학 알차게 보내세요',\n",
       " '퓨마·뱀 득실 아르헨 사막서 5세 소년 실종 24시간만에 구조',\n",
       " '내부까지 청결하게…삼성 패널 분리되는 무풍에어컨 출시',\n",
       " '의정부 신한대 학생 8명 잇단 확진…보건당국 비상',\n",
       " '울산교육청 미래교육관 설립 추진…사회 변화 대비',\n",
       " 'KT 아현동 인근 100대 맛집 지도 제작해 배포',\n",
       " '그래픽 기업 채용 계획 인원 추이',\n",
       " '코로나로 1분기 국내기관 해외증권투자액 96억달러 줄어',\n",
       " '고용노동부 올해 인적자원개발 우수기관 인증 신청 접수 시작',\n",
       " 'SNS돋보기 금수저 탈세 백태…슬픈 한국의 현실',\n",
       " 'V리그 트라이아웃 안드리치 서브 스파이크 자신 있다',\n",
       " '이탈리아 시칠리아 연안에 정박 중인 난민구조선에 접근 금지령',\n",
       " 'KBS 연구동 화장실 불법촬영 용의자 직원 아니다',\n",
       " '신간 화엄교학 강론',\n",
       " '국민 절반이 코로나 이후 실직 또는 임금 줄었다…취약층 소득↓',\n",
       " '논술시험 마친 수험생들',\n",
       " '멕시코시티 인근 화산 대규모 분화 조짐…경계경보 격상',\n",
       " '건산연 학교시설물 78% 내진성능 미달…보강 시급',\n",
       " '넥센타이어 강호찬 대표이사 사장 신규 선임',\n",
       " '코로나19 직격탄 맞은 삼성폰…영업익 1조원대로 떨어져',\n",
       " '멕시코 인권단체 정부 교황방문 핑계로 노숙자 대청소',\n",
       " '검찰 서울대에 조국 기소사실 통보…서울대 추가 정보 요청',\n",
       " '삼성디스플레이에도 한국노총 산하 노조 들어선다',\n",
       " '강봉균 대기업 족쇄로 해결안돼…국책銀 구조조정 역할 강화',\n",
       " '이장우 특별감찰 내용 유출됐다면 국기문란…상응 조치해야',\n",
       " '이주열 아태국가 경제복원력 강화해 충격 대응능력 높여야',\n",
       " '프로농구 전자랜드 할로웨이 부상공시…다니엘스 일시 영입',\n",
       " '금천구 일당 50만원 기간제 근로자로 선별진료소 의사 긴급채용',\n",
       " '지방선거 앞두고 농식품부 등 일부 부처 보각 전망',\n",
       " '마타렐라 이탈리아 대통령 화마 할퀸 노트르담 대성당 방문',\n",
       " '한산한 인천국제공항 제2터미널 출국장',\n",
       " '영상 손석희 앵커직 하차…많은 일 있었고 많이 배웠다',\n",
       " '서초·마포 등 서울 14개구 3.3㎡당 평균 아파트값 전 고점 돌파',\n",
       " '캐나다서 6·25전쟁 해외 참전용사 위해 보은행사 연 대학생',\n",
       " '서울시유스오케스트라 베토벤·전통무용가 김묘선 인연지무',\n",
       " '이총리 5·18계엄군 성폭행에 피해자와 광주시민께 깊이 사과',\n",
       " '노동부 올해 일자리 창출 유공 정부포상 신청 접수',\n",
       " '팩트체크 우리나라 상속세율이 65%…명목세율 최대 50%',\n",
       " '한국프랜차이즈協 새 회장에 정현식 해마로푸드 회장',\n",
       " '中 국유언론사에 동영상 플랫폼업체 지분 인수 종용',\n",
       " '금융시장 충격 일단 소강국면…주가 낙폭 줄고 환율도 하락',\n",
       " '中지린 올봄 인공강우 로켓탄 1천발 발사해 4.5억㎥ 강수효과',\n",
       " '5·18묘지 참배하는 한국노총 신임 위원장',\n",
       " '새해 감동다큐 3편…파바로티 몽마르트 파파 울지마 톤즈2',\n",
       " '게시판 전남대 수산해양대 공무원 47명 배출',\n",
       " '전국 123개교 등교 못 해…수도권 등교 재개에 두 달 만에 최소',\n",
       " '판사에서 변호사로 변신한 작가 도진기의 첫 소설집',\n",
       " '세련된 힐러리 싫어…샌더스에 열광하는 젊은 민주당원들',\n",
       " '올림픽 입실 대기하는 북측 단원들',\n",
       " '게시판 한음저협 국내 음악저작물 관리곡수 70만건',\n",
       " '수능 이번 주인데 고3 수험생 확진 잇달아…교육 당국 촉각',\n",
       " '고흥군 윤호21병원 화재 피해자 지원대책 마련',\n",
       " 'KCGI 내일 한진그룹 경영참여 방침 발표 기자회견',\n",
       " '한수원기업은행 코로나 피해 원전협력사 대출기금 400억 조성',\n",
       " '질문에 답하는 구본창 사교육걱정없는세상 정책국장',\n",
       " '모바일 게임 아라미 퍼즈벤처 글로벌 다운로드 100만 달성',\n",
       " 'KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략',\n",
       " 'LG전자·LG디스플레이 환경부와 포장재 재사용 시범사업',\n",
       " '레고 블록 맞추듯 GS건설 프리캐스트콘크리트 공법 적용',\n",
       " '카슈끄지 살해 당시 녹음파일 첫 공개…부검톱 소리도 담겨',\n",
       " '특징주 항공주 유가하락·원화강세에 함박웃음종합',\n",
       " '한경대 코로나19 특별장학금 1인당 10만원 지급',\n",
       " '행남사 스튜디오 썸머로 사명 변경…각자대표 선임',\n",
       " '집단탈북 종업원에 인민배우 최삼숙 딸 포함 RFA',\n",
       " 'KBS 비정규직 고용 프로그램 단위 아닌 전사 차원 검토',\n",
       " '朴대통령 양자·다자 추가 대북제재…北도발시 응분 대가',\n",
       " '동양네트웍스 최대주주 케이제이프리텍으로 변경',\n",
       " '거가대로 천성IC 부근 차량 추돌사고로 3명 중경상',\n",
       " '상사 잘못에도 비서는 죄송합니다…말할 곳 없는 감정노동',\n",
       " '7개월 만에 만난 문 대통령아베 총리 8초간 악수종합2보',\n",
       " '이재갑 장관 더 좋은 일자리를 위해',\n",
       " '베스트셀러 돌아온 룬의 아이들 출간 첫주 톱10',\n",
       " '조원태 회장 한진그룹 경영권 분쟁 1라운드 완승종합2보',\n",
       " '개강했지만 한산한 대학 취업상담 부스',\n",
       " '19세기 문장가 이건창 저술 엮은 전집 출간',\n",
       " '동정 송종욱 광주은행장 세계수영대회 홍보',\n",
       " '비규제지역 오피스텔도 청약 활활…인천 송도에 5만7천명 몰려',\n",
       " '완도군 지방인사혁신 경진대회서 인사분야 최우수상',\n",
       " '조각가 최만린의 30년 손때 묻은 정릉집 미술관이 되다',\n",
       " '강릉원주대 원주캠퍼스 도서관 개관식',\n",
       " '다운증후군 산전검사 신뢰도 높인다…검사기관용 표준물질 개발',\n",
       " 'LGU 효율적인 셀 설계로 5G 균등속도 보장…커버리지도 확대',\n",
       " '근로복지공단 이사장에 강순희 씨 임명…24일 취임',\n",
       " '생생한 소식 전달할게요…군산시 사이버 기자단 발대',\n",
       " '등산하려다 추워서 찜질방 가요…입춘 한파 움츠러든 시민들',\n",
       " '신한카드도 월세 결제 서비스…집주인 사업자등록 불필요',\n",
       " '대전 78명·충남 191명…교육청 지방공무원 채용계획 공고종합',\n",
       " '국제신문 신임 사장에 박무성 논설주간 선임',\n",
       " '접촉자만 수백명…부산 대학 캠퍼스발 집단감염 무서운 확산세종합',\n",
       " '美민주 차기 상원 원내대표 배넌의 편협성 백악관에 만연할 것',\n",
       " '유치원 등원 하루 앞두고',\n",
       " '국정원 서쪽갱도서 북동쪽 2㎞떨어진 곁가지갱도서 실험한듯',\n",
       " '코로나19 대응상황 점검하는 유은혜 부총리',\n",
       " '발표하는 임서정 노동부 차관',\n",
       " '법원 MBC의 계약직 아나운서들 해고 처분 부당',\n",
       " '왕성 식욕 에버턴 vs 지지부진 맨유…EPL 이적시...',\n",
       " '이틀 있으면 초등생 등교…충북교육청 학사운영 고심',\n",
       " '3개 자산운용사 금투협 정회원 신규 가입',\n",
       " '신간 미래중독자·아빠 퇴사하고 육아해요',\n",
       " '고용보험 가입자 증가 폭 2월 수준 회복…공공행정 20만명 급증종합',\n",
       " '국립부여박물관 중국 뤄양서 보존과학 특별전',\n",
       " 'KT 네팔 안나푸르나봉에 위치추적 산악구조센터 개소',\n",
       " '한국폴리텍대학 광명융합기술교육원 정식 개원',\n",
       " '최정윤 전통춤 경연대회 대통령상 수상',\n",
       " '포스코 최정우號 출범 한 달…권오준과 달리 정중동',\n",
       " '속보 코로나19에 전국 7천13개교 등교 못 해…어제보다 3곳 늘어',\n",
       " '베이징시 공원서 개 산책시키기 금지…애견인들 반발',\n",
       " '청주서 갓길 정차했다 트럭에 받힌 승용차 불에 타',\n",
       " '상반기 DLS 발행금액 10.5조원…1년 새 30% 감소',\n",
       " '초등 돌봄 6일 파업 예고 부산 돌봄교실 차질 우려',\n",
       " '340만 인구에 의대 정원 겨우 76명…경남 의료 인력 확충하라',\n",
       " '충북도청 빈 사무실 들어가 예산서 훔친 50대 검거',\n",
       " '단독 이세돌 아자황 매너 좋고 대단한 사람…꿈에도 등장',\n",
       " '긴급재난지원금으로 지역 상권도 살리고 어려운 이웃도 돕는 양천구',\n",
       " 'KBS 청소노동자 파업 찬성 98%…쟁의행위 가결',\n",
       " '장석주 시인 사랑은 새로운 이야기가 잉태되는 순간',\n",
       " '기자회견하는 노동자들',\n",
       " '北 김정은 中 휴대전화 사용자 반역자로 처벌 지시',\n",
       " '베를린서 1만명 로자 룩셈부르크 피살 100년 추모행진',\n",
       " '금융위 적극행정 직원에 혜택 주고 면책 범위는 늘린다',\n",
       " '삼성카드 3분기 순이익 1천281억 41.1%↑…내실경영 효과',\n",
       " '윤봉길 의사 유묵 위작 논란에 매도인 하자 없는 진품',\n",
       " '퇴직금 95억원 지급 책임은…부산공동어시장·항운노조 갈등',\n",
       " '순찰차 쪽잠 무더기 경고 처분 비판에 전북경찰청 곤혹',\n",
       " '세계야구선수권 대표팀 사령탑에 이연수 성균관대 감독',\n",
       " '당정청 주민조례발안제 도입…지방의회에도 윤리위 설치종합',\n",
       " '민생안정대책 발표하는 이용섭 광주시장',\n",
       " '코레일네트웍스 노조 파업…매표 등 큰 지장 없어종합',\n",
       " '현대제철 서울 잠원동 사옥 판다…현금 확보 차원',\n",
       " '의·정 대화 물꼬 텄지만…전임의 파업 가세 변곡점 맞나',\n",
       " '부산연구원 제조업 고용 부진 원인은 취약한 산업구조',\n",
       " '가나아트한남 개관…첫 전시 주인공은 1991년생 작가',\n",
       " '美 구호단체 북한내 29개 시설에 영양쌀 지원 VOA',\n",
       " '면담 요구에 폭력으로 응답',\n",
       " '한국 학생 글로벌 역량 OECD 회원국 평균보다 우수',\n",
       " '서울대 이경무 교수팀 3D 핸드 포즈 추정 챌린지 우승',\n",
       " 'JTBC 아나운서 지원자를 기자로 합격시켜 특혜 논란',\n",
       " '조선시대 실경산수화展 30일부터 3주간 연장 전시',\n",
       " '서울대병원 노사 일회용 방역용품 재사용 지시 vs 사실무근종합',\n",
       " '동정 한양대 언론정보대학원 총동문회장에 이영만 전 경향신문 사장',\n",
       " '코로나19 확산…제천 유치원·학교 58곳 18일까지 원격수업',\n",
       " '광주·전남 내일 수능 97개 시험장서…마스크 착용 필수',\n",
       " '지구 임계온도 1.5도 목표 촉구 1인 시위',\n",
       " '제일기획 뉴욕페스티벌서 역대 최다 수상',\n",
       " '전북소식 고용보험 부정수급 자진신고 기간 운영…5월 한달간',\n",
       " '트럼프 견습생 출연여성들에 외설적·성차별적 발언 거듭',\n",
       " '그래픽 5대 시중은행 정규·비정규직 현황',\n",
       " '日 도카이무라 핵연구소 방사성 물질 누출',\n",
       " '부천서 16명 코로나19 양성…100세 이상 확진자도 포함',\n",
       " '조손가정 아픔 다룬 황선미 작가 신작 할머니와…',\n",
       " '김종인 그 따위로 대접하는 정당에서 일할 생각 추호도 없어',\n",
       " '국회의원이랑 친한데… 로비자금 뜯어낸 60대 징역형',\n",
       " '삼정KPMG 코로나19로 국내 17개 산업중 16개 부정적 영향',\n",
       " '은성수 주택시장 안정 때까지 대출규제 위반 점검종합',\n",
       " '민주노총 전북본부 세계노동절 130주년 기념 거리행진',\n",
       " '베어링운용 증시 기초여건 우호적…위험요건은 상존',\n",
       " '영남대병원 해고자 고공농성 해결될 듯…노사 의견 접근',\n",
       " '이승엽·손연재·현주엽…아시안게임 별들의 전쟁',\n",
       " '쌍용차 마힌드라 대신할 투자자 찾을 수 있을까',\n",
       " '성지건설 65억원 규모 김포 아파트 조경공사 수주',\n",
       " '한화에어로스페이스 노사 3년 교섭 끝 임단협 결실',\n",
       " '연합이매진 서울 잠실에서 西海를 보다',\n",
       " 'CJB 이두영 의장은 고 이재학 PD 진상조사 결과 수용하라',\n",
       " '코로나19 속 돌봄교실 한산…인천서 신청 학생 절반만 나와',\n",
       " '오렌지카운티레지스터 류현진 휠러보다 평균 연봉 높아야',\n",
       " '이사장 146억 횡령 비리 서해대 올해 신입생 0명',\n",
       " '금호타이어 함께 그린 희망 공부방 14호점 완공',\n",
       " '대구 기도원에 불…인명피해 없이 20분만에 꺼져',\n",
       " '침으로 고지혈증 진단한다…KIST 콜레스테롤 분석기술 개발',\n",
       " '내일부터 은행서 코로나대출·재난지원금 신청…창구 혼잡할 듯',\n",
       " '동정 서정협 서울시장 권한대행 캠퍼스타운 판로지원 협약',\n",
       " '독일 특수부대원 나치 경례했다가 군복 못 입게 돼',\n",
       " '판데이크 가장 비싼 수비수 등극…1천억원에 리버풀行',\n",
       " '신간 조선시대 지주제 연구·동의수세보원',\n",
       " 'KB손보 전산센터 이전으로 내달 4일까지 일부 서비스 중단',\n",
       " '전북대 수험생 맞춤형 온라인 입시상담 실시',\n",
       " '그래픽 늙어가는 한국…60세 이상 경제활동인구 20대 추월',\n",
       " '대전·세종·충남 21개 대학 지역혁신 지원사업 도전',\n",
       " '3번 연기한 충북 기능경기대회 열려…일부 경기 차질',\n",
       " '선진국 따라잡기에서 후진국 따돌리기…한국 현대과학 발전사',\n",
       " '소설가 하명희 올해 가톨릭문학상 신인상',\n",
       " '이명박 前대통령 모레 이포보에서 자전거 라이딩',\n",
       " '한국GM 창원공장 비정규직 해고 후 다시 비정규직 채용해 투입',\n",
       " '뇌물 혐의 무죄 김성태 총선 매진해 정권 전횡 맞설 것',\n",
       " '부여 백마강 둔치 코스모스 만발',\n",
       " '한국 최초 고공 농성 여성 노동자 삶과 사랑 그린 체공녀 강주룡',\n",
       " '북한 주재 中대사 설 연회 마련…당대회 성과적 개최 축원',\n",
       " '전북대병원 전공의 181명 사직서 제출…정부 의료정책 반대',\n",
       " '그래픽 구직급여 신청자·지급액 추이',\n",
       " '브리핑하는 조희연 서울시교육감',\n",
       " '주택금융공사 디애셋誌 최우수 지속가능 금융기관상 수상',\n",
       " '침 땀 묻은 자동차 만지는데 방역장비 없어…정비사 노동실태',\n",
       " '선생님 감사합니다 부산교육청 스승 존경 운동',\n",
       " 'MLB 로스터 26명 증원·승률 높은 팀에 신인지명 우선권',\n",
       " '올림픽 답변하는 랜디 희수 그리핀',\n",
       " 'CJ 비비고만두 상반기 매출 12% 증가…점유율 1위',\n",
       " '동서대·부산화장품산업협회 전문인력 양성 협력',\n",
       " '소방차량 출동 42% 골든타임 초과…긴급차 우선신호제 필요',\n",
       " '곡식 수확하고 국화전 먹던 선조들의 가을 일상',\n",
       " '중학교 복도에서 교사에 욕설한 학부모…교육청 경찰에 고발',\n",
       " '서울 아파트 전셋값 46개월 연속 상승…2년 남짓에 1억↑',\n",
       " '알라모 렌터카 봄맞이 프로모션 이벤트 마련',\n",
       " '서쪽은 연일 눈·비 동쪽은 바짝 말라…유사 푄현상 탓',\n",
       " '달러 약세·증시 호조 속 원달러 환율 1180원대로 떨어져',\n",
       " '풍물패와 놀아보세',\n",
       " '옥천 장령산 휴양림에 숲속 카페 생긴다…내년 6월 개장',\n",
       " '수도권강원충청호남 코로나19 집단감염 동시다발 확산 비상',\n",
       " '서면보다 구두 정부보다 국회 아웃복싱하는 GM',\n",
       " '우루과이 법원 2차대전 침몰 獨전함 나치 독수리상 매각해라',\n",
       " '카자흐 카샤간 유전 현대화…1일 생산량 45만 배럴로 늘듯',\n",
       " '중대재해기업처벌법 제정 비정규직 국회앞 단식농성',\n",
       " '美앨라배마서 14세 소년이 가족 5명에 총격…모두 사망종합',\n",
       " '효성 계열사 3곳 한국기업지배구조원 ESG 평가서 A 등급',\n",
       " '캐리 람 홍콩장관 첫 시민과 대화…인근서는 반대 시위',\n",
       " '트럼프 므누신 재무장관윌버 상무장관 지명…월가인사 줄발탁',\n",
       " '개강 첫날 대학 온라인강의 서버 폭삭…교수·학생 우왕좌왕',\n",
       " '파크론 거실매트 어반지그재그 할인',\n",
       " 'BIFF 아시아필름마켓 공동운영위원장에 차승재·오동진',\n",
       " '아시안게임 수비수 이시영·정태욱 공격에서도 한 몫 해...',\n",
       " '배달·돌봄 등 대면 접촉 노동자 54% 임금 줄어',\n",
       " '강제윤이 카메라로 기록한 섬…사진전 당신에게 섬',\n",
       " '코로나19 여파…김포 구인은 줄고 구직자는 늘어',\n",
       " '카톡방서 주고받은 사진·메모 서랍에서 모아본다',\n",
       " '짜왕·진짬뽕·비비고·허니버터칩…대박 뒤에 RD 있다',\n",
       " '구호외치는 김명환 민주노총 위원장',\n",
       " '군경과 4년간 숨바꼭질 인니 최악테러범 결국 사살종합',\n",
       " '부산 명지신도시 과밀학급 숨통…교육청 명지5초 자체 설립',\n",
       " '英 새 하원의장에 노동당 출신 린지 호일 경 선출',\n",
       " '질의하는 정경희 의원',\n",
       " '컨버터블 노트북 인기…삼성 펜 11만대 판매·LG 내년 가세',\n",
       " '정부 코로나19 자가격리자에 등기 발송…집배원 감염 위험종합',\n",
       " '올해 홍진기 창조인상에 여자 컬링 대표팀',\n",
       " '추미애 검언유착 수사 피의사실 공표 혐의로 고발돼',\n",
       " '부산 택시노조 최저임금 일부 승소 판결에 환영…사측은 항소',\n",
       " '눈에는 눈…이란의 키사스 식 대 서방 대응',\n",
       " '방과후학교 강사 긴급생활자금 비상금대출 저금리 지원 업무협약 체결',\n",
       " '연합뉴스와 인터뷰 하는 방문규 수출입은행장',\n",
       " '고용위기 대응반 회의',\n",
       " '토비스 자사주 30억원 취득 결정',\n",
       " '1인당 하루 5만원 가족돌봄휴가 비용 신청 내달 20일 마감',\n",
       " '광주 노동자 3명 중 1명은 비정규직…급여도 광역시 중 최저',\n",
       " '2년간 입주 방송사 구하지 못한 329억원짜리 인천 방송시설',\n",
       " '금광맥에 자라는 풀이 있다고…자연과 교감하는 감수성 배우기',\n",
       " '첫 등교 잘 적응했으려나 걱정인 학부모들',\n",
       " '大寒 폭설에 곳곳 쾅쾅 꽈당…빙판길 출근대란종합2보',\n",
       " 'GS건설 화성서 신동탄파크자이 2차 6월 분양',\n",
       " '올해 중소형주 펀드 수익률 마이너스 전환',\n",
       " '토트넘 아르헨티나 19세 수비수 후안 포이스 영입',\n",
       " '페인트 분진 피해 보상해야 울산플랜트건설노조 차량 시위',\n",
       " '강창일 원내대표 출마 일심일당으로 대선승리 발판',\n",
       " '강만수 대우조선 부당투자 강요 없었다…檢 본인 주장',\n",
       " '김학범호 FC서울과 연습경기서 41 대승…한승규 결승골',\n",
       " '농식품부 침체 화훼업계 돕고자 꽃 100만송이 산다',\n",
       " '정은경·김강립 브리핑 음성 안정 속 신뢰감 줘',\n",
       " '이정명 伊문학상 프레미오 셀레지오네 반카렐라 수상',\n",
       " '성장세 이어가는 P2P금융업…개점휴업 국회에 법제화 깜깜',\n",
       " '하청노동자 임금체불 해결하라',\n",
       " '함평군 해보면 모평마을숲 국가산림문화자산 지정',\n",
       " '프로농구 kt에서 뛴 내쉬 NBA 최고 승률 휴스턴 입단할 듯',\n",
       " '토박이들이 추천한 전남 피서지…계곡·휴양림으로 가자',\n",
       " '여자축구 최강 현대제철 스포츠토토에 30 완승',\n",
       " '광주 계수초 학생 2명 확진…학생·교직원 1주간 자가격리종합',\n",
       " '이종석 청문회…민주 편향적·위장전입 vs 한국 법대로 재판',\n",
       " '日 관민펀드 LCD업체 재팬디스플레이에 7천600억원 지원',\n",
       " '이목희 고위공무원과 고액연봉 공기업 임직원 급여 동결해야',\n",
       " '신종 코로나 대응 관련 노동현안 점검회의',\n",
       " '흠흠신서는 공정한 재판 위한 책…오늘날 법조인도 봐야',\n",
       " '홍준표 北 핵실험장 폐쇄쇼…민주 레드라인 넘어종합',\n",
       " '한권으로 읽는 실록 21년 대장정…박영규 역사 대중화 자부',\n",
       " '영상 죽음 안타깝지만 성추문 밝혀야…5일장 반대 청원 11만명↑',\n",
       " '산재 노동자 고용 유지한 사업주에 최대 월 80만원 준다',\n",
       " '박인자 조직위원장 겸 예술감독 인사말',\n",
       " '예금보험공사 상임이사에 박연서 조사총괄부장',\n",
       " '이탈리아 로마 시내에 쓰레기 쌓이는 이유는…근무 태만',\n",
       " 'HDC현대산업개발 3분기 영업이익 1천326억원…작년 대비 41.4%↑',\n",
       " '창원시엘프시스템 투자유치 협약',\n",
       " '청춘합창단과 김태원',\n",
       " '원격수업만으론 충분한 교육제공 못해…등교재개 검사후 결정',\n",
       " '28일 새벽에 개기월식…과천과학관 특별관측회 개최',\n",
       " '단일팀 기운 이어갈까 여자농구 대표팀 월드컵 결단식',\n",
       " '증시 시가총액 하루 68조원 감소…공포지수 급등종합',\n",
       " '쥐포·먹태 안주 1천원…을지로 신중부시장 건어물맥주축제',\n",
       " '노동연구원장 코로나19 고용위기 계기로 임금체계 개편해야',\n",
       " '제8회 젊은작가상 대상에 임현',\n",
       " '제주 영리병원 반대 항의서한 전달',\n",
       " '안영준 등 KBL 3대3 선발팀 태극마크 향한 담금질 시작',\n",
       " '한동훈 유시민 전담 취재 언급에 그건 해볼 만하지종합2보',\n",
       " '영상 故 조양호 회장 빈소에 조문 행렬…추모객 발길 이어져',\n",
       " '발표하는 이시우 카카오 게임퍼블리싱 본부장',\n",
       " '5·18 진실찾기 40년 ② 진상규명의 열쇠…발포명령·헬기사격',\n",
       " '코로나19 확진 수험생 위한 고사장 설치',\n",
       " '슈틸리케는 베일·기성용은 메시…또 엇갈린 투표',\n",
       " '내년도 최저임금 심의 오늘 시작…최대 변수는 코로나19종합',\n",
       " '이름값 해낸 황정민의 열연…연극 리차드 3세',\n",
       " '1보 코스피 반등 출발…장중 1620선 회복',\n",
       " '대전교육청 중학교 학교군·중학구 축소 행정예고',\n",
       " '창원 시내버스 파업 이틀 앞으로…시 비상수송대책 수립',\n",
       " '이수건설 양산 범어주공1단지 재건축 수주',\n",
       " '기고 아인슈타인 지휘에 맞춰 블랙홀 듀엣 연주가 시작됐다',\n",
       " '신간 첨성대의 건축학적 수수께끼·화가의 일상',\n",
       " '신세계몰 인테리어 소품 최대 42% 할인판매',\n",
       " '길따라 멋따라 타임머신 타고 정조의 꿈 엿보는 수원 화성 여행',\n",
       " '정지선 현대百그룹 회장 새로운 10년 위한 출발점이자 전환점',\n",
       " '등교하자마자 다시 집으로…경기지역 병원 이송 학생 잇따라',\n",
       " '교육부전교조 본교섭 재개',\n",
       " '日밴드 세카이노 오와리 11월 내한공연',\n",
       " '아프리카의 곡창지대 짐바브웨에 대기근 공포 감돈다',\n",
       " '슬램덩크 세대들의 자기계발서 슬램덩크 인생특강 발간',\n",
       " '영동군 야간학습 중·고생 100원만 내면 택시로 귀가',\n",
       " '안산·대구·대전·부여에서 노후 공공건축물 리뉴얼 사업',\n",
       " '부산외대 AI 기반 정보보안시스템 연구 인재 양성',\n",
       " '원로수필가 정진권 전 한국체대 교수 별세',\n",
       " '사랑이 넘치면서 부재하는 시대에 찾아온 사랑잡가',\n",
       " '두산중공업 명예퇴직 시행에 노조 반발…단체협상 위반',\n",
       " '2021년도 최저임금 심의 착수 의사봉 두드리는 박준식 위원장',\n",
       " '레반도프스키 해트트릭 뮌헨 함부르크에 80 대승',\n",
       " '방송문화진흥회 이완기 이사장 이사장직 사임',\n",
       " '무허가 클럽에 손님 66명 입장 시켜 불법 영업한 업주 적발',\n",
       " '한국투자증권 해외주식 모바일앱 누적거래액 1천억 돌파',\n",
       " '신간 모르타라 납치사건·일자리의 미래',\n",
       " '쉐보레 네버 기브 업 기증식',\n",
       " '평택시 붉은 수돗물ㆍ피부염 사건에 주민 탓 브리핑자료 논란',\n",
       " '대전 꿈나래교육원 제8기 입교식…덕분에 챌린지도',\n",
       " '게시판 NH농협은행 서울 안산서 사업추진 결의대회',\n",
       " '현대아울렛도 라이브 커머스 시작…주중 날마다 방송',\n",
       " '가짜 서류로 경력 속여 소방공무원 응시 합격',\n",
       " '대구·경기·충북에 교육청 직속 미디어교육센터 들어선다',\n",
       " '전국 전문대 정시 원서접수 내년 1월7일 시작…총 2만5천명 모집',\n",
       " '심의정보 유출 이상로 방심위원 통신소위서 배제',\n",
       " '식당가에 배달오토바이만',\n",
       " '고향 인심·겨울 정취…홍천강 꽁꽁축제 설 연휴 진행',\n",
       " '친구에게 잔소리한다며 의자로 아내 폭행한 60대 남편',\n",
       " '여름 결혼 할만하네…호텔업계 프로모션 풍성',\n",
       " '동아지질 333억원 규모 홍콩국제공항 공사 수주',\n",
       " '유명희 통상교섭본부장 다보스포럼 참석 차 출국',\n",
       " '혈연농구 논란 극복 못한 농구 대통령 허재 씁쓸한 퇴...',\n",
       " '광주 코로나19 진정세…수험생 등 방역 수칙 준수 거듭 당부',\n",
       " '광주 유·초·중·고 12일부터 등교수업 확대',\n",
       " '러드 전 호주총리 눈물…정부 반대로 유엔총장 도전 못해',\n",
       " '창작가무극 신과함께 시리즈 대만 진출…2020년 5월 가오슝',\n",
       " '3분기 전 부문 흑자 낸 한화솔루션…헬스케어에도 진출한다종합2보',\n",
       " '잉글랜드 U20 대표팀 솔랑케 리버풀로 이적',\n",
       " '청주 고교생들 코로나19 의료진 응원 배지 제작',\n",
       " '한국당 맹탕 대북정책 중단하고 한미동맹 복원기회 삼아야종합',\n",
       " '전교조 충남지부 성명 학교 혁신과 거리 먼 교육청 인사',\n",
       " '홍영표 기무사 개혁 말단 세포까지 바꾸는 대수술 돼야',\n",
       " '신종코로나 피해 중기·자영업자에 2조원 금융지원',\n",
       " '대전MBC 아나운서 채용 성차별 문제 대책위 발족',\n",
       " '공로상 수상한 양지운',\n",
       " 'SK스토아 데이터 기반의 VOD 광고상품 출시',\n",
       " '기협 채널A지회 검찰 협의 아닌 일방적 강제집행 규탄',\n",
       " '프로농구 FA 최진수·조성민 소속팀과 재계약…문태종 결렬...',\n",
       " '연세대 비대면강의 실태조사…선택적 패스제는 도입 않기로종합2보',\n",
       " '현대건설 한남3구역 재개발 사업 공사계약 체결',\n",
       " '말하기 편해요 투명 위생 마스크 만들어 사용하는 초등교사',\n",
       " '한국노총 최저임금 동결 소비 위축할 것…경영계와 신경전',\n",
       " '평창올림픽 성화 순천만 정원서 강강술래로 환경 구현',\n",
       " '게시판 대웅그룹 가을학기 학점연계형 현장실습 인턴 모집',\n",
       " '충남교육청 17일부터 아산지역 고교입시제도 변경 여론조사',\n",
       " '장남식 손보협회장 재난·정보유출 등 관련 신상품 활성화',\n",
       " '신간 자현 스님이 들려주는 불교사 100장면',\n",
       " '위기의 女농구…박찬숙·박정은 이름표부터 달고 다시 뜁니다',\n",
       " '과천과학관 My hero 로봇 태권브이 기획전 개최',\n",
       " '올해의 방송기자 대상에 SBS 옵티머스 사건 보도',\n",
       " '수아레스·메시 득점 앞세운 바르사 비야레알 제압…선두 질주',\n",
       " '태극 얼굴 박용식씨 보육원생과 러시아로 월드컵 응원 간다',\n",
       " '경제개혁硏 총수일가 미등기임원 연봉 평균 22억6천만원',\n",
       " '獨 정치인 자전거 통근자 휴가 하루 더 줘라 이색 제안',\n",
       " '주말 N 여행 영남권 케이팝 스타 부산 밤하늘 빛낸다',\n",
       " '내일 수도권 주택 공급대책 발표…시장 기대 부응할까',\n",
       " '청년내일채움공제 수기 공모전 시상식',\n",
       " '게시판 방통대 2학기 신·편입생 모집 카카오톡 상담 진행',\n",
       " '부산 7일째 지역사회 감염 O…해외감염 2건 추가종합',\n",
       " '원격수업 시작 알리며 인사하는 교장선생님',\n",
       " '英진공청소기 업체 창업자 다이슨 EU 농업보조금도 빨아들였다',\n",
       " 'W홀딩컴퍼니 계열사 초록뱀미디어 주식 136억원에 추가취득',\n",
       " '한무숙문학상에 김언수 장편소설 뜨거운 피',\n",
       " '장성소식 가로수 생장 방해하고 경관 해치는 칡덩굴 제거',\n",
       " '공운위 금감원 공공기관 지정유보…강원랜드 공기업으로 변경',\n",
       " '60여차례 어린이 학대한 50대 전직 어린이집 교사 검찰송치',\n",
       " '1인 창작자 지원 사업체 방문한 고삼석 상임위원',\n",
       " '신간 웃음의 철학·히트 리프레시',\n",
       " '이름값도 눌러버린 구위 류현진 각 팀 에이스 연파',\n",
       " '김명수 대법원장 퇴근',\n",
       " '류현진의 조정 평균자책점 매덕스·쿠팩스보다 위',\n",
       " '오거돈 보좌관 복귀 결정 반발하는 공무원노조',\n",
       " '돌봄노조 정규직과 복리후생 차별 철폐해야…23∼24일 파업',\n",
       " '삼척 이끼폭포에 내년까지 생태탐방로 조성',\n",
       " '野 여성의원들 안희정 무죄 성토…노 민스 노 룰 도입해야',\n",
       " '이란 외무 트럼프 볼턴에 들볶여 알렉산더도 못한 일 하려해',\n",
       " '포천 명성산서 가을 정취 만끽…사흘간 억새꽃 축제',\n",
       " '범인 단번에 알아본 형사 눈썰미…절도범 잇따라 덜미',\n",
       " '광주 인공지능 사관학교 개교…실무 인재 양성 닻 올려',\n",
       " '올림픽 구텐베르크 아녜요 외신기자들 열광한 활판인쇄전시',\n",
       " '인스타그램 우리는 쇼핑·브랜딩 플랫폼…국내 수익화 박차',\n",
       " '수능 입시업체 국어 1등급컷 87∼89점·수학 가형 89∼92점 예상',\n",
       " '정몽구 회장 연봉 70억원…정의선 부회장은 52억원 76% 올라종합',\n",
       " '삼성디스플레이 노조 출범…정당한 노동의 대가 누릴 것종합',\n",
       " '한국 건축가들이 지구 반대편서 지은 알로이시오의 집',\n",
       " '게시판 한국외국어신문협회 창립 5주년 기념식',\n",
       " '암컷 대게 520마리 보관한 수산물 판매업자 덜미',\n",
       " '진달래·벚꽃·복숭아꽃…부천 3대 봄꽃 축제 이달 개막',\n",
       " 'KBS 검언유착 오보 관련자 감봉 등 징계',\n",
       " '게시판 신한은행삼정KPMG 외국인·해외투자 기업 유치 협약',\n",
       " '한수원 원전중단 원인 고무이음관 12년마다 교체',\n",
       " '온라인으로 열린 민주노총 제2차 중앙위원회',\n",
       " '대전소식 중국 하문의학원 대전대에 마스크 500장 보내',\n",
       " '레바논 새 총리에 디아브 전 교육장관…정치안정 시급종합',\n",
       " '에이프로젠 KIC 에이프로젠제약 주식 500억원에 추가취득',\n",
       " '한국문협작가상에 임지훈·안은순·문육자·박예자',\n",
       " '서울아산병원서 총 6명 코로나19 확진',\n",
       " '하정애 신임 국립현대무용단 비상임 이사장',\n",
       " '민주당사 앞에서 삭발식하는 초등돌봄전담사들',\n",
       " '대구지하철 참사 17주기…노동자 위험한 철도는 승객에도 위험',\n",
       " '여준형 전 빙상 대표팀 코치 피해자가 맞서 싸우기 힘든 구조',\n",
       " '中고전 금병매 5권에 1만4천500원…올재클래식스 22번째',\n",
       " '제2의 윤창호 비극 막는다…주류광고서 음주 장면 금지종합',\n",
       " '환노소위 김용균법 합의불발…내일 오전 재논의키로종합2보',\n",
       " '아시안게임 3대3농구대표팀 집단 배탈 증세 선수촌 ...',\n",
       " 'MBC 직장 내 괴롭힘 엄벌…예능 PD 해고',\n",
       " '100만 체험객 목전에 둔 화천 산천어축제',\n",
       " '손님 없다. 너 나가 코로나에 길거리 내몰린 취약 노동자',\n",
       " '아자디 광장에서 열린 이란 이슬람혁명 40주년 대규모 집회',\n",
       " '1천100원대로 내려간 원달러 환율…당분간 원화 강세종합',\n",
       " '영상 인니 경찰 2m 넘는 구렁이로 위협 심문…거짓말 하면 물린다',\n",
       " '여성작가 한말숙·정연희 들여다보는 전시',\n",
       " '노동자 권리 보장촉구',\n",
       " '대통령·與대표 권한대행 회동…명콤비 돼보자종합',\n",
       " '안전보건 분야 채용박람회 내달 6∼8일 온라인으로 개최',\n",
       " '우리은행 모든 영업점에 코로나19 예방 칸막이 설치',\n",
       " '웰크론 작년 영업익 57억…흑자전환',\n",
       " '게시판 미래에셋박현주재단 교환학생 300명에 장학증서',\n",
       " '태영건설 부산 부전동 오피스텔 신축공사 870억에 수주',\n",
       " '전반기 40경기 포심 0개 송은범 후반기에는 다시 ...',\n",
       " '스스로 생각하는 로봇…인공지능 액션브레인 개발',\n",
       " '민주노총 여의도 집회 금지에 방역 실패 책임 떠넘기기',\n",
       " '하이골드3ㆍ12호 현대상선 용선료 조정 요청 공문 접수',\n",
       " '등촌동 장애인·비장애인 복합공간 건립 물꼬…인근 초교 동의',\n",
       " '머르기트 다리 밑 유람선 참사 희생자 추모 공간',\n",
       " '이마트몰 카카오톡 장보기 서비스 개시',\n",
       " '구글 네이버·카카오도 구글 아니면 글로벌 진출 어려웠을 것',\n",
       " '중저가폰 외양 변한다… LG전자도 연내 물방울 노치 탑재',\n",
       " '잔소리한다며 어머니 흉기로 찌른 아들 2심도 징역 2년6개월',\n",
       " '제낙스 주가급등 관련 중요정보 없다',\n",
       " 'NH투자 연준 제로금리·트럼프 기자회견 경기 우려 확산',\n",
       " '부산소식 동서대 디자인대학 수업 작품 옥외광고전 수상',\n",
       " '단방향 온라인 수업 중',\n",
       " '정경심 10일 석방…법원 증거인멸 우려 적어종합2보',\n",
       " '송영무 흥진호 나포 언론보도 보고 알았다',\n",
       " '필리핀 토지은행·리잘상업은행 한진중공업 주식 취득',\n",
       " 'KAIST 총동문회장에 차기철 인바디 대표',\n",
       " '홍남기 503명 고용 강원형 일자리에 1천120억원 지원',\n",
       " 'QA 코로나19 환자 다녀간 시설 소독하면 문제없어',\n",
       " '경기개선 기대감에 시총 상위 10개중 7개 목표주가↑',\n",
       " '유은혜 부총리 장애학생 진로교육 업무협약식',\n",
       " '구글 최고연구자 사고력 지닌 AI는 먼 훗날 얘기',\n",
       " '한은경 북한축구협 부회장 방남…30일 EAFF 총회 참석',\n",
       " 'LH 양주 회천신도시 일반상업용지 5필지 경쟁입찰로 공급',\n",
       " '도르트문트 강설로 경기 연기…박주호는 명단제외',\n",
       " '내년도 최저임금 노사 입장차 팽팽',\n",
       " '호날두 탈루액 186억원 납부 생각 없다',\n",
       " '천주교주교회의 사형제도 폐지해야',\n",
       " '체육 분야 인권 전문가 간담회',\n",
       " '인사말 하는 강상현 방통위원장',\n",
       " '네이버 명함 자동인식 앱 운영사에 50억원 출자종합',\n",
       " '중대재해기업처벌법 관련 경제계 공동 기자회견',\n",
       " '민주국민의당 으르렁…역사의 패배자 vs 어이없는 남탓',\n",
       " '코로나19 관련 기자 브리핑 갖는 김명환 민주노총 위원장',\n",
       " '복직 교사 뒤로 나타난 해무리',\n",
       " '팀 타율 1할대 롯데 채태인 빼고 김문호 선발 출전',\n",
       " '공룡도 수풀에 몸 숨기려고 위장색 사용',\n",
       " '문 열지도 못했는데 민군복합항 크루즈 기항예약 취소 악재',\n",
       " '검언유착 의혹 채널A 기자 측 수사심의위 소집 안한다종합',\n",
       " '갤러리조은 불혹 미혹하다·선화랑 예감 전',\n",
       " '만장일치 호평받은 헐치 강서브 자신 있다',\n",
       " '전국 초등돌봄전담사 총파업 선포 기자회견',\n",
       " '코로나19 여파로 온라인으로 채용설명회',\n",
       " '우수과학도서 인증제·우수과학문화상품 공모전 8월말까지 접수',\n",
       " '최악 폭염 속 학교 조리실 종사자 대책 마련하라',\n",
       " '조선 순조21년 서울 강수량 2천566㎜ 최대…기청제 지내',\n",
       " '정운호 네이처리퍼블릭 대표 경영 복귀…책임경영 필요',\n",
       " '억새 은빛 물결 장관 충주 비내섬 10월 가볼만한 곳 선정',\n",
       " '김인건 전 태릉선수촌장 일대기 다룬 맘보 김인건 출간',\n",
       " '3.1운동 100주년 기념사하는 법륜 스님',\n",
       " '춘제 끝나자마자 中 허난성 高法부원장 기율위반 조사',\n",
       " '獨 도이체·코메르츠방크 합병 무산…충분한 이익 어려워',\n",
       " '연인과 함께 느끼던 맛의 기억…음식은 사랑을 위한 최음제',\n",
       " '톈안먼 주역 왕단 홍콩 학생들에 역사를 바로 배워라',\n",
       " '위지윅스튜디오 인스터 주식 20억원어치 양수',\n",
       " '기자실 들어서는 김현종 본부장과 유명희 수석대표',\n",
       " '시진핑 매형 세운 부동산기업 부패 스캔들 휘말려',\n",
       " 'NBA 러브의 용기있는 고백…경기 중 공황발작 찾아왔다',\n",
       " '중국 대도시 에스컬레이터 두줄서기 확산…상하이도 가세',\n",
       " '사이먼 32점 11리바운드…인삼공사 SK 제압하고 5연승 질주',\n",
       " '신간 이성의 운명·세계철학사2·학문과 정치',\n",
       " '학교에서 나오는 상일여고 학생들',\n",
       " '포항제철고 야구부 해체 추진에 학부모 반발…학생 버리나',\n",
       " '전북 모라이스 감독과 2년 계약…마르케스 코치 선임',\n",
       " '구자범 코리안심포니 지휘…랑고르 교향곡 1번 아시아 초연',\n",
       " '이중섭 은지화부터 백남준 다다익선까지…미술품 보존 묘수는',\n",
       " '中경제 서비스화로 성장률 하락 전망…우리도 대비해야',\n",
       " '코스피 잇단 대외 악재에 1%대 급락…2230선으로 후퇴종합',\n",
       " '원자력안전위 정기검사 한빛 5호기 재가동 승인',\n",
       " '서울 초등학생 새학기부터 구강검진 결과 스마트폰으로 확인',\n",
       " '로봇이 수건 가져다준다…노보텔 앰배서더 동대문 엔봇 시작',\n",
       " '속보 경북 정신의료·장기요양기관 직원 등 5% 샘플링 검사',\n",
       " '내달부터 30일 이상 무급휴직 노동자에 최대 150만원씩 준다',\n",
       " '아시안피스컵 남북 男배구팀 열전 펼쳐…양쪽 똑같이 응원',\n",
       " '신경민 의원 통신비 고지서서 단말기할부금 항목 빼야',\n",
       " '사우샘프턴 가봉 국가대표 미드필더 레미나 영입',\n",
       " '이다은 명창 판소리 다섯바탕 13시간 완창',\n",
       " '등교 개학 대비한 시설물 점검',\n",
       " '특징주 켐온 화평법 수혜 기대감에 상한가',\n",
       " '특징주 한진그룹 경영권 분쟁에 한진칼 주가 사상 최고',\n",
       " '신규확진 사흘연속 1천명 넘을듯…정부 3단계 문턱서 고민',\n",
       " '日 中해경선 센카쿠 일본 영해 침범…총리관저 대책실 설치',\n",
       " '여자프로농구 11월 3일 스타트…우리은행신한은행 개막전',\n",
       " '춘천시 학교 밖 청소년 전용공간 조성',\n",
       " '캠코 국유부동산 123건 공개 대부·17건 매각',\n",
       " '익산을 한병도 후보 선당후사 명령에 전략공천 수락',\n",
       " '추상화단 거목 박서보 국립현대미술관 서울서 회고전',\n",
       " '중기중앙회도 대기업에 납품대금 조정 신청할 수 있게 된다',\n",
       " '중국판 GPS 베이더우 총기 위치까지 추적한다',\n",
       " '은행권 연말까지 매월 신용대출 증가폭 2조원대로 관리',\n",
       " '학교 비정규직 복리후생 차별 해소하라',\n",
       " '제주도교육청 유치원 3법 통과 환영',\n",
       " '출연연 국내출장비 정산 실비정산→정액지급…증빙수단 간소화',\n",
       " '유럽 각국 코로나 대응 긴급 언론지원…프랑스 9천억원 예산',\n",
       " '여객선 못 뜨면 낭패 울릉 수험생 수능 8일 앞두고 포항 도착',\n",
       " '그래픽 5G 네트워크 장비 시장점유율',\n",
       " '군산소식 방역 일자리사업 참여자 45명 모집',\n",
       " '사학권력국가권력시장권력이 지배한 한국대학 100년사',\n",
       " '그래픽 민간 건설사 분양 계획',\n",
       " '전국 기능경기대회 순위 공개 금지해야',\n",
       " '브라질 상파울루서 빛난 주얼리옥공예 앙상블…명품한류 눈길',\n",
       " '엘리베이터에 25분이나 갇힌 교황…삼종기도회 지각 참석종합',\n",
       " '코로나 우려에 학교는 문 닫았는데 사설학원은 수업 중',\n",
       " '프로농구 개막…첫 득점 LG 박인태 첫 3점은 SK 김선형',\n",
       " '소니 초소형 하이엔드 카메라 RXO Ⅱ 출시',\n",
       " '언론노조 KBS본부 라디오 편파 진행 논란 공방위서 논의 제안',\n",
       " '한국 음악계 그래미 도전사…누가 수상하고 후보 올랐나종합',\n",
       " '충청권 NGO 유성기업 사업주 엄중 처벌하라종합',\n",
       " '광고비가 음식…인터넷 언론사 횡포에 공무원 분노',\n",
       " '광주교육청 무단 폐쇄 유명 영어유치원 고발 검토',\n",
       " '日 다케시마 문제 국가 백년대계 입각해 대처',\n",
       " '수산물 판매 나선 문성혁 장관',\n",
       " '퍼포먼스에 갇혔던 정강자의 50년 화업을 돌아보다',\n",
       " '임진강 독개다리에 평화의 가상철로 선보인다',\n",
       " '철길 없는 남해군에 문화장터 간이역 들어선다',\n",
       " '日축구스타 혼다 멕시코 파추카 입단회견서 깜짝 스페인어',\n",
       " '보안기술 경연대회 K사이버 시큐리티 챌린지 참가신청 접수',\n",
       " '신종코로나 2차전파 발생 8개국 여행이력 의료기관에 제공종합',\n",
       " '넥센 타격코치 바꾼 NC에 17안타 13득점 불방망이',\n",
       " '충북대 비대면 수업 내달 11일까지 연장',\n",
       " '프로포즈 꽃 칼라 활짝',\n",
       " '대만 법무부 음주 사망사고에 고의살인죄 적용 추진',\n",
       " '국토차관 양도세 낮춰 다주택자 퇴로 열어줘라 난 동의 못해',\n",
       " '인도 마루티스즈키 승용차 7만여대 리콜…에어백 등 결함',\n",
       " '우한교민 3차 전세기 투입 예정…입국제한 확대는 보류종합',\n",
       " '특징주 기생충 오스카 4관왕에 관련주 사흘째 급등',\n",
       " '민주 황교안 1인 시위 아닌 자기반성부터 해야',\n",
       " '300억 들인 인천 계양구 방송통신시설…공실 되나',\n",
       " '파워넷 7일 코스닥시장에 신규 상장',\n",
       " '제조업 영업이익 4년 상승기 끝내고 내년부터 하강 국면',\n",
       " '경북 유치원생·초등학생 1천901명 개학 전 긴급돌봄',\n",
       " '경기북부 강추위 여전…포천시 일동면 영하 17.3도',\n",
       " '대북매체 유엔제재대상 선박 한일영해 12일간 운항',\n",
       " '카톡으로 주식 산다…카카오 증권업 진출종합',\n",
       " '르노삼성자동차 QM3 비비드 매니아 이벤트 진행',\n",
       " 'KT 차세대 미디어 코덱에 100억원 투자 유치',\n",
       " '파이즈 아시아 선수 최초로 FIFA 푸슈카시상 수상',\n",
       " '자이언트스텝 등 3개사 코스닥 상장예비심사 통과',\n",
       " '한국청년회의소 승일희망재단에 루게릭병원 건립 기금 기부',\n",
       " '뚫린 수비 속 분전 최철순 이용과 좋은 경쟁하겠다',\n",
       " '전국노동자대회 발열검사',\n",
       " '한국방송학회 한반도 평화 주제 한일 웨비나 개최',\n",
       " '마이크로미터 크기 굴곡에도 잘 달라붙는 패치 개발',\n",
       " '㈜두산 3분기 영업이익 2천174억원…작년보다 20%↑',\n",
       " '주말 N 여행 수도권 산수유·노란 복수초 진한 내음 맡으며 봄맞이',\n",
       " '신간 백점 아들 육식동물 아빠·나는야 호기심 많은 관찰자',\n",
       " '농협중앙회 조합구조개선부 임직원 농번기 농촌일손돕기 나서',\n",
       " '박범계 민주 당대표 출마선언…유능한 혁신가의 공정한 돌풍',\n",
       " '빚갚기 힘들면 금융회사에 채무조정 요청할 수 있게 된다',\n",
       " '서울교육청 안 쓰는 책상·의자 미얀마 직업학교에 지원',\n",
       " '경남 대학가 등록금 반환 운동 열풍…동참 잇따라',\n",
       " '독일 하원의장 터키 대통령 비판 의원면책 폐지 독재적',\n",
       " '코로나19로 쌓인 재고 면세품 국내판매 한시 허용종합',\n",
       " '7월 고산의 꽃…하늘나리',\n",
       " '감사 인사하는 전교조',\n",
       " '교사 보복해임·왕따 논란 명진고 이번엔 도서관 근무해라',\n",
       " '테임즈와 경쟁 아길라 탬파베이행…최지만과 경쟁',\n",
       " '태영호 황장엽 이후 20년 만에 고위급 탈북민 회견',\n",
       " '기업은행장 디스커버리펀드 투자자 피해 최소화 부단히 노력',\n",
       " '경찰 서울노동청 점거농성 전교조 해직교사 18명 연행',\n",
       " '혼돈의 학교⑤ 매년 학교 떠나는 교사·학생 6천여명…이유는',\n",
       " '신한은행 착한 선결제 캠페인 동참',\n",
       " '한양디지텍 종속회사 주식 25억원어치 취득',\n",
       " '철원군 방학 맞은 대학생 140명에게 단기 일자리 제공',\n",
       " '필리핀관광청·탐앤탐스 보홀 여행권 증정 이벤트',\n",
       " '소마젠 코로나19 타액 진단서비스 미국 내 공급자로 선정',\n",
       " '서울교통공사 신입사원 559명 공채…14∼18일 원서접수',\n",
       " '중앙일보 신규 통합 BI The JoongAng 선포',\n",
       " '공동창업주 金·千 철수 수순…安과 루비콘강 건너나',\n",
       " '서울시교육청 등교 수업 운영 방안은',\n",
       " 'IBK투자증권 서병기 차기 대표이사 내정',\n",
       " '세종교육청 소방서 연계 찾아가는 초등생존수영 교육',\n",
       " '영생을 찾아 떠난 영웅 길가메시의 모험',\n",
       " '경북교육청 공무원 임용시험 경쟁률 평균 11.5대 1',\n",
       " '서울시 공공도서관 사서 감정노동 피해예방 지침 시행',\n",
       " '공학한림원 김성조 부총장 등 신입 정회원 27명 선정',\n",
       " 'KIST 질화갈륨 대체 청색광 반도체 소자기술 개발',\n",
       " '미정부 쿠바 옥죄기 나서나…헬름스버튼법 발동 검토',\n",
       " '올해 출연연 박사후연구원 채용 규모 110명→153명으로 확대',\n",
       " '로또 아파트 때문에…아파트투유 한때 청약 먹통',\n",
       " '시민단체 채널A 기자 명예훼손 등 혐의로 최강욱 대표 등 고발',\n",
       " '과기정통부 1조7천억원 규모 내년 기초연구사업 공모 착수',\n",
       " '화학무기금지기구 작년 4월 시리아 두마서 화학무기 사용돼',\n",
       " '영장 유출 혐의 현직 판사들 무죄…양승태 재판에 영향 불가피종합',\n",
       " '국립발레단 신작 마타하리',\n",
       " '나노입자로 계면활성제 제작…제약·화학 연구 활용 기대',\n",
       " '유안타증권 2월 MSCI 정기변경서 종목 편·출입 가능성 작아',\n",
       " '경남도청 혁신 문제 해결형 원샷 워크숍',\n",
       " '朴대통령 어린이가 나라의 보배로 성장하도록 힘껏 응원',\n",
       " '남수단 대통령·야권 지도자 교황 초청으로 교황청서 피정 돌입',\n",
       " '언론중재위 여름방학 청소년 언론중재스쿨 비대면 진행',\n",
       " '롯데관광개발 9년 연속 크루즈 전세선 운항',\n",
       " '캐나다에서 즐기는 등골 오싹 유령투어',\n",
       " 'UAE 알아인 남미 챔피언 리버플레이트 꺾고 클럽월드컵 결승행',\n",
       " '남양주시 여행사 통한 관광 형태 직원 국외연수 불허',\n",
       " '연초 조정장에서도 각종 연금펀드 자금몰이',\n",
       " '재건축 시행자 기부채납 50%까지 현금납부 가능',\n",
       " '野 최순실씨 주술적 멘토일 수도…邪敎 의구심 제기',\n",
       " '그래픽 5대 은행 개인 신용대출 추이',\n",
       " '젊은 혈관 면역학자 정철호를 기억하며',\n",
       " '또 불안해진 부동산시장…정부 군포·인천·안산·대전 주시',\n",
       " '日 마음의 상처 치유 심리사 국가자격제로 뽑는다',\n",
       " '과기부 황우석 전 교수 최고과학기술인상 16년 만에 취소',\n",
       " '중소 제조업체 4곳 충남에 700억원 투자…610명 신규고용',\n",
       " '도요타코리아 올 뉴 아발론 하이브리드 사전계약',\n",
       " '정진석 무소속 당선인 궁극적으로 받아주되 서두를 필요없어',\n",
       " '이스라엘 EU 지원받은 팔레스타인 조립식 초등교실 경매',\n",
       " '트럼프 또 런던시장에 악감정 표출 그는 재앙…새 시장 필요해',\n",
       " 'KTB증권 뉴트리바이오텍 화재 영향 길지 않을 것',\n",
       " '박현제 SW정책연구소장 AI정책연구소로 거듭나겠다',\n",
       " '김성태 자유민주주의 사수…김무성 살인마에 면죄부 안돼',\n",
       " '송도해상케이블카 1년…지역 살린 대박 vs 민간사업 특혜',\n",
       " '수능 작년보다 쉬워…1등급 컷 국어·수학가 92점·수학나 88점',\n",
       " '미투 보도 최다 등장인물은 안희정 전 지사',\n",
       " '시청 각도 마음대로…삼성전자 자유시점 영상 전송 성공',\n",
       " '국정원 올해도 채용 연계형 인턴 공채…실무형 인재 선발',\n",
       " '전남교육청 2천564억원 제2차 추경안 편성',\n",
       " '노딜 브렉시트 우려…英 응급처치용 의료장비 비축',\n",
       " '포즈취하는 국회의장과 3당 원내대표',\n",
       " '김정원의 음악신보…네 차례 브람스 조명',\n",
       " '비정규직이 실업급여를 받지 못한 이유는',\n",
       " '양대노총 특별연장근로 인가확대 취소소송 제기',\n",
       " '전문가들 6만가구 사전청약 공급 불안 심리 진정 효과',\n",
       " '얘기 나누는 조국 민정수석과 조현옥 인사수석',\n",
       " '최고의 순간에 치부 꺼낸 김재환 약물 문제 매일 후회했다',\n",
       " '유럽 최대 프랑스 릴 벼룩시장 축제 테러 우려에 취소',\n",
       " 'KIST 탄소나노소재로 우주복 섬유·방사선차폐재 개발중',\n",
       " '금호그룹 라임 통해 계열사 자금 아시아나 지원…위법 논란',\n",
       " '신협 중장년층 겨냥한 체크카드 출시…골프·주유소 캐시백',\n",
       " '꿀잼여행 호남권 젊음이 물씬 장흥에 흠뻑…지상 최대의 물싸움',\n",
       " '코로나19로 돌봄노동자 피해 커…생계·고용지원 대책 필요',\n",
       " '뇌진탕 겪은 구자철 도르트문트전서 복귀…52분 활약',\n",
       " '김정은 중국 다롄 방문…시진핑 주석 연회 개최',\n",
       " '라디오처럼 즐기는 클래식 콘서트…해설은 배우 이아현',\n",
       " '코오롱베니트 서버제조기업 케이티엔에프와 공공 총판계약',\n",
       " '전북기자협회 집중호우 피해복구 성금 전북도에 전달',\n",
       " '단독 남궁연 성추행 전혀 사실무근 명예훼손 고소',\n",
       " '게시판 서울 강남구 글로벌기업 취업 온라인 멘토링',\n",
       " '소설가 최옥정 암 투병하다 별세',\n",
       " '라인 음식 촬영 전용 카메라앱 푸디 출시',\n",
       " '조선 문인 이수광·민우수 문집 완역 출간',\n",
       " '강원교육청 무료 글꼴 4종 배포',\n",
       " '프랑스 국공립 병원에 대규모 공적자금 수혈',\n",
       " '양인모 파가니니 24개 카프리스 전곡 연주',\n",
       " '국세청 넷플릭스 한국법인 세무조사 착수',\n",
       " '겸재정선미술관 백납병풍 공개',\n",
       " '발리 공항서 이민국 직원 따귀 때린 英 여성 6개월 실형 신세',\n",
       " '주류 출고량 내리막길…수입량은 5년 만에 125% 급증',\n",
       " '우리은행 영국 애버딘 스탠다드 인베스트먼츠와 업무제휴',\n",
       " '사이테크 플러스 크리스퍼 유전자가위로 카사바 개량 성공',\n",
       " '신풍제약 자사주 2천억원어치 매각…장중 주가 24% 급락',\n",
       " '대전 시내버스 노사 임금 협상 타결',\n",
       " '미디어교육원 개관식',\n",
       " '묘비명 알리…故무하마드 알리 10만명 추모받으며 영면종합',\n",
       " '산업기사 필기시험 컴퓨터 기반으로 개편…이달부터 적용',\n",
       " '하나금투 대전 둔산WM센터 등 복합점포 7곳 신규개설',\n",
       " '서울대 연구팀 액체상에서 이온 분리 메커니즘 증명',\n",
       " '카메라뉴스 연꽃사이 카누 연지탐험',\n",
       " '통일 심포지엄 김건 북핵단장 충분하고 일관된 대북압박 필요',\n",
       " '갤S8 색감 조정하면 된다는 삼성…해외 반응이 관건',\n",
       " '불법파견 처벌하고 즉각 정규직화 하라',\n",
       " '강원 전교조 교사 복직 행사',\n",
       " '방글라데시 전 독재자 에르샤드 노환으로 별세',\n",
       " '색 차이 측정장비로 어류 산란시기 예측한다',\n",
       " '서울대·고려대 코로나19 상황 반영 입학전형 방식 변경종합',\n",
       " '민주노총 코로나19 확산속 내일 총파업 강행…방역지침 준수종합',\n",
       " '전남교육청 올해 첫 검정고시 5월 23일로 다시 연기',\n",
       " '교실에 비치된 손 소독제',\n",
       " '코로나19 한미 언론 온라인 합동 토론',\n",
       " '특징주 상장폐지 에임하이 정리매매 첫날 90% 폭락',\n",
       " '유니드 3분기 영업이익 236억원…작년 동기 대비 9%↑',\n",
       " '법무부대검 갈등 1주일 만에 봉합…파국은 막았다',\n",
       " '은수저 물고 태어나… 유럽서 英정치인 조롱 반면교사 삼기도종합',\n",
       " '그래픽 사업체 종사자 증감 폭 상위 업종',\n",
       " '국내 첫 항공사 신용카드 대한항공카드 출시종합',\n",
       " '혼돈의 레바논서 이번엔 아운 대통령 지지 집회',\n",
       " '4월6일 개학할수 있을까 원격수업 시연',\n",
       " '朴대통령 우간다서 첫 새마을운동 교육원 개원식 참석',\n",
       " 'KT스카이라이프 무비초이스 25개 채널로 확대',\n",
       " '코로나 확산으로 30∼50대 고용 회복 더 어려워져',\n",
       " 'LG에너지솔루션 공식 출범…2024년 매출 30조원 목표',\n",
       " '충북교육청 사자성어 승풍파랑…바람 타고 물결 헤쳐나간다',\n",
       " '국립 부산대 특혜임용 점입가경…심사위원에게 청탁 전화도']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hQojQCo9boGv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'IT과학', 'score': 0.865001916885376},\n",
       " {'label': '사회', 'score': 0.4700917601585388},\n",
       " {'label': '생활문화', 'score': 0.6098476648330688},\n",
       " {'label': '사회', 'score': 0.5673221945762634},\n",
       " {'label': '생활문화', 'score': 0.8178379535675049}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"wooseok0303/roberta-base-klue-ynat-classification\"\n",
    "\n",
    "model_pipeline = pipeline(\"text-classification\", model=model_id)\n",
    "\n",
    "model_pipeline(dataset['test']['title'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJoFN-mEysQF"
   },
   "source": [
    "## 예제 3.31. 커스텀 파이프라인 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3k6Q34dJjkC3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'IT과학', 'score': 0.8650020360946655},\n",
       " {'label': '사회', 'score': 0.4700918197631836},\n",
       " {'label': '생활문화', 'score': 0.6098476052284241},\n",
       " {'label': '사회', 'score': 0.5673221945762634},\n",
       " {'label': '생활문화', 'score': 0.8178381323814392}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "class CustomPipeline:\n",
    "    def __init__(self, model_id):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        tokenized = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokenized)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        probabilities = softmax(logits, dim=-1)\n",
    "        scores, labels = torch.max(probabilities, dim=-1)\n",
    "        labels_str = [self.model.config.id2label[label_idx] for label_idx in labels.tolist()]\n",
    "\n",
    "        return [{\"label\": label, \"score\": score.item()} for label, score in zip(labels_str, scores)]\n",
    "\n",
    "custom_pipeline = CustomPipeline(model_id)\n",
    "custom_pipeline(dataset['test']['title'][:5])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lang310",
   "language": "python",
   "name": "lang310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
