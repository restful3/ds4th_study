{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5008724f",
   "metadata": {},
   "source": [
    "# 벡터 집합\n",
    "\n",
    "- 벡터들의 모음을 집합(set) 이라고 한다\n",
    "- 벡터들의 집합은 ***S*** , ***V*** 와 같이 대문자 이탤릭체로 표시\n",
    "\n",
    "***V***$ = \\{v_1, \\dots , v_n\\}$\n",
    "\n",
    "- 빈 벡터 집합 : ***V***$ = \\{ \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb77a13",
   "metadata": {},
   "source": [
    "# 선형 가중 결합\n",
    "\n",
    "- 선형 가중 결합(linear weighted combination) : 여러 변수마다 가중치를 다르게 주어 정보를 혼합 하는 방법\n",
    "    - 선형 혼합(linear mixture), 가중 결합(weighted combination) 이라고도 함\n",
    "    - 가중 대신 계수 (coefficient) 라는 용어를 사용하기도\n",
    "    - 스칼라-벡터 곱셈을 한 다음 합하는 것 \n",
    "    - 벡터 집합에서 각 벡터에 스칼라 곱을 한 다음 이들을 더해 하나의 벡터를 만드는 것 \n",
    "    - 여기서 모든 벡터 $v_i$의 차원은 같다고 가정 \n",
    "    - 식 2-1 에서, 뼬셈은 $\\lambda_i$를 음수로 두는 것과 같음\n",
    "    - 벡터 부분공간과 행렬 공간을 생성하는 메커니즘, 선형 독립성의 핵심\n",
    "    - 선형 가중 결합과 내적은 선형대수 계산의 가장 중요한 구성 요소\n",
    "\n",
    "<img src='./images/e_02_01.png'>\n",
    "\n",
    "<img src='./images/e_02_02.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1aa1f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7,  -4, -13])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "l1, l2, l3 = 1, 2, -3\n",
    "v1 = np.array([4,5,1])\n",
    "v2 = np.array([-4, 0, -4])\n",
    "v3 = np.array([1, 3, 2])\n",
    "l1*v1 + l2*v2 + l3*v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c8990",
   "metadata": {},
   "source": [
    "- 선형 가중 결합의 응용\n",
    "    - 통계 모델로 부터 예측된 데이터에는 최소제곱 알고리즘을 통해 계산되는 회귀변수(regressor)독립변수와 계수(스칼라)의 선형 가중 결합으로 생성\n",
    "    - 주성분 분석과 같은 차원 축소 과정에서 각 성분(인자 또는 모드)은 성분의 분산을 최대화하는 가중치(계수)와 데이터 채널의 선형 가중 결합으로 도출 \n",
    "    - 인공 신경망에는 두 가지 연산, 즉 입력신호의 선형 가중 결합과 비선형 변환이 있다. 가중치는 비용함수를 최소화 하도록 학습, 비용 함수는 일반적으로 모델 예측과 실제 목표 변수 사이의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e8fac",
   "metadata": {},
   "source": [
    "# 선형 독립성\n",
    "\n",
    "- 선형 종속적(linearly dependent) : 벡터 집합에서 적어도 하나의 벡터를 집합의 다른 벡터들의 선형 가중 결합으로 나타낼 수 있을 때\n",
    "- 선형 독립적(linearly independent) : 벡터 집합에 있는 벡터들의 선형 가중 결합으로 집합의 아무런 벡터도 나타낼 수 없을 때\n",
    "- 다음 두 벡터 집합은 종속인가 독립 인가?\n",
    "\n",
    "<img src='./images/e_02_02_02.png'>\n",
    "\n",
    "- ***V***는 독립, ***S***는 종속 \n",
    "- $v_1 = \\lambda v_2$ 로 표현이 안됨\n",
    "- $s_1 = 0.5*s_2$ 혹은 $s_2 = 2*s_1$\n",
    "\n",
    "<p/>\n",
    "\n",
    "- ***T*** 집합은 선형인가 독립인가?\n",
    "<img src='./images/e_02_02_03.png'>\n",
    "\n",
    "- 종속임, (처음 3개의 열의 합이, 마지막 열의 두배와 동일)\n",
    "- 눈으로 바로 확인 어려움\n",
    "- 선형 독립을 알아 애는 방법\n",
    "    - 벡터 집합으로 행렬을 만들고\n",
    "    - 행렬의 계수를 계산한 다음\n",
    "    - 행의 수와 열의 수 중에 더 작은 값과 비교 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb85d5",
   "metadata": {},
   "source": [
    "## 수학에서 선형 독립성\n",
    "\n",
    "<img src='./images/e_02_03.png'>\n",
    "\n",
    "- 식 2-3의 의미\n",
    "    - 선형 종속적 이라면, 집합의 벡터들의 선형 가중 결합으로 영벡터를 만들 수 있다\n",
    "    - 식을 참으로 만드는 $\\lambda$를 찾을 수 있다면, 벡터 집합은 선형 종속\n",
    "    - 반대로 벡터를 선형적으로 결합해서 영벡터를 생성할 수 있는 방법이 없다면 벡터는 선형 독립\n",
    "\n",
    "<p/>\n",
    "\n",
    "- 선형 종속의 재정의\n",
    "\n",
    "<img src='./images/e_02_03_02.png'>\n",
    "\n",
    "- \n",
    "\n",
    "<img src='./images/e_02_03_03.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072df791",
   "metadata": {},
   "source": [
    "## 독립성과 영벡터\n",
    "\n",
    "<img src='./images/e_02_03_04.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef7c69",
   "metadata": {},
   "source": [
    "# 부분공간과 생성\n",
    "\n",
    "<img src='./images/e_02_03_05.png'>\n",
    "\n",
    "<img src='./images/fig_02_01.png'>\n",
    "\n",
    "<img src='./images/e_02_03_06.png'>\n",
    "\n",
    "<img src='./images/fig_02_02.png'>\n",
    "\n",
    "<img src='./images/e_02_03_07.png'>\n",
    "\n",
    "<img src='./images/fig_02_03.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed30928",
   "metadata": {},
   "source": [
    "# 기저\n",
    "\n",
    "<img src='./images/e_02_03_08.png'>\n",
    "\n",
    "<img src='./images/e_02_03_09.png'>\n",
    "\n",
    "<img src='./images/fig_02_04.png'>\n",
    "\n",
    "<img src='./images/fig_02_05.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a23fd",
   "metadata": {},
   "source": [
    "## 기저 정의\n",
    "\n",
    "<img src='./images/fig_02_06.png'>\n",
    "\n",
    "<img src='./images/e_02_03_10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf263ca",
   "metadata": {},
   "source": [
    "# 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879bbfe",
   "metadata": {},
   "source": [
    "# 연습 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510536a",
   "metadata": {},
   "source": [
    "## 연습 문제 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab9001",
   "metadata": {},
   "source": [
    "## 연습 문제 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd920b1",
   "metadata": {},
   "source": [
    "## 연습 문제 3\n",
    "\n",
    "<img src='./images/fig_02_07.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad2085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
